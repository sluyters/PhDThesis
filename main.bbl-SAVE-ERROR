% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{Ackad:2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=8c23326c53c2f18180a0aa0564bbf4a7}{%
           family={Ackad},
           familyi={A\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=3ae3687788b58305e2e3efe69f86ca58}{%
           family={Clayphan},
           familyi={C\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=2ddbec28b2e9674b25b164176b225a23}{%
           family={Tomitsch},
           familyi={T\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
        {{hash=10d118bb40da1dffa1d8a7942a5961e8}{%
           family={Kay},
           familyi={K\bibinitperiod},
           given={Judy},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6ed4b3c80c315d97ec8b172605c96c90}
      \strng{fullhash}{af637368017d7dbfadd34ce4c5bdf392}
      \strng{bibnamehash}{6ed4b3c80c315d97ec8b172605c96c90}
      \strng{authorbibnamehash}{6ed4b3c80c315d97ec8b172605c96c90}
      \strng{authornamehash}{6ed4b3c80c315d97ec8b172605c96c90}
      \strng{authorfullhash}{af637368017d7dbfadd34ce4c5bdf392}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes the design and evaluation of our Media Ribbon, a large public interactive display for browsing hierarchical information, with mid-air gestures. Browsing a hierarchical information space is a fundamental form of interaction. Designing learnable mid-air gestures is a current challenge for large display interaction. Our in-the-wild evaluation draws on 41 days of quantitative log data, with 4484 gestures detected, and qualitative data from 15 interviews, and associated video. We explored: whether our design enabled people to learn the gestures; how our tutorial and feedback mechanisms supported learning; and the effectiveness of support for browsing hierarchical information. Our contributions are: (1) design of large public display for browsing of hierarchical information; (2) with its gesture set; (3) insights into the ways people learn and use this interface in our context; and (4) guidelines for designing learnable mid-air gestures.}
      \field{booktitle}{Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing}
      \field{isbn}{9781450335744}
      \field{series}{UbiComp '15}
      \field{title}{{An In-the-Wild Study of Learning Mid-Air Gestures to Browse Hierarchical Information at a Large Interactive Public Display}}
      \field{venue}{Osaka, Japan}
      \field{year}{2015}
      \field{pages}{1227\bibrangedash 1238}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/2750858.2807532
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2750858.2807532
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2750858.2807532
      \endverb
      \keyw{interactive public information displays,gestural interaction,user centred design and pervasive computing}
    \endentry
    \entry{Agresti:2019}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=c5d33869de29c43ec9c8bf1a74327062}{%
           family={Agresti},
           familyi={A\bibinitperiod},
           given={Gianluca},
           giveni={G\bibinitperiod}}}%
        {{hash=58e8839b8d117250af8b6fba5b640307}{%
           family={Milani},
           familyi={M\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{9bbf4b468ac0074246458f3f71049b41}
      \strng{fullhash}{9bbf4b468ac0074246458f3f71049b41}
      \strng{bibnamehash}{9bbf4b468ac0074246458f3f71049b41}
      \strng{authorbibnamehash}{9bbf4b468ac0074246458f3f71049b41}
      \strng{authornamehash}{9bbf4b468ac0074246458f3f71049b41}
      \strng{authorfullhash}{9bbf4b468ac0074246458f3f71049b41}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing}
      \field{series}{ICASSP 2019}
      \field{title}{{Material Identification Using RF Sensors and Convolutional Neural Networks}}
      \field{venue}{Brighton, UK}
      \field{year}{2019}
      \field{pages}{3662\bibrangedash 3666}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2019.8682296
      \endverb
    \endentry
    \entry{Ahmad:2021}{incollection}{}
      \name{author}{5}{}{%
        {{hash=c81e52be3f3980f6308f7b3bff46235b}{%
           family={Ahmad},
           familyi={A\bibinitperiod},
           given={Misbah},
           giveni={M\bibinitperiod}}}%
        {{hash=6735667c7b88e00f3cb8fd4b49c1901b}{%
           family={Ghawale},
           familyi={G\bibinitperiod},
           given={Milind},
           giveni={M\bibinitperiod}}}%
        {{hash=2272d7a415561998ee8061de1efd94a2}{%
           family={Dubey},
           familyi={D\bibinitperiod},
           given={Sakshi},
           giveni={S\bibinitperiod}}}%
        {{hash=3cd346d360fbc10c57d97fb81aa9e5ec}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Ayushi},
           giveni={A\bibinitperiod}}}%
        {{hash=ef93cd3e92e45e2425a58601ffc2a28b}{%
           family={Sonar},
           familyi={S\bibinitperiod},
           given={Poonam},
           giveni={P\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=cd295e31e2306be8e6ca909c1ea0fbfc}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Joy\bibnamedelima Iong-Zong},
           giveni={J\bibinitperiod\bibinitdelim I\bibinithyphendelim Z\bibinitperiod}}}%
        {{hash=bda653383f0be03ea9a7518cb47e1066}{%
           family={Tavares},
           familyi={T\bibinitperiod},
           given={João\bibnamedelimb Manuel\bibnamedelimb R.\bibnamedelimi S.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod\bibinitdelim R\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=597b6cfc05b9254a1bb4f638d1c106c5}{%
           family={Shakya},
           familyi={S\bibinitperiod},
           given={Subarna},
           giveni={S\bibinitperiod}}}%
        {{hash=c1345939715ee2d39d56804123842931}{%
           family={Iliyasu},
           familyi={I\bibinitperiod},
           given={Abdullah\bibnamedelima M.},
           giveni={A\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{4f273e8765a45a82ed1cc7bceb81fb1b}
      \strng{fullhash}{d4484d82ab42be2f77cb808ffab502d2}
      \strng{bibnamehash}{4f273e8765a45a82ed1cc7bceb81fb1b}
      \strng{authorbibnamehash}{4f273e8765a45a82ed1cc7bceb81fb1b}
      \strng{authornamehash}{4f273e8765a45a82ed1cc7bceb81fb1b}
      \strng{authorfullhash}{d4484d82ab42be2f77cb808ffab502d2}
      \strng{editorbibnamehash}{e95eff670b5bf501db6df50a87f49e36}
      \strng{editornamehash}{e95eff670b5bf501db6df50a87f49e36}
      \strng{editorfullhash}{94d80aab02a8fb8604ec912dab563e97}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{booktitle}{Image {Processing} and {Capsule} {Networks}}
      \field{isbn}{978-3-030-51858-5 978-3-030-51859-2}
      \field{note}{Series Title: Advances in Intelligent Systems and Computing}
      \field{shorttitle}{{GigaHertz}}
      \field{title}{{GigaHertz}: {Gesture} {Sensing} {Using} {Microwave} {Radar} and {IR} {Sensor} with {Machine} {Learning} {Algorithms}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{1200}
      \field{year}{2021}
      \field{urldateera}{ce}
      \field{pages}{422\bibrangedash 434}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1007/978-3-030-51859-2_39
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-030-51859-2_39
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-030-51859-2_39
      \endverb
    \endentry
    \entry{Ahmed:2020}{article}{}
      \name{author}{2}{}{%
        {{hash=d23c7b8929dd4fcbf27c6636ce96b5e9}{%
           family={Ahmed},
           familyi={A\bibinitperiod},
           given={Shahzad},
           giveni={S\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{abe39850c7548f223ee95de665faadf9}
      \strng{fullhash}{abe39850c7548f223ee95de665faadf9}
      \strng{bibnamehash}{abe39850c7548f223ee95de665faadf9}
      \strng{authorbibnamehash}{abe39850c7548f223ee95de665faadf9}
      \strng{authornamehash}{abe39850c7548f223ee95de665faadf9}
      \strng{authorfullhash}{abe39850c7548f223ee95de665faadf9}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The emerging integration of technology in daily lives has increased the need for more convenient methods for human-computer interaction (HCI). Given that the existing HCI approaches exhibit various limitations, hand gesture recognition-based HCI may serve as a more natural mode of man-machine interaction in many situations. Inspired by an inception module-based deep-learning network (GoogLeNet), this paper presents a novel hand gesture recognition technique for impulse-radio ultra-wideband (IR-UWB) radars which demonstrates a higher gesture recognition accuracy. First, methodology to demonstrate radar signals as three-dimensional image patterns is presented and then, the inception module-based variant of GoogLeNet is used to analyze the pattern within the images for the recognition of different hand gestures. The proposed framework is exploited for eight different hand gestures with a promising classification accuracy of 95\%. To verify the robustness of the proposed algorithm, multiple human subjects were involved in data acquisition.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{2}
      \field{title}{Hand {Gesture} {Recognition} {Using} an {IR}-{UWB} {Radar} with an {Inception} {Module}-{Based} {Classifier}}
      \field{volume}{20}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{doi}
      \verb 10.3390/s20020564
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/20/2/564
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/20/2/564
      \endverb
    \endentry
    \entry{Ahmed:2019}{article}{}
      \name{author}{5}{}{%
        {{hash=d23c7b8929dd4fcbf27c6636ce96b5e9}{%
           family={Ahmed},
           familyi={A\bibinitperiod},
           given={Shahzad},
           giveni={S\bibinitperiod}}}%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=c3a10724898c231b33e9bab3fc42f2bc}{%
           family={Ghaffar},
           familyi={G\bibinitperiod},
           given={Asim},
           giveni={A\bibinitperiod}}}%
        {{hash=e8a448fc4c94dade1de3adb8b7fa3a3d}{%
           family={Hussain},
           familyi={H\bibinitperiod},
           given={Farhan},
           giveni={F\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{61aee23c309ac127eb31327d1bca8c50}
      \strng{fullhash}{cda05b1f53f715577feb9fcace94d9e0}
      \strng{bibnamehash}{61aee23c309ac127eb31327d1bca8c50}
      \strng{authorbibnamehash}{61aee23c309ac127eb31327d1bca8c50}
      \strng{authornamehash}{61aee23c309ac127eb31327d1bca8c50}
      \strng{authorfullhash}{cda05b1f53f715577feb9fcace94d9e0}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The diversion of a driver's attention from driving can be catastrophic. Given that conventional button- and touch-based interfaces may distract the driver, developing novel distraction-free interfaces for the various devices present in cars has becomes necessary. Hand gesture recognition may provide an alternative interface inside cars. Given that cars are the targeted application area, we determined the optimal location for the radar sensor, so that the signal reflected from the driver's hand during gesturing is unaffected by interference from the motion of the driver's body or other motions within the car. We implemented a Convolutional Neural Network-based technique to recognize the finger-counting-based hand gestures using an Impulse Radio (IR) radar sensor. The accuracy of the proposed method was sufficiently high for real-world applications.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{6}
      \field{title}{Finger-{Counting}-{Based} {Gesture} {Recognition} within {Cars} {Using} {Impulse} {Radar} with {Convolutional} {Neural} {Network}}
      \field{volume}{19}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 14}
      \range{pages}{14}
      \verb{doi}
      \verb 10.3390/s19061429
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/19/6/1429
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/19/6/1429
      \endverb
    \endentry
    \entry{Aich:2023}{inproceedings}{}
      \name{author}{12}{}{%
        {{hash=a7b489055936169e1e4dbc5d65f2bee9}{%
           family={Aich},
           familyi={A\bibinitperiod},
           given={Shubhra},
           giveni={S\bibinitperiod}}}%
        {{hash=d81515d12e025792800327f4fc47f7ea}{%
           family={Ruiz-Santaquiteria},
           familyi={R\bibinithyphendelim S\bibinitperiod},
           given={Jesus},
           giveni={J\bibinitperiod}}}%
        {{hash=20e40bc259c139ec3d881d1ee8445fd5}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Zhenyu},
           giveni={Z\bibinitperiod}}}%
        {{hash=e8f35750463fb510b82c7b243abf02dd}{%
           family={Garg},
           familyi={G\bibinitperiod},
           given={Prachi},
           giveni={P\bibinitperiod}}}%
        {{hash=66841b8de1f44387d8a09b0f9322803f}{%
           family={Joseph},
           familyi={J\bibinitperiod},
           given={K.\bibnamedelimi J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=b9de449efa149ede6f0e095a03a901a4}{%
           family={Garcia},
           familyi={G\bibinitperiod},
           given={Alvaro\bibnamedelima Fernandez},
           giveni={A\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=1a6d0bd847a9168d28d9e43f792ba079}{%
           family={Balasubramanian},
           familyi={B\bibinitperiod},
           given={Vineeth\bibnamedelima N.},
           giveni={V\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=ec318221792b13029caf9dabd4462686}{%
           family={Kin},
           familyi={K\bibinitperiod},
           given={Kenrick},
           giveni={K\bibinitperiod}}}%
        {{hash=b3e326a238efa7269302402456b97829}{%
           family={Wan},
           familyi={W\bibinitperiod},
           given={Chengde},
           giveni={C\bibinitperiod}}}%
        {{hash=e26d1e4dcbbd4df610a983d39d53f65a}{%
           family={Camgoz},
           familyi={C\bibinitperiod},
           given={Necati\bibnamedelima Cihan},
           giveni={N\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=83199b49a3aeae98d8e9f561110b470f}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Shugao},
           giveni={S\bibinitperiod}}}%
        {{hash=bbc767f3ae3d0bb767e79f8120573a4f}{%
           family={De\bibnamedelima La\bibnamedelima Torre},
           familyi={D\bibinitperiod\bibinitdelim L\bibinitperiod\bibinitdelim T\bibinitperiod},
           given={Fernando},
           giveni={F\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Los Alamitos, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE Computer Society}%
      }
      \strng{namehash}{ccd16179563c35493b1515323c22522f}
      \strng{fullhash}{f6f163cd4d4c269274f0e5364bdd4cac}
      \strng{bibnamehash}{ccd16179563c35493b1515323c22522f}
      \strng{authorbibnamehash}{ccd16179563c35493b1515323c22522f}
      \strng{authornamehash}{ccd16179563c35493b1515323c22522f}
      \strng{authorfullhash}{f6f163cd4d4c269274f0e5364bdd4cac}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper investigates data-free class-incremental learning (DFCIL) for hand gesture recognition from 3D skeleton sequences. In this class-incremental learning (CIL) setting, while incrementally registering the new classes, we do not have access to the training samples (i.e. data-free) of the already known classes due to privacy. Existing DFCIL methods primarily focus on various forms of knowledge distillation for model inversion to mitigate catastrophic forgetting. Unlike SOTA methods, we delve deeper into the choice of the best samples for inversion. Inspired by the well-grounded theory of max-margin classification, we find that the best samples tend to lie close to the approximate decision boundary within a reasonable margin. To this end, we propose BOAT-MI – a simple and effective boundary-aware prototypical sampling mechanism for model inversion for DFCIL. Our sampling scheme outperforms SOTA methods significantly on two 3D skeleton gesture datasets, the publicly available SHREC 2017, and EgoGesture3D – which we extract from a publicly available RGBD dataset. Both our codebase and the EgoGesture3D skeleton dataset are publicly available: https://github.com/humansensinglab/dfcil-hgr.}
      \field{booktitle}{2023 IEEE/CVF International Conference on Computer Vision (ICCV)}
      \field{month}{10}
      \field{title}{{Data-Free Class-Incremental Hand Gesture Recognition}}
      \field{year}{2023}
      \field{pages}{20901\bibrangedash 20910}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICCV51070.2023.01916
      \endverb
      \verb{urlraw}
      \verb https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01916
      \endverb
      \verb{url}
      \verb https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01916
      \endverb
      \keyw{training;data privacy;computer vision;three-dimensional displays;gesture recognition;skeleton}
    \endentry
    \entry{Aigner:2012}{report}{}
      \name{author}{8}{}{%
        {{hash=793b5f459c105e4860c48d1da1f4e860}{%
           family={Aigner},
           familyi={A\bibinitperiod},
           given={Roland},
           giveni={R\bibinitperiod}}}%
        {{hash=a1d167c2e159bbe494e59e21a3fb2dbb}{%
           family={Wigdor},
           familyi={W\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=2c511d23516d76038744bfd9895fd71d}{%
           family={Benko},
           familyi={B\bibinitperiod},
           given={Hrvoje},
           giveni={H\bibinitperiod}}}%
        {{hash=c8862e8d9c35c57433ef39acd5444865}{%
           family={Haller},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=93589e5f5a77d13a33c493784678898b}{%
           family={Lindbauer},
           familyi={L\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=dc52614caf13c1d690a373cad652344e}{%
           family={Ion},
           familyi={I\bibinitperiod},
           given={Alexandra},
           giveni={A\bibinitperiod}}}%
        {{hash=291c5780e88fb08a06bdb33184bea8c5}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Shengdong},
           giveni={S\bibinitperiod}}}%
        {{hash=51b300e8666c5fc5889e81ef2b20d227}{%
           family={Koh},
           familyi={K\bibinitperiod},
           given={Jeffrey\bibnamedelimb Tzu\bibnamedelimb Kwan\bibnamedelima Valino},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod\bibinitdelim K\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Microsoft Research}%
      }
      \strng{namehash}{b0c9ba1a11f54134a7e9e5b9f5e6e6eb}
      \strng{fullhash}{f632267caee011667693cd29231538b4}
      \strng{bibnamehash}{b0c9ba1a11f54134a7e9e5b9f5e6e6eb}
      \strng{authorbibnamehash}{b0c9ba1a11f54134a7e9e5b9f5e6e6eb}
      \strng{authornamehash}{b0c9ba1a11f54134a7e9e5b9f5e6e6eb}
      \strng{authorfullhash}{f632267caee011667693cd29231538b4}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we present the results of a study of human preferences in using mid-air gestures for directing other humans. Rather than contributing a specific set of gestures, we contribute a set of gesture types, which together make a set of the core actions needed to complete any of our six chosen tasks in the domain of human-to-human gestural communication without the speech channel. We observed 12 participants, cooperating to accomplish different tasks only using hand gestures to communicate. We analyzed 5,500 gestures in terms of hand usage and gesture type, using a novel classification scheme which combines three existing taxonomies in order to better capture this interaction space. Our findings indicate that, depending on the meaning of the gesture, there is preference in the usage of gesture types, such as pointing, pantomimic acting, direct manipulation, semaphoric, or iconic gestures. These results can be used as guidelines to design purely gesture driven interfaces for interactive environments and surfaces.}
      \field{month}{11}
      \field{number}{MSR-TR-2012-111}
      \field{title}{{Understanding Mid-Air Hand Gestures: A Study of Human Preferences in Usage of Gesture Types for HCI}}
      \field{type}{techreport}
      \field{year}{2012}
      \verb{urlraw}
      \verb https://www.microsoft.com/en-us/research/publication/understanding-mid-air-hand-gestures-a-study-of-human-preferences-in-usage-of-gesture-types-for-hci/
      \endverb
      \verb{url}
      \verb https://www.microsoft.com/en-us/research/publication/understanding-mid-air-hand-gestures-a-study-of-human-preferences-in-usage-of-gesture-types-for-hci/
      \endverb
    \endentry
    \entry{Alt:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=f8c53b5f30050d520620f02d2c1fa245}{%
           family={Alt},
           familyi={A\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod}}}%
        {{hash=7a26f3c7c16774be144f29e42146649b}{%
           family={Geiger},
           familyi={G\bibinitperiod},
           given={Sabrina},
           giveni={S\bibinitperiod}}}%
        {{hash=743ec89d3404877ce1c4ffd6775e2135}{%
           family={Höhl},
           familyi={H\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Munich, Germany}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4b426be50419ede6f80ac2956719fed6}
      \strng{fullhash}{4b426be50419ede6f80ac2956719fed6}
      \strng{bibnamehash}{4b426be50419ede6f80ac2956719fed6}
      \strng{authorbibnamehash}{4b426be50419ede6f80ac2956719fed6}
      \strng{authornamehash}{4b426be50419ede6f80ac2956719fed6}
      \strng{authorfullhash}{4b426be50419ede6f80ac2956719fed6}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present ShapelineGuide, a dynamic visual guide that supports users of large interactive displays while performing mid-air gestures. Today, we find many examples of large displays supporting interaction through gestures performed in Mid-air. Yet, approaches that support users in learning and executing these gestures are still scarce. Prior approaches require complex setups, are targeted towards the use of 2D gestures, or focus on the initial gestures only. Our work extends state-of-the-art by presenting a feedforward system that provides users constant updates on their gestures. We report on the design and implementation of the approach and present findings from an evaluation of the system in a lab study (N=44), focusing on learning performance, accuracy, and errors. We found that ShapelineGuide helps users with regard to learning the gestures as well as decreases execution times and cognitive load.}
      \field{booktitle}{Proceedings of the 7th ACM International Symposium on Pervasive Displays}
      \field{isbn}{9781450357654}
      \field{series}{PerDis '18}
      \field{title}{{ShapelineGuide: Teaching Mid-Air Gestures for Large Interactive Displays}}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3205873.3205887
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3205873.3205887
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3205873.3205887
      \endverb
      \keyw{Displays,Dynamic Guides,Feedback,Feedforward,Gestures}
    \endentry
    \entry{Amin:2020}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=77203d8e52a8a50d541ea84825719adb}{%
           family={Amin},
           familyi={A\bibinitperiod},
           given={Moeness\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=71ad6b78804801deaf79df5615e86582}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Zhengxin},
           giveni={Z\bibinitperiod}}}%
        {{hash=1432e4d153e4cdd63cfbf5c18fd848c1}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{fullhash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{bibnamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authorbibnamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authornamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authorfullhash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \field{extraname}{1}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Hand and arm gesture recognition using the radio frequency (RF) sensing modality proves valuable in man-machine interface and smart environment. In this paper, we use curve matching techniques for measuring the similarities and differences of the maximum instantaneous Doppler frequencies corresponding to different arm gestures. In particular, we apply both Fréchet and dynamic time warping (DTW) distances that, unlike the Euclidean (L2) and Manhattan (L1) distances, take into account both the location and the order of the points for rendering two curves similar or dissimilar. It is shown that improved arm gesture classification can be achieved by using the DTW method, in lieu of L2 and L1 distances, under the nearest neighbor (NN) classifier.}
      \field{booktitle}{Proceedings of the {IEEE} {International} {Radar} {Conference}}
      \field{month}{4}
      \field{note}{ISSN: 2640-7736}
      \field{series}{RADAR '20}
      \field{title}{Arm {Motion} {Classification} {Using} {Curve} {Matching} of {Maximum} {Instantaneous} {Doppler} {Frequency} {Signatures}}
      \field{year}{2020}
      \field{pages}{303\bibrangedash 308}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/RADAR42522.2020.9114779
      \endverb
      \keyw{arm gesture classification,arm motion classification,Arm motion recognition,curve matching,curve matching techniques,digital signatures,DTW distance,dynamic time warping,Euclidean distances,Frechet time warping,gesture recognition,hand gesture recognition,image classification,image matching,image motion analysis,instantaneous Doppler frequency,instantaneous Doppler frequency signatures,man-machine interface,Manhattan distances,micro-Doppler signature,nearest neighbor classifier,radio frequency sensing modality,smart environment}
    \endentry
    \entry{Amin:2019b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=77203d8e52a8a50d541ea84825719adb}{%
           family={Amin},
           familyi={A\bibinitperiod},
           given={Moeness\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=71ad6b78804801deaf79df5615e86582}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Zhengxin},
           giveni={Z\bibinitperiod}}}%
        {{hash=1432e4d153e4cdd63cfbf5c18fd848c1}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{fullhash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{bibnamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authorbibnamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authornamehash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \strng{authorfullhash}{0b02682e7dbba8b0c04a8bf5db57286d}
      \field{extraname}{2}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce a simple but effective technique in automatic hand gesture recognition using radar. The proposed technique classifies hand gestures based on the envelopes of their micro-Doppler (MD) signatures. These envelopes capture the distinctions among different hand movements and their corresponding positive and negative Doppler frequencies that are generated during each gesture act. We detect the positive and negative frequency envelopes of MD separately, and form a feature vector of their augmentation. We use the k-nearest neighbor (kNN) classifier and Manhattan distance (L1) measure, in lieu of Euclidean distance (L2), so as not to diminish small but critical envelope values. It is shown that this method outperforms both low-dimension representation techniques based on principal component analysis (PCA) and sparse reconstruction using Gaussian-windowed Fourier dictionary, and can achieve very high classification rates.}
      \field{booktitle}{Proceedings of the {IEEE} Int. {Radar} {Conference}}
      \field{month}{4}
      \field{note}{ISSN: 2375-5318}
      \field{series}{RADAR '19}
      \field{title}{Hand {Gesture} {Recognition} based on {Radar} {Micro}-{Doppler} {Signature} {Envelopes}}
      \field{venue}{Boston, MA, USA}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/RADAR.2019.8835661
      \endverb
      \keyw{automatic hand gesture recognition,Correlation,Doppler effect,Doppler radar,Euclidean distance,Feature extraction,feature vector,Fourier transforms,Gaussian processes,Gaussian-windowed Fourier dictionary,gesture recognition,Gesture recognition,Hand gesture recognition,hand movements,image classification,image reconstruction,image representation,k-nearest neighbor classifier,kNN classifier,low-dimension representation techniques,Manhattan distance,micro-Doppler,microDoppler signatures,nearest neighbour methods,negative Doppler frequencies,negative frequency envelopes,PCA,positive Doppler frequencies,positive frequency envelopes,principal component analysis,Radar,radar microDoppler signature envelopes,sparse reconstruction,Spectrogram,Time-frequency analysis,time-frequency representations}
    \endentry
    \entry{Amin:2019a}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=77203d8e52a8a50d541ea84825719adb}{%
           family={Amin},
           familyi={A\bibinitperiod},
           given={Moeness\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=71ad6b78804801deaf79df5615e86582}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Zhengxin},
           giveni={Z\bibinitperiod}}}%
        {{hash=1432e4d153e4cdd63cfbf5c18fd848c1}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
        {{hash=7712fcd71618e1fe86313cb7e38b2184}{%
           family={Guendel},
           familyi={G\bibinitperiod},
           given={R.G.},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{178a857c39657eadb8e89c270f10b7ad}
      \strng{fullhash}{7ef4daffe0c8a82a6b753ab3634adcaf}
      \strng{bibnamehash}{178a857c39657eadb8e89c270f10b7ad}
      \strng{authorbibnamehash}{178a857c39657eadb8e89c270f10b7ad}
      \strng{authornamehash}{178a857c39657eadb8e89c270f10b7ad}
      \strng{authorfullhash}{7ef4daffe0c8a82a6b753ab3634adcaf}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In considering man-machine interface for smart home technology, we introduce a simple but effective technique in automatic arm motion recognition using radar. The proposed technique classifies arm motions based on the envelopes of their micro-Doppler (MD) signatures. These envelopes capture the distinctions among different arm movements and their corresponding positive and negative Doppler frequencies that are generated during each arm motion. We detect the positive and negative frequency envelopes of MD separately, and form a feature vector of their augmentation. We use the k-nearest neighbor (k NN) classifier and Manhattan distance (L1) measure, in lieu of Euclidean distance (L2), so as not to diminish small but critical envelope values. It is shown that this method can achieve higher than 99\% classification rates when choosing specific arm motion articulations from a sitting down position.}
      \field{booktitle}{Proceedings of the IEEE {International} {Radar} {Conference}}
      \field{month}{9}
      \field{note}{ISSN: 2640-7736}
      \field{series}{RADAR '19}
      \field{title}{Automatic {Arm} {Motion} {Recognition} {Using} {Radar} for {Smart} {Home} {Technologies}}
      \field{venue}{Boston, MA, USA}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/RADAR41533.2019.171318
      \endverb
      \keyw{arm motion articulations,arm motion recognition,arm movements,automatic arm motion recognition,critical envelope values,Doppler effect,Doppler radar,Euclidean distance,feature extraction,Feature extraction,gesture recognition,home automation,image classification,image motion analysis,k-nearest neighbor classifier,kNN classifier,L1 measure,man-machine interface,Manhattan distance,micro-Doppler,microDoppler signatures,negative Doppler frequencies,negative frequency envelopes,positive Doppler frequencies,positive frequency envelopes,Radar applications,radar imaging,smart home technology,smart homes,Spectrogram,Time-frequency analysis,time-frequency representations}
    \endentry
    \entry{Annett:2014}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=c5d6c57de009e610eb96005b8b2aa4ab}{%
           family={Annett},
           familyi={A\bibinitperiod},
           given={Michelle},
           giveni={M\bibinitperiod}}}%
        {{hash=bb5580de00e552bee2a79b0b2dd9f710}{%
           family={Ng},
           familyi={N\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
        {{hash=70c3f4e92bb7e75bbaffb6c4c032225a}{%
           family={Dietz},
           familyi={D\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=2888b90167fd317eb1043ce7ecb6e110}{%
           family={Bischof},
           familyi={B\bibinitperiod},
           given={Walter\bibnamedelima F.},
           giveni={W\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=05b2c8261675d94fa92064f8561eb8d2}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Anoop},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {CAN}%
      }
      \list{publisher}{1}{%
        {Canadian Information Processing Society}%
      }
      \strng{namehash}{968ce2d67d3c05ebc9a683adf7884fce}
      \strng{fullhash}{b41b3d4503a3db4e3a2d6b8abbb97725}
      \strng{bibnamehash}{968ce2d67d3c05ebc9a683adf7884fce}
      \strng{authorbibnamehash}{968ce2d67d3c05ebc9a683adf7884fce}
      \strng{authornamehash}{968ce2d67d3c05ebc9a683adf7884fce}
      \strng{authorfullhash}{b41b3d4503a3db4e3a2d6b8abbb97725}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent advances in hardware have enabled researchers to study the perception of latency. Thus far, latency research has utilized simple touch and stylus-based tasks that do not represent inking activities found in the real world. In this work, we report on two studies that utilized writing and sketching tasks to understand the limits of human perception. Our studies revealed that latency perception while inking is worse (~50 milliseconds) than perception while performing non-inking tasks reported previously (~2-7 milliseconds). We also determined that latency perception is not based on the distance from the stylus' nib to the ink, but rather on the presence of a visual referent such as the hand or stylus. The prior and current work has informed the Latency Perception Model, a framework upon which latency knowledge and the underlying mechanisms of perception can be understood and further explored.}
      \field{booktitle}{Proceedings of Graphics Interface 2014}
      \field{isbn}{9781482260038}
      \field{series}{GI '14}
      \field{title}{{How Low Should We Go? Understanding the Perception of Latency While Inking}}
      \field{venue}{Montreal, Quebec, Canada}
      \field{year}{2014}
      \field{pages}{167\bibrangedash 174}
      \range{pages}{8}
      \keyw{latency perception model,psychophysics,pen,stylus,latency,just-noticeable difference,direct interaction,responsiveness,perception,indirect interaction,delay}
    \endentry
    \entry{Anthony:2013}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=c409c5ecb8bcc6ef5af1868d1698aa26}{%
           family={Anthony},
           familyi={A\bibinitperiod},
           given={Lisa},
           giveni={L\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {CAN}%
      }
      \list{publisher}{1}{%
        {Canadian Information Processing Society}%
      }
      \strng{namehash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \strng{fullhash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \strng{bibnamehash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \strng{authorbibnamehash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \strng{authornamehash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \strng{authorfullhash}{cae9995acb9c9451d8da07bcf41dcc3b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Little work has been done on understanding the articulation patterns of users' touch and surface gestures, despite the importance of such knowledge to inform the design of gesture recognizers and gesture sets for different applications. We report a methodology to analyze user consistency in gesture production, both between-users and within-user, by employing articulation features such as stroke type, stroke direction, and stroke ordering, and by measuring variations in execution with geometric and kinematic gesture descriptors. We report results on four gesture datasets (40,305 samples of 63 gesture types by 113 users). We find a high degree of consistency within-users (.91), lower consistency between-users (.55), higher consistency for certain gestures (e.g., less geometrically complex shapes are more consistent than complex ones), and a loglinear relationship between number of strokes and consistency. We highlight implications of our results to help designers create better surface gesture interfaces informed by user behavior.}
      \field{booktitle}{Proceedings of Graphics Interface 2013}
      \field{isbn}{9781482216806}
      \field{series}{GI '13}
      \field{title}{{Understanding the Consistency of Users' Pen and Finger Stroke Gesture Articulation}}
      \field{venue}{Regina, Sascatchewan, Canada}
      \field{year}{2013}
      \field{pages}{87\bibrangedash 94}
      \range{pages}{8}
    \endentry
    \entry{Anthony:2012}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=c409c5ecb8bcc6ef5af1868d1698aa26}{%
           family={Anthony},
           familyi={A\bibinitperiod},
           given={Lisa},
           giveni={L\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Toronto, Ont., Canada}%
      }
      \list{publisher}{1}{%
        {Canadian Information Processing Society}%
      }
      \strng{namehash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \strng{fullhash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \strng{bibnamehash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \strng{authorbibnamehash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \strng{authornamehash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \strng{authorfullhash}{ee9b784c5c8c561206b1eed0b5b73caf}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of Graphics Interface 2012}
      \field{isbn}{978-1-4503-1420-6}
      \field{series}{GI '12}
      \field{title}{{\$N-ProTractor: A Fast and Accurate Multistroke Recognizer}}
      \field{venue}{Toronto, Ontario, Canada}
      \field{year}{2012}
      \field{pages}{117\bibrangedash 120}
      \range{pages}{4}
      \verb{urlraw}
      \verb http://dl.acm.org/citation.cfm?id=2305276.2305296
      \endverb
      \verb{url}
      \verb http://dl.acm.org/citation.cfm?id=2305276.2305296
      \endverb
      \keyw{\$N,evaluation,multistroke gesture recognition,protractor,stroke recognition,template matching}
    \endentry
    \entry{Archer:1997}{article}{}
      \name{author}{1}{}{%
        {{hash=ebb80489212b644261cec21b0082af31}{%
           family={Archer},
           familyi={A\bibinitperiod},
           given={Dane},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{ebb80489212b644261cec21b0082af31}
      \strng{fullhash}{ebb80489212b644261cec21b0082af31}
      \strng{bibnamehash}{ebb80489212b644261cec21b0082af31}
      \strng{authorbibnamehash}{ebb80489212b644261cec21b0082af31}
      \strng{authornamehash}{ebb80489212b644261cec21b0082af31}
      \strng{authorfullhash}{ebb80489212b644261cec21b0082af31}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Qualitative Sociology}
      \field{title}{{Unspoken Diversity: Cultural Differences in Gestures}}
      \field{volume}{20}
      \field{year}{1997}
      \field{pages}{79\bibrangedash 105}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1023/A:1024716331692
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:142578394
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:142578394
      \endverb
    \endentry
    \entry{Arsalan:2019}{article}{}
      \name{author}{2}{}{%
        {{hash=ca418e29948bc143cff4839c39c4659c}{%
           family={Arsalan},
           familyi={A\bibinitperiod},
           given={Muhammad},
           giveni={M\bibinitperiod}}}%
        {{hash=f82219bcf97702d81f4dc65d14059788}{%
           family={Santra},
           familyi={S\bibinitperiod},
           given={Avik},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{96a1e4a256e80537dd8ff80d64fb882e}
      \strng{fullhash}{96a1e4a256e80537dd8ff80d64fb882e}
      \strng{bibnamehash}{96a1e4a256e80537dd8ff80d64fb882e}
      \strng{authorbibnamehash}{96a1e4a256e80537dd8ff80d64fb882e}
      \strng{authornamehash}{96a1e4a256e80537dd8ff80d64fb882e}
      \strng{authorfullhash}{96a1e4a256e80537dd8ff80d64fb882e}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar technology plays a vital role in contact-less detection of hand gestures or motions, which forms an alternate and intuitive form of human-computer interface. Air-writing refers to the writing of linguistic characters or words in free space by hand gesture movements. In this paper, we propose an air-writing system based on a network of millimeter wave radars. We propose a two-stage approach for extraction and recognition of handwriting gestures. The extraction processing stage uses a fine range estimate combined with the trilateration technique to detect and localize the hand marker, followed by a smoothening filter to create a trajectory of the character through the hand movement. For the recognition stage, we explore two approaches: one extracts the time-series trajectory data and recognizes the drawn character using long short term memory (LSTM), bi-directional LSTM (BLSTM), and convolutional LSTM (ConvLSTM) with connectionist temporal classification (CTC) loss function, and the other approach reconstructs a 2D image from the trajectory of drawn character and uses deep convolutional neural network (DCNN) to classify the alphabets drawn by the user. ConvLSTM-CTC performs best among LSTM variants on time-series trajectory data achieving 98.33\% classification accuracy similar to DCNN over the chosen character set. This paper employs real data using a network of three 60-GHz millimeter wave radar sensor to demonstrate the success of the proposed setup and associated algorithm with design consideration.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{10}
      \field{number}{19}
      \field{title}{Character {Recognition} in {Air}-{Writing} {Based} on {Network} of {Radars} for {Human}-{Machine} {Interface}}
      \field{volume}{19}
      \field{year}{2019}
      \field{pages}{8855\bibrangedash 8864}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/JSEN.2019.2922395
      \endverb
      \keyw{2D image,60 GHz mm-wave radar,air-writing system,bidirectional LSTM,BLSTM,character recognition,Chirp,connectionist temporal classification,connectionist temporal classification loss function,contact-less detection,ConvLSTM-CTC,convolutional LSTM,convolutional neural nets,DCNN,deep convolutional neural network,drawn character,extraction processing stage,feature extraction,frequency 60 GHz,gesture recognition,hand gesture movements,hand marker,handwriting gestures,handwritten character recognition,human computer interaction,human-computer interface,human-machine interface,image classification,image filtering,learning (artificial intelligence),linguistic characters,long short term memory,millimeter wave radar sensor,millimeter wave radars,millimetre wave radar,network of radars,object detection,Radar antennas,Radar cross-sections,radar detection,radar receivers,radar technology,sensing,Sensors,smoothening filter,smoothing methods,time series,time-series trajectory data,Trajectory,trilateration technique,Writing}
    \endentry
    \entry{Arthamanolap:2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=0297d9cf8e5f799abf0e17a5efad15ed}{%
           family={Arthamanolap},
           familyi={A\bibinitperiod},
           given={Kongphum},
           giveni={K\bibinitperiod}}}%
        {{hash=0c6e09a954e88f8ac52b8621b795aeb8}{%
           family={Gabbualoy},
           familyi={G\bibinitperiod},
           given={Somprasong},
           giveni={S\bibinitperiod}}}%
        {{hash=ea89f12eea6fb426beea247b526487e4}{%
           family={Phasukkit},
           familyi={P\bibinitperiod},
           given={Pattarapong},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{5739185425cef3eb57bc577659915553}
      \strng{fullhash}{5739185425cef3eb57bc577659915553}
      \strng{bibnamehash}{5739185425cef3eb57bc577659915553}
      \strng{authorbibnamehash}{5739185425cef3eb57bc577659915553}
      \strng{authornamehash}{5739185425cef3eb57bc577659915553}
      \strng{authorfullhash}{5739185425cef3eb57bc577659915553}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{From previous researches, Doppler radar was used to detect signal for implement with many applications. Nevertheless, it is difficult to analyze for recognize object. At present, technique of deep learning in terms of signal processing and image processing are using in many researches to classify categories of data. In this paper, signal image was used by deep learning to classify hand gesture by receiving signals from 24GHz transceiver: BGT24MTR11. We transformed the signals to images for 3 categories including Spectrogram, Time domain from original signal and feature MFCC graph. After that those of converted image will be trained by Deep learning for classify the hand gesture types. From the result of this experiment has been shown that signal image can be used to recognize hand gesture and Spectrogram graph makes the highest accuracy as 94\%.}
      \field{booktitle}{Proceedings of 16th {International} {Conference} on {Electrical} {Engineering}/{Electronics}, {Computer}, {Telecommunications} and {Information} {Technology}}
      \field{month}{7}
      \field{series}{{ECTI}-{CON}'19}
      \field{title}{Doppler {Radar} for {Dynamic} {Hand} {Gesture} {Recognition} based on {Signal} {Image} {Processing}}
      \field{venue}{Pattaya, Thailand}
      \field{year}{2019}
      \field{pages}{931\bibrangedash 934}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ECTI-CON47248.2019.8955217
      \endverb
      \keyw{BGT24MTR11,converted image,Deep Learning,deep learning technique,Doppler radar,feature MFCC graph,frequency 24.0 GHz,gesture recognition,graph theory,hand gesture,hand gesture recognition,image classification,image processing,learning (artificial intelligence),MFCC,neural nets,object recognition,radar computing,radar detection,radar imaging,signal image,signal image processing,Spectrogram,Spectrogram graph}
    \endentry
    \entry{Ashbrook:2010}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=b1062551ea473fdddc844c1ea8a68371}{%
           family={Ashbrook},
           familyi={A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=7a96a3a35e4889c76f26209f02d2ca8e}{%
           family={Starner},
           familyi={S\bibinitperiod},
           given={Thad},
           giveni={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{41bdba144cfcfba9af11c7e982db38eb}
      \strng{fullhash}{41bdba144cfcfba9af11c7e982db38eb}
      \strng{bibnamehash}{41bdba144cfcfba9af11c7e982db38eb}
      \strng{authorbibnamehash}{41bdba144cfcfba9af11c7e982db38eb}
      \strng{authornamehash}{41bdba144cfcfba9af11c7e982db38eb}
      \strng{authorfullhash}{41bdba144cfcfba9af11c7e982db38eb}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781605589299}
      \field{series}{CHI ’10}
      \field{title}{{MAGIC}: A Motion Gesture Design Tool}
      \field{venue}{Atlanta, Georgia, USA}
      \field{year}{2010}
      \field{pages}{2159\bibrangedash 2168}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1753326.1753653
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1753326.1753653
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1753326.1753653
      \endverb
      \keyw{gesture}
    \endentry
    \entry{Avrahami:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=081fea60d130f582ab9ff1ac0322102b}{%
           family={Avrahami},
           familyi={A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=eaad0979aec1f7ecb7b0dd8b7221d023}{%
           family={Patel},
           familyi={P\bibinitperiod},
           given={Mitesh},
           giveni={M\bibinitperiod}}}%
        {{hash=583092d837c36df89aa4a43a3f3f3950}{%
           family={Yamaura},
           familyi={Y\bibinitperiod},
           given={Yusuke},
           giveni={Y\bibinitperiod}}}%
        {{hash=0277a74ec85e0182761f9120184b99b7}{%
           family={Kratz},
           familyi={K\bibinitperiod},
           given={Sven},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{fullhash}{87c2264acfcc9c96233c535f7c4d0185}
      \strng{bibnamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authorbibnamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authornamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authorfullhash}{87c2264acfcc9c96233c535f7c4d0185}
      \field{extraname}{1}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Activity recognition is a core component of many intelligent and context-aware systems. In this paper, we present a solution for discreetly and unobtrusively recognizing common work activities above a work surface without using cameras. We demonstrate our approach, which utilizes an RF-radar sensor mounted under the work surface, in two work domains; recognizing work activities at a convenience-store counter (useful for post-hoc analytics) and recognizing common office deskwork activities (useful for real-time applications). We classify seven clerk activities with 94.9\% accuracy using data collected in a lab environment, and recognize six common deskwork activities collected in real offices with 95.3\% accuracy. We show that using multiple projections of RF signal leads to improved recognition accuracy. Finally, we show how smartwatches worn by users can be used to attribute an activity, recognized with the RF sensor, to a particular user in multi-user scenarios. We believe our solution can mitigate some of users privacy concerns associated with cameras and is useful for a wide range of intelligent systems.}
      \field{booktitle}{Proc. of the 23rd ACM International Conference on Intelligent User Interfaces}
      \field{isbn}{9781450349451}
      \field{series}{IUI '18}
      \field{title}{Below the Surface: Unobtrusive Activity Recognition for Work Surfaces Using RF-Radar Sensing}
      \field{venue}{Tokyo, Japan}
      \field{year}{2018}
      \field{pages}{439\bibrangedash 451}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1145/3172944.3172962
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3172944.3172962
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3172944.3172962
      \endverb
      \keyw{retail,activity recognition,IMU,radio frequency radar sensor,deskwork,sensing}
    \endentry
    \entry{Avrahami:2020}{article}{}
      \name{author}{5}{}{%
        {{hash=081fea60d130f582ab9ff1ac0322102b}{%
           family={Avrahami},
           familyi={A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=eaad0979aec1f7ecb7b0dd8b7221d023}{%
           family={Patel},
           familyi={P\bibinitperiod},
           given={Mitesh},
           giveni={M\bibinitperiod}}}%
        {{hash=583092d837c36df89aa4a43a3f3f3950}{%
           family={Yamaura},
           familyi={Y\bibinitperiod},
           given={Yusuke},
           giveni={Y\bibinitperiod}}}%
        {{hash=0277a74ec85e0182761f9120184b99b7}{%
           family={Kratz},
           familyi={K\bibinitperiod},
           given={Sven},
           giveni={S\bibinitperiod}}}%
        {{hash=d612dc661847b3d3fd6f13ea4361423b}{%
           family={Cooper},
           familyi={C\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{fullhash}{46bce27012e9c69ffa3576f3f87f6d1b}
      \strng{bibnamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authorbibnamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authornamehash}{76294157cec7ed0c04779ad441f062b8}
      \strng{authorfullhash}{46bce27012e9c69ffa3576f3f87f6d1b}
      \field{extraname}{2}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Activity recognition is a core component of many intelligent and context-aware systems. We present a solution for discreetly and unobtrusively recognizing common work activities above a work surface without using cameras. We demonstrate our approach, which utilizes an RF-radar sensor mounted under the work surface, in three domains: recognizing work activities at a convenience-store counter, recognizing common office deskwork activities, and estimating the position of customers in a showroom environment. Our examples illustrate potential benefits for both post-hoc business analytics and for real-time applications. Our solution was able to classify seven clerk activities with 94.9\% accuracy using data collected in a lab environment and able to recognize six common deskwork activities collected in real offices with 95.3\% accuracy. Using two sensors simultaneously, we demonstrate coarse position estimation around a large surface with 95.4\% accuracy. We show that using multiple projections of RF signal leads to improved recognition accuracy. Finally, we show how smartwatches worn by users can be used to attribute an activity, recognized with the RF sensor, to a particular user in multi-user scenarios. We believe our solution can mitigate some of users’ privacy concerns associated with cameras and is useful for a wide range of intelligent systems.}
      \field{issn}{2160-6455}
      \field{journaltitle}{ACM Trans. Interact. Intell. Syst.}
      \field{month}{8}
      \field{number}{1}
      \field{title}{Unobtrusive Activity Recognition and Position Estimation for Work Surfaces Using RF-Radar Sensing}
      \field{volume}{10}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1145/3241383
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3241383
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3241383
      \endverb
      \keyw{retail,radio frequency radar sensor,deskwork,IMU,sensing,Activity recognition}
    \endentry
    \entry{Bachmann:2018}{article}{}
      \name{author}{3}{}{%
        {{hash=07694fd4c3f7297f22890df99969a7f2}{%
           family={Bachmann},
           familyi={B\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=e776c75932f3687a061fd53948b02564}{%
           family={Weichert},
           familyi={W\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod}}}%
        {{hash=f182f7e44c8614163dfdabe3dd062a6d}{%
           family={Rinkenauer},
           familyi={R\bibinitperiod},
           given={Gerhard},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MDPI AG}%
      }
      \strng{namehash}{1b23adfb45f19926f1ad247a82d01e8f}
      \strng{fullhash}{1b23adfb45f19926f1ad247a82d01e8f}
      \strng{bibnamehash}{1b23adfb45f19926f1ad247a82d01e8f}
      \strng{authorbibnamehash}{1b23adfb45f19926f1ad247a82d01e8f}
      \strng{authornamehash}{1b23adfb45f19926f1ad247a82d01e8f}
      \strng{authorfullhash}{1b23adfb45f19926f1ad247a82d01e8f}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{month}{7}
      \field{number}{7}
      \field{title}{{Review of Three-Dimensional Human-Computer Interaction with Focus on the Leap Motion Controller}}
      \field{volume}{18}
      \field{year}{2018}
      \field{pages}{2194}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/s18072194
      \endverb
      \verb{urlraw}
      \verb http://dx.doi.org/10.3390/s18072194
      \endverb
      \verb{url}
      \verb http://dx.doi.org/10.3390/s18072194
      \endverb
    \endentry
    \entry{Bangor:2008}{article}{}
      \name{author}{3}{}{%
        {{hash=05ed7926f59ed51998e7d806c8a2ca30}{%
           family={Bangor},
           familyi={B\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
        {{hash=221e957dde9bcf783fdee858cf2b365e}{%
           family={Kortum},
           familyi={K\bibinitperiod},
           given={Philip},
           giveni={P\bibinitperiod}}}%
        {{hash=bff0e87eeab4ba1e74ae3e776e15d490}{%
           family={Miller},
           familyi={M\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Taylor \& Francis}%
      }
      \strng{namehash}{069c4734e30da9449cee720f93eda80e}
      \strng{fullhash}{069c4734e30da9449cee720f93eda80e}
      \strng{bibnamehash}{069c4734e30da9449cee720f93eda80e}
      \strng{authorbibnamehash}{069c4734e30da9449cee720f93eda80e}
      \strng{authornamehash}{069c4734e30da9449cee720f93eda80e}
      \strng{authorfullhash}{069c4734e30da9449cee720f93eda80e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Journal of Human–Computer Interaction}
      \field{number}{6}
      \field{title}{An Empirical Evaluation of the System Usability Scale}
      \field{volume}{24}
      \field{year}{2008}
      \field{pages}{574\bibrangedash 594}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1080/10447310802205776
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1080/10447310802205776
      \endverb
      \verb{url}
      \verb https://doi.org/10.1080/10447310802205776
      \endverb
    \endentry
    \entry{Bannon:2020}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=92aea4bcffec20ca4ce7844851ff9034}{%
           family={Bannon},
           familyi={B\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=8966dc82be6e614bf5f0eaa6607b5795}{%
           family={Capraru},
           familyi={C\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{2db6de5ee42861eaf26326686bca075c}
      \strng{fullhash}{2db6de5ee42861eaf26326686bca075c}
      \strng{bibnamehash}{2db6de5ee42861eaf26326686bca075c}
      \strng{authorbibnamehash}{2db6de5ee42861eaf26326686bca075c}
      \strng{authornamehash}{2db6de5ee42861eaf26326686bca075c}
      \strng{authorfullhash}{2db6de5ee42861eaf26326686bca075c}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar-based hand gesture recognition is an area receiving a significant amount of interest in recent years due to the rapid increase in the availability of low-cost low-footprint RF sensors. The most common configuration is Frequency Modulated Continuous Wave (FMCW), whereas Continuous Wave (CW) radar is not receiving as much attention. In this paper we explore the use of extremely low cost CW radar modules for gesture recognition. In doing so a set of signal processing electronics is developed, implemented, and used to supply the resulting signal to PC audio input for recording. A dataset of gestures was recorded and gesture recognition accuracy was compared to FMCW recordings to show that CW systems can provide a high accuracy for gesture recognition at a very low cost.}
      \field{booktitle}{Proceedings of the {IEEE} {International} {Radar} {Conference}}
      \field{month}{4}
      \field{note}{ISSN: 2640-7736}
      \field{series}{{RADAR}'20}
      \field{title}{Exploring gesture recognition with low-cost {CW} radar modules in comparison to {FMCW} architectures}
      \field{venue}{Washington, DC, USA}
      \field{year}{2020}
      \field{pages}{744\bibrangedash 748}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/RADAR42522.2020.9114650
      \endverb
      \keyw{CW radar,FM radar,FMCW radar module systems,FMCW recording architectures,frequency modulated continuous wave radar,gesture recognition,low-footprint RF sensors,radar-based hand gesture recognition}
    \endentry
    \entry{Bau:2008}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=351236e64198d96c9bbee359740732ee}{%
           family={Bau},
           familyi={B\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
        {{hash=2d0cc7c7deb5aa48acdd152ca1a3ebc3}{%
           family={Mackay},
           familyi={M\bibinitperiod},
           given={Wendy\bibnamedelima E.},
           giveni={W\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Monterey, CA, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{2dec89a667afdf3e543fe23e1e949db3}
      \strng{fullhash}{2dec89a667afdf3e543fe23e1e949db3}
      \strng{bibnamehash}{2dec89a667afdf3e543fe23e1e949db3}
      \strng{authorbibnamehash}{2dec89a667afdf3e543fe23e1e949db3}
      \strng{authornamehash}{2dec89a667afdf3e543fe23e1e949db3}
      \strng{authorfullhash}{2dec89a667afdf3e543fe23e1e949db3}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe OctoPocus, an example of a dynamic guide that combines on-screen feedforward and feedback to help users learn, execute and remember gesture sets. OctoPocus can be applied to a wide range of single-stroke gestures and recognition algorithms and helps users progress smoothly from novice to expert performance. We provide an analysis of the design space and describe the results of two experi-ments that show that OctoPocus is significantly faster and improves learning of arbitrary gestures, compared to con-ventional Help menus. It can also be adapted to a mark-based gesture set, significantly improving input time compared to a two-level, four-item Hierarchical Marking menu.}
      \field{booktitle}{Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology}
      \field{isbn}{9781595939753}
      \field{series}{UIST '08}
      \field{title}{{OctoPocus: a dynamic guide for learning gesture-based command sets}}
      \field{year}{2008}
      \field{pages}{37\bibrangedash 46}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1449715.1449724
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1449715.1449724
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1449715.1449724
      \endverb
      \keyw{pen input,octopocus,mouse input,gesture recognition,feedforward,feedback,dynamic guides}
    \endentry
    \entry{Berenguer:2019}{article}{}
      \name{author}{6}{}{%
        {{hash=5a2dfcbac79bc4d5bf31cde706e2e5cc}{%
           family={Berenguer},
           familyi={B\bibinitperiod},
           given={Abel\bibnamedelima Díaz},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=c8379b57902e433931a369e429518d4f}{%
           family={Oveneke},
           familyi={O\bibinitperiod},
           given={Meshia\bibnamedelima Cédric},
           giveni={M\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=1d0bce0b275d46cc374cd226bda48ab4}{%
           family={Khalid},
           familyi={K\bibinitperiod},
           given={Habib-Ur-Rehman},
           giveni={H\bibinithyphendelim U\bibinithyphendelim R\bibinitperiod}}}%
        {{hash=984de102b15abddcb9084cab3dd0554e}{%
           family={Alioscha-Perez},
           familyi={A\bibinithyphendelim P\bibinitperiod},
           given={Mitchel},
           giveni={M\bibinitperiod}}}%
        {{hash=ba0a21c25cdd81842e390bd80e0cc7c7}{%
           family={Bourdoux},
           familyi={B\bibinitperiod},
           given={André},
           giveni={A\bibinitperiod}}}%
        {{hash=f3f0497b5c1b5b23c7ceec878fa60922}{%
           family={Sahli},
           familyi={S\bibinitperiod},
           given={Hichem},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{602e984eb4a9734c5e156ba2ee1c4487}
      \strng{fullhash}{b96ae8650132a6e93c43cbe34c4c504a}
      \strng{bibnamehash}{602e984eb4a9734c5e156ba2ee1c4487}
      \strng{authorbibnamehash}{602e984eb4a9734c5e156ba2ee1c4487}
      \strng{authornamehash}{602e984eb4a9734c5e156ba2ee1c4487}
      \strng{authorfullhash}{b96ae8650132a6e93c43cbe34c4c504a}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Access}
      \field{title}{GestureVLAD: Combining Unsupervised Features Representation and Spatio-Temporal Aggregation for Doppler-Radar Gesture Recognition}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{137122\bibrangedash 137135}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2942305
      \endverb
    \endentry
    \entry{Bole:2014}{incollection}{}
      \name{author}{3}{}{%
        {{hash=b9695d26b02e1d38f3757b5ba98d4b63}{%
           family={Bole},
           familyi={B\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=539172022194b19336e2d7786978affc}{%
           family={Wall},
           familyi={W\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=4a54951dbf8d3c978f86e38612e96f16}{%
           family={Norris},
           familyi={N\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=b9695d26b02e1d38f3757b5ba98d4b63}{%
           family={Bole},
           familyi={B\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=539172022194b19336e2d7786978affc}{%
           family={Wall},
           familyi={W\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=4a54951dbf8d3c978f86e38612e96f16}{%
           family={Norris},
           familyi={N\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Oxford}%
      }
      \list{publisher}{1}{%
        {Butterworth-Heinemann}%
      }
      \strng{namehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{fullhash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{bibnamehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{authorbibnamehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{authornamehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{authorfullhash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{editorbibnamehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{editornamehash}{7fb7085a58d4e5e511f30c16b698d191}
      \strng{editorfullhash}{7fb7085a58d4e5e511f30c16b698d191}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{It is here that the equipment for actually obtaining the range and bearing of a target is considered in a way that does not assume any previous knowledge of electronic technology. Conventional magnetron-based radar is described as well as the more recently available coherent radars, together with the benefits that the latter can bring to the navigator. The importance and role of digital processing in modern marine radar systems is considered, as well as how the processed information is finally displayed. All this is directed to allow the user to have a detailed understanding of the optimisation of a radar and its display, not least in filtering out responses from sea and rain clutter.}
      \field{booktitle}{Radar and ARPA Manual (Third Edition)}
      \field{edition}{Third Edition}
      \field{isbn}{978-0-08-097752-2}
      \field{title}{Chapter 2 - The Radar System – Technical Principles}
      \field{year}{2014}
      \field{pages}{29\bibrangedash 137}
      \range{pages}{109}
      \verb{doi}
      \verb https://doi.org/10.1016/B978-0-08-097752-2.00002-7
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/B9780080977522000027
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/B9780080977522000027
      \endverb
      \keyw{Magnetron,Coherent,Barker codes,Clutter,Transmitter,Receiver,Amplifier,Modulator,Pulse Repetition Frequency (PRF),Radio Frequency (RF),Gain,Pulse length Beamwidth,Antenna Siting,Interference,Sidelobes,Pulse compression,Interswitching}
    \endentry
    \entry{Brandon:2014}{book}{}
      \name{author}{1}{}{%
        {{hash=311726883ed88890ea1fa829ff8e0fb6}{%
           family={Brandon},
           familyi={B\bibinitperiod},
           given={Sanders},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Birmingham}%
      }
      \list{publisher}{1}{%
        {Packt Publishing}%
      }
      \strng{namehash}{311726883ed88890ea1fa829ff8e0fb6}
      \strng{fullhash}{311726883ed88890ea1fa829ff8e0fb6}
      \strng{bibnamehash}{311726883ed88890ea1fa829ff8e0fb6}
      \strng{authorbibnamehash}{311726883ed88890ea1fa829ff8e0fb6}
      \strng{authornamehash}{311726883ed88890ea1fa829ff8e0fb6}
      \strng{authorfullhash}{311726883ed88890ea1fa829ff8e0fb6}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-783-55139-2}
      \field{title}{Mastering Leap Motion}
      \field{year}{2014}
    \endentry
    \entry{Brooke:1996}{article}{}
      \name{author}{1}{}{%
        {{hash=813064283275c281401d7a7483420c67}{%
           family={Brooke},
           familyi={B\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {CRC press}%
      }
      \strng{namehash}{813064283275c281401d7a7483420c67}
      \strng{fullhash}{813064283275c281401d7a7483420c67}
      \strng{bibnamehash}{813064283275c281401d7a7483420c67}
      \strng{authorbibnamehash}{813064283275c281401d7a7483420c67}
      \strng{authornamehash}{813064283275c281401d7a7483420c67}
      \strng{authorfullhash}{813064283275c281401d7a7483420c67}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Usability evaluation in industry}
      \field{title}{{SUS-A quick and dirty usability scale}}
      \field{year}{1996}
      \field{pages}{189\bibrangedash 194}
      \range{pages}{6}
    \endentry
    \entry{Brunelli:2009}{book}{}
      \name{author}{1}{}{%
        {{hash=bf7c2971ab6807484e84a7bbc6175bac}{%
           family={Brunelli},
           familyi={B\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York}%
      }
      \list{publisher}{1}{%
        {John Wiley \& Sons}%
      }
      \strng{namehash}{bf7c2971ab6807484e84a7bbc6175bac}
      \strng{fullhash}{bf7c2971ab6807484e84a7bbc6175bac}
      \strng{bibnamehash}{bf7c2971ab6807484e84a7bbc6175bac}
      \strng{authorbibnamehash}{bf7c2971ab6807484e84a7bbc6175bac}
      \strng{authornamehash}{bf7c2971ab6807484e84a7bbc6175bac}
      \strng{authorfullhash}{bf7c2971ab6807484e84a7bbc6175bac}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-0-470-51706-2}
      \field{title}{Template Matching Techniques in Computer Vision: Theory and Practice}
      \field{year}{2009}
    \endentry
    \entry{Bush:2011}{incollection}{}
      \name{author}{2}{}{%
        {{hash=1c35cc61bd787e135987eccd46a59574}{%
           family={Bush},
           familyi={B\bibinitperiod},
           given={Ashley},
           giveni={A\bibinitperiod}}}%
        {{hash=b3b1fce90efea94644b2189df6155319}{%
           family={Purao},
           familyi={P\bibinitperiod},
           given={Sandeep},
           giveni={S\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=17ba57d6ffcdf7c38bb96e0b62e0425d}{%
           family={Rossi},
           familyi={R\bibinitperiod},
           given={Matti},
           giveni={M\bibinitperiod}}}%
        {{hash=02b9ab1df280ccae041a9d0054223995}{%
           family={Siau},
           familyi={S\bibinitperiod},
           given={Keng},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IDEA Publishing Group}%
      }
      \strng{namehash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{fullhash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{bibnamehash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{authorbibnamehash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{authornamehash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{authorfullhash}{12f8cbd5087c9ef96966b9fd45fe7c6c}
      \strng{editorbibnamehash}{0461e1f45a549d1ab6431d427176e774}
      \strng{editornamehash}{0461e1f45a549d1ab6431d427176e774}
      \strng{editorfullhash}{0461e1f45a549d1ab6431d427176e774}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Information Modeling in the New Millennium}
      \field{chapter}{12}
      \field{title}{{Mapping UML Techniques to Design Activities}}
      \field{year}{2011}
      \field{pages}{199\bibrangedash 217}
      \range{pages}{19}
    \endentry
    \entry{Cai:2019}{article}{}
      \name{author}{2}{}{%
        {{hash=19731b8dc0ecc3b172a87c94dc53c489}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Minghao},
           giveni={M\bibinitperiod}}}%
        {{hash=51d555a66f087144817202384cae46ca}{%
           family={Tanaka},
           familyi={T\bibinitperiod},
           given={Jiro},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{9c94ac7dd6d9ec8246de579677c28638}
      \strng{fullhash}{9c94ac7dd6d9ec8246de579677c28638}
      \strng{bibnamehash}{9c94ac7dd6d9ec8246de579677c28638}
      \strng{authorbibnamehash}{9c94ac7dd6d9ec8246de579677c28638}
      \strng{authornamehash}{9c94ac7dd6d9ec8246de579677c28638}
      \strng{authorfullhash}{9c94ac7dd6d9ec8246de579677c28638}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2192-1962}
      \field{journaltitle}{Hum.-Centric Comput. Inf. Sci.}
      \field{month}{12}
      \field{number}{1}
      \field{title}{{Go Together: Providing Nonverbal Awareness Cues to Enhance Co-Located Sensation in Remote Communication}}
      \field{volume}{9}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1186/s13673-019-0180-y
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13673-019-0180-y
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13673-019-0180-y
      \endverb
      \keyw{Collaboration,Awareness,Togetherness,Remote communication,Mixed reality,Gesture,360° view sharing}
    \endentry
    \entry{Callender:1979}{article}{}
      \name{author}{2}{}{%
        {{hash=796434880b8d658418ea6d49f141d744}{%
           family={Callender},
           familyi={C\bibinitperiod},
           given={John\bibnamedelima C.},
           giveni={J\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=2e0fe7e8a4720e1e8b43d9d881983f3d}{%
           family={Osburn},
           familyi={O\bibinitperiod},
           given={H.\bibnamedelimi G.},
           giveni={H\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {[National Council on Measurement in Education, Wiley]}%
      }
      \strng{namehash}{589be7fb859d128387c62f7d1a7c7651}
      \strng{fullhash}{589be7fb859d128387c62f7d1a7c7651}
      \strng{bibnamehash}{589be7fb859d128387c62f7d1a7c7651}
      \strng{authorbibnamehash}{589be7fb859d128387c62f7d1a7c7651}
      \strng{authornamehash}{589be7fb859d128387c62f7d1a7c7651}
      \strng{authorfullhash}{589be7fb859d128387c62f7d1a7c7651}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{It has long been recognized that some procedures for estimating internal consistency reliability may be superior mathematically to the more commonly used methods such as Coefficient Alpha or odd-even split-half coefficients, but two problems have limited their practical application. One is computational difficulty, coupled with very limited empirical evidence of noticeable improvements in accuracy. The other problem--that of using sample coefficients to infer population reliability--is especially relevant for the better reliability estimators (those that maximize statistical functions) because of the possibility of overestimation due to capitalization on chance sampling error. An empirical comparison of MSPLIT maximized split-half coefficients, Guttman's λ 2, and Coefficient Alpha (Guttman's λ 3) showed that a cross-validation procedure applied to the MSPLIT coefficients produced a noticeable improvement in accuracy and thus seems to offer a solution for both practical limitations.}
      \field{issn}{00220655, 17453984}
      \field{journaltitle}{Journal of Educational Measurement}
      \field{number}{2}
      \field{title}{{An Empirical Comparison of Coefficient Alpha, Guttman's Lambda - 2, and MSPLIT Maximized Split-Half Reliability Estimates}}
      \field{volume}{16}
      \field{year}{1979}
      \field{pages}{89\bibrangedash 99}
      \range{pages}{11}
      \verb{urlraw}
      \verb http://www.jstor.org/stable/1434452
      \endverb
      \verb{url}
      \verb http://www.jstor.org/stable/1434452
      \endverb
    \endentry
    \entry{Calvary:2003}{article}{}
      \name{author}{6}{}{%
        {{hash=722e88a3bebc78dbb735d310f62a0f09}{%
           family={Calvary},
           familyi={C\bibinitperiod},
           given={Gaëlle},
           giveni={G\bibinitperiod}}}%
        {{hash=2d8750fea8604f6ee55610477a88807e}{%
           family={Coutaz},
           familyi={C\bibinitperiod},
           given={Joëlle},
           giveni={J\bibinitperiod}}}%
        {{hash=caf1725b03dcbfb12ea9768e7c72a366}{%
           family={Thevenin},
           familyi={T\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=175304bbb36965809f9d7e67a0f14b12}{%
           family={Limbourg},
           familyi={L\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=998dfbc690b4ec245ef2aeb9b196e7cd}{%
           family={Bouillon},
           familyi={B\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{c21404f547c21ea6d55c2ab7b5aff7f9}
      \strng{fullhash}{040fc50262120957a5721e50c82cb98e}
      \strng{bibnamehash}{c21404f547c21ea6d55c2ab7b5aff7f9}
      \strng{authorbibnamehash}{c21404f547c21ea6d55c2ab7b5aff7f9}
      \strng{authornamehash}{c21404f547c21ea6d55c2ab7b5aff7f9}
      \strng{authorfullhash}{040fc50262120957a5721e50c82cb98e}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Interact. Comput.}
      \field{number}{3}
      \field{title}{{A Unifying Reference Framework for multi-target user interfaces}}
      \field{volume}{15}
      \field{year}{2003}
      \field{pages}{289\bibrangedash 308}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1016/S0953-5438(03)00010-9
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/S0953-5438(03)00010-9
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/S0953-5438(03)00010-9
      \endverb
    \endentry
    \entry{Caputo:2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=1e8c99da4eab6e5def938a29679f3b88}{%
           family={Caputo},
           familyi={C\bibinitperiod},
           given={Fabio\bibnamedelima Marco},
           giveni={F\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=80273d06b3415ed6c848dc69ffd2cc52}{%
           family={Giachetti},
           familyi={G\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{d5716561163a684a592ece1aabbcaadd}
      \strng{fullhash}{d5716561163a684a592ece1aabbcaadd}
      \strng{bibnamehash}{d5716561163a684a592ece1aabbcaadd}
      \strng{authorbibnamehash}{d5716561163a684a592ece1aabbcaadd}
      \strng{authornamehash}{d5716561163a684a592ece1aabbcaadd}
      \strng{authorfullhash}{d5716561163a684a592ece1aabbcaadd}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter}
      \field{isbn}{9781450336840}
      \field{series}{CHItaly 2015}
      \field{title}{Evaluation of Basic Object Manipulation Modes for Low-Cost Immersive Virtual Reality}
      \field{venue}{Rome, Italy}
      \field{year}{2015}
      \field{pages}{74\bibrangedash 77}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/2808435.2808439
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2808435.2808439
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2808435.2808439
      \endverb
    \endentry
    \entry{Caputo:2017}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=1e8c99da4eab6e5def938a29679f3b88}{%
           family={Caputo},
           familyi={C\bibinitperiod},
           given={Fabio\bibnamedelima Marco},
           giveni={F\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=8b53230485f42f63bd1be15ecbe5e062}{%
           family={Prebianca},
           familyi={P\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=5f8bf4850a79b9d88ee2e925825885f5}{%
           family={Carcangiu},
           familyi={C\bibinitperiod},
           given={Alessandro},
           giveni={A\bibinitperiod}}}%
        {{hash=228c1ad2f6058a81cad36162530caa74}{%
           family={Spano},
           familyi={S\bibinitperiod},
           given={Lucio\bibnamedelima Davide},
           giveni={L\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=80273d06b3415ed6c848dc69ffd2cc52}{%
           family={Giachetti},
           familyi={G\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Goslar, DEU}%
      }
      \list{publisher}{1}{%
        {Eurographics Association}%
      }
      \strng{namehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{fullhash}{8aec390fc7c89d9222d78229f95a6d65}
      \strng{bibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorbibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authornamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorfullhash}{8aec390fc7c89d9222d78229f95a6d65}
      \field{extraname}{1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Conference on Smart Tools and Applications in Computer Graphics}
      \field{series}{STAG ’17}
      \field{title}{{A 3 Cent Recognizer: Simple and Effective Retrieval and Classification of Mid-Air Gestures from Single 3D Traces}}
      \field{venue}{Catania, Italy}
      \field{year}{2017}
      \field{pages}{9\bibrangedash 15}
      \range{pages}{7}
      \verb{doi}
      \verb 10.2312/stag.20171221
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.2312/stag.20171221
      \endverb
      \verb{url}
      \verb https://doi.org/10.2312/stag.20171221
      \endverb
    \endentry
    \entry{Caputo:2018}{article}{}
      \name{author}{5}{}{%
        {{hash=1e8c99da4eab6e5def938a29679f3b88}{%
           family={Caputo},
           familyi={C\bibinitperiod},
           given={Fabio\bibnamedelima Marco},
           giveni={F\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=8b53230485f42f63bd1be15ecbe5e062}{%
           family={Prebianca},
           familyi={P\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=5f8bf4850a79b9d88ee2e925825885f5}{%
           family={Carcangiu},
           familyi={C\bibinitperiod},
           given={Alessandro},
           giveni={A\bibinitperiod}}}%
        {{hash=228c1ad2f6058a81cad36162530caa74}{%
           family={Spano},
           familyi={S\bibinitperiod},
           given={Lucio\bibnamedelima Davide},
           giveni={L\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=80273d06b3415ed6c848dc69ffd2cc52}{%
           family={Giachetti},
           familyi={G\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{fullhash}{8aec390fc7c89d9222d78229f95a6d65}
      \strng{bibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorbibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authornamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorfullhash}{8aec390fc7c89d9222d78229f95a6d65}
      \field{extraname}{2}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0097-8493}
      \field{journaltitle}{Computers \& Graphics}
      \field{title}{{Comparing 3D trajectories for simple mid-air gesture recognition}}
      \field{volume}{73}
      \field{year}{2018}
      \field{pages}{17\bibrangedash 25}
      \range{pages}{9}
      \verb{doi}
      \verb https://doi.org/10.1016/j.cag.2018.02.009
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S0097849318300335
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S0097849318300335
      \endverb
      \keyw{Gestures recognition,Trajectory matching,Classification,Mid-air gestures,Gestures dataset}
    \endentry
    \entry{Caputo:2019}{inproceedings}{}
      \name{author}{18}{}{%
        {{hash=1e8c99da4eab6e5def938a29679f3b88}{%
           family={Caputo},
           familyi={C\bibinitperiod},
           given={Fabio\bibnamedelima Marco},
           giveni={F\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=5996f2e5a224a36695701cf563eb977e}{%
           family={Burato},
           familyi={B\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=19d57eb1b64ee86bf47054ed198e65d8}{%
           family={Pavan},
           familyi={P\bibinitperiod},
           given={Gianni},
           giveni={G\bibinitperiod}}}%
        {{hash=a5b54bf3236ea653c8a7cc5648b01246}{%
           family={Voillemin},
           familyi={V\bibinitperiod},
           given={Théo},
           giveni={T\bibinitperiod}}}%
        {{hash=12e365e453b0159869812a93f26b6336}{%
           family={Wannous},
           familyi={W\bibinitperiod},
           given={Hazem},
           giveni={H\bibinitperiod}}}%
        {{hash=b49da2cad6ed218e27f519dcdcc03d90}{%
           family={Vandeborre},
           familyi={V\bibinitperiod},
           given={Jean-Philippe},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
        {{hash=c90fc658d0ad6672733c19d1db437678}{%
           family={Maghoumi},
           familyi={M\bibinitperiod},
           given={Mehran},
           giveni={M\bibinitperiod}}}%
        {{hash=49ec62c0f388ba6345aea9a21bd3e9e7}{%
           family={Taranta\bibnamedelima II},
           familyi={T\bibinitperiod\bibinitdelim I\bibinitperiod},
           given={Eugene\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=e312a8ee037d14ba0cd3ca2f8935f110}{%
           family={Razmjoo},
           familyi={R\bibinitperiod},
           given={Alaleh},
           giveni={A\bibinitperiod}}}%
        {{hash=106180b1302f004e9329ecf5926e737f}{%
           family={LaViola\bibnamedelima Jr.},
           familyi={L\bibinitperiod\bibinitdelim J\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=ab8c66f8895d2e91c26898fcc9b85b40}{%
           family={Manganaro},
           familyi={M\bibinitperiod},
           given={Fabio},
           giveni={F\bibinitperiod}}}%
        {{hash=4bbe947d1a849de10a36342be603cd61}{%
           family={Pini},
           familyi={P\bibinitperiod},
           given={Stefano},
           giveni={S\bibinitperiod}}}%
        {{hash=883be01b4988a35ff18b3811252412a1}{%
           family={Borghi},
           familyi={B\bibinitperiod},
           given={Guido},
           giveni={G\bibinitperiod}}}%
        {{hash=d976bd1fe13ca2c980a198da0d959e64}{%
           family={Vezzani},
           familyi={V\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod}}}%
        {{hash=810bd268a2927d0db658eaeda49ff357}{%
           family={Cucchiara},
           familyi={C\bibinitperiod},
           given={Rita},
           giveni={R\bibinitperiod}}}%
        {{hash=08caeba1bc76f0e34a7fb31989e8257e}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Hai{-}Dang},
           giveni={H\bibinitperiod}}}%
        {{hash=25d343c97ea65b97fdba3b09d82e1d7a}{%
           family={Tran},
           familyi={T\bibinitperiod},
           given={Minh{-}Triet},
           giveni={M\bibinitperiod}}}%
        {{hash=80273d06b3415ed6c848dc69ffd2cc52}{%
           family={Giachetti},
           familyi={G\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=1da1c76f4cf7a755efb3fd68f8b9bc06}{%
           family={Biasotti},
           familyi={B\bibinitperiod},
           given={Silvia},
           giveni={S\bibinitperiod}}}%
        {{hash=12b4a5a36e8ea49948d021b7129ae79e}{%
           family={Lavoué},
           familyi={L\bibinitperiod},
           given={Guillaume},
           giveni={G\bibinitperiod}}}%
        {{hash=86f8537a7a7f6c3fbe1a77521ff96dd2}{%
           family={Veltkamp},
           familyi={V\bibinitperiod},
           given={Remco},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {The Eurographics Association}%
      }
      \strng{namehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{fullhash}{2028bebfe8b68f56ccef60b2d557f594}
      \strng{bibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorbibnamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authornamehash}{ae3e4da877e70c3e360721208a6cac99}
      \strng{authorfullhash}{2028bebfe8b68f56ccef60b2d557f594}
      \strng{editorbibnamehash}{5daeceb2e55cc957f6f46c117b571051}
      \strng{editornamehash}{5daeceb2e55cc957f6f46c117b571051}
      \strng{editorfullhash}{5daeceb2e55cc957f6f46c117b571051}
      \field{extraname}{3}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Eurographics Workshop on 3D Object Retrieval}
      \field{isbn}{978-3-03868-077-2}
      \field{issn}{1997-0471}
      \field{title}{{Online Gesture Recognition}}
      \field{year}{2019}
      \field{pages}{93\bibrangedash 102}
      \range{pages}{10}
      \verb{doi}
      \verb 10.2312/3dor.20191067
      \endverb
    \endentry
    \entry{Casiez:2012}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=317482d7ee43e1efb36494dda9cd24ba}{%
           family={Casiez},
           familyi={C\bibinitperiod},
           given={Géry},
           giveni={G\bibinitperiod}}}%
        {{hash=2febb2b64f8627ea8fcbd56ce2e11f97}{%
           family={Roussel},
           familyi={R\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=f94f65826718458aba9a7e2ee4834749}{%
           family={Vogel},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{889aca3990c1c9b029b8f8aa9d17f392}
      \strng{fullhash}{889aca3990c1c9b029b8f8aa9d17f392}
      \strng{bibnamehash}{889aca3990c1c9b029b8f8aa9d17f392}
      \strng{authorbibnamehash}{889aca3990c1c9b029b8f8aa9d17f392}
      \strng{authornamehash}{889aca3990c1c9b029b8f8aa9d17f392}
      \strng{authorfullhash}{889aca3990c1c9b029b8f8aa9d17f392}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The 1 € filter ("one Euro filter") is a simple algorithm to filter noisy signals for high precision and responsiveness. It uses a first order low-pass filter with an adaptive cutoff frequency: at low speeds, a low cutoff stabilizes the signal by reducing jitter, but as speed increases, the cutoff is increased to reduce lag. The algorithm is easy to implement, uses very few resources, and with two easily understood parameters, it is easy to tune. In a comparison with other filters, the 1 € filter has less lag using a reference amount of jitter reduction.}
      \field{booktitle}{Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}}
      \field{isbn}{978-1-4503-1015-4}
      \field{month}{5}
      \field{series}{{CHI} '12}
      \field{shorttitle}{1€ filter}
      \field{title}{{1€ filter: a simple speed-based low-pass filter for noisy input in interactive systems}}
      \field{urlday}{29}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{2527\bibrangedash 2530}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/2207676.2208639
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2207676.2208639
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2207676.2208639
      \endverb
      \keyw{precision,signal,filtering,jitter,lag,noise,responsiveness}
    \endentry
    \entry{Chatterjee:2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=1436df1f848b9ea8e5322e861a4d3ca2}{%
           family={Chatterjee},
           familyi={C\bibinitperiod},
           given={Ishan},
           giveni={I\bibinitperiod}}}%
        {{hash=4a67b2cfdea06a9ccec17195cc5498de}{%
           family={Xiao},
           familyi={X\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=e52ad2039fb196a545861357d70928fa}{%
           family={Harrison},
           familyi={H\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{bfd2bdba687e3fab391935f98976317b}
      \strng{fullhash}{bfd2bdba687e3fab391935f98976317b}
      \strng{bibnamehash}{bfd2bdba687e3fab391935f98976317b}
      \strng{authorbibnamehash}{bfd2bdba687e3fab391935f98976317b}
      \strng{authornamehash}{bfd2bdba687e3fab391935f98976317b}
      \strng{authorfullhash}{bfd2bdba687e3fab391935f98976317b}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2015 ACM on International Conference on Multimodal Interaction}
      \field{isbn}{9781450339124}
      \field{series}{ICMI '15}
      \field{title}{{Gaze+Gesture: Expressive, Precise and Targeted Free-Space Interactions}}
      \field{venue}{Seattle, Washington, USA}
      \field{year}{2015}
      \field{pages}{131\bibrangedash 138}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2818346.2820752
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2818346.2820752
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2818346.2820752
      \endverb
      \keyw{eye tracking,sensors,input technologies,touch-free interaction,interaction techniques,cursor,pointing,free-space gestures}
    \endentry
    \entry{Chen:2016}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=903372eaacb45870dfe218898004c259}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Yineng},
           giveni={Y\bibinitperiod}}}%
        {{hash=f78e58bc2d01dce3fd16eb0058680300}{%
           family={Su},
           familyi={S\bibinitperiod},
           given={Xiaojun},
           giveni={X\bibinitperiod}}}%
        {{hash=1487e60477fb6a315fa69b2f8ee53c9f}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Feng},
           giveni={F\bibinitperiod}}}%
        {{hash=5d2994c0168811c3036aaa4ce5a267b7}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Jin},
           giveni={J\bibinitperiod}}}%
        {{hash=f55040787f300acd4f880ff3932a53fa}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiaolong\bibnamedelima (Luke)},
           giveni={X\bibinitperiod\bibinitdelim (\bibinitperiod}}}%
        {{hash=cf94247a16e88fe22e8363aa882a4847}{%
           family={Dai},
           familyi={D\bibinitperiod},
           given={Guozhong},
           giveni={G\bibinitperiod}}}%
        {{hash=ed1f4db1d87834a0f89df4cf6d9739df}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Hongan},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{a9feed51d699980d46b4c1ff45aa846c}
      \strng{fullhash}{80e5f7a091ad7d5382acb73af7198738}
      \strng{bibnamehash}{a9feed51d699980d46b4c1ff45aa846c}
      \strng{authorbibnamehash}{a9feed51d699980d46b4c1ff45aa846c}
      \strng{authornamehash}{a9feed51d699980d46b4c1ff45aa846c}
      \strng{authorfullhash}{80e5f7a091ad7d5382acb73af7198738}
      \field{extraname}{1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems}
      \field{isbn}{9781450340823}
      \field{series}{CHI EA ’16}
      \field{title}{{Pactolus: A Method for Mid-Air Gesture Segmentation within EMG}}
      \field{venue}{San Jose, California, USA}
      \field{year}{2016}
      \field{pages}{1760\bibrangedash 1765}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/2851581.2892492
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2851581.2892492
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2851581.2892492
      \endverb
      \keyw{midas problem,EMG,mid-air gesture segmentation}
    \endentry
    \entry{Chen:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=8b1ee88161dfa048d349ca79ece23b62}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Zhaoxi},
           giveni={Z\bibinitperiod}}}%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=d271b8d79d135292f5569754056368a8}{%
           family={Fioranelli},
           familyi={F\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
        {{hash=4e97f6c29f732a77ae7d4a2e90e1474d}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Piscataway, NJ, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{3ef7443cbb7963ce0dbb325ead2e9640}
      \strng{fullhash}{964a2e660e6de09c4425ccf494b80acc}
      \strng{bibnamehash}{3ef7443cbb7963ce0dbb325ead2e9640}
      \strng{authorbibnamehash}{3ef7443cbb7963ce0dbb325ead2e9640}
      \strng{authornamehash}{3ef7443cbb7963ce0dbb325ead2e9640}
      \strng{authorfullhash}{964a2e660e6de09c4425ccf494b80acc}
      \field{extraname}{2}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a novel convolutional neural network (CNN) for dynamic hand gesture classification based on multistatic radar micro-Doppler signatures. The time-frequency spectrograms of micro-Doppler signatures at all the receiver antennas are adopted as the input to CNN, where data fusion of different receivers is carried out at an adjustable position. The optimal fusion position that achieves the highest classification accuracy is determined by a series of experiments. Experimental results on measured data show that 1) the accuracy of classification using multistatic radar is significantly higher than monostatic radar, and that 2) fusion at the middle of CNN achieves the best classification accuracy.}
      \field{booktitle}{Proceedings of the {IEEE} International {Radar} {Conference}}
      \field{month}{4}
      \field{note}{ISSN: 2375-5318}
      \field{series}{RADAR '19}
      \field{title}{Dynamic {Hand} {Gesture} {Classification} {Based} on {Multistatic} {Radar} {Micro}-{Doppler} {Signatures} {Using} {Convolutional} {Neural} {Network}}
      \field{venue}{Boston, MA, USA}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 5}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/RADAR.2019.8835796
      \endverb
      \keyw{classification accuracy,CNN,Convolution,convolutional neural nets,convolutional neural network,data fusion,dynamic hand gesture classification,Feature extraction,gesture recognition,image classification,image fusion,micro-Doppler,micro-Doppler signatures,multistatic radar,Multistatic radar,multistatic radar microdoppler signatures,optimal fusion position,Radar antennas,receiver antennas,Receivers,sensor fusion,Spectrogram,time-frequency analysis,time-frequency spectrograms}
    \endentry
    \entry{Chen:2017}{thesis}{}
      \name{author}{1}{}{%
        {{hash=3895148f4d2392bf49cfaad6ff8274f9}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Zhaoxin},
           giveni={Z\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {{INSA} de Rennes, France}%
      }
      \strng{namehash}{3895148f4d2392bf49cfaad6ff8274f9}
      \strng{fullhash}{3895148f4d2392bf49cfaad6ff8274f9}
      \strng{bibnamehash}{3895148f4d2392bf49cfaad6ff8274f9}
      \strng{authorbibnamehash}{3895148f4d2392bf49cfaad6ff8274f9}
      \strng{authornamehash}{3895148f4d2392bf49cfaad6ff8274f9}
      \strng{authorfullhash}{3895148f4d2392bf49cfaad6ff8274f9}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Recognition and interpretation of multi-touch gesture interaction.}}
      \field{type}{phdthesis}
      \field{year}{2017}
      \verb{urlraw}
      \verb https://tel.archives-ouvertes.fr/tel-01578068
      \endverb
      \verb{url}
      \verb https://tel.archives-ouvertes.fr/tel-01578068
      \endverb
    \endentry
    \entry{Cheng:2016}{article}{}
      \name{author}{3}{}{%
        {{hash=7f716c207f29a9f09b9764f354497a91}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Hong},
           giveni={H\bibinitperiod}}}%
        {{hash=646d76d5238bdf80e3e4c146444ba1f3}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=aaf82b828c51f08749f4d70b2a2f681a}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zicheng},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{6b6507e39578c676e3548cef83433fd4}
      \strng{fullhash}{6b6507e39578c676e3548cef83433fd4}
      \strng{bibnamehash}{6b6507e39578c676e3548cef83433fd4}
      \strng{authorbibnamehash}{6b6507e39578c676e3548cef83433fd4}
      \strng{authornamehash}{6b6507e39578c676e3548cef83433fd4}
      \strng{authorfullhash}{6b6507e39578c676e3548cef83433fd4}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Circuits and Systems for Video Technology}
      \field{number}{9}
      \field{title}{{Survey on 3D Hand Gesture Recognition}}
      \field{volume}{26}
      \field{year}{2016}
      \field{pages}{1659\bibrangedash 1673}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TCSVT.2015.2469551
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7208833
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7208833
      \endverb
    \endentry
    \entry{Chew:1990}{book}{}
      \name{author}{1}{}{%
        {{hash=2b4068cadce0a5b57df69f7e94fe5433}{%
           family={Chew},
           familyi={C\bibinitperiod},
           given={Weng\bibnamedelima Cho},
           giveni={W\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York}%
      }
      \list{publisher}{1}{%
        {Van Nostrand Reinhold}%
      }
      \strng{namehash}{2b4068cadce0a5b57df69f7e94fe5433}
      \strng{fullhash}{2b4068cadce0a5b57df69f7e94fe5433}
      \strng{bibnamehash}{2b4068cadce0a5b57df69f7e94fe5433}
      \strng{authorbibnamehash}{2b4068cadce0a5b57df69f7e94fe5433}
      \strng{authornamehash}{2b4068cadce0a5b57df69f7e94fe5433}
      \strng{authorfullhash}{2b4068cadce0a5b57df69f7e94fe5433}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Waves and Fields in Inhomogeneous Media}}
      \field{year}{1990}
    \endentry
    \entry{Chiang:2017}{article}{}
      \name{author}{3}{}{%
        {{hash=0157e936707ca0c19adefd07ddf0d087}{%
           family={Chiang},
           familyi={C\bibinitperiod},
           given={Cheng-Chin},
           giveni={C\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=e53728a7fe7584f36afdf9e03a85122c}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ren-Hong},
           giveni={R\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=8d80ea0a801ccb580027f41013c8f534}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Bo-Ruei},
           giveni={B\bibinithyphendelim R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Elsevier Science Inc.}%
      }
      \strng{namehash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \strng{fullhash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \strng{bibnamehash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \strng{authorbibnamehash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \strng{authornamehash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \strng{authorfullhash}{1eb5cb9427f8b2c97f3fa8aa113d07c4}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0031-3203}
      \field{journaltitle}{Pattern Recogn.}
      \field{month}{1}
      \field{number}{C}
      \field{title}{{Recognizing Arbitrarily Connected and Superimposed Handwritten Numerals in Intangible Writing Interfaces}}
      \field{volume}{61}
      \field{year}{2017}
      \field{pages}{15\bibrangedash 28}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1016/j.patcog.2016.07.018
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.patcog.2016.07.018
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.patcog.2016.07.018
      \endverb
      \keyw{Intangible writing interface,Dynamic time warping,Key numeral spotting,Finger gesture recognition,Graph path finding}
    \endentry
    \entry{Choi:2014}{article}{}
      \name{author}{3}{}{%
        {{hash=6cc07d59c61b2cae9c34afd5e74203cc}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={Eunjung},
           giveni={E\bibinitperiod}}}%
        {{hash=ebf6c6364405cd96aac238fa3401a4b6}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Heejin},
           giveni={H\bibinitperiod}}}%
        {{hash=8e5e67af65a7e21ebc6b8dc937c4b1f7}{%
           family={Chung},
           familyi={C\bibinitperiod},
           given={Min\bibnamedelima K.},
           giveni={M\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{170631f44c5db39ea991869754625767}
      \strng{fullhash}{170631f44c5db39ea991869754625767}
      \strng{bibnamehash}{170631f44c5db39ea991869754625767}
      \strng{authorbibnamehash}{170631f44c5db39ea991869754625767}
      \strng{authornamehash}{170631f44c5db39ea991869754625767}
      \strng{authorfullhash}{170631f44c5db39ea991869754625767}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, studies on gesture-based interfaces have made an effort to improve the intuitiveness of gesture commands by asking users to define a gesture for a command. However, there are few methods to organize and notate user-defined gestures in a systematic approach. To resolve this, we propose a three-dimensional (3D) Hand Gesture Taxonomy and Notation Method. We first derived elements of a hand gesture by analyzing related studies and subsequently developed the 3D Hand Gesture Taxonomy based on the elements. Moreover, we devised a Notation Method based on a combination of the elements and also matched a code to each element for easy notation. Finally, we have verified the usefulness of the Notation Method by training participants to notate hand gestures and by asking another set of participants to recreate the notated gestures. In short, this research proposes a novel and systematic approach to notate hand gesture commands. Relevance to industry This study develops a 3D Hand Gesture Taxonomy and Notation Method. The results of this study can be used as a guideline to organize hand gestures for enhancing the usability of gesture-based interfaces.}
      \field{issn}{0169-8141}
      \field{journaltitle}{International Journal of Industrial Ergonomics}
      \field{month}{1}
      \field{number}{1}
      \field{title}{{A taxonomy and notation method for three-dimensional hand gestures}}
      \field{urlday}{6}
      \field{urlmonth}{1}
      \field{urlyear}{2021}
      \field{volume}{44}
      \field{year}{2014}
      \field{urldateera}{ce}
      \field{pages}{171\bibrangedash 188}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1016/j.ergon.2013.10.011
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S0169814113001285
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S0169814113001285
      \endverb
      \keyw{Hand gesture commands,Hand gesture elements,Hand gesture notation method,Hand gesture taxonomy}
    \endentry
    \entry{Choi:2019}{article}{}
      \name{author}{3}{}{%
        {{hash=85fcf48fa88ed022498fd4cdce676041}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=59fe2e92f1a64a587a6e505b33371850}{%
           family={Ryu},
           familyi={R\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=b2236af712a294693dcea632d195b1fb}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \strng{fullhash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \strng{bibnamehash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \strng{authorbibnamehash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \strng{authornamehash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \strng{authorfullhash}{3b7d12caa8c9fac6a75c55fa74dab5eb}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Due to the development of short-range radar with high-resolution, the radar sensor has a high potential to be used in real human-computer interaction (HCI) applications. The radar sensor has advantages over optical cameras in that it is unaffected by illumination and it is able to detect the objects in an occluded environment. This paper proposes a hand gesture recognition system for a real-time application of HCI using 60 GHz frequency-modulated continuous wave (FMCW) radar, Soli, developed by Google. The overall system includes signal processing part that generates range-Doppler map (RDM) sequences without clutter and machine learning part including a long short-term memory (LSTM) encoder to learn the temporal characteristics of the RDM sequences. A set of data is collected from 10 participants for the experiment. The proposed hand gesture recognition system successfully distinguishes 10 gestures with a high classification accuracy of 99.10\%. It also recognizes the gestures of a new participant with an accuracy of 98.48\%.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Short-{Range} {Radar} {Based} {Real}-{Time} {Hand} {Gesture} {Recognition} {Using} {LSTM} {Encoder}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{33610\bibrangedash 33618}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2903586
      \endverb
      \keyw{Clutter,CW radar,Doppler effect,Doppler radar,FM radar,FMCW radar,frequency 60.0 GHz,frequency-modulated continuous wave radar,gesture recognitio,gesture recognition,Gesture recognition,hand gesture recognition system,HCI applications,human computer interaction,human-computer interaction applications,image classification,Laser radar,long short-term memory encoder,LSTM encoder,machine learning,occluded environment,optical cameras,radar clutter,range-Doppler map sequence generation,RDM sequence generation,real-time interaction,short-range radar resolution,short-range radar sensor,signal processing,Signal processing}
    \endentry
    \entry{Clark:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2cbd4ecb5e4b9f7beaa3b8b4fa01e734}{%
           family={Clark},
           familyi={C\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=7b8fe080b2884b5af1694b696762ef38}{%
           family={Moodley},
           familyi={M\bibinitperiod},
           given={Deshendran},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{14fa8c628c927e5749e6b271d80e75a7}
      \strng{fullhash}{14fa8c628c927e5749e6b271d80e75a7}
      \strng{bibnamehash}{14fa8c628c927e5749e6b271d80e75a7}
      \strng{authorbibnamehash}{14fa8c628c927e5749e6b271d80e75a7}
      \strng{authornamehash}{14fa8c628c927e5749e6b271d80e75a7}
      \strng{authorfullhash}{14fa8c628c927e5749e6b271d80e75a7}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Annual Conference of the South African Institute of Computer Scientists and Information Technologists}
      \field{isbn}{9781450348058}
      \field{series}{SAICSIT '16}
      \field{title}{{A System for a Hand Gesture-Manipulated Virtual Reality Environment}}
      \field{venue}{Johannesburg, South Africa}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1145/2987491.2987511
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2987491.2987511
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2987491.2987511
      \endverb
      \keyw{Machine Learning,Virtual Reality,Leap Motion Controller,Hand Gesture Recognition}
    \endentry
    \entry{Colgan:2017}{misc}{}
      \name{author}{1}{}{%
        {{hash=ca373fedcc6d28a1e6f977e1c0b776b8}{%
           family={Colgan},
           familyi={C\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \strng{fullhash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \strng{bibnamehash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \strng{authorbibnamehash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \strng{authornamehash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \strng{authorfullhash}{ca373fedcc6d28a1e6f977e1c0b776b8}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Leap Motion Blog}
      \field{month}{1}
      \field{title}{{How Does the Leap Motion Controller Work?}}
      \field{year}{2017}
      \verb{urlraw}
      \verb https://blog.leapmotion.com/hardware-to-software-how-does-the-leap-motion-controller-work/
      \endverb
      \verb{url}
      \verb https://blog.leapmotion.com/hardware-to-software-how-does-the-leap-motion-controller-work/
      \endverb
    \endentry
    \entry{Cook:2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=634ad7fc533e3c03d4fb0e6b67025cc8}{%
           family={Cook},
           familyi={C\bibinitperiod},
           given={Harisson},
           giveni={H\bibinitperiod}}}%
        {{hash=09ca540d657f70e761dd6c24f6b68713}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Quang\bibnamedelima Vinh},
           giveni={Q\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=e71e737936656985d7e10377dec1b952}{%
           family={Simoff},
           familyi={S\bibinitperiod},
           given={Simeone},
           giveni={S\bibinitperiod}}}%
        {{hash=d69e8a01f41c51758c6b14315b8857f2}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Mao\bibnamedelima Lin},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Computer Science Research Notes CSRN}%
      }
      \strng{namehash}{ad6293ed0ec23b4935a1f8f3d62684e5}
      \strng{fullhash}{85d046aa959207bae00143545654a929}
      \strng{bibnamehash}{ad6293ed0ec23b4935a1f8f3d62684e5}
      \strng{authorbibnamehash}{ad6293ed0ec23b4935a1f8f3d62684e5}
      \strng{authornamehash}{ad6293ed0ec23b4935a1f8f3d62684e5}
      \strng{authorfullhash}{85d046aa959207bae00143545654a929}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 24th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision}
      \field{isbn}{978-80-86943-58-9}
      \field{month}{6}
      \field{title}{{Enabling Gesture Interaction with 3D Point Cloud}}
      \field{volume}{2602}
      \field{year}{2016}
      \field{pages}{59\bibrangedash 68}
      \range{pages}{10}
      \verb{urlraw}
      \verb https://opus.lib.uts.edu.au/handle/10453/45407
      \endverb
      \verb{url}
      \verb https://opus.lib.uts.edu.au/handle/10453/45407
      \endverb
    \endentry
    \entry{Copic:2019}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=2fa914d302565e715f25ea38a688cbfd}{%
           family={Copič\bibnamedelima Pucihar},
           familyi={C\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Klen},
           giveni={K\bibinitperiod}}}%
        {{hash=4c3694e09d08b9f465f39a6d87e75425}{%
           family={Sandor},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=fdc22cba11bf6a6d03c1f0fb18a13d64}{%
           family={Kljun},
           familyi={K\bibinitperiod},
           given={Matjaž},
           giveni={M\bibinitperiod}}}%
        {{hash=8b5e8a5dad2a0d5be41d00d85b4f6d68}{%
           family={Huerst},
           familyi={H\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
        {{hash=e239c53df5fc80d2b9d9b7873c777e1c}{%
           family={Plopski},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=db5ddeca43552aaaa67b79b2784aad1f}{%
           family={Taketomi},
           familyi={T\bibinitperiod},
           given={Takafumi},
           giveni={T\bibinitperiod}}}%
        {{hash=0827fe60578494a531607ae22130c6e3}{%
           family={Kato},
           familyi={K\bibinitperiod},
           given={Hirokazu},
           giveni={H\bibinitperiod}}}%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{af1253566dfa5386589bebc60c24bc66}
      \strng{fullhash}{46d5649510e6fa6e5cff955af86df441}
      \strng{bibnamehash}{af1253566dfa5386589bebc60c24bc66}
      \strng{authorbibnamehash}{af1253566dfa5386589bebc60c24bc66}
      \strng{authornamehash}{af1253566dfa5386589bebc60c24bc66}
      \strng{authorfullhash}{46d5649510e6fa6e5cff955af86df441}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Augmenting arbitrary physical objects with digital content leads to the missing interface problem, because those objects were never designed to incorporate such digital content and so they lack a user interface. A review of related work reveals that current approaches fail due to limited detection fidelity and spatial resolution. Our proposal, based on Google Soli's radar sensing technology, is designed to detect micro-gestures on objects with sub-millimeter precision. Preliminary results with a custom gesture set show that Soli's core features and traditional machine learning models (Random Forest and Support Vector Machine) do not lead to robust recognition accuracy, and so more advanced techniques should be used instead, possibly incorporating additional sensor features.}
      \field{booktitle}{Extended {Abstracts} of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}}
      \field{isbn}{978-1-4503-5971-9}
      \field{month}{5}
      \field{series}{{CHI} {EA} '19}
      \field{shorttitle}{The {Missing} {Interface}}
      \field{title}{The {Missing} {Interface}: {Micro}-{Gestures} on {Augmented} {Objects}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3290607.3312986
      \endverb
      \verb{file}
      \verb Čopič Pucihar et al. - 2019 - The Missing Interface Micro-Gestures on Augmented.pdf:C\:\\Users\\asluyters\\Zotero\\storage\\42B36A47\\Čopič Pucihar et al. - 2019 - The Missing Interface Micro-Gestures on Augmented.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3290607.3312986
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3290607.3312986
      \endverb
      \keyw{augmented reality,google soli,micro-gesture recognition,millimeter-wave radar}
    \endentry
    \entry{Pucihar:2022}{article}{}
      \name{author}{5}{}{%
        {{hash=cd51d40b40e689dab10b2edde63c4d32}{%
           family={Čopič\bibnamedelima Pucihar},
           familyi={Č\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Klen},
           giveni={K\bibinitperiod}}}%
        {{hash=2d13dddd6425b29c8d5f5c93d0143040}{%
           family={Attygalle},
           familyi={A\bibinitperiod},
           given={Nuwan\bibnamedelima T.},
           giveni={N\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{hash=c81693beede01e4b9b543d359a34b585}{%
           family={Kljun},
           familyi={K\bibinitperiod},
           given={Matjaz},
           giveni={M\bibinitperiod}}}%
        {{hash=4c3694e09d08b9f465f39a6d87e75425}{%
           family={Sandor},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{ec59d78a855177069a90e6bee067acb4}
      \strng{fullhash}{5866aaa7934ecfafb7d91aa4acbc1fd2}
      \strng{bibnamehash}{ec59d78a855177069a90e6bee067acb4}
      \strng{authorbibnamehash}{ec59d78a855177069a90e6bee067acb4}
      \strng{authornamehash}{ec59d78a855177069a90e6bee067acb4}
      \strng{authorfullhash}{5866aaa7934ecfafb7d91aa4acbc1fd2}
      \field{sortinit}{Č}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition with miniaturised radar sensors has received increasing attention as a novel interaction medium. The practical use of radar technology, however, often requires sensing through materials. Yet, it is still not well understood how the internal structure of materials impacts recognition performance. To tackle this challenge, we collected a large dataset of 14,090 radar recordings for 6 paradigmatic gesture classes sensed through a variety of everyday materials, performed by humans (6 materials) and a robot system (75 materials). Next, we developed a hybrid CNN+LSTM deep learning model and derived a robust indirect method to measure signal distortions, which we used to compile a comprehensive catalogue of materials for radar-based interaction. Among other findings, our experiments show that it is possible to estimate how different materials would affect gesture recognition performance of arbitrary classifiers by selecting just 3 reference materials. Our catalogue, software, models, data collection platform, and labeled datasets are publicly available.}
      \field{journaltitle}{Proc. ACM Hum.-Comput. Interact.}
      \field{month}{6}
      \field{number}{EICS}
      \field{title}{{Solids on Soli: Millimetre-Wave Radar Sensing through Materials}}
      \field{volume}{6}
      \field{year}{2022}
      \verb{doi}
      \verb 10.1145/3532212
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3532212
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3532212
      \endverb
      \keyw{radar interaction,deep learning,gestures,materials,soli}
    \endentry
    \entry{Cornet:2023}{thesis}{}
      \name{author}{1}{}{%
        {{hash=687be9ac28f160d57c0c04062dc1f2e1}{%
           family={Cornet},
           familyi={C\bibinitperiod},
           given={Erwin},
           giveni={E\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{687be9ac28f160d57c0c04062dc1f2e1}
      \strng{fullhash}{687be9ac28f160d57c0c04062dc1f2e1}
      \strng{bibnamehash}{687be9ac28f160d57c0c04062dc1f2e1}
      \strng{authorbibnamehash}{687be9ac28f160d57c0c04062dc1f2e1}
      \strng{authornamehash}{687be9ac28f160d57c0c04062dc1f2e1}
      \strng{authorfullhash}{687be9ac28f160d57c0c04062dc1f2e1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Thalmic Lab’s Myo Armband is a wearable device that arrived on the market several years ago. It embeds both hardware and software to transmit data that is continuously generated by sensors to a computer linked to it in order to recognize a predefined set of gestures performed by the user. The device has been studied several times in the past, in various contexts and with different techniques. However, the product was recently discontinued, and the support and documentation gone with it. The objective of this thesis is to recreate the pipeline, from the extraction of data to the insertion of processed samples into a custom framework designed for gesture recognition, emphasizing on modularity and reusability. This task requires to explore the possibility of re-engineering the entire pipeline from scratch, or with what is reminiscent of the past, for the benefit of anyone who would be in the same circumstances. It is also an opportunity to extend the set of gestures and evaluate the behaviour of the system with custom parameters. In this work, we will talk low-level programming of communication protocols, data gathering, GUI, processing of data, properties of sensors, and more.}
      \field{title}{{Human-Computer Interaction with an Armband by Electromyography}}
      \field{type}{phdthesis}
      \field{year}{2023}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:43237
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:43237
      \endverb
      \keyw{Myo,Armband,QuantumLeap,Wearable Device,Gesture Recognition}
    \endentry
    \entry{Costabile:2008}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=641575ef494a190068fe89a6ecc72b18}{%
           family={Costabile},
           familyi={C\bibinitperiod},
           given={Maria\bibnamedelima Francesca},
           giveni={M\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=0e5859af64c7ba058db25823114d01bf}{%
           family={Mussio},
           familyi={M\bibinitperiod},
           given={Piero},
           giveni={P\bibinitperiod}}}%
        {{hash=4f721f67ff1247c4feb102bbf39b06d8}{%
           family={Parasiliti\bibnamedelima Provenza},
           familyi={P\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Loredana},
           giveni={L\bibinitperiod}}}%
        {{hash=0364c6a114189e5090fe8c8a82dc9393}{%
           family={Piccinno},
           familyi={P\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{02409d54a10d1cee86f368d8a6255675}
      \strng{fullhash}{efa57286a234d5ceaaa264c74f828c48}
      \strng{bibnamehash}{02409d54a10d1cee86f368d8a6255675}
      \strng{authorbibnamehash}{02409d54a10d1cee86f368d8a6255675}
      \strng{authornamehash}{02409d54a10d1cee86f368d8a6255675}
      \strng{authorfullhash}{efa57286a234d5ceaaa264c74f828c48}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The widespread use of personal software systems and the boom of the so-called Web 2.0 is erasing the distinctions between those who create software products and those who use or consume them. End users are increasingly involved in the design and development of the tools they use. Unfortunately, there is a high incidence of errors in applications developed by end users. In this paper, a view on end-user development is outlined, which identifies the communication gap between end users and professional software developers as one main source of errors. The spectrum of users that lie between pure end users and professional developers is examined. In particular, the focus is on a particular type of end users that are very active in shaping software tools to their needs without being aware that they are programming: in short, they are unwitting programmers. Their characteristics and their need of appropriate development techniques and environments are analyzed. Finally, the meta-design participatory approach we have developed is briefly described to show how it fills the communication gap and well supports the activities of unwitting programmers.}
      \field{booktitle}{Proceedings of the 4th International Workshop on End-User Software Engineering}
      \field{isbn}{9781605580340}
      \field{series}{WEUSE '08}
      \field{title}{{End Users as Unwitting Software Developers}}
      \field{venue}{Leipzig, Germany}
      \field{year}{2008}
      \field{pages}{6\bibrangedash 10}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1145/1370847.1370849
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1370847.1370849
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1370847.1370849
      \endverb
      \keyw{end-user development,meta-design,end user,user classification}
    \endentry
    \entry{Coyette:2007}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=c1917a35af2268384b65f35cbac04c3b}{%
           family={Coyette},
           familyi={C\bibinitperiod},
           given={Adrien},
           giveni={A\bibinitperiod}}}%
        {{hash=48c038b7599e75957bf473a372b98152}{%
           family={Schimke},
           familyi={S\bibinitperiod},
           given={Sascha},
           giveni={S\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=eef25b80cfce8ca6c407848e94a1944c}{%
           family={Vielhauer},
           familyi={V\bibinitperiod},
           given={Claus},
           giveni={C\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=75b6a931783894ea9dc520bf30b422f8}{%
           family={Baranauskas},
           familyi={B\bibinitperiod},
           given={Cécilia},
           giveni={C\bibinitperiod}}}%
        {{hash=91779e8d5b875867d491385500e54a30}{%
           family={Palanque},
           familyi={P\bibinitperiod},
           given={Philippe},
           giveni={P\bibinitperiod}}}%
        {{hash=4f1268978d2059c4d9c2006944abe14e}{%
           family={Abascal},
           familyi={A\bibinitperiod},
           given={Julio},
           giveni={J\bibinitperiod}}}%
        {{hash=a835ae1f8355aa4fb015ae31b3dd6905}{%
           family={Barbosa},
           familyi={B\bibinitperiod},
           given={Simone\bibnamedelimb Diniz\bibnamedelima Junqueira},
           giveni={S\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{30ff7b9a25eb0eb74f2ce097bb534dc3}
      \strng{fullhash}{b021db1d01ac07016dc5c377a8733b09}
      \strng{bibnamehash}{30ff7b9a25eb0eb74f2ce097bb534dc3}
      \strng{authorbibnamehash}{30ff7b9a25eb0eb74f2ce097bb534dc3}
      \strng{authornamehash}{30ff7b9a25eb0eb74f2ce097bb534dc3}
      \strng{authorfullhash}{b021db1d01ac07016dc5c377a8733b09}
      \strng{editorbibnamehash}{a91f00c682977e19ece65bb66499b994}
      \strng{editornamehash}{a91f00c682977e19ece65bb66499b994}
      \strng{editorfullhash}{563099bcac481807ff14172eca940453}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we present a new algorithm for automatic recognition of hand drawn sketches based on the Levenshtein distance. The purpose for drawing sketches in our application is to create graphical user interfaces in a similar manner as the well established paper sketching. The new algorithm is trainable by every user and improves the recognition performance of the techniques which were used before for widget recognition. In addition, this algorithm ay serve for recognizing other types of sketches, such as letters, figures, and commands. In this way, there is no modality disruption at sketching time.}
      \field{booktitle}{Proc. of 11th {IFIP} {TC} 13 International Conference on Human-Computer Interaction, {INTERACT} '07}
      \field{isbn}{978-3-540-74796-3}
      \field{title}{Trainable Sketch Recognizer for Graphical User Interface Design}
      \field{venue}{Rio de Janeiro, Brazil}
      \field{year}{2007}
      \field{pages}{124\bibrangedash 135}
      \range{pages}{12}
    \endentry
    \entry{Vatavu:2016}{misc}{}
      \name{author}{3}{}{%
        {{hash=201fa2613858b4229d9056017d518b1c}{%
           family={Craciun},
           familyi={C\bibinitperiod},
           given={Elena-Gina},
           giveni={E\bibinithyphendelim G\bibinitperiod}}}%
        {{hash=683258864004d393cc414ebb6f9fb077}{%
           family={Rusu},
           familyi={R\bibinitperiod},
           given={Ionela},
           giveni={I\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \strng{namehash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \strng{fullhash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \strng{bibnamehash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \strng{authorbibnamehash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \strng{authornamehash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \strng{authorfullhash}{f32f3a42e4b88157e9d4f2f47929d99d}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{howpublished}{\url{http://www.eed.usv.ro/mintviz/projects/GIVISIMP/data/Pseudocode2.pdf}}
      \field{note}{[Online; accessed 09-August-2020]}
      \field{title}{{Free-Hand Gesture Recognizer Pseudocode}}
      \field{year}{2016}
      \keyw{Recognizer,FreeHand}
    \endentry
    \entry{Creed:2018}{article}{}
      \name{author}{1}{}{%
        {{hash=644f3ca039cbc883393c20dd43d2b96c}{%
           family={Creed},
           familyi={C\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Routledge}%
      }
      \strng{namehash}{644f3ca039cbc883393c20dd43d2b96c}
      \strng{fullhash}{644f3ca039cbc883393c20dd43d2b96c}
      \strng{bibnamehash}{644f3ca039cbc883393c20dd43d2b96c}
      \strng{authorbibnamehash}{644f3ca039cbc883393c20dd43d2b96c}
      \strng{authornamehash}{644f3ca039cbc883393c20dd43d2b96c}
      \strng{authorfullhash}{644f3ca039cbc883393c20dd43d2b96c}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Disability \& Society}
      \field{number}{7}
      \field{title}{{Assistive technology for disabled visual artists: exploring the impact of digital technologies on artistic practice}}
      \field{volume}{33}
      \field{year}{2018}
      \field{pages}{1103\bibrangedash 1119}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1080/09687599.2018.1469400
      \endverb
      \verb{eprint}
      \verb https://doi.org/10.1080/09687599.2018.1469400
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1080/09687599.2018.1469400
      \endverb
      \verb{url}
      \verb https://doi.org/10.1080/09687599.2018.1469400
      \endverb
    \endentry
    \entry{Daniels:2014}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=c718f75c0a43e1fb01e1fb7cfe431780}{%
           family={Daniels},
           familyi={D\bibinitperiod},
           given={Zachary\bibnamedelima A.},
           giveni={Z\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=88b22156b9fc71e428a342d1161be97f}{%
           family={Stinson},
           familyi={S\bibinitperiod},
           given={Steven\bibnamedelima R.},
           giveni={S\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=6eff45854010d221f562003a7239ab7c}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Shenchi},
           giveni={S\bibinitperiod}}}%
        {{hash=ce3c3833e7fd0cc6f5b27f5514c09e3c}{%
           family={Mulbry},
           familyi={M\bibinitperiod},
           given={Evan},
           giveni={E\bibinitperiod}}}%
        {{hash=bc972041ec4e3b6bf00f84d480945094}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Brian\bibnamedelima Y.},
           giveni={B\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{0ec20216d95e13fc4d8e3654e7377913}
      \strng{fullhash}{494defbae2941e29be126f0da97d9da0}
      \strng{bibnamehash}{0ec20216d95e13fc4d8e3654e7377913}
      \strng{authorbibnamehash}{0ec20216d95e13fc4d8e3654e7377913}
      \strng{authornamehash}{0ec20216d95e13fc4d8e3654e7377913}
      \strng{authorfullhash}{494defbae2941e29be126f0da97d9da0}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2014 Workshop on Mobile Augmented Reality and Robotic Technology-Based Systems}
      \field{isbn}{9781450328234}
      \field{series}{MARS '14}
      \field{title}{{A Gesture-Based Interface for the Exploration and Classification of Protein Binding Cavities}}
      \field{venue}{Bretton Woods, New Hampshire, USA}
      \field{year}{2014}
      \field{pages}{47\bibrangedash 50}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/2609829.2609838
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2609829.2609838
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2609829.2609838
      \endverb
      \keyw{gesture-recognition,human computer interaction,protein structure analysis}
    \endentry
    \entry{DeCoster:2018a}{article}{}
      \name{author}{2}{}{%
        {{hash=3bcb58fdd31ff63bd36db11857d955ef}{%
           family={De\bibnamedelima Coster},
           familyi={D\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Albéric},
           giveni={A\bibinitperiod}}}%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{eae803924da78aa5dcf49d2e6e41b27f}
      \strng{fullhash}{eae803924da78aa5dcf49d2e6e41b27f}
      \strng{bibnamehash}{eae803924da78aa5dcf49d2e6e41b27f}
      \strng{authorbibnamehash}{eae803924da78aa5dcf49d2e6e41b27f}
      \strng{authornamehash}{eae803924da78aa5dcf49d2e6e41b27f}
      \strng{authorfullhash}{eae803924da78aa5dcf49d2e6e41b27f}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}
      \field{number}{2}
      \field{title}{{Fusion of Multifrequency GPR Data Freed From Antenna Effects}}
      \field{volume}{11}
      \field{year}{2018}
      \field{pages}{664\bibrangedash 674}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/JSTARS.2018.2790419
      \endverb
    \endentry
    \entry{DePrisco:2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=674f111b2f47c7ef6b86397c18252107}{%
           family={De\bibnamedelima Prisco},
           familyi={D\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod}}}%
        {{hash=2ede4a9fdaa49fc81499496b8389753a}{%
           family={Malandrino},
           familyi={M\bibinitperiod},
           given={Delfina},
           giveni={D\bibinitperiod}}}%
        {{hash=f6fa46a329ecbd9789939fbeaf05273a}{%
           family={Zaccagnino},
           familyi={Z\bibinitperiod},
           given={Gianluca},
           giveni={G\bibinitperiod}}}%
        {{hash=1a6d3e25353c7bbdd25f52442447952a}{%
           family={Zaccagnino},
           familyi={Z\bibinitperiod},
           given={Rocco},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{f0540978a72883a65586a1aace90d9d8}
      \strng{fullhash}{988b6a47eb7d30c6812a2ffc6c3c22d8}
      \strng{bibnamehash}{f0540978a72883a65586a1aace90d9d8}
      \strng{authorbibnamehash}{f0540978a72883a65586a1aace90d9d8}
      \strng{authornamehash}{f0540978a72883a65586a1aace90d9d8}
      \strng{authorfullhash}{988b6a47eb7d30c6812a2ffc6c3c22d8}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the International Working Conference on Advanced Visual Interfaces}
      \field{isbn}{9781450341318}
      \field{series}{AVI '16}
      \field{title}{{Natural User Interfaces to Support and Enhance Real-Time Music Performance}}
      \field{venue}{Bari, Italy}
      \field{year}{2016}
      \field{pages}{204\bibrangedash 211}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2909132.2909249
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2909132.2909249
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2909132.2909249
      \endverb
      \keyw{Music Performance,Neural Networks,Evaluation,Natural User Interfaces}
    \endentry
    \entry{DeSmedt:2017}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=b9967969dce6160958bd9cdd7787b2a5}{%
           family={De\bibnamedelima Smedt},
           familyi={D\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=12e365e453b0159869812a93f26b6336}{%
           family={Wannous},
           familyi={W\bibinitperiod},
           given={Hazem},
           giveni={H\bibinitperiod}}}%
        {{hash=b49da2cad6ed218e27f519dcdcc03d90}{%
           family={Vandeborre},
           familyi={V\bibinitperiod},
           given={Jean-Philippe},
           giveni={J\bibinithyphendelim P\bibinitperiod}}}%
        {{hash=5b81c6ce94bdf88a53febe71831cfcbf}{%
           family={Guerry},
           familyi={G\bibinitperiod},
           given={Joris},
           giveni={J\bibinitperiod}}}%
        {{hash=ad90438395d3b982c0cc109ec887849f}{%
           family={Saux},
           familyi={S\bibinitperiod},
           given={Bertrand\bibnamedelima Le},
           giveni={B\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=86d3a84fdaeef92ef05a26619046b52c}{%
           family={Filliat},
           familyi={F\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Goslar, DEU}%
      }
      \list{publisher}{1}{%
        {Eurographics Association}%
      }
      \strng{namehash}{bc20c25941e41f228ecdebad6d26d246}
      \strng{fullhash}{5c4219d99103829aad091cc7aee51835}
      \strng{bibnamehash}{bc20c25941e41f228ecdebad6d26d246}
      \strng{authorbibnamehash}{bc20c25941e41f228ecdebad6d26d246}
      \strng{authornamehash}{bc20c25941e41f228ecdebad6d26d246}
      \strng{authorfullhash}{5c4219d99103829aad091cc7aee51835}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Workshop on 3D Object Retrieval}
      \field{series}{3Dor ’17}
      \field{title}{{3D Hand Gesture Recognition Using a Depth and Skeletal Dataset: SHREC’17 Track}}
      \field{venue}{Lyon, France}
      \field{year}{2017}
      \field{pages}{33\bibrangedash 38}
      \range{pages}{6}
      \verb{doi}
      \verb 10.2312/3dor.20171049
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.2312/3dor.20171049
      \endverb
      \verb{url}
      \verb https://doi.org/10.2312/3dor.20171049
      \endverb
    \endentry
    \entry{Dekker:2017}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=071bca7c77f0381c3ef7b5c077a08a0f}{%
           family={Dekker},
           familyi={D\bibinitperiod},
           given={Bastiaan},
           giveni={B\bibinitperiod}}}%
        {{hash=0b1194a972ee5450d94ffd6bd64e3693}{%
           family={Jacobs},
           familyi={J\bibinitperiod},
           given={Sebastiaan},
           giveni={S\bibinitperiod}}}%
        {{hash=0a3354030cab00fc1adb39df0df67ea1}{%
           family={Kossen},
           familyi={K\bibinitperiod},
           given={A.\bibnamedelimi S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=746b46dec3fa133fc76b560c707e47a7}{%
           family={Kruithof},
           familyi={K\bibinitperiod},
           given={Maarten\bibnamedelima C.},
           giveni={M\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=f45c30e680d384053634f8fd0a877796}{%
           family={Huizing},
           familyi={H\bibinitperiod},
           given={Albert\bibnamedelima G.},
           giveni={A\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=a6f1daa24ba1a6ef40f75c037412d162}{%
           family={Geurts},
           familyi={G\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{2d2421c6ffe424fd5b6b62bd8ff6400a}
      \strng{fullhash}{0ded61ba750b40daf1ad57e3d8c1eb7d}
      \strng{bibnamehash}{2d2421c6ffe424fd5b6b62bd8ff6400a}
      \strng{authorbibnamehash}{2d2421c6ffe424fd5b6b62bd8ff6400a}
      \strng{authornamehash}{2d2421c6ffe424fd5b6b62bd8ff6400a}
      \strng{authorfullhash}{0ded61ba750b40daf1ad57e3d8c1eb7d}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition with radar enables remote control of consumer devices such as audio equipment, television sets and gaming consoles. In this paper, experimental results of hand gesture recognition with a low power FMCW radar and a deep convolutional neural network (CNN) are presented. The FMCW radar operates in the 24 GHz ISM frequency band and has an effective isotropic radiated power level of 0 dBm. Since low power consumption is a key aspect for application in consumer devices, the FMCW radar has only one receive channel which is different from other FMCW radars with multiple receive channels that have been described in literature. The recognition of gestures is performed with a deep convolutional neural network that is trained and tested with micro-Doppler spectrograms yielding excellent recognition performance in a simple test case consisting of 3 different gestures. A comparison of the training and test results for an amplitude spectrogram and a complex-valued spectrogram as the CNN input shows that in this test case there is no major benefit of using the phase information in the spectrogram.}
      \field{booktitle}{Proceedings of the {European} {Radar} {Conference}}
      \field{month}{10}
      \field{series}{{EURAD} '17}
      \field{title}{Gesture recognition with a low power {FMCW} radar and a deep convolutional neural network}
      \field{year}{2017}
      \field{pages}{163\bibrangedash 166}
      \range{pages}{4}
      \verb{doi}
      \verb 10.23919/EURAD.2017.8249172
      \endverb
      \keyw{24 GHz,24 GHz ISM frequency band,amplitude spectrogram,CNN,complex-valued spectrogram,consumer devices,convolution,convolutional neural network,CW radar,deep convolutional neural network,deep learning,Doppler radar,feedforward neural nets,FM radar,FMCW,frequency 24.0 GHz,gesture,gesture recognition,Gesture recognition,hand gesture recognition,low power consumption,low power FMCW radar,low power radar device,micro-Doppler spectrograms,Optical sensors,phase information,power level,radar,Radar,Radar antennas,recognition,remote control,Spectrogram,telecontrol,Training}
    \endentry
    \entry{Delamare:2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=49492c24f5f178ee1c9f2ae111b2f17f}{%
           family={Delamare},
           familyi={D\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
        {{hash=bfd7e05f18f3b2e1aeb8944a09c68452}{%
           family={Silpasuwanchai},
           familyi={S\bibinitperiod},
           given={Chaklam},
           giveni={C\bibinitperiod}}}%
        {{hash=ed3a7762006d0a336ea53624b05675d0}{%
           family={Sarcar},
           familyi={S\bibinitperiod},
           given={Sayan},
           giveni={S\bibinitperiod}}}%
        {{hash=2b681bf14c36517f33cdcf7f161480c3}{%
           family={Shiraki},
           familyi={S\bibinitperiod},
           given={Toshiaki},
           giveni={T\bibinitperiod}}}%
        {{hash=d26f0fbb9c09d02285a9ccf424703009}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Xiangshi},
           giveni={X\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6403267011f5cf776c450e21c27e025b}
      \strng{fullhash}{ae65e0762b6f97f0f6f2c7009e1c40f5}
      \strng{bibnamehash}{6403267011f5cf776c450e21c27e025b}
      \strng{authorbibnamehash}{6403267011f5cf776c450e21c27e025b}
      \strng{authornamehash}{6403267011f5cf776c450e21c27e025b}
      \strng{authorfullhash}{ae65e0762b6f97f0f6f2c7009e1c40f5}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Current gesture interaction paradigm mainly involves a one-to-one gesture-command mapping. This leads to memorability issues regarding (1) the mapping - as each new command requires a new gesture, and (2) the gestures specifics (e.g., motion paths) - that can be complex to leverage the recognition of several gestures. We explore the concept of combining 3D gestures when interacting in smart environments. We first propose a design space to characterize the temporal and spatial combination aspects, and the gesture types used by the combination. We then report results from three user studies in the context of smart TV interaction. The first study reveals that end-users can create gesture sets with combinations fully optimized to reuse gestures. The second study shows that combining gestures can lead to improved memorability compared to single gestures. The third study reveals that preferences for gestures combination appear when single gestures have an abstract gesture-command mapping.}
      \field{booktitle}{Proceedings of the 2019 ACM International Conference on Interactive Surfaces and Spaces}
      \field{isbn}{9781450368919}
      \field{series}{ISS '19}
      \field{title}{{On Gesture Combination: An Exploration of a Solution to Augment Gesture Interaction}}
      \field{venue}{Daejeon, Republic of Korea}
      \field{year}{2019}
      \field{pages}{135\bibrangedash 146}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3343055.3359706
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3343055.3359706
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3343055.3359706
      \endverb
      \keyw{two-handed interaction,mid-air interaction,gestural interaction,gesture combination,freehand gestures}
    \endentry
    \entry{Dingler:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=17cf45d6cd389acaf019fa2be25746d4}{%
           family={Dingler},
           familyi={D\bibinitperiod},
           given={Tilman},
           giveni={T\bibinitperiod}}}%
        {{hash=62baa9c0964811ebaff2ae3bcc7f2f95}{%
           family={Rzayev},
           familyi={R\bibinitperiod},
           given={Rufat},
           giveni={R\bibinitperiod}}}%
        {{hash=dffcddeada9e3fcc5ff2bcfbcb0625dd}{%
           family={Shirazi},
           familyi={S\bibinitperiod},
           given={Alireza\bibnamedelima Sahami},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=c1973e9439e04486b2d6cabaa70cc385}{%
           family={Henze},
           familyi={H\bibinitperiod},
           given={Niels},
           giveni={N\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{dd4385676cd005837a79e139e70b15ab}
      \strng{fullhash}{6baaec6394b24300cd006c4633bb3d96}
      \strng{bibnamehash}{dd4385676cd005837a79e139e70b15ab}
      \strng{authorbibnamehash}{dd4385676cd005837a79e139e70b15ab}
      \strng{authornamehash}{dd4385676cd005837a79e139e70b15ab}
      \strng{authorfullhash}{6baaec6394b24300cd006c4633bb3d96}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In the era of ubiquitous computing, people expect applications to work across different devices. To provide a seamless user experience it is therefore crucial that interfaces and interactions are consistent across different device types. In this paper, we present a method to create gesture sets that are consistent and easily transferable. Our proposed method entails 1) the gesture elicitation on each device type, 2) the consolidation of a unified gesture set, and 3) a final validation by calculating a transferability score. We tested our approach by eliciting a set of user-defined gestures for reading with Rapid Serial Visual Presentation (RSVP) of text for three device types: phone, watch, and glasses. We present the resulting, unified gesture set for RSVP reading and show the feasibility of our method to elicit gesture sets that are consistent across device types with different form factors.}
      \field{booktitle}{Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450356206}
      \field{series}{CHI '18}
      \field{title}{{Designing Consistent Gestures Across Device Types: Eliciting RSVP Controls for Phone, Watch, and Glasses}}
      \field{venue}{Montreal QC, Canada}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 12}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3173574.3173993
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3173574.3173993
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3173574.3173993
      \endverb
      \keyw{rsvp,gesture elicitation,consistency,transferability,design methods}
    \endentry
    \entry{Dong:2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=3002d5572e17530ea024008f0defb98c}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Haiwei},
           giveni={H\bibinitperiod}}}%
        {{hash=e0e7d32ef3a3c11385c44ce34e53e2a6}{%
           family={Figueroa},
           familyi={F\bibinitperiod},
           given={Nadia},
           giveni={N\bibinitperiod}}}%
        {{hash=62d97bc93eec46205dd45afb8e2a6140}{%
           family={El\bibnamedelima Saddik},
           familyi={E\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={Abdulmotaleb},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \strng{fullhash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \strng{bibnamehash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \strng{authorbibnamehash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \strng{authornamehash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \strng{authorfullhash}{10f27710460ec8fe0e5e7ebd25ad1521}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the introduction of new depth sensing technologies, interactive hand-gesture devices are rapidly emerging. However, the hand-gestures used in these devices do not follow a common vocabulary, making certain control command device-specific. In this paper we present an initial effort to create a standardized interactive hand-gesture vocabulary for the next generation of television applications. We conduct a user-elicitation study using a survey in order to define a common vocabulary for specific control commands, such as Volume up/down, Menu open/close, etc. This survey is entirely user-oriented and thus it has two phases. In the first phase, we ask open questions about specific commands. In the second phase, we use the answers suggested from the first phase to create a multiple choice questionnaire. Based on the results from the survey, we study the gesture attitudes and preferences between gender groups, and between age groups with a quantitative and qualitative statistical analysis. Finally, the hand-gesture vocabulary is derived after applying an agreement analysis on the user-elicited gestures. The proposed methodology for gesture set design is comparable with existing methodologies and yields higher agreement levels than relevant user-elicited studies in the field.}
      \field{booktitle}{Proceedings of the 23rd ACM International Conference on Multimedia}
      \field{isbn}{9781450334594}
      \field{series}{MM '15}
      \field{title}{{An Elicitation Study on Gesture Attitudes and Preferences Towards an Interactive Hand-Gesture Vocabulary}}
      \field{venue}{Brisbane, Australia}
      \field{year}{2015}
      \field{pages}{999\bibrangedash 1002}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/2733373.2806385
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2733373.2806385
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2733373.2806385
      \endverb
      \keyw{hand-gesture interaction,kinect,preferences and attitudes}
    \endentry
    \entry{Drossis:2013}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=57492d79e69cf208e8a619c00ac766fd}{%
           family={Drossis},
           familyi={D\bibinitperiod},
           given={Giannis},
           giveni={G\bibinitperiod}}}%
        {{hash=45541752bfc9fb6411b2d1a861a62d11}{%
           family={Grammenos},
           familyi={G\bibinitperiod},
           given={Dimitris},
           giveni={D\bibinitperiod}}}%
        {{hash=239f1ba4aff79005c8924f6258531382}{%
           family={Birliraki},
           familyi={B\bibinitperiod},
           given={Chryssi},
           giveni={C\bibinitperiod}}}%
        {{hash=24eede26cf84a8d622e5673c93b91295}{%
           family={Stephanidis},
           familyi={S\bibinitperiod},
           given={Constantine},
           giveni={C\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=24eede26cf84a8d622e5673c93b91295}{%
           family={Stephanidis},
           familyi={S\bibinitperiod},
           given={Constantine},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{45be3ca8ee85162a1344048d56abfd76}
      \strng{fullhash}{901d92b3c562891457247c14d674abf2}
      \strng{bibnamehash}{45be3ca8ee85162a1344048d56abfd76}
      \strng{authorbibnamehash}{45be3ca8ee85162a1344048d56abfd76}
      \strng{authornamehash}{45be3ca8ee85162a1344048d56abfd76}
      \strng{authorfullhash}{901d92b3c562891457247c14d674abf2}
      \strng{editorbibnamehash}{24eede26cf84a8d622e5673c93b91295}
      \strng{editornamehash}{24eede26cf84a8d622e5673c93b91295}
      \strng{editorfullhash}{24eede26cf84a8d622e5673c93b91295}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Touchless remote interaction empowers users to interact with systems at a distance without the burden of actually coming to physical contact with any tangible object. The research presented in this paper focuses on motion-based interaction in public spaces through hand detection using Microsoft's Kinect, in order to allow natural interaction in mid-air. The paper presents the development of a system that allows browsing and exploring large collections of multimedia information (images and videos).}
      \field{booktitle}{HCI International 2013 - Posters' Extended Abstracts}
      \field{isbn}{978-3-642-39473-7}
      \field{title}{{MAGIC: Developing a Multimedia Gallery Supporting mid-Air Gesture-Based Interaction and Control}}
      \field{year}{2013}
      \field{pages}{303\bibrangedash 307}
      \range{pages}{5}
    \endentry
    \entry{Du:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=774bcea731ae3c9c871f634a59777b3a}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Chong\bibnamedelima Yang},
           giveni={C\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
        {{hash=25e9200955211577f5650155825f9f1f}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xin\bibnamedelima Huai},
           giveni={X\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=de5bf0b7cc3fb12c49ab3007b21752ed}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Zuan\bibnamedelima Xing},
           giveni={Z\bibinitperiod\bibinitdelim X\bibinitperiod}}}%
        {{hash=cb03af4cfc17800e9475f6e64d65b7ff}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Yin},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{becc1c5e02e73db0b11882bfa9d95e17}
      \strng{fullhash}{573769dbd1d4b3407e4f1b2603e21b59}
      \strng{bibnamehash}{becc1c5e02e73db0b11882bfa9d95e17}
      \strng{authorbibnamehash}{becc1c5e02e73db0b11882bfa9d95e17}
      \strng{authornamehash}{becc1c5e02e73db0b11882bfa9d95e17}
      \strng{authorfullhash}{573769dbd1d4b3407e4f1b2603e21b59}
      \field{extraname}{1}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper a gesture recognition system based on millimeter wave radar (MMW) will be presented. The radio frequency (RF) transceiver circuit is built with the TI-manufactured AWR1443 highly integrated frequency modulated continuous wave (FMCW) RF transceiver chip which has an operating frequency of 76-81 GHz, a 3-channel transmitter, and a 4-channel receptor. The antenna array is constructed with a 1 x 16 microstrip antenna. The deep learning is conducted using TensorFlow on the sample data acquired from an ADC sampling done at the radar front-end section, which ultimately realizes the function of gesture recognition.}
      \field{booktitle}{2019 {International} {Conference} on {Microwave} and {Millimeter} {Wave} {Technology} ({ICMMT})}
      \field{month}{5}
      \field{title}{Design of {Gesture} {Recognition} {System} {Based} on {77GHz} {Millimeter} {Wave} {Radar}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 3}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1109/ICMMT45702.2019.8992849
      \endverb
      \keyw{1 x 16 microstrip antenna,3-channel transmitter,4-channel receptor,antenna arrays,continuous wave RF transceiver chip,CW radar,FM radar,frequency 76.0 GHz to 81.0 GHz,frequency modulation,gesture recognition,gesture recognition system,microstrip antenna arrays,microstrip antennas,millimeter wave radar,millimetre wave radar,operating frequency,radar antennas,radar front-end section,radio frequency transceiver circuit,road vehicle radar,TI-manufactured AWR1443 highly integrated frequency}
    \endentry
    \entry{Du:2020}{article}{}
      \name{author}{5}{}{%
        {{hash=d9ad83d78196c33e32e44ee316afe819}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Chuan},
           giveni={C\bibinitperiod}}}%
        {{hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
        {{hash=3da3e37c88472b0cc032bccb1facf3b7}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Xiping},
           giveni={X\bibinitperiod}}}%
        {{hash=4d0026a8acbc76f5eae94e86a0898801}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Junxu},
           giveni={J\bibinitperiod}}}%
        {{hash=34667f9a9ac02f9b439df63c6fa33cba}{%
           family={Sheng},
           familyi={S\bibinitperiod},
           given={Jialian},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{bc37e9d1c2348f5f2c1cb4b1a1857cfa}
      \strng{fullhash}{11d1ae09bc2d430b2a5ac3c179cc4226}
      \strng{bibnamehash}{bc37e9d1c2348f5f2c1cb4b1a1857cfa}
      \strng{authorbibnamehash}{bc37e9d1c2348f5f2c1cb4b1a1857cfa}
      \strng{authornamehash}{bc37e9d1c2348f5f2c1cb4b1a1857cfa}
      \strng{authorfullhash}{11d1ae09bc2d430b2a5ac3c179cc4226}
      \field{extraname}{2}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Millimeter-wave (MMW) radar hand gesture recognition technology is becoming important in many electronic device control applications. Currently, most existing approaches utilize the radical and micro-Doppler features from single-channel MMW radar, which ignores the different importance of the information contained in the micro-Doppler feature background or target areas. In this paper, we propose an algorithm for hand gesture recognition jointly using multi-channel signatures. The algorithm blends the information of both micro-Doppler features and instantaneous angles (azimuth and elevation) to accomplish hand gesture recognition performed with the convolutional neural network (CNN). To have a better features fusion and make CNN focus on the most important target signal regions and suppress the unnecessary noise areas, we apply the channel and spatial attention-based feature refinement modules. We also employ gesture movement mechanism-based data augmentation for more effective training to alleviate potential overfitting. Extensive experiments demonstrate the effectiveness and superiorities of the proposed algorithm. This method achieves a correct classification rate of 96.61\%, approximately 5\% higher than that of the single-channel-based recognition strategy as measured based on MMW radar datasets.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Enhanced {Multi}-{Channel} {Feature} {Synthesis} for {Hand} {Gesture} {Recognition} {Based} on {CNN} {With} a {Channel} and {Spatial} {Attention} {Mechanism}}
      \field{volume}{8}
      \field{year}{2020}
      \field{pages}{144610\bibrangedash 144620}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/ACCESS.2020.3010063
      \endverb
      \keyw{Azimuth,channel and spatial attention mechanism,CNN,convolutional neural nets,convolutional neural network,data augmentation,electronic device control applications,enhanced multichannel feature synthesis,feature extraction,features fusion,gesture movement mechanism-based data augmentation,gesture recognition,Gesture recognition,Hand gesture recognition,image classification,microDoppler features,Millimeter wave radar,millimeter-wave radar hand gesture recognition technology,MMW radar datasets,multi-channel signatures,multichannel signatures,Radar antennas,Sensors,single-channel MMW radar,single-channel-based recognition strategy,spatial attention-based feature refinement modules,target areas,target signal regions,Task analysis}
    \endentry
    \entry{Duda:2000}{book}{}
      \name{author}{3}{}{%
        {{hash=972ec1d2535a1c1ea947c7b5fad399f6}{%
           family={Duda},
           familyi={D\bibinitperiod},
           given={Richard\bibnamedelima O.},
           giveni={R\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=a9ce6ce2ae6a0f1ac64e4efe810d622c}{%
           family={Hart},
           familyi={H\bibinitperiod},
           given={Peter\bibnamedelima E.},
           giveni={P\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=4c472620a4d52e9eee98e123daa1c44b}{%
           family={Stork},
           familyi={S\bibinitperiod},
           given={David\bibnamedelima G.},
           giveni={D\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Wiley \& Sons, New York}%
      }
      \strng{namehash}{c267cc9aa71114d9d59df71aa85e913f}
      \strng{fullhash}{c267cc9aa71114d9d59df71aa85e913f}
      \strng{bibnamehash}{c267cc9aa71114d9d59df71aa85e913f}
      \strng{authorbibnamehash}{c267cc9aa71114d9d59df71aa85e913f}
      \strng{authornamehash}{c267cc9aa71114d9d59df71aa85e913f}
      \strng{authorfullhash}{c267cc9aa71114d9d59df71aa85e913f}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Pattern Classification}
      \field{year}{2000}
    \endentry
    \entry{Dumas:2019}{article}{}
      \name{author}{4}{}{%
        {{hash=d79f56d746de547b61125a1f1b06057b}{%
           family={Dumas},
           familyi={D\bibinitperiod},
           given={Catherine},
           giveni={C\bibinitperiod}}}%
        {{hash=51f83e2214aeb9888fb429a564fe73a0}{%
           family={Erdelez},
           familyi={E\bibinitperiod},
           given={Sanda},
           giveni={S\bibinitperiod}}}%
        {{hash=015d9e2db1619dcb76b709e313ecae3e}{%
           family={Pomerantz},
           familyi={P\bibinitperiod},
           given={Jeffrey},
           giveni={J\bibinitperiod}}}%
        {{hash=b70ec80fe0586da49b51076bf4a9a3d5}{%
           family={Parthiban},
           familyi={P\bibinitperiod},
           given={Vik},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{9da61b15a894fedf7cb16bc085938ee1}
      \strng{fullhash}{a092adfe734fa4bd194e72c3f4b75c34}
      \strng{bibnamehash}{9da61b15a894fedf7cb16bc085938ee1}
      \strng{authorbibnamehash}{9da61b15a894fedf7cb16bc085938ee1}
      \strng{authornamehash}{9da61b15a894fedf7cb16bc085938ee1}
      \strng{authorfullhash}{a092adfe734fa4bd194e72c3f4b75c34}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{ABSTRACT A usability study was conducted on a new human-computer web interface for large displays created by researchers from the Media Lab at MIT (Massachusetts Institute of Technology). Data was collected by observing 12 subjects who were asked interact with a large screen monitor using a set of gestures. The subjects were also asked to complete a survey after they participated. The purpose of the study was to discover new methods of how people interact with a large display using gestures. By understanding how people use this interface, novel applications that reflect user preferences can be designed. Our findings discovered usability and technology issues that were given to the creators of the web-interface that was evaluated in this study. We also created usability testing protocol that will be used in future studies of this gesture-based application.}
      \field{journaltitle}{Proceedings of the Association for Information Science and Technology}
      \field{number}{1}
      \field{title}{{Usability testing of LUI: A new human-computer interface for large displays}}
      \field{volume}{56}
      \field{year}{2019}
      \field{pages}{645\bibrangedash 647}
      \range{pages}{3}
      \verb{doi}
      \verb https://doi.org/10.1002/pra2.118
      \endverb
      \verb{eprint}
      \verb https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.118
      \endverb
      \verb{urlraw}
      \verb https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.118
      \endverb
      \verb{url}
      \verb https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.118
      \endverb
      \keyw{usability testing,gesture-based technology,extended reality}
    \endentry
    \entry{Eggimann:2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=823d7cf844f6f06cea54d180d8200dd2}{%
           family={Eggimann},
           familyi={E\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod}}}%
        {{hash=493bd5768227bd32990a23d84374a72e}{%
           family={Erb},
           familyi={E\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod}}}%
        {{hash=bf30cc5f43921c4f91540b119e0c3fdf}{%
           family={Mayer},
           familyi={M\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod}}}%
        {{hash=f5c1a59b7136775c61075aa97ace5d61}{%
           family={Magno},
           familyi={M\bibinitperiod},
           given={Michele.},
           giveni={M\bibinitperiod}}}%
        {{hash=ba31f0daddec3d14ef6a4f5279845d2d}{%
           family={Benini},
           familyi={B\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{4f4df8b161a52e306399a60817f23660}
      \strng{fullhash}{70f0d4ab439dec7d64e60358652984c5}
      \strng{bibnamehash}{4f4df8b161a52e306399a60817f23660}
      \strng{authorbibnamehash}{4f4df8b161a52e306399a60817f23660}
      \strng{authornamehash}{4f4df8b161a52e306399a60817f23660}
      \strng{authorfullhash}{70f0d4ab439dec7d64e60358652984c5}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This work proposes a low-power high-accuracy embedded hand-gesture recognition using low power short-range radar sensors. The hardware and software match the requirements for battery-operated wearable devices. A 2D Convolutional Neural Network (CNN) using range frequency Doppler features is combined with a Temporal Convolutional Neural Network (TCN) for time sequence prediction. The final algorithm has a model size of only 45723 parameters, yielding a memory footprint of only 91kB. Two datasets containing 11 challenging hand gestures performed by 26 different people have been recorded containing a total of 20210 gesture instances. On the 11 hands, gestures and an accuracy of 87\% (26 users) and 92\% (single user) have been achieved. Furthermore, the prediction algorithm has been implemented in the GAP8 Parallel Ultra-Low-Power processor by GreenWaves Technologies, showing that live-prediction is feasible with only 21mW of power consumption for the full gesture prediction neural network.}
      \field{booktitle}{2019 {IEEE} {SENSORS}}
      \field{month}{10}
      \field{note}{ISSN: 2168-9229}
      \field{title}{Low {Power} {Embedded} {Gesture} {Recognition} {Using} {Novel} {Short}-{Range} {Radar} {Sensors}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/SENSORS43011.2019.8956617
      \endverb
      \keyw{2D convolutional neural network using range frequency Doppler features,battery-operated wearable devices,challenging hand gestures,convolutional neural nets,Embedded Artificial Intelligence,GAP8 parallel ultra-low-power processor,gesture instances,gesture prediction neural network,gesture recognition,Gesture recognition,Low power,low power short-range radar sensors,low-power high-accuracy embedded hand-gesture recognition,Mini-Radar sensors,novel short-range radar sensors,power consumption,prediction algorithm,radar detection,temporal convolutional neural network,time sequence prediction,Wearable,wearable computers}
    \endentry
    \entry{Ehrnsperger:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=2bd9936b4e58ba2cf87613296e376cbd}{%
           family={Ehrnsperger},
           familyi={E\bibinitperiod},
           given={Matthias\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=a03addfd6cad324457f2c6fc4407fde9}{%
           family={Hoese},
           familyi={H\bibinitperiod},
           given={Henri\bibnamedelima L.},
           giveni={H\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=4e233aa9aa21cf4bbc59a47976a0aa1d}{%
           family={Siart},
           familyi={S\bibinitperiod},
           given={Uwe},
           giveni={U\bibinitperiod}}}%
        {{hash=187f734d83455337adb74192c8e7cf01}{%
           family={Eibert},
           familyi={E\bibinitperiod},
           given={Thomas\bibnamedelima F.},
           giveni={T\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{fullhash}{302c089dae047e0413e2c601b3b2318b}
      \strng{bibnamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authorbibnamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authornamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authorfullhash}{302c089dae047e0413e2c601b3b2318b}
      \field{extraname}{1}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar based gesture recognition offers great opportunities to increase user-friendliness of countless applications at home, in transportation and for industries. Here, not only data-intensive image and video processing, but also 1D multior single-channel time-series signals are in focus. We examine classical machine learning (ML) approaches and compare them in a reproducible manner. We evaluate the performance of naive methods-such as threshold detection (THD)-and classical ML methods-such as the support vector machine (SVM). The performance is hereby judged by elements such as accuracy, false-positive rate (FPR), training and prediction time, hardware (HW) requirements and real-time capabilities as well as the size of the classifier. To create the library needed for the given investigation, a two channel continuous wave (CW) modulated radar system with carrier frequency of 10 GHz has been employed. We conclude that naive methods are outperformed by all investigated classical ML methodologies. The results in terms of accuracy and FPR are satisfactory. However, there are large differences between naive and ML methods in terms of HW requirements and real time performance. In conclusion, classical ML methods fulfil the defined requirements satisfactorily, only the real-time performance on low-performance HW is limited due to the required computing power. Thus, the algorithms are a good choice for gesture recognition-of 1D multior single-channel time-series signals-if applied correctly.}
      \field{booktitle}{2019 {Kleinheubach} {Conference}}
      \field{month}{9}
      \field{title}{Performance {Investigation} of {Machine} {Learning} {Algorithms} for {Simple} {Human} {Gesture} {Recognition} {Employing} an {Ultra} {Low} {Cost} {Radar} {System}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \keyw{1D multior single-channel time-series signals,Artificial Intelligence,channel continuous wave modulated radar system,classical machine learning approaches,classical ML methods,countless applications,data-intensive image,Feature extraction,FPR,frequency 10.0 GHz,gesture recognition,Gesture recognition,Gesture Recognition,Hardware,hardware requirements,HW requirements,investigated classical ML methodologies,learning (artificial intelligence),Low-Cost-Radar,low-performance HW,Machine Learning,naive methods,Neural Networks,prediction time,Radar,radar based gesture recognition,real-time capabilities,real-time performance,Real-time systems,reproducible manner,simple human gesture recognition,support vector machine,support vector machines,Support vector machines,threshold detection,Training,ultra low cost radar system,user-friendliness,video processing}
    \endentry
    \entry{Ehrnsperger:2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=2bd9936b4e58ba2cf87613296e376cbd}{%
           family={Ehrnsperger},
           familyi={E\bibinitperiod},
           given={Matthias\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=821c79eb23d7b75bcab9e11c7d98d52e}{%
           family={Brenner},
           familyi={B\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=4e233aa9aa21cf4bbc59a47976a0aa1d}{%
           family={Siart},
           familyi={S\bibinitperiod},
           given={Uwe},
           giveni={U\bibinitperiod}}}%
        {{hash=187f734d83455337adb74192c8e7cf01}{%
           family={Eibert},
           familyi={E\bibinitperiod},
           given={Thomas\bibnamedelima F.},
           giveni={T\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{fullhash}{fa583bdfea010827b03b03575615ffec}
      \strng{bibnamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authorbibnamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authornamehash}{cb076fd9b8cea4b15d027514e8ee969c}
      \strng{authorfullhash}{fa583bdfea010827b03b03575615ffec}
      \field{extraname}{2}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Ultra-low-cost radar hardware (HW) in combination with low-cost processing units is investigated in order to create and evaluate a holistic ultra-low-cost gesture recognition system. We study the real-time performance of novel machine learning (nML) methods: neural networks (NNs), in particular shallow architectures of convolutional neural networks (CNNs). The real-time performance of each approach is judged by computational complexity, prediction time, accuracy, and false-positive rate (FPR). As HW, a two-channel radar system with continuous wave (CW) modulation at a carrier frequency of 10 GHz has been employed throughout the investigations. The algorithms are designed, trained, evaluated, and juxtaposed. The results show that the classification process on low-cost HW is feasible and allows to achieve accuracies of 97.9\% and FPRs of 1.72\%, all of which with a response time of less than 180 ms.}
      \field{booktitle}{2020 {German} {Microwave} {Conference} ({GeMiC})}
      \field{month}{3}
      \field{note}{ISSN: 2167-8022}
      \field{title}{Real-{Time} {Gesture} {Recognition} with {Shallow} {Convolutional} {Neural} {Networks} {Employing} an {Ultra} {Low} {Cost} {Radar} {System}}
      \field{year}{2020}
      \field{pages}{88\bibrangedash 91}
      \range{pages}{4}
      \keyw{artificial intelligence,continuous wave modulation,convolutional neural nets,false-positive rate,gesture recognition,holistic ultra-low-cost gesture recognition system,learning (artificial intelligence),low-cost,machine learning,neural networks,radar,real-time,real-time gesture recognition,shallow architectures,shallow convolutional neural networks,two-channel radar system,ultra low cost radar system,ultra-low-cost radar hardware}
    \endentry
    \entry{Ekman:1969}{article}{}
      \name{author}{2}{}{%
        {{hash=f57fd5f1b9feec71b7d8f0ce35b57dbc}{%
           family={Ekman},
           familyi={E\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=cddd249b8d4a78b56d625f20556bcc88}{%
           family={Friesen},
           familyi={F\bibinitperiod},
           given={Wallace\bibnamedelima V.},
           giveni={W\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{7c96d5c8319baea6fb804debef7b7748}
      \strng{fullhash}{7c96d5c8319baea6fb804debef7b7748}
      \strng{bibnamehash}{7c96d5c8319baea6fb804debef7b7748}
      \strng{authorbibnamehash}{7c96d5c8319baea6fb804debef7b7748}
      \strng{authornamehash}{7c96d5c8319baea6fb804debef7b7748}
      \strng{authorfullhash}{7c96d5c8319baea6fb804debef7b7748}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Semiotica}
      \field{number}{1}
      \field{title}{{The Repertoire of Nonverbal Behavior: Categories, Origins, Usage, and Coding}}
      \field{volume}{1}
      \field{year}{1969}
      \field{pages}{49\bibrangedash 98}
      \range{pages}{50}
      \verb{doi}
      \verb doi:10.1515/semi.1969.1.1.49
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1515/semi.1969.1.1.49
      \endverb
      \verb{url}
      \verb https://doi.org/10.1515/semi.1969.1.1.49
      \endverb
    \endentry
    \entry{IEEE:2020}{article}{}
      \name{author}{2}{}{%
        {{hash=3b4f0f3fbf57a67f138dbb29074557ff}{%
           family={Electrical},
           familyi={E\bibinitperiod},
           given={Institute},
           giveni={I\bibinitperiod},
           prefix={of},
           prefixi={o\bibinitperiod}}}%
        {{hash=4b130cfa309b2ff17cea51cb7fb7d85f}{%
           family={Engineers},
           familyi={E\bibinitperiod},
           given={Electronics},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{bbcfa0997876af8df433758706aa3923}
      \strng{fullhash}{bbcfa0997876af8df433758706aa3923}
      \strng{bibnamehash}{bbcfa0997876af8df433758706aa3923}
      \strng{authorbibnamehash}{bbcfa0997876af8df433758706aa3923}
      \strng{authornamehash}{bbcfa0997876af8df433758706aa3923}
      \strng{authorfullhash}{bbcfa0997876af8df433758706aa3923}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Std 521-2019 (Revision of IEEE Std 521-2002)}
      \field{title}{{IEEE Standard Letter Designations for Radar-Frequency Bands}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 15}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/IEEESTD.2020.8999849
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/servlet/opac?punumber=8999827
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/servlet/opac?punumber=8999827
      \endverb
    \endentry
    \entry{Erazo:2020}{article}{}
      \name{author}{2}{}{%
        {{hash=5d7ae9691728e70850dfc0670c7f7105}{%
           family={Erazo},
           familyi={E\bibinitperiod},
           given={Ana\bibnamedelima Belén},
           giveni={A\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=26e421a082868c7dd0695a437d2d0a4f}{%
           family={Pérez\bibnamedelima Medina},
           familyi={P\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Jorge\bibnamedelima Luis},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {INSIGHT - Indonesian Society for Knowledge}%
        {Human Development}%
      }
      \strng{namehash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \strng{fullhash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \strng{bibnamehash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \strng{authorbibnamehash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \strng{authornamehash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \strng{authorfullhash}{8cca02e1aeba08fc4f2c5f712a75896f}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2088-5334}
      \field{journaltitle}{International Journal on Advanced Science, Engineering and Information Technology}
      \field{number}{2}
      \field{title}{{Algorithmic Efficiency of Stroke Gesture Recognizers: a Comparative Analysis}}
      \field{volume}{10}
      \field{year}{2020}
      \field{pages}{438\bibrangedash 446}
      \range{pages}{9}
      \verb{doi}
      \verb 10.18517/ijaseit.10.2.10807
      \endverb
      \verb{urlraw}
      \verb http://ijaseit.insightsociety.org/index.php?option=com_content\&view=article\&id=9\&Itemid=1\&article_id=10807
      \endverb
      \verb{url}
      \verb http://ijaseit.insightsociety.org/index.php?option=com_content%5C&view=article%5C&id=9%5C&Itemid=1%5C&article_id=10807
      \endverb
      \keyw{gesture interaction; gesture recognition; algorithmic efficiency; stroke analysis.}
    \endentry
    \entry{Feldt:2010}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=586e398faf79549b53f97ca8d2463143}{%
           family={Feldt},
           familyi={F\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=daa4ee522ffae0a8f42a0be709234e90}{%
           family={Magazinius},
           familyi={M\bibinitperiod},
           given={Ana},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Knowledge Systems Institute Graduate School}%
      }
      \strng{namehash}{3f9700ef3e28ecb9c88a625547e67498}
      \strng{fullhash}{3f9700ef3e28ecb9c88a625547e67498}
      \strng{bibnamehash}{3f9700ef3e28ecb9c88a625547e67498}
      \strng{authorbibnamehash}{3f9700ef3e28ecb9c88a625547e67498}
      \strng{authornamehash}{3f9700ef3e28ecb9c88a625547e67498}
      \strng{authorfullhash}{3f9700ef3e28ecb9c88a625547e67498}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 22nd International Conference on Software Engineering {\&} Knowledge Engineering (SEKE'2010), Redwood City, San Francisco Bay, CA, USA, July 1 - July 3, 2010}
      \field{title}{{Validity Threats in Empirical Software Engineering Research - An Initial Survey}}
      \field{year}{2010}
      \field{pages}{374\bibrangedash 379}
      \range{pages}{6}
    \endentry
    \entry{Feng:2019}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=1d409748a239e6689baf944344f026f6}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=bacf54ba763aa83e33c49ee52c9f0107}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Qun},
           giveni={Q\bibinitperiod}}}%
        {{hash=fa3f0a7e3f28380190b272e3fd94495b}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Qingfang},
           giveni={Q\bibinitperiod}}}%
        {{hash=15c705db0a63fe4bb07f5ec62b4af370}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Duo},
           giveni={D\bibinitperiod}}}%
        {{hash=07052bbc57d8cec393358776e2d7e59b}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Zhanfeng},
           giveni={Z\bibinitperiod}}}%
        {{hash=a0fed714855ec8b7f4b1c44bad24e88e}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Yinan},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{35c106dba90570134cde57de11a2502e}
      \strng{fullhash}{f799b789028612f9f0234d14d66752cd}
      \strng{bibnamehash}{35c106dba90570134cde57de11a2502e}
      \strng{authorbibnamehash}{35c106dba90570134cde57de11a2502e}
      \strng{authornamehash}{35c106dba90570134cde57de11a2502e}
      \strng{authorfullhash}{f799b789028612f9f0234d14d66752cd}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Hand gesture recognition using radar has been widely applied to control electronic appliances, military appliances and so on. In this paper, we investigate the feasibility of recognizing hand gestures using fused multiple time-frequency signatures, which ensembles micro-Doppler signatures, range-time signatures and angle-time signatures on spectrograms, with an Enhanced Deep Convolutional Neural Network (EDCNN). Several typical gestures included Tick, Double pushing, Rotating clockwise, and Rotating counterclockwise, were measured using Mm-wave radar and their spectrograms investigated. Therein EDCNN was employed to classify the spectrograms, with 80\% of the data utilized for training and the remaining 20\% for validation. Simulation said that the classification accuracy of the proposed method was found to be 96.2\%.}
      \field{booktitle}{2019 {Asia}-{Pacific} {Signal} and {Information} {Processing} {Association} {Annual} {Summit} and {Conference} ({APSIPA} {ASC})}
      \field{month}{11}
      \field{note}{ISSN: 2640-0103}
      \field{title}{Hand {Gesture} {Recognition} with {Ensemble} {Time}-{Frequency} {Signatures} {Using} {Enhanced} {Deep} {Convolutional} {Neural} {Network}}
      \field{year}{2019}
      \field{pages}{1602\bibrangedash 1605}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/APSIPAASC47483.2019.9023254
      \endverb
      \keyw{angle-time signatures,Convolution,convolutional neural nets,Convolutional neural networks,Doppler radar,electronic appliances,enhanced deep convolutional neural network,ensemble time-frequency signatures,Feature extraction,gesture recognition,Gesture recognition,hand gesture recognition,hand gestures,image classification,learning (artificial intelligence),microDoppler signatures,military appliances,range-time signatures,Spectrogram,spectrograms,time-frequency analysis}
    \endentry
    \entry{Fennedy:2021}{article}{}
      \name{author}{5}{}{%
        {{hash=f9b73187f4efdc7754faaff6975c9d32}{%
           family={Fennedy},
           familyi={F\bibinitperiod},
           given={Katherine},
           giveni={K\bibinitperiod}}}%
        {{hash=4182ceb5a4143ea62392a4cb344caba5}{%
           family={Hartmann},
           familyi={H\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod}}}%
        {{hash=e64cb7fa3e628c42e4f690c425db34c9}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=2ab8f12dde8330c7fe114ec1d17902aa}{%
           family={Perrault},
           familyi={P\bibinitperiod},
           given={Simon\bibnamedelima Tangi},
           giveni={S\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{hash=f94f65826718458aba9a7e2ee4834749}{%
           family={Vogel},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {IEEE Educational Activities Department}%
      }
      \strng{namehash}{79775649eeebd5156037dae160d23960}
      \strng{fullhash}{0acd284debe0c32461f1c866a1a52442}
      \strng{bibnamehash}{79775649eeebd5156037dae160d23960}
      \strng{authorbibnamehash}{79775649eeebd5156037dae160d23960}
      \strng{authornamehash}{79775649eeebd5156037dae160d23960}
      \strng{authorfullhash}{0acd284debe0c32461f1c866a1a52442}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Bau and Mackays OctoPocus dynamic guide helps novices learn, execute, and remember 2D surface gestures. We adapt OctoPocus to 3D mid-air gestures in Virtual Reality (VR) using an optimization-based recognizer, and by introducing an optional exploration mode to help visualize the spatial complexity of guides in a 3D gesture set. A replication of the original experiment protocol is used to compare OctoPocus in VR with a VR implementation of a crib-sheet. Results show that despite requiring 0.9s more reaction time than crib-sheet, OctoPocus enables participants to execute gestures 1.8s faster with 13.8 percent more accuracy during training, while remembering a comparable number of gestures. Subjective ratings support these results, 75 percent of participants found OctoPocus easier to learn and 83 percent found it more accurate. We contribute an implementation and empirical evidence demonstrating that an adaptation of the OctoPocus guide to VR is feasible and beneficial.}
      \field{issn}{1077-2626}
      \field{journaltitle}{IEEE Transactions on Visualization and Computer Graphics}
      \field{month}{12}
      \field{number}{12}
      \field{title}{{OctoPocus in VR: Using a Dynamic Guide for 3D Mid-Air Gestures in Virtual Reality}}
      \field{volume}{27}
      \field{year}{2021}
      \field{pages}{4425\bibrangedash 4438}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TVCG.2021.3101854
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/TVCG.2021.3101854
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/TVCG.2021.3101854
      \endverb
    \endentry
    \entry{Ferreira:2019}{article}{}
      \name{author}{3}{}{%
        {{hash=55bfbc3adc1acc372a96161d9315e788}{%
           family={Ferreira},
           familyi={F\bibinitperiod},
           given={Pedro\bibnamedelima M.},
           giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=a1995a9c00d299e6557664ff4a86535e}{%
           family={Cardoso},
           familyi={C\bibinitperiod},
           given={Jaime\bibnamedelima S.},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=39b025eab499ca9b0a42b900ee65ed39}{%
           family={Rebelo},
           familyi={R\bibinitperiod},
           given={Ana},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \strng{fullhash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \strng{bibnamehash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \strng{authorbibnamehash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \strng{authornamehash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \strng{authorfullhash}{17c78d4989c2b32086fcbeb08b2f3cde}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{4}
      \field{number}{8}
      \field{title}{{On the Role of Multimodal Learning in the Recognition of Sign Language}}
      \field{volume}{78}
      \field{year}{2019}
      \field{pages}{10035\bibrangedash 10056}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1007/s11042-018-6565-5
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11042-018-6565-5
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11042-018-6565-5
      \endverb
      \keyw{Convolutional neural networks,Sign language recognition,Leap motion,Kinect,Multimodal learning}
    \endentry
    \entry{Fhager:2019}{article}{}
      \name{author}{5}{}{%
        {{hash=417a4ead9ff55c2620357467a4488fde}{%
           family={Fhager},
           familyi={F\bibinitperiod},
           given={Lars\bibnamedelima Ohlsson},
           giveni={L\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=eb7afd02497dd9d528b40ee0e01511fb}{%
           family={Heunisch},
           familyi={H\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=bb957689aa651d73f5a6cf375ea13f87}{%
           family={Dahlberg},
           familyi={D\bibinitperiod},
           given={Hannes},
           giveni={H\bibinitperiod}}}%
        {{hash=d44b99fd64579486ec1ca328caa83975}{%
           family={Evertsson},
           familyi={E\bibinitperiod},
           given={Anton},
           giveni={A\bibinitperiod}}}%
        {{hash=a2ef740deffd7496dae581e5762066d0}{%
           family={Wernersson},
           familyi={W\bibinitperiod},
           given={Lars-Erik},
           giveni={L\bibinithyphendelim E\bibinitperiod}}}%
      }
      \strng{namehash}{3badf7d2b6165c4f290847d6f3b8df7e}
      \strng{fullhash}{8c307c65c6f566efb89ea29f34ce9d01}
      \strng{bibnamehash}{3badf7d2b6165c4f290847d6f3b8df7e}
      \strng{authorbibnamehash}{3badf7d2b6165c4f290847d6f3b8df7e}
      \strng{authornamehash}{3badf7d2b6165c4f290847d6f3b8df7e}
      \strng{authorfullhash}{8c307c65c6f566efb89ea29f34ce9d01}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A pulsed millimeter wave radar operating at a frame rate of 144 Hz is utilized to record 2160 scattering signatures of 12 generic hand gestures. Gesture recognition is achieved by machine learning, utilizing transfer learning on a pretrained convolutional neural network. This yields excellent classification results with a validation accuracy of 99.5\%, based on a 60\% training versus 40\% validation split. The corresponding confusion matrix is also presented, showing a high level of classification orthogonality between the tested gestures. This is the first demonstration where data from a pulsed millimeter wave radar is used for gesture recognition by machine learning. It proves that the range-time envelope representation of high frame-rate data from a pulsed radar is suitable for hand gesture recognition. Further improvements are expected for more complex detection schemes and tailored neural networks.}
      \field{issn}{2475-1472}
      \field{journaltitle}{IEEE Sensors Letters}
      \field{month}{12}
      \field{number}{12}
      \field{title}{Pulsed {Millimeter} {Wave} {Radar} for {Hand} {Gesture} {Sensing} and {Classification}}
      \field{volume}{3}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/LSENS.2019.2953022
      \endverb
      \keyw{12 generic hand gestures,60\% training versus 40\% validation split,classification,convolutional neural nets,convolutional neural network,Convolutional neural networks,frequency 144.0 Hz,gesture recognition,gesture sensing,hand gesture recognition,hand gesture sensing,high frame-rate data,image classification,learning (artificial intelligence),machine learning,matrix algebra,Microwave/millimeter wave sensors,Millimeter wave measurements,millimeter wave radar,Millimeter wave radar,millimetre wave radar,pulsed millimeter wave radar,pulsed radar,Radar imaging,Sensors,tested gestures,transfer learning,yields excellent classification results}
    \endentry
    \entry{Filho:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=315120a264e03f18b66b5b9e22dae994}{%
           family={Filho},
           familyi={F\bibinitperiod},
           given={Ivo\bibnamedelimb Aluízio\bibnamedelima Stinghen},
           giveni={I\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=38ccedc99167084f5fe0f83b4dfbf151}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Estevam\bibnamedelima Nicolas},
           giveni={E\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=74786bb15dc2ba8ba8d0ca7d27068b4c}{%
           family={Silva\bibnamedelima Junior},
           familyi={S\bibinitperiod\bibinitdelim J\bibinitperiod},
           given={Jucimar\bibnamedelima Maia},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod},
           prefix={da},
           prefixi={d\bibinitperiod}}}%
        {{hash=c1a894cb284327734f36cb8c30edf5ff}{%
           family={Silva\bibnamedelima Barboza},
           familyi={S\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Ricardo},
           giveni={R\bibinitperiod},
           prefix={da},
           prefixi={d\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{97a81f179e33800f7d3757db5c71027d}
      \strng{fullhash}{f07fae7145d369aead0e061496562e9a}
      \strng{bibnamehash}{97a81f179e33800f7d3757db5c71027d}
      \strng{authorbibnamehash}{97a81f179e33800f7d3757db5c71027d}
      \strng{authornamehash}{97a81f179e33800f7d3757db5c71027d}
      \strng{authorfullhash}{f07fae7145d369aead0e061496562e9a}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{ACM SIGGRAPH 2018 Posters}
      \field{isbn}{9781450358170}
      \field{series}{SIGGRAPH '18}
      \field{title}{{Gesture Recognition Using Leap Motion: A Comparison between Machine Learning Algorithms}}
      \field{venue}{Vancouver, British Columbia, Canada}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3230744.3230750
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3230744.3230750
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3230744.3230750
      \endverb
      \keyw{leap motion,machine learning,motion capture,virtual reality}
    \endentry
    \entry{Flintoff:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=5bb8583cb8ec51613c959ad88e687392}{%
           family={Flintoff},
           familyi={F\bibinitperiod},
           given={Zak},
           giveni={Z\bibinitperiod}}}%
        {{hash=8c5500385da0f8d38320fe877e208e2f}{%
           family={Johnston},
           familyi={J\bibinitperiod},
           given={Bruno},
           giveni={B\bibinitperiod}}}%
        {{hash=ac83c3112830c741515469e820666f52}{%
           family={Liarokapis},
           familyi={L\bibinitperiod},
           given={Minas},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{797126427a98a977dcb181d0afcf0e28}
      \strng{fullhash}{797126427a98a977dcb181d0afcf0e28}
      \strng{bibnamehash}{797126427a98a977dcb181d0afcf0e28}
      \strng{authorbibnamehash}{797126427a98a977dcb181d0afcf0e28}
      \strng{authornamehash}{797126427a98a977dcb181d0afcf0e28}
      \strng{authorfullhash}{797126427a98a977dcb181d0afcf0e28}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}
      \field{title}{{Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors}}
      \field{year}{2018}
      \field{pages}{1943\bibrangedash 1950}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/IROS.2018.8594166
      \endverb
    \endentry
    \entry{Fruchard:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=458f03118e8189287ca12513c9c85f62}{%
           family={Fruchard},
           familyi={F\bibinitperiod},
           given={Bruno},
           giveni={B\bibinitperiod}}}%
        {{hash=38f0959fca525c7e663bd8795c1e53f0}{%
           family={Lecolinet},
           familyi={L\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=e51fdfe8a946a726b9ee900a23d47866}{%
           family={Chapuis},
           familyi={C\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{3aff16b1ad794a633be962150c35ab3b}
      \strng{fullhash}{3aff16b1ad794a633be962150c35ab3b}
      \strng{bibnamehash}{3aff16b1ad794a633be962150c35ab3b}
      \strng{authorbibnamehash}{3aff16b1ad794a633be962150c35ab3b}
      \strng{authornamehash}{3aff16b1ad794a633be962150c35ab3b}
      \strng{authorfullhash}{3aff16b1ad794a633be962150c35ab3b}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Various techniques have been proposed to faster command selection. Many of them either rely on directional gestures (e.g. Marking menus) or pointing gestures using a spatially-stable arrangement of items (e.g. FastTap). Both types of techniques are known to leverage memorization, but not necessarily for the same reasons. In this paper, we investigate whether using directions or positions affects gesture learning. Our study shows that, while recall rates are not significantly different, participants used the novice mode more often and spent more time while learning commands with directional gestures, and they also reported more physical and mental efforts. Moreover, this study also highlights the importance of semantic relationships between gestural commands and reports on the memorization strategies that were elaborated by the participants.}
      \field{booktitle}{Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces}
      \field{isbn}{9781450356947}
      \field{series}{ISS '18}
      \field{title}{{How Memorizing Positions or Directions Affects Gesture Learning?}}
      \field{venue}{Tokyo, Japan}
      \field{year}{2018}
      \field{pages}{107\bibrangedash 114}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/3279778.3279787
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3279778.3279787
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3279778.3279787
      \endverb
      \keyw{pointing,spatial memory,user study,command selection,memorization,gestures}
    \endentry
    \entry{Fu:2016}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=8cd3a70312c383e5cbba1ec86a629f65}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Zeqing},
           giveni={Z\bibinitperiod}}}%
        {{hash=59ffbda8020ea3dc19a7c7624dcde55a}{%
           family={Deng},
           familyi={D\bibinitperiod},
           given={Yiyi},
           giveni={Y\bibinitperiod}}}%
        {{hash=a17ff8f8888b1b10bc4d2a44c1f61853}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod}}}%
        {{hash=4b8da17a1cd42b7bfaba56a8dbcf5168}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
        {{hash=9ecbbc189a409817b73e4dc5fbe03563}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Xiaoming},
           giveni={X\bibinitperiod}}}%
        {{hash=cdded4c2eb618f280f650f0ab35b14e3}{%
           family={Luo},
           familyi={L\bibinitperiod},
           given={Yanlin},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{d89d5e38aee79b07b81ebdc9ae92f54a}
      \strng{fullhash}{f156e9be905d1b3d6ee8b2785d1d0aba}
      \strng{bibnamehash}{d89d5e38aee79b07b81ebdc9ae92f54a}
      \strng{authorbibnamehash}{d89d5e38aee79b07b81ebdc9ae92f54a}
      \strng{authornamehash}{d89d5e38aee79b07b81ebdc9ae92f54a}
      \strng{authorfullhash}{f156e9be905d1b3d6ee8b2785d1d0aba}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry - Volume 1}
      \field{isbn}{9781450346924}
      \field{series}{VRCAI '16}
      \field{title}{{Automated Brain Extraction and Associated 3D Inspection Layers for the Rhesus Macaque MRI Datasets}}
      \field{venue}{Zhuhai, China}
      \field{year}{2016}
      \field{pages}{261\bibrangedash 269}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/3013971.3013984
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3013971.3013984
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3013971.3013984
      \endverb
      \keyw{volume visualization,Rhesus macaque,brain extraction,3D inspection,bimanual gesture interaction}
    \endentry
    \entry{Galea:2018}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=3c8a2a40d5eda460ff15f973c5f68eed}{%
           family={Galea},
           familyi={G\bibinitperiod},
           given={Claire},
           giveni={C\bibinitperiod}}}%
        {{hash=7069097254809bf52159c1625c4d89ea}{%
           family={Porter},
           familyi={P\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Swindon, GBR}%
      }
      \list{publisher}{1}{%
        {BCS Learning \& Development Ltd.}%
      }
      \strng{namehash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \strng{fullhash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \strng{bibnamehash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \strng{authorbibnamehash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \strng{authornamehash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \strng{authorfullhash}{3e9ab3d3057e62ecc1e0a4e67b8f8cee}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 32nd International BCS Human Computer Interaction Conference}
      \field{series}{HCI '18}
      \field{title}{{Accessible Choral Ensembles for Visually Impaired Singers}}
      \field{venue}{Belfast, United Kingdom}
      \field{year}{2018}
      \verb{doi}
      \verb 10.14236/ewic/HCI2018.37
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.14236/ewic/HCI2018.37
      \endverb
      \verb{url}
      \verb https://doi.org/10.14236/ewic/HCI2018.37
      \endverb
      \keyw{gesture recognition and interpretation,realtime communications,human-computer interaction in choral activities}
    \endentry
    \entry{Ghaffar:2019}{article}{}
      \name{author}{3}{}{%
        {{hash=c3a10724898c231b33e9bab3fc42f2bc}{%
           family={Ghaffar},
           familyi={G\bibinitperiod},
           given={Asim},
           giveni={A\bibinitperiod}}}%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{11c07cd0bd3703929a8f82c098c93ed4}
      \strng{fullhash}{11c07cd0bd3703929a8f82c098c93ed4}
      \strng{bibnamehash}{11c07cd0bd3703929a8f82c098c93ed4}
      \strng{authorbibnamehash}{11c07cd0bd3703929a8f82c098c93ed4}
      \strng{authornamehash}{11c07cd0bd3703929a8f82c098c93ed4}
      \strng{authorfullhash}{11c07cd0bd3703929a8f82c098c93ed4}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital menu boards (DMB) are convenient for customers as well as sellers. In this paper, we have implemented a DMB using IR-UWB transceivers. Unlike the traditional touch-based interfaces for menu selection, in our proposed system, users can select items from the menu without touching the screen. The screen is used to display the menu, and the users point to the specific menu item to select it. Multiple radar transceivers are used to create a virtual space divided into different grid blocks in front of the digital display. Patterns in the radar data are analyzed using a multiclass support vector machine (SVM) classifier and a histogram of oriented gradient descriptor. The system is trained at two different distances from the radar sensors in order to make it robust against distance changes. The proposed hand pointing-based DMB system was verified through different experiments, with different grid sizes, to investigate accuracy dependence on grid size. The results showed high accuracy; therefore, the system can be used in real-life scenarios.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Hand {Pointing} {Gestures} {Based} {Digital} {Menu} {Board} {Implementation} {Using} {IR}-{UWB} {Transceivers}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{58148\bibrangedash 58157}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2914410
      \endverb
      \keyw{Clutter,digital display,Digital menu board (DMB),digital menu board implementation,digital menu boards,Digital multimedia broadcasting,gesture recognition,Gesture recognition,gestures recognition,grid blocks,grid sizes,hand pointing gestures,hand pointing-based DMB system,histogram,impulse radio ultrawideband,interactive systems,IR-UWB transceivers,menu item,menu selection,multiclass support vector machine classifier,multiple radar transceivers,pattern analysis,pattern classification,Radar,radar data,radar receivers,radar sensors,screen,Sensors,support vector machines,Support vector machines,SVM,touch-based interfaces,transceivers,Two dimensional displays,ultra wideband communication,users point}
    \endentry
    \entry{Gheran:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=47b03d23cd9e814e1ef8743f41af131d}{%
           family={Gheran},
           familyi={G\bibinitperiod},
           given={Bogdan{-}Florin},
           giveni={B\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \name{editor}{5}{}{%
        {{hash=d6190003d090198334bd9e4c52fb87ee}{%
           family={Koskinen},
           familyi={K\bibinitperiod},
           given={Ilpo},
           giveni={I\bibinitperiod}}}%
        {{hash=c212c4a5c0d12db72a2e8fed20713446}{%
           family={Lim},
           familyi={L\bibinitperiod},
           given={Youn{-}Kyung},
           giveni={Y\bibinitperiod}}}%
        {{hash=f3474a62c2b8282a12ed4fd6ba78bff5}{%
           family={Cerratto{-}Pargman},
           familyi={C\bibinitperiod},
           given={Teresa},
           giveni={T\bibinitperiod}}}%
        {{hash=e9fe5f1e57c4d35df859c5463a400338}{%
           family={Chow},
           familyi={C\bibinitperiod},
           given={Kenny\bibnamedelimb K.\bibnamedelimi N.},
           giveni={K\bibinitperiod\bibinitdelim K\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=17aecc97d49c8b0ddee027fbf5923440}{%
           family={Odom},
           familyi={O\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{f971c2df7962b3591f00998c51037426}
      \strng{fullhash}{f971c2df7962b3591f00998c51037426}
      \strng{bibnamehash}{f971c2df7962b3591f00998c51037426}
      \strng{authorbibnamehash}{f971c2df7962b3591f00998c51037426}
      \strng{authornamehash}{f971c2df7962b3591f00998c51037426}
      \strng{authorfullhash}{f971c2df7962b3591f00998c51037426}
      \strng{editorbibnamehash}{63295103006274ee1d7b7d295eefb7c3}
      \strng{editornamehash}{63295103006274ee1d7b7d295eefb7c3}
      \strng{editorfullhash}{b304fc6ec61491165a047799c8581725}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proc. of the 2018 Designing Interactive Systems Conference}
      \field{isbn}{9781450351980}
      \field{series}{DIS ’18}
      \field{title}{{Gestures for Smart Rings: Empirical Results, Insights, and Design Implications}}
      \field{venue}{Hong Kong, China}
      \field{year}{2018}
      \field{pages}{623\bibrangedash 635}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1145/3196709.3196741
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3196709.3196741
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3196709.3196741
      \endverb
    \endentry
    \entry{Gigie:2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=32146a30aeea8f2e7439946227b68ccd}{%
           family={Gigie},
           familyi={G\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=5539ec4baa6de06b57415fac251a0bd9}{%
           family={Rani},
           familyi={R\bibinitperiod},
           given={Smriti},
           giveni={S\bibinitperiod}}}%
        {{hash=fe67c47919b4d708b68962b1cb44c58f}{%
           family={Chowdhury},
           familyi={C\bibinitperiod},
           given={Arijit},
           giveni={A\bibinitperiod}}}%
        {{hash=9634f5c511907bc02afdaf4d64e2e1f4}{%
           family={Chakravarty},
           familyi={C\bibinitperiod},
           given={Tapas},
           giveni={T\bibinitperiod}}}%
        {{hash=7c6e354cdb8f1c1dda61f7dad841885d}{%
           family={Pal},
           familyi={P\bibinitperiod},
           given={Arpan},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{cf93cf0c3e9f1dce4817efe0e779eb79}
      \strng{fullhash}{ffb6b343cf351b943c18bc7d3eaba84a}
      \strng{bibnamehash}{cf93cf0c3e9f1dce4817efe0e779eb79}
      \strng{authorbibnamehash}{cf93cf0c3e9f1dce4817efe0e779eb79}
      \strng{authornamehash}{cf93cf0c3e9f1dce4817efe0e779eb79}
      \strng{authorfullhash}{ffb6b343cf351b943c18bc7d3eaba84a}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A large and diversified dataset is the cornerstone for the analysis of many real world systems. Data collection, especially involving living beings, is a time and effort consuming approach. Data augmentation using analytical models is gaining traction in computing systems because of data scarcity in real world applications. In this paper, we demonstrate a case study of data explosion for radar based human gesture detection. We present a physical model based simulation framework for obtaining radar signals corresponding to different human gestures. Radar based public datasets have not yet been so easily available because of its high cost and less availability. On the contrary, Kinect based datasets are easily available because of its market dominance and commercialization of devices such as Xbox Kinect. Thus, for the simulation framework, we have used the publicly available dataset for gaming gestures based on Kinect data (obtained from Microsoft Cambridge joint initiative). This Kinect data containing the coordinates of joint positions of human skeletons performing different gaming gestures is then fed to a radar based simulation framework to calculate the radar data. Furthermore, we have tuned different parameters in this simulation framework and exploded it to generate radar micro Doppler signatures in a controlled way, keeping in mind the physical constraints. On this exploded data, machine learning algorithms have been applied to evaluate gesture detection accuracy. The enlarged dataset for four gestures has shown an accuracy of around 94.7 \% for 10 fold cross validation in training phase. A comparison of simulated radar data with respect to experimentally obtained hardware radar data for different gestures has also been reported to show the relevance of the proposed method.}
      \field{booktitle}{Adjunct {Proceedings} of the 2019 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2019 {ACM} {International} {Symposium} on {Wearable} {Computers}}
      \field{isbn}{978-1-4503-6869-8}
      \field{month}{9}
      \field{series}{{UbiComp}/{ISWC} '19 {Adjunct}}
      \field{title}{{An agile approach for human gesture detection using synthetic radar data}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{558\bibrangedash 564}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1145/3341162.3349332
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3341162.3349332
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3341162.3349332
      \endverb
      \keyw{gesture detection,kinect datasets,physical model based synthetic data generation,radar simulation framework,synthetic data generation}
    \endentry
    \entry{Giot:2023}{thesis}{}
      \name{author}{1}{}{%
        {{hash=cd9b4c4223ea5233cec5fa25d5c50cc2}{%
           family={Giot},
           familyi={G\bibinitperiod},
           given={Emile},
           giveni={E\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \strng{fullhash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \strng{bibnamehash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \strng{authorbibnamehash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \strng{authornamehash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \strng{authorfullhash}{cd9b4c4223ea5233cec5fa25d5c50cc2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In the recent years, radar-based gesture recognition has seen an increase in popularity. Indeed, radar sensors have various advantages over the widely used wearable and image-based sensors. They are less intrusive and less sensitive to ambient and lighting conditions. Moreover, as the radar waves are able to propagate through materials depending on its permittivity, radar sensors are the go to candidates to perform gesture recognition through materials. In this work, an off-the-shelf radar, the Walabot, is used to acquire a dataset of hand gestures performed in front of three different material plates (wood, PVC and glass) placed in-between the radar and the participant. In order to evaluate the suitability of using the Walabot in such scenarios, multiple recognizers based on template matching are trained using the acquired hand gesture dataset and their accuracy at performing hand gesture recognition is evaluated. This thesis presents the complete methodology followed to perform hand gesture recognition through 3 different material plates (wood, PVC and glass), from the acquisition of the dataset using the Walabot and the processing of the radar data with the RadarSense pipeline, to the training and testing of the recognizers with the QuantumLeap framework.}
      \field{title}{{Radar-based gesture interaction: from sensing to recognition}}
      \field{type}{phdthesis}
      \field{year}{2023}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:43330
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:43330
      \endverb
      \keyw{Gesture recognition,Radar-based interaction,Template matching,Walabot,Human computer interaction,RadarSense,QuantumLeap}
    \endentry
    \entry{Goker:2017}{article}{}
      \name{author}{2}{}{%
        {{hash=936f0ae2c4d03adf45482864bb6aea15}{%
           family={Göker},
           familyi={G\bibinitperiod},
           given={Pınar},
           giveni={P\bibinitperiod}}}%
        {{hash=1ba56590ddf606e241d615c9d390586b}{%
           family={Gülhal\bibnamedelima Bozkir},
           familyi={G\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Memduha},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{5d649a83aa06f1fde071d03be9a5d802}
      \strng{fullhash}{5d649a83aa06f1fde071d03be9a5d802}
      \strng{bibnamehash}{5d649a83aa06f1fde071d03be9a5d802}
      \strng{authorbibnamehash}{5d649a83aa06f1fde071d03be9a5d802}
      \strng{authornamehash}{5d649a83aa06f1fde071d03be9a5d802}
      \strng{authorfullhash}{5d649a83aa06f1fde071d03be9a5d802}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Trauma and Emergency Care}
      \field{month}{5}
      \field{number}{4}
      \field{title}{{Determination of hand and palm surface areas as a percentage of body surface area in Turkish young adults}}
      \field{volume}{2}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.15761/TEC.1000135
      \endverb
      \verb{urlraw}
      \verb https://www.oatext.com/pdf/TEC-2-135.pdf
      \endverb
      \verb{url}
      \verb https://www.oatext.com/pdf/TEC-2-135.pdf
      \endverb
    \endentry
    \entry{GomezDonoso:2017}{article}{}
      \name{author}{7}{}{%
        {{hash=52927a06c6f765996ccdd103f2f8f635}{%
           family={Gomez-Donoso},
           familyi={G\bibinithyphendelim D\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod}}}%
        {{hash=8ada7bec05943efc23b4650617d28091}{%
           family={Orts-Escolano},
           familyi={O\bibinithyphendelim E\bibinitperiod},
           given={Sergio},
           giveni={S\bibinitperiod}}}%
        {{hash=91b377111e9be859ad399e1438044568}{%
           family={Garcia-Garcia},
           familyi={G\bibinithyphendelim G\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod}}}%
        {{hash=7916bbdff49946e9d942ad67055a314d}{%
           family={Garcia-Rodriguez},
           familyi={G\bibinithyphendelim R\bibinitperiod},
           given={Jose},
           giveni={J\bibinitperiod}}}%
        {{hash=17cd9af69708de427242bdaf3d08eaeb}{%
           family={Castro-Vargas},
           familyi={C\bibinithyphendelim V\bibinitperiod},
           given={John\bibnamedelima Alejandro},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=3a9510305a6149c4a67871c70a959079}{%
           family={Ovidiu-Oprea},
           familyi={O\bibinithyphendelim O\bibinitperiod},
           given={Sergiu},
           giveni={S\bibinitperiod}}}%
        {{hash=573aaeaaa16f2b86e60a655d35f8e45e}{%
           family={Cazorla},
           familyi={C\bibinitperiod},
           given={Miguel},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Elsevier Science Inc.}%
      }
      \strng{namehash}{93e99fc4ce102d2546c39c7a97a801b1}
      \strng{fullhash}{5fad803fbe140e82ece0bf6f0deb1bc0}
      \strng{bibnamehash}{93e99fc4ce102d2546c39c7a97a801b1}
      \strng{authorbibnamehash}{93e99fc4ce102d2546c39c7a97a801b1}
      \strng{authornamehash}{93e99fc4ce102d2546c39c7a97a801b1}
      \strng{authorfullhash}{5fad803fbe140e82ece0bf6f0deb1bc0}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0167-8655}
      \field{journaltitle}{Pattern Recogn. Lett.}
      \field{month}{11}
      \field{number}{C}
      \field{title}{{A Robotic Platform for Customized and Interactive Rehabilitation of Persons with Disabilities}}
      \field{volume}{99}
      \field{year}{2017}
      \field{pages}{105\bibrangedash 113}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1016/j.patrec.2017.05.027
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.patrec.2017.05.027
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.patrec.2017.05.027
      \endverb
    \endentry
    \entry{Goswami:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=a0b42c76d14fe0a3ed7342a8f169b34c}{%
           family={Goswami},
           familyi={G\bibinitperiod},
           given={Piyali},
           giveni={P\bibinitperiod}}}%
        {{hash=0453f48933d1c7f4a8c1ac8c644fad1f}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Sandeep},
           giveni={S\bibinitperiod}}}%
        {{hash=9894e73d00ba5799ae206d096b44bb9a}{%
           family={Bharadwaj},
           familyi={B\bibinitperiod},
           given={Sachin},
           giveni={S\bibinitperiod}}}%
        {{hash=a68fc2e1d0c900bfb3505a16443595bc}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Amanda},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{3cfbf98ccf36b0c75647173d01b3e656}
      \strng{fullhash}{72f7f583c97c82e169e1b9103646de3a}
      \strng{bibnamehash}{3cfbf98ccf36b0c75647173d01b3e656}
      \strng{authorbibnamehash}{3cfbf98ccf36b0c75647173d01b3e656}
      \strng{authornamehash}{3cfbf98ccf36b0c75647173d01b3e656}
      \strng{authorfullhash}{72f7f583c97c82e169e1b9103646de3a}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Innovations in CMOS radar has paved way for new functions like gesture-based human-machine interaction using radar for consumer and automotive electronics. Single chip radars which integrate the RF front-end and digital processing logic are fit for such applications due to their cost and form factor but are constrained in angular resolution, memory, and processing power. In this paper, we propose low complexity radar-based multi-gesture classification solution which overcomes these constraints to achieve 96\% accuracy for 6 gestures generalized across 8 users. The algorithm developed was found to consume only 8.4\% DSP cycles and 256KiB memory on Texas Instrument's AWR1642.}
      \field{booktitle}{2019 {IEEE} {International} {Conference} on {Consumer} {Electronics} ({ICCE})}
      \field{month}{1}
      \field{note}{ISSN: 2158-4001}
      \field{title}{Real-{Time} {Multi}-{Gesture} {Recognition} using 77 {GHz} {FMCW} {MIMO} {Single} {Chip} {Radar}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICCE.2019.8662006
      \endverb
      \keyw{77 GHz CMOS Radar,angular resolution,automotive electronics,CMOS radar,consumer,CW radar,digital processing logic,digital signal processing chips,FM radar,FMCW MIMO single chip radar,form factor,frequency 77.0 GHz,gesture recognition,Gesture Recognition,gesture-based human-machine interaction,human computer interaction,image classification,low complexity radar-based multigesture classification solution,processing power,radar signal processing,real-time multigesture recognition,RF front-end,Single Chip Radar,single chip radars}
    \endentry
    \entry{Grier:2015}{article}{}
      \name{author}{1}{}{%
        {{hash=45624c4382fbe254596a53dcf8c7ec6f}{%
           family={Grier},
           familyi={G\bibinitperiod},
           given={Rebecca\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{45624c4382fbe254596a53dcf8c7ec6f}
      \strng{fullhash}{45624c4382fbe254596a53dcf8c7ec6f}
      \strng{bibnamehash}{45624c4382fbe254596a53dcf8c7ec6f}
      \strng{authorbibnamehash}{45624c4382fbe254596a53dcf8c7ec6f}
      \strng{authornamehash}{45624c4382fbe254596a53dcf8c7ec6f}
      \strng{authorfullhash}{45624c4382fbe254596a53dcf8c7ec6f}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a descriptive analysis of over 1000 global NASA Task Load Index (TLX; Hart \& Staveland, 1988) scores from over 200 publications. This analysis is similar to that which was suggested by Hart (2006). The frequency distributions and measures of central tendency presented will aid practitioners in understanding global NASA-TLX scores observed in system tests.}
      \field{issn}{2169-5067}
      \field{journaltitle}{Proceedings of the Human Factors and Ergonomics Society Annual Meeting}
      \field{month}{9}
      \field{note}{Publisher: SAGE Publications Inc}
      \field{number}{1}
      \field{shorttitle}{How {High} is {High}?}
      \field{title}{How {High} is {High}? {A} {Meta}-{Analysis} of {NASA}-{TLX} {Global} {Workload} {Scores}}
      \field{urlday}{8}
      \field{urlmonth}{2}
      \field{urlyear}{2021}
      \field{volume}{59}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{1727\bibrangedash 1731}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1177/1541931215591373
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1177/1541931215591373
      \endverb
      \verb{url}
      \verb https://doi.org/10.1177/1541931215591373
      \endverb
    \endentry
    \entry{Grijincu:2014}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=884d624cfee2de9f45987f5643834f46}{%
           family={Grijincu},
           familyi={G\bibinitperiod},
           given={Daniela},
           giveni={D\bibinitperiod}}}%
        {{hash=f483c1ba76e286def20f9438b4b6ba7c}{%
           family={Nacenta},
           familyi={N\bibinitperiod},
           given={Miguel\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=db3b6a3624f37d3c580dff8ae2a9c807}{%
           family={Kristensson},
           familyi={K\bibinitperiod},
           given={Per\bibnamedelima Ola},
           giveni={P\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{deb28220cf7e3061ece6c825f35f43b2}
      \strng{fullhash}{deb28220cf7e3061ece6c825f35f43b2}
      \strng{bibnamehash}{deb28220cf7e3061ece6c825f35f43b2}
      \strng{authorbibnamehash}{deb28220cf7e3061ece6c825f35f43b2}
      \strng{authornamehash}{deb28220cf7e3061ece6c825f35f43b2}
      \strng{authorfullhash}{deb28220cf7e3061ece6c825f35f43b2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Ninth ACM International Conference on Interactive Tabletops and Surfaces}
      \field{isbn}{9781450325875}
      \field{series}{ITS ’14}
      \field{title}{{User-Defined Interface Gestures: Dataset and Analysis}}
      \field{venue}{Dresden, Germany}
      \field{year}{2014}
      \field{pages}{25\bibrangedash 34}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2669485.2669511
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2669485.2669511
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2669485.2669511
      \endverb
      \keyw{gesture elicitation,gesture annotation,gesture analysis methodology,gesture design,user-defined gestures,gesture datasets,gesture memorability}
    \endentry
    \entry{Groenewald:2016}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=6cc434db9ce7ef159a8a3f637878defb}{%
           family={Groenewald},
           familyi={G\bibinitperiod},
           given={Celeste},
           giveni={C\bibinitperiod}}}%
        {{hash=03ae530fb216598bac3f965d02add76d}{%
           family={Anslow},
           familyi={A\bibinitperiod},
           given={Craig},
           giveni={C\bibinitperiod}}}%
        {{hash=13290df3292d3c1f1fdcc89b19a67c15}{%
           family={Islam},
           familyi={I\bibinitperiod},
           given={Junayed},
           giveni={J\bibinitperiod}}}%
        {{hash=1e70701f6ab6f480cdf0fe3aaa5b172d}{%
           family={Rooney},
           familyi={R\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
        {{hash=dd38ec63a5a6484a5733266ed855b06b}{%
           family={Passmore},
           familyi={P\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=072ebc19cbad98825be7045b25bc4c63}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={William},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Swindon, GBR}%
      }
      \list{publisher}{1}{%
        {BCS Learning \& Development Ltd.}%
      }
      \strng{namehash}{7cf521ab9f8309b30343772c86480b00}
      \strng{fullhash}{a63ac5935f9c4dcc86bc22c75d7a36f3}
      \strng{bibnamehash}{7cf521ab9f8309b30343772c86480b00}
      \strng{authorbibnamehash}{7cf521ab9f8309b30343772c86480b00}
      \strng{authornamehash}{7cf521ab9f8309b30343772c86480b00}
      \strng{authorfullhash}{a63ac5935f9c4dcc86bc22c75d7a36f3}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{3D gesture based systems are becoming ubiquitous and there are many mid-air hand gestures that exist for interacting with digital surfaces and displays. There is no well defined gesture set for 3D mid-air hand gestures which makes it difficult to develop applications that have consistent gestures. To understand what gestures exist we conducted the first comprehensive systematic literature review on mid-air hand gestures following existing research methods. The results of the review identified 65 papers where the mid-air hand gestures supported tasks for selection, navigation, and manipulation. We also classified the gestures according to a gesture classification scheme and identified how these gestures have been empirically evaluated. The results of the review provide a richer understanding of what mid-air hand gestures have been designed, implemented, and evaluated in the literature which can help developers design better user experiences for digital interactive surfaces and displays.}
      \field{booktitle}{Proceedings of the 30th International BCS Human Computer Interaction Conference: Fusion!}
      \field{series}{HCI '16}
      \field{title}{{Understanding 3D Mid-Air Hand Gestures with Interactive Surfaces and Displays: A Systematic Literature Review}}
      \field{venue}{Poole, United Kingdom}
      \field{year}{2016}
      \verb{doi}
      \verb 10.14236/ewic/HCI2016.43
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.14236/ewic/HCI2016.43
      \endverb
      \verb{url}
      \verb https://doi.org/10.14236/ewic/HCI2016.43
      \endverb
      \keyw{HCI,3D gestures,interaction gestures,systematic literature review,mid-air hand gestures}
    \endentry
    \entry{Gupta:2017}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=bca9282db5047ec6a404a5ce6a7a9472}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Aakar},
           giveni={A\bibinitperiod}}}%
        {{hash=7bf4810161280e5974df5ecaece87f7b}{%
           family={Pietrzak},
           familyi={P\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=3d88732e65b4b8e6f005957fac599c07}{%
           family={Yau},
           familyi={Y\bibinitperiod},
           given={Cleon},
           giveni={C\bibinitperiod}}}%
        {{hash=2febb2b64f8627ea8fcbd56ce2e11f97}{%
           family={Roussel},
           familyi={R\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=56b75ac1304af45b6c3f0a9bca7fa615}{%
           family={Balakrishnan},
           familyi={B\bibinitperiod},
           given={Ravin},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{dc20a1f86c2190072fa076c9e68cb8d8}
      \strng{fullhash}{f9af72ea55988a001a8de64d56656b90}
      \strng{bibnamehash}{dc20a1f86c2190072fa076c9e68cb8d8}
      \strng{authorbibnamehash}{dc20a1f86c2190072fa076c9e68cb8d8}
      \strng{authornamehash}{dc20a1f86c2190072fa076c9e68cb8d8}
      \strng{authorfullhash}{f9af72ea55988a001a8de64d56656b90}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Current freehand interactions with large displays rely on point \& select as the dominant paradigm. However, constant hand movement in air for pointer navigation leads to hand fatigue quickly. We introduce summon \& select, a new model for freehand interaction where, instead of navigating to the control, the user summons it into focus and then manipulates it. Summon \& select solves the problems of constant pointer navigation, need for precise selection, and out-of-bounds gestures that plague point \& select. We describe the design and conduct two studies to evaluate the design and compare it against point \& select in a multi-button selection study. The results show that summon \& select is significantly faster and has less physical and mental demand than point \& select.}
      \field{booktitle}{Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces}
      \field{isbn}{9781450346917}
      \field{series}{ISS '17}
      \field{title}{{Summon and Select: Rapid Interaction with Interface Controls in Mid-Air}}
      \field{venue}{Brighton, United Kingdom}
      \field{year}{2017}
      \field{pages}{52\bibrangedash 61}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3132272.3134120
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3132272.3134120
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3132272.3134120
      \endverb
      \keyw{Gestures,Freehand,Mid-air,Haptics}
    \endentry
    \entry{Gurbuz:2020}{inproceedings}{}
      \name{author}{9}{}{%
        {{hash=4aabd4b8987d9a07648c7553a90c5790}{%
           family={Gurbuz},
           familyi={G\bibinitperiod},
           given={Sevgi\bibnamedelima Z.},
           giveni={S\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=5ed5af09082d04ed2529b99716d9b544}{%
           family={Gurbuz},
           familyi={G\bibinitperiod},
           given={Ali\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=4bb0f7f5bbe4b53360ba458fb34dafc1}{%
           family={Malaia},
           familyi={M\bibinitperiod},
           given={Evie\bibnamedelima A.},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=b03ba843c5a67e855737c194a84b1313}{%
           family={Griffin},
           familyi={G\bibinitperiod},
           given={Darrin\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=531d569600702c7681d6c15009c4df72}{%
           family={Crawford},
           familyi={C\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
        {{hash=a1c7958f9ae7a15c3be39b9afcecacea}{%
           family={Kurtoglu},
           familyi={K\bibinitperiod},
           given={Emre},
           giveni={E\bibinitperiod}}}%
        {{hash=768b374d9ffa9cb63678e618021f9412}{%
           family={Rahman},
           familyi={R\bibinitperiod},
           given={Mohammad\bibnamedelima Mahbubur},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=319862d5678e173566479719abbed747}{%
           family={Aksu},
           familyi={A\bibinitperiod},
           given={Ridvan},
           giveni={R\bibinitperiod}}}%
        {{hash=c96686f73975599b2e3d95528189c314}{%
           family={Mdrafi},
           familyi={M\bibinitperiod},
           given={Robiulhossain},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{979b9d3f16616df31a7cdfe063342a5c}
      \strng{fullhash}{6f0ced804fe915c52f08bab2000bf733}
      \strng{bibnamehash}{979b9d3f16616df31a7cdfe063342a5c}
      \strng{authorbibnamehash}{979b9d3f16616df31a7cdfe063342a5c}
      \strng{authornamehash}{979b9d3f16616df31a7cdfe063342a5c}
      \strng{authorfullhash}{6f0ced804fe915c52f08bab2000bf733}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As a means for leveraging technology in the design of Deaf spaces, this paper presents initial results on American Sign Language (ASL) recognition using RF sensing. RF sensors are non-contact, non-invasive, and protective of privacy, making them of special interest for use in personal areas. Using just the kinematic properties of signing as captured by the micro-Doppler signatures of a multi-frequency RF sensor network, this paper shows that native and imitation signing can be differentiated with \%99 accuracy, while up to 20 ASL signs are recognized with an accuracy of \%72 or higher.}
      \field{booktitle}{2020 {IEEE} {Sensors}}
      \field{month}{10}
      \field{note}{ISSN: 2168-9229}
      \field{title}{{ASL} {Recognition} {Based} on {Kinematics} {Derived} from a {Multi}-{Frequency} {RF} {Sensor} {Network}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/SENSORS47125.2020.9278864
      \endverb
      \keyw{American sign language,Assistive technology,Discrete cosine transforms,Feature extraction,gesture recognition,Gesture recognition,Radar,radar micro-Doppler,Radio frequency,RF sensing,Support vector machines}
    \endentry
    \entry{Gusenbauer:2020}{article}{}
      \name{author}{2}{}{%
        {{hash=3ce9e5d29bb74ef30e92ad7aad854505}{%
           family={Gusenbauer},
           familyi={G\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=2d1ada6d2c48c912cb12f21cbcb80095}{%
           family={Haddaway},
           familyi={H\bibinitperiod},
           given={Neal\bibnamedelima R.},
           giveni={N\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \strng{namehash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \strng{fullhash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \strng{bibnamehash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \strng{authorbibnamehash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \strng{authornamehash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \strng{authorfullhash}{272a5fbd8c20b0b8526956e8b2c0cd96}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Rigorous evidence identification is essential for systematic reviews and meta-analyses (evidence syntheses) because the sample selection of relevant studies determines a review's outcome, validity, and explanatory power. Yet, the search systems allowing access to this evidence provide varying levels of precision, recall, and reproducibility and also demand different levels of effort. To date, it remains unclear which search systems are most appropriate for evidence synthesis and why. Advice on which search engines and bibliographic databases to choose for systematic searches is limited and lacking systematic, empirical performance assessments. This study investigates and compares the systematic search qualities of 28 widely used academic search systems, including Google Scholar, PubMed, and Web of Science. A novel, query-based method tests how well users are able to interact and retrieve records with each system. The study is the first to show the extent to which search systems can effectively and efficiently perform (Boolean) searches with regards to precision, recall, and reproducibility. We found substantial differences in the performance of search systems, meaning that their usability in systematic searches varies. Indeed, only half of the search systems analyzed and only a few Open Access databases can be recommended for evidence syntheses without adding substantial caveats. Particularly, our findings demonstrate why Google Scholar is inappropriate as principal search system. We call for database owners to recognize the requirements of evidence synthesis and for academic journals to reassess quality requirements for systematic reviews. Our findings aim to support researchers in conducting better searches for better evidence synthesis.}
      \field{journaltitle}{Research Synthesis Methods}
      \field{number}{2}
      \field{title}{{Which academic search systems are suitable for systematic reviews or meta-analyses? Evaluating retrieval qualities of Google Scholar, PubMed, and 26 other resources}}
      \field{volume}{11}
      \field{year}{2020}
      \field{pages}{181\bibrangedash 217}
      \range{pages}{37}
      \verb{doi}
      \verb https://doi.org/10.1002/jrsm.1378
      \endverb
      \verb{eprint}
      \verb https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1378
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1378
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1378
      \endverb
      \keyw{academic search systems,discovery,evaluation,information retrieval,systematic review,systematic search}
    \endentry
    \entry{Guttman:1945}{article}{}
      \name{author}{1}{}{%
        {{hash=e0dbcd08b0c32faa7ed0470e98aa7e18}{%
           family={Guttman},
           familyi={G\bibinitperiod},
           given={Louis},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \strng{fullhash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \strng{bibnamehash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \strng{authorbibnamehash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \strng{authornamehash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \strng{authorfullhash}{e0dbcd08b0c32faa7ed0470e98aa7e18}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Psychometrika}
      \field{month}{12}
      \field{title}{{A basis for analyzing test-retest reliability}}
      \field{volume}{10}
      \field{year}{1945}
      \field{pages}{255\bibrangedash 282}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1007/BF02288892
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/BF02288892
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/BF02288892
      \endverb
    \endentry
    \entry{Guzsvinecz:2019}{article}{}
      \name{author}{3}{}{%
        {{hash=f9d2ac60b0b3b60d8f5d19d5ba8ea880}{%
           family={Guzsvinecz},
           familyi={G\bibinitperiod},
           given={Tibor},
           giveni={T\bibinitperiod}}}%
        {{hash=15c0688c6b062da4799918e5df83329e}{%
           family={Szucs},
           familyi={S\bibinitperiod},
           given={Veronika},
           giveni={V\bibinitperiod}}}%
        {{hash=369321400779d6e955da2b1fec76029c}{%
           family={Sik-Lanyi},
           familyi={S\bibinithyphendelim L\bibinitperiod},
           given={Cecilia},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{9c3db991431b4ee5e2ad0b22cf825697}
      \strng{fullhash}{9c3db991431b4ee5e2ad0b22cf825697}
      \strng{bibnamehash}{9c3db991431b4ee5e2ad0b22cf825697}
      \strng{authorbibnamehash}{9c3db991431b4ee5e2ad0b22cf825697}
      \strng{authornamehash}{9c3db991431b4ee5e2ad0b22cf825697}
      \strng{authorfullhash}{9c3db991431b4ee5e2ad0b22cf825697}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As the need for sensors increases with the inception of virtual reality, augmented reality and mixed reality, the purpose of this paper is to evaluate the suitability of the two Kinect devices and the Leap Motion Controller. When evaluating the suitability, the authors's focus was on the state of the art, device comparison, accuracy, precision, existing gesture recognition algorithms and on the price of the devices. The aim of this study is to give an insight whether these devices could substitute more expensive sensors in the industry or on the market. While in general the answer is yes, it is not as easy as it seems: There are significant differences between the devices, even between the two Kinects, such as different measurement ranges, error distributions on each axis and changing depth precision relative to distance.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{5}
      \field{title}{{Suitability of the Kinect Sensor and Leap Motion Controller—A Literature Review}}
      \field{volume}{19}
      \field{year}{2019}
      \verb{doi}
      \verb 10.3390/s19051072
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/19/5/1072
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/19/5/1072
      \endverb
    \endentry
    \entry{Hansberger:2017}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=4c9d9de1575356ca25188601c2018dcf}{%
           family={Hansberger},
           familyi={H\bibinitperiod},
           given={Jeffrey\bibnamedelima T.},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{hash=f4c11bfeb13b5897278b3b2c6412c3c2}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={Chao},
           giveni={C\bibinitperiod}}}%
        {{hash=8e83e6e30bc7e478b123134c7f49a941}{%
           family={Mathis},
           familyi={M\bibinitperiod},
           given={Shannon\bibnamedelima L.},
           giveni={S\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=3d2f4b14277a81d636b189d5ba573bc9}{%
           family={Areyur\bibnamedelima Shanthakumar},
           familyi={A\bibinitperiod\bibinitdelim S\bibinitperiod},
           given={Vaidyanath},
           giveni={V\bibinitperiod}}}%
        {{hash=80434e5b8476a854f5f946d1741b5c54}{%
           family={Meacham},
           familyi={M\bibinitperiod},
           given={Sarah\bibnamedelima C.},
           giveni={S\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=e6ef18e730cc2a78b609645e5936360a}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Lizhou},
           giveni={L\bibinitperiod}}}%
        {{hash=3b66fc6feecb5a236457d6aff4337b42}{%
           family={Blakely},
           familyi={B\bibinitperiod},
           given={Victoria\bibnamedelima R.},
           giveni={V\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=442bd5d1a52f916650ddcd2158bc468f}{%
           family={Lackey},
           familyi={L\bibinitperiod},
           given={Stephanie},
           giveni={S\bibinitperiod}}}%
        {{hash=2afe470fb3f1124d80ad4f782a664423}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jessie},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{1f7548a69b36f2debb447cf8fd34c6b4}
      \strng{fullhash}{5495d3bddf33f058da376c8252c669b5}
      \strng{bibnamehash}{1f7548a69b36f2debb447cf8fd34c6b4}
      \strng{authorbibnamehash}{1f7548a69b36f2debb447cf8fd34c6b4}
      \strng{authornamehash}{1f7548a69b36f2debb447cf8fd34c6b4}
      \strng{authorfullhash}{5495d3bddf33f058da376c8252c669b5}
      \strng{editorbibnamehash}{90e0750355a06613e21d25244c8ee131}
      \strng{editornamehash}{90e0750355a06613e21d25244c8ee131}
      \strng{editorfullhash}{90e0750355a06613e21d25244c8ee131}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The use of gestures as a way to interact with computer systems has shown promise as a natural way to interact and manipulate digital information. However, users performing mid-air gestures for even moderate periods of time experience arm fatigue and discomfort, earning its name of the gorilla arm syndrome. Based on the natural use of hands during communication, a new gesture vocabulary was created that supports the arms while the user performs the gestures. A repeated measures within subject design was conducted where participants interacted with a custom video game using 3 types of input for 30 min each, (1) keyboard, (2) mid-air gestures and (3) supported gestures. Three measures of exertion were collected, (1) time, (2) energy expenditure, and (3) perceived exertion. The newly designed supported gestures required significantly less physical and perceived effort than the mid-air gestures and required similar exertion as the keyboard condition.}
      \field{booktitle}{Virtual, Augmented and Mixed Reality}
      \field{isbn}{978-3-319-57987-0}
      \field{title}{{Dispelling the Gorilla Arm Syndrome: The Viability of Prolonged Gesture Interactions}}
      \field{year}{2017}
      \field{pages}{505\bibrangedash 520}
      \range{pages}{16}
    \endentry
    \entry{Hart:1988}{incollection}{}
      \name{author}{2}{}{%
        {{hash=3c980fec4ba43d342b9a70395a28e428}{%
           family={Hart},
           familyi={H\bibinitperiod},
           given={Sandra\bibnamedelima G.},
           giveni={S\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=a6046a8b39af8e784bfee58f91b7c89e}{%
           family={Staveland},
           familyi={S\bibinitperiod},
           given={Lowell\bibnamedelima E.},
           giveni={L\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=2cd63fdeb7635ada82df27eda081c8ff}{%
           family={Hancock},
           familyi={H\bibinitperiod},
           given={Peter\bibnamedelima A.},
           giveni={P\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=3831385f9302823ce625bb3f22073a36}{%
           family={Meshkati},
           familyi={M\bibinitperiod},
           given={Najmedin},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {North-Holland}%
      }
      \strng{namehash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{fullhash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{bibnamehash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{authorbibnamehash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{authornamehash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{authorfullhash}{469efa314baa32a3f4d461e0dce2d6ea}
      \strng{editorbibnamehash}{5ab5a00388696d8bd79285d2c914a7f0}
      \strng{editornamehash}{5ab5a00388696d8bd79285d2c914a7f0}
      \strng{editorfullhash}{5ab5a00388696d8bd79285d2c914a7f0}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.}
      \field{booktitle}{Human Mental Workload}
      \field{issn}{0166-4115}
      \field{series}{Advances in Psychology}
      \field{title}{{Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research}}
      \field{volume}{52}
      \field{year}{1988}
      \field{pages}{139\bibrangedash 183}
      \range{pages}{45}
      \verb{doi}
      \verb https://doi.org/10.1016/S0166-4115(08)62386-9
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S0166411508623869
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S0166411508623869
      \endverb
    \endentry
    \entry{Hayashi:2021}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=7105b4650cb4c50e52a0854793504b76}{%
           family={Hayashi},
           familyi={H\bibinitperiod},
           given={Eiji},
           giveni={E\bibinitperiod}}}%
        {{hash=5858a49df4f45760271051cb85536f29}{%
           family={Lien},
           familyi={L\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod}}}%
        {{hash=9461d29e911cdf4cf0bf584d64a40d4a}{%
           family={Gillian},
           familyi={G\bibinitperiod},
           given={Nicholas},
           giveni={N\bibinitperiod}}}%
        {{hash=6187a67f1c03805aed7c58bc8c5a2da6}{%
           family={Giusti},
           familyi={G\bibinitperiod},
           given={Leonardo},
           giveni={L\bibinitperiod}}}%
        {{hash=2e8cf9f595e20fd21d541d7cc6a5c633}{%
           family={Weber},
           familyi={W\bibinitperiod},
           given={Dave},
           giveni={D\bibinitperiod}}}%
        {{hash=d6ab693b64d53e1c5e1cfac676db1421}{%
           family={Yamanaka},
           familyi={Y\bibinitperiod},
           given={Jin},
           giveni={J\bibinitperiod}}}%
        {{hash=dce60cc0e665b7ecc0e6e18923202bb9}{%
           family={Bedal},
           familyi={B\bibinitperiod},
           given={Lauren},
           giveni={L\bibinitperiod}}}%
        {{hash=e1b6c7b998ff4368f042c24f7c1b6350}{%
           family={Poupyrev},
           familyi={P\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{8a2e72ed3b92db7788841cdc363ba056}
      \strng{fullhash}{09e80b1e2b2a53861651971b4b710512}
      \strng{bibnamehash}{8a2e72ed3b92db7788841cdc363ba056}
      \strng{authorbibnamehash}{8a2e72ed3b92db7788841cdc363ba056}
      \strng{authornamehash}{8a2e72ed3b92db7788841cdc363ba056}
      \strng{authorfullhash}{09e80b1e2b2a53861651971b4b710512}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gestures are a promising candidate as an input modality for ambient computing where conventional input modalities such as touchscreens are not available. Existing works have focused on gesture recognition using image sensors. However, their cost, high battery consumption, and privacy concerns made cameras challenging as an always-on solution. This paper introduces an efficient gesture recognition technique using a miniaturized 60 GHz radar sensor. The technique recognizes four directional swipes and an omni-swipe using a radar chip (6.5 \texttimes{} 5.0 mm) integrated into a mobile phone. We developed a convolutional neural network model efficient enough for battery powered and computationally constrained processors. Its model size and inference time is less than 1/5000 compared to an existing gesture recognition technique using radar. Our evaluations with large scale datasets consisting of 558,000 gesture samples and 3,920,000 negative samples demonstrated our algorithm’s efficiency, robustness, and readiness to be deployed outside of research laboratories.}
      \field{booktitle}{Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450380966}
      \field{series}{CHI '21}
      \field{title}{{RadarNet: Efficient Gesture Recognition Technique Utilizing a Miniature Radar Sensor}}
      \field{venue}{Yokohama, Japan}
      \field{year}{2021}
      \verb{doi}
      \verb 10.1145/3411764.3445367
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3411764.3445367
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3411764.3445367
      \endverb
      \keyw{mobile,gesture recognition,radar sensing,deep learning}
    \endentry
    \entry{Hazra:2019b}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=1f8393e7b55c6e636efc0f5f02199812}{%
           family={Hazra},
           familyi={H\bibinitperiod},
           given={Souvik},
           giveni={S\bibinitperiod}}}%
        {{hash=f82219bcf97702d81f4dc65d14059788}{%
           family={Santra},
           familyi={S\bibinitperiod},
           given={Avik},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{fullhash}{137502645c7c673708c1a09bc03a55a9}
      \strng{bibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorbibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authornamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorfullhash}{137502645c7c673708c1a09bc03a55a9}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition provides an easy, convenient and intuitive way of remotely controlling several consumer electronics devices such as audio devices, television sets, projector or gaming consoles. In recent years, radar sensors have been shown to be effective sensing modality to sense and recognize fine-grained dynamic finger-gestures in watch or smartphone and thus offers an user-friendly human-computer interface in ultrashort range applications. However, hand-gesture recognition from a farther distance such as to control consumer devices like TV or projector pose challenge particularly arising due to interferences from multiple humans in the field of view. In this paper, we present a novel unguided spatio-Doppler attention mechanism to enable hand-gesture recognition in presence of multiple humans using a low power, compact 60-GHz FMCW radar operated in 500MHz ISM frequency band. The spatio-Doppler mechanism in 2D deep convolutional neural network with long short term memory (2D CNN-LSTM) makes use of the range-Doppler images and range-angle images. We experimentally present the classification accuracy of 94.75\% of our proposed system on test dataset using eight gestures, namely wave, push forward, pull, left swipe, right swipe, clockwise rotate, anti-clockwise rotate, cross, in presence of interfering people, such as walking or arbitrary movements.}
      \field{booktitle}{2019 18th {IEEE} {International} {Conference} {On} {Machine} {Learning} {And} {Applications} ({ICMLA})}
      \field{month}{12}
      \field{title}{Radar {Gesture} {Recognition} {System} in {Presence} of {Interference} using {Self}-{Attention} {Neural} {Network}}
      \field{year}{2019}
      \field{pages}{1409\bibrangedash 1414}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ICMLA.2019.00230
      \endverb
      \keyw{2D CNN-LSTM,2D deep convolutional neural network,audio devices,bandwidth 500.0 MHz,Chirp,consumer electronics,consumer electronics devices,CW radar,Doppler effect,Doppler radar,effective sensing modality,fine-grained dynamic finger-gestures,FM radar,FMCW radar,frequency 60 GHz,gesture recognition,Gesture recognition,Gesture Recognition,hand-gesture recognition,human computer interaction,Human-Computer Interface,image sensors,ISM frequency band,long short term memory,millimetre wave radar,mm-wave radar,neural nets,radar computing,radar gesture recognition system,radar imaging,radar sensors,range-angle images,range-Doppler images,self-attention neural network,Sensors,spatio-Doppler mechanism,television sets,Two dimensional displays,ultrashort range applications,unguided spatio-Doppler attention,user-friendly human-computer interface}
    \endentry
    \entry{Hazra:2018}{article}{}
      \name{author}{2}{}{%
        {{hash=1f8393e7b55c6e636efc0f5f02199812}{%
           family={Hazra},
           familyi={H\bibinitperiod},
           given={Souvik},
           giveni={S\bibinitperiod}}}%
        {{hash=f82219bcf97702d81f4dc65d14059788}{%
           family={Santra},
           familyi={S\bibinitperiod},
           given={Avik},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{fullhash}{137502645c7c673708c1a09bc03a55a9}
      \strng{bibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorbibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authornamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorfullhash}{137502645c7c673708c1a09bc03a55a9}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition is one of the most intuitive forms of human-computer interface. Gesture sensing can replace interfaces such as touch and clicks needed for interacting with a device. In this article, we present a short-range compact 60-GHz mm-wave radar sensor that is sensitive to fine dynamic hand motions. A series of range-Doppler images are extracted and processed using a long recurrent all-convolution neural network for real-time dynamic hand gesture recognition. Furthermore, we make use of novel data augmentation techniques for the proposed gesture recognition system to generalize for multiple users and operating environments. The results show accurate classification performance requiring very low processor footprint facilitating implementation in embedded platforms with real-time user feedback.}
      \field{issn}{2475-1472}
      \field{journaltitle}{IEEE Sensors Letters}
      \field{month}{12}
      \field{number}{4}
      \field{title}{Robust {Gesture} {Recognition} {Using} {Millimetric}-{Wave} {Radar} {System}}
      \field{volume}{2}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/LSENS.2018.2882642
      \endverb
      \keyw{60-GHz mm-wave radar,data augmentation techniques,dynamic hand motions,Feature extraction,frequency 60 GHz,gesture recognition,Gesture recognition,gesture recognition system,gesture sensing,Human computer interaction,human-computer interface,human–computer interface,Millimeter wave radar,millimetric-wave radar system,neural nets,neural network,radar imaging,Radar imaging,range-Doppler images,real-time dynamic hand gesture recognition,real-time user feedback,robust gesture recognition,sensing,Sensor signals processing,short-range compact mm-wave radar sensor}
    \endentry
    \entry{Hazra:2019a}{article}{}
      \name{author}{2}{}{%
        {{hash=1f8393e7b55c6e636efc0f5f02199812}{%
           family={Hazra},
           familyi={H\bibinitperiod},
           given={Souvik},
           giveni={S\bibinitperiod}}}%
        {{hash=f82219bcf97702d81f4dc65d14059788}{%
           family={Santra},
           familyi={S\bibinitperiod},
           given={Avik},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{fullhash}{137502645c7c673708c1a09bc03a55a9}
      \strng{bibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorbibnamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authornamehash}{137502645c7c673708c1a09bc03a55a9}
      \strng{authorfullhash}{137502645c7c673708c1a09bc03a55a9}
      \field{extraname}{3}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition is the most intuitive form of human computer-interface. Gesture sensing can replace interfaces such as touch and clicks needed for interacting with a device. Gesture recognition in a practical scenario is an open-set classification, i.e. the recognition system should classify correct known gestures while rejecting arbitrary unknown gestures during inference. To address the issue of gesture recognition in an open set, we present, in this paper, a novel distance-metric based meta-learning approach to learn embedding features from a video of range-Doppler images generated by hand gestures at the radar receiver. Further, k-Nearest Neighbor (kNN) is used to classify known gestures, distance-thresholding is used to reject unknown gesture motions and clustering is used to add new custom gestures on-the-fly without explicit model re-training. We propose to use 3D Deep Convolutional Neural Network (3D-DCNN) architecture to learn the embedding model using distance-based triplet-loss similarity metric. We demonstrate our approach to correctly classify gestures using short-range 60-GHz compact short-range radar sensor achieving an overall classification accuracy of 94.5\% over six fine-grained gestures under challenging practical environments, while rejecting other unknown gestures with 0.935 F1 score, and capable of adding new gestures on-the-fly without an explicit model re-training.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Short-{Range} {Radar}-{Based} {Gesture} {Recognition} {System} {Using} {3D} {CNN} {With} {Triplet} {Loss}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{125623\bibrangedash 125633}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2938725
      \endverb
      \keyw{arbitrary unknown gestures,convolutional neural nets,correct known gestures,custom gestures on-the-fly,Data models,Deep learning,distance-based triplet-loss similarity,distance-metric based meta-learning approach,Doppler radar,Feature extraction,fine-grained gestures,gesture recognition,Gesture recognition,gesture sensing,hand gestures,human computer interaction,human-machine interface,image classification,learning (artificial intelligence),mm-wave radar,nearest neighbour methods,open-set classification,pattern classification,Radar,Receivers,short-range 60-GHz compact short-range radar sensor,short-range radar-based gesture recognition system,Three-dimensional displays,triplet loss,unknown gesture motions}
    \endentry
    \entry{HernandezVela:2014}{article}{}
      \name{author}{8}{}{%
        {{hash=f5a5e631fd14baf06f45b1a6f8fda3ef}{%
           family={Hernández-Vela},
           familyi={H\bibinithyphendelim V\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
        {{hash=a68e3c79835d251e6d3c32ae07d33b61}{%
           family={Bautista},
           familyi={B\bibinitperiod},
           given={Miguel\bibnamedelima Ángel},
           giveni={M\bibinitperiod\bibinitdelim Á\bibinitperiod}}}%
        {{hash=e8c3db9c5eee2d7ffd9fca7fb621e7d5}{%
           family={Perez-Sala},
           familyi={P\bibinithyphendelim S\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
        {{hash=1b9a235f0635441757c2d850cf58fdf7}{%
           family={Ponce-López},
           familyi={P\bibinithyphendelim L\bibinitperiod},
           given={Víctor},
           giveni={V\bibinitperiod}}}%
        {{hash=d551650e8cc9944645e34ae01c81034e}{%
           family={Escalera},
           familyi={E\bibinitperiod},
           given={Sergio},
           giveni={S\bibinitperiod}}}%
        {{hash=4a3adcc48a274f3b246cfc3902b1c1a6}{%
           family={Baró},
           familyi={B\bibinitperiod},
           given={Xavier},
           giveni={X\bibinitperiod}}}%
        {{hash=28656f71cb8f915d250dc2451225fa96}{%
           family={Pujol},
           familyi={P\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod}}}%
        {{hash=2f8c58ae109b1b6121d690802654dc95}{%
           family={Angulo},
           familyi={A\bibinitperiod},
           given={Cecilio},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{143c0ca4b23e1fd661ae3325805b035b}
      \strng{fullhash}{ce27cae497988ae265bc5d029fa4389c}
      \strng{bibnamehash}{143c0ca4b23e1fd661ae3325805b035b}
      \strng{authorbibnamehash}{143c0ca4b23e1fd661ae3325805b035b}
      \strng{authornamehash}{143c0ca4b23e1fd661ae3325805b035b}
      \strng{authorfullhash}{ce27cae497988ae265bc5d029fa4389c}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a methodology to address the problem of human gesture segmentation and recognition in video and depth image sequences. A Bag-of-Visual-and-Depth-Words (BoVDW) model is introduced as an extension of the Bag-of-Visual-Words (BoVW) model. State-of-the-art RGB and depth features, including a newly proposed depth descriptor, are analysed and combined in a late fusion form. The method is integrated in a Human Gesture Recognition pipeline, together with a novel probability-based Dynamic Time Warping (PDTW) algorithm which is used to perform prior segmentation of idle gestures. The proposed DTW variant uses samples of the same gesture category to build a Gaussian Mixture Model driven probabilistic model of that gesture class. Results of the whole Human Gesture Recognition pipeline in a public data set show better performance in comparison to both standard BoVW model and DTW approach.}
      \field{issn}{0167-8655}
      \field{journaltitle}{Pattern Recognition Letters}
      \field{note}{Depth Image Analysis}
      \field{title}{{Probability-based Dynamic Time Warping and Bag-of-Visual-and-Depth-Words for Human Gesture Recognition in RGB-D}}
      \field{volume}{50}
      \field{year}{2014}
      \field{pages}{112\bibrangedash 121}
      \range{pages}{10}
      \verb{doi}
      \verb https://doi.org/10.1016/j.patrec.2013.09.009
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0167865513003450
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0167865513003450
      \endverb
      \keyw{RGB-D,Bag-of-Words,Dynamic Time Warping,Human Gesture Recognition}
    \endentry
    \entry{Hincapie:2014}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=c4d0b1cbbe18a18152053493e1be5e3f}{%
           family={Hincapié-Ramos},
           familyi={H\bibinithyphendelim R\bibinitperiod},
           given={Juan\bibnamedelima David},
           giveni={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=b894fd1a7f9613451ac9e9fc8d6175e9}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=c10edc2f27df6a64a6ae998a9ef93bfb}{%
           family={Moghadasian},
           familyi={M\bibinitperiod},
           given={Paymahn},
           giveni={P\bibinitperiod}}}%
        {{hash=b971847f0bbef7e53040c3b3ea1bba38}{%
           family={Irani},
           familyi={I\bibinitperiod},
           given={Pourang},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Toronto, Ontario, Canada}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b70d67eff8a4ae8124ca6608031a440a}
      \strng{fullhash}{b8ef29c2dfdf0ba245145945f8ba37bd}
      \strng{bibnamehash}{b70d67eff8a4ae8124ca6608031a440a}
      \strng{authorbibnamehash}{b70d67eff8a4ae8124ca6608031a440a}
      \strng{authornamehash}{b70d67eff8a4ae8124ca6608031a440a}
      \strng{authorfullhash}{b8ef29c2dfdf0ba245145945f8ba37bd}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450324731}
      \field{series}{CHI '14}
      \field{title}{{Consumed endurance: a metric to quantify arm fatigue of mid-air interactions}}
      \field{year}{2014}
      \field{pages}{1063\bibrangedash 1072}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2556288.2557130
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2556288.2557130
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2556288.2557130
      \endverb
      \keyw{consumed endurance,endurance,gorilla-arm,mid-air interactions,mid-air text-entry,seato mid-air keyboard}
    \endentry
    \entry{Hinderks:2019}{article}{}
      \name{author}{5}{}{%
        {{hash=9aa46ba977c60b7e085ab820b41df600}{%
           family={Hinderks},
           familyi={H\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=131c7fe2089d9229c28f4e7a09b3a096}{%
           family={Schrepp},
           familyi={S\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
        {{hash=f93a314b6451a3841bfc8928d19699d0}{%
           family={Domínguez\bibnamedelima Mayo},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Francisco\bibnamedelima José},
           giveni={F\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=f50b76aed42d0d628d112871e598842c}{%
           family={Escalona},
           familyi={E\bibinitperiod},
           given={M.J.},
           giveni={M\bibinitperiod}}}%
        {{hash=f3bf7546743b7280490d85d6c7818717}{%
           family={Thomaschewski},
           familyi={T\bibinitperiod},
           given={Jörg},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{4b031a28e3c46943d363c7af625ff941}
      \strng{fullhash}{2ca2ab231ad07cbbc5ea57b5eca56a79}
      \strng{bibnamehash}{4b031a28e3c46943d363c7af625ff941}
      \strng{authorbibnamehash}{4b031a28e3c46943d363c7af625ff941}
      \strng{authornamehash}{4b031a28e3c46943d363c7af625ff941}
      \strng{authorfullhash}{2ca2ab231ad07cbbc5ea57b5eca56a79}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Computer Standards \& Interfaces}
      \field{month}{7}
      \field{title}{{Developing a UX KPI based on the User Experience Questionnaire}}
      \field{volume}{65}
      \field{year}{2019}
      \field{pages}{38\bibrangedash 44}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1016/j.csi.2019.01.007
      \endverb
    \endentry
    \entry{AlHourani:2018}{incollection}{}
      \name{author}{8}{}{%
        {{hash=16a5e1000b27333c7b09a14308067993}{%
           family={Al-Hourani},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Akram},
           giveni={A\bibinitperiod}}}%
        {{hash=f9b901055dfcef13d4fc6121a0435227}{%
           family={Evans},
           familyi={E\bibinitperiod},
           given={Robin\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=d26a5aeabe8d12b3b0bbd3b0c6152640}{%
           family={Farrell},
           familyi={F\bibinitperiod},
           given={Peter\bibnamedelima M.},
           giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=030950161f5bd447dc43227a7017cbe5}{%
           family={Moran},
           familyi={M\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod}}}%
        {{hash=444e83243af39ba3c5dbbd4694f3f661}{%
           family={Martorella},
           familyi={M\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
        {{hash=1d626a8ae0426ec3fedd9d28c67487cd}{%
           family={Kandeepan},
           familyi={K\bibinitperiod},
           given={Sithamparanathan},
           giveni={S\bibinitperiod}}}%
        {{hash=f3feccc8a27663debae064c69256027b}{%
           family={Skafidas},
           familyi={S\bibinitperiod},
           given={Stan},
           giveni={S\bibinitperiod}}}%
        {{hash=df9f2c8f7f79d3b27696e3d02ae516ed}{%
           family={Parampalli},
           familyi={P\bibinitperiod},
           given={Udaya},
           giveni={U\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=58e34e482e0dd6e755329ae57da3b293}{%
           family={Chellappa},
           familyi={C\bibinitperiod},
           given={Rama},
           giveni={R\bibinitperiod}}}%
        {{hash=fd3acabdbe6cc1c8fdbab64dd76ae135}{%
           family={Theodoridis},
           familyi={T\bibinitperiod},
           given={Sergios},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Academic Press}%
      }
      \strng{namehash}{0e422e7eda07d8bf9b8f61206fab3808}
      \strng{fullhash}{a814ee8ac46bc7b2e94226f0a0d42ba6}
      \strng{bibnamehash}{0e422e7eda07d8bf9b8f61206fab3808}
      \strng{authorbibnamehash}{0e422e7eda07d8bf9b8f61206fab3808}
      \strng{authornamehash}{0e422e7eda07d8bf9b8f61206fab3808}
      \strng{authorfullhash}{a814ee8ac46bc7b2e94226f0a0d42ba6}
      \strng{editorbibnamehash}{b70dd0ff523cf903cd068ad0db6ccb2e}
      \strng{editornamehash}{b70dd0ff523cf903cd068ad0db6ccb2e}
      \strng{editorfullhash}{b70dd0ff523cf903cd068ad0db6ccb2e}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent advances in semiconductor fabrication are providing the opportunity to build very small and cost-effective single chip integrated radar systems operating at millimeter-wave frequencies and beyond. These tiny radar systems will enable a wide range of new applications such as automotive radar, safety helmet radar, robot guidance radar, UAV collision avoidance and mapping radar, bicycle safety radar, and many other possibilities. Considerable progress has been made in designing and building such systems; however, many challenges remain related to limitations imposed by radio frequency IC technology such as Complementary Metal Oxide Semiconductors (CMOS) including modest dynamic range and modest noise figure for low noise amplifies (LNAs), oscillator phase noise, limited transmit power, etc. There is also likely to be a significant interference challenge arising from large numbers of small radars operating in close spatial and spectral proximity in many of the envisioned applications. In this chapter we present an overview of some of the design challenges facing millimeter-wave radar, and shed light on recent advances in system design and signal processing techniques, including adaptive waveform scheduling and interference mitigation. Advances in signal processing will allow multiple radars to operate in an uncoordinated manner with limited processing power using adaptive waveform scheduling, that leads to better interference mitigation and higher ranging performance. We present some properties of the millimeter-wave spectrum and investigate ray-tracing methods as an efficient, accurate, and rapid testing platform for consumer radars applications, where we develop a ray-tracing propagation model for automotive radar operating in an urban environment. Also, we introduce novel tools from stochastic geometry to characterize the statistics of the interference resulting from many radars sharing the same spectrum in a particular location. Specifically, we study automotive radar applications and obtain interference statistics and the estimated detection performance. Finally, we briefly discuss certain fundamental limitations imposed on radar system capabilities, by CMOS technology and by the information carrying capacity of electromagnetic waves.}
      \field{booktitle}{Academic Press Library in Signal Processing, Volume 7}
      \field{isbn}{978-0-12-811887-0}
      \field{title}{Chapter 7 - Millimeter-wave integrated radar systems and techniques}
      \field{year}{2018}
      \field{pages}{317\bibrangedash 363}
      \range{pages}{47}
      \verb{doi}
      \verb https://doi.org/10.1016/B978-0-12-811887-0.00007-9
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/B9780128118870000079
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/B9780128118870000079
      \endverb
      \keyw{Integrated radar,Radar on a chip,Pseudo-random stepped frequency radar,Radar interference,Millimeter-wave radar,Radar information theory}
    \endentry
    \entry{Huang:2019}{article}{}
      \name{author}{3}{}{%
        {{hash=416d33afec6eb17e435e951afefdb5ea}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Jinmiao},
           giveni={J\bibinitperiod}}}%
        {{hash=b8c432fea81cd7cdb95d4c2c17d0264d}{%
           family={Jaiswal},
           familyi={J\bibinitperiod},
           given={Prakhar},
           giveni={P\bibinitperiod}}}%
        {{hash=db08eef6561ed01b6a552ba974099fd0}{%
           family={Rai},
           familyi={R\bibinitperiod},
           given={Rahul},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Cambridge University Press}%
      }
      \strng{namehash}{6d2eaf08d8c46ca3552df5c729805433}
      \strng{fullhash}{6d2eaf08d8c46ca3552df5c729805433}
      \strng{bibnamehash}{6d2eaf08d8c46ca3552df5c729805433}
      \strng{authorbibnamehash}{6d2eaf08d8c46ca3552df5c729805433}
      \strng{authornamehash}{6d2eaf08d8c46ca3552df5c729805433}
      \strng{authorfullhash}{6d2eaf08d8c46ca3552df5c729805433}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Artificial Intelligence for Engineering Design, Analysis and Manufacturing}
      \field{number}{1}
      \field{title}{{Gesture-based system for next generation natural and intuitive interfaces}}
      \field{volume}{33}
      \field{year}{2019}
      \field{pages}{54\bibrangedash 68}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1017/S0890060418000045
      \endverb
    \endentry
    \entry{Huesser:2021}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=9403691bd41c4d2da31493126a4dc080}{%
           family={Huesser},
           familyi={H\bibinitperiod},
           given={Cloe},
           giveni={C\bibinitperiod}}}%
        {{hash=4bda2abea1e3f6ac73ba9db14be48e2c}{%
           family={Schubiger},
           familyi={S\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod}}}%
        {{hash=f266a7e9a0c9e5b6317f6d7d1779b664}{%
           family={Çöltekin},
           familyi={Ç\bibinitperiod},
           given={Arzu},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{7}{}{%
        {{hash=6ba7acef9f230b2922e1571d81e91670}{%
           family={Ardito},
           familyi={A\bibinitperiod},
           given={Carmelo},
           giveni={C\bibinitperiod}}}%
        {{hash=479c124b854bbad1575b41e37a6618a4}{%
           family={Lanzilotti},
           familyi={L\bibinitperiod},
           given={Rosa},
           giveni={R\bibinitperiod}}}%
        {{hash=a5b4735be11498db0a98f1841f8a6799}{%
           family={Malizia},
           familyi={M\bibinitperiod},
           given={Alessio},
           giveni={A\bibinitperiod}}}%
        {{hash=b3f52839e2d73a9a02dd0d202befaae8}{%
           family={Petrie},
           familyi={P\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod}}}%
        {{hash=0364c6a114189e5090fe8c8a82dc9393}{%
           family={Piccinno},
           familyi={P\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
        {{hash=31d94cf1c75cc043411163a15b0fd7a2}{%
           family={Desolda},
           familyi={D\bibinitperiod},
           given={Giuseppe},
           giveni={G\bibinitperiod}}}%
        {{hash=0e3f2e4008eae58f045d17d431e2227c}{%
           family={Inkpen},
           familyi={I\bibinitperiod},
           given={Kori},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{61cdbfc2785233708af23714cdce4f80}
      \strng{fullhash}{61cdbfc2785233708af23714cdce4f80}
      \strng{bibnamehash}{61cdbfc2785233708af23714cdce4f80}
      \strng{authorbibnamehash}{61cdbfc2785233708af23714cdce4f80}
      \strng{authornamehash}{61cdbfc2785233708af23714cdce4f80}
      \strng{authorfullhash}{61cdbfc2785233708af23714cdce4f80}
      \strng{editorbibnamehash}{852cf895f72c7c44c1b026761d4716cd}
      \strng{editornamehash}{852cf895f72c7c44c1b026761d4716cd}
      \strng{editorfullhash}{c3555e1cf443b1b9f87d4770b71e6dbd}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We explore gestures as interaction methods in virtual reality (VR). We detect hand and body gestures using human pose estimation based on off-the-shelf optical camera images using machine learning, and obtain reliable gesture recognition without additional sensors. We then employ an avatar to prompt users to learn and use gestures to communicate. Finally, to understand how well gestures serve as interaction methods, we compare the studied gesture-based interaction methods with baseline common interaction modalities in VR (controllers, gaze interaction) in a pilot study including usability testing.}
      \field{booktitle}{Human-Computer Interaction -- INTERACT 2021}
      \field{isbn}{978-3-030-85613-7}
      \field{title}{Gesture Interaction in Virtual Reality}
      \field{year}{2021}
      \field{pages}{151\bibrangedash 160}
      \range{pages}{10}
    \endentry
    \entry{Ecma:2017}{misc}{}
      \name{author}{1}{}{%
        {{hash=465e8a87e9374ae02e0399ddf89fd1b1}{%
           family={International},
           familyi={I\bibinitperiod},
           given={ECMA},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \strng{fullhash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \strng{bibnamehash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \strng{authorbibnamehash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \strng{authornamehash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \strng{authorfullhash}{465e8a87e9374ae02e0399ddf89fd1b1}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{edition}{2nd}
      \field{month}{12}
      \field{title}{Standard ECMA-404 -- The JSON Data Interchange Syntax}
      \field{year}{2017}
      \verb{urlraw}
      \verb https://www.ecma-international.org/publications/standards/Ecma-404.htm
      \endverb
      \verb{url}
      \verb https://www.ecma-international.org/publications/standards/Ecma-404.htm
      \endverb
    \endentry
    \entry{Ishak:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=bb78c99be97903c1cc253e86fb1bfdfa}{%
           family={Ishak},
           familyi={I\bibinitperiod},
           given={Karim},
           giveni={K\bibinitperiod}}}%
        {{hash=3a2aa03caf331c530134023b94276bd5}{%
           family={Appenrodt},
           familyi={A\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
        {{hash=3605940e7acf464b8c62e3a0a6a7728f}{%
           family={Dickmann},
           familyi={D\bibinitperiod},
           given={Jrgen},
           giveni={J\bibinitperiod}}}%
        {{hash=89042ea1ee9e986b1f6d3a92ad45f9a5}{%
           family={Waldschmidt},
           familyi={W\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{65bcb291fd2a5a83c68159df87ea1125}
      \strng{fullhash}{f4d9625585aec2cc0931600540a9d1c4}
      \strng{bibnamehash}{65bcb291fd2a5a83c68159df87ea1125}
      \strng{authorbibnamehash}{65bcb291fd2a5a83c68159df87ea1125}
      \strng{authornamehash}{65bcb291fd2a5a83c68159df87ea1125}
      \strng{authorfullhash}{f4d9625585aec2cc0931600540a9d1c4}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar sensors are utilized for detection and classification purposes in various applications. In order to use deep learning techniques, lots of training data are required. Accordingly, lots of measurements and labelling tasks are then needed. For the purpose of pre-training or examining first ideas before bringing them into reality, synthetic radar data are of great help. In this paper, a workflow for automatically generating radar data of human gestures is presented, starting with creating the desired animations until synthesizing radar data and getting the final required dataset. The dataset could then be used for training deep learning models. A classification scenario applying this workflow is also introduced.}
      \field{booktitle}{2018 {IEEE} {MTT}-{S} {International} {Conference} on {Microwaves} for {Intelligent} {Mobility} ({ICMIM})}
      \field{month}{4}
      \field{title}{Human {Motion} {Training} {Data} {Generation} for {Radar} {Based} {Deep} {Learning} {Applications}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICMIM.2018.8443559
      \endverb
      \keyw{Animation,classification scenario,computer animation,Databases,deep learning models,deep learning techniques,gesture recognition,human gestures,human motion training data generation,image classification,image motion analysis,labelling tasks,learning (artificial intelligence),object detection,radar applications,radar based deep learning applications,Radar cross-sections,radar data synthesis,Radar imaging,radar sensors,Sensors,Spectrogram,synthetic radar data}
    \endentry
    \entry{iso25010}{report}{}
      \name{author}{1}{}{%
        {{hash=5b512ee8a59deb284ad0a6a035ba10b1}{%
           family={ISO},
           familyi={I\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {International Standard Organization}%
      }
      \list{location}{1}{%
        {Geneva}%
      }
      \strng{namehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{fullhash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{bibnamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authorbibnamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authornamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authorfullhash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \field{extraname}{1}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{ISO/IEC 25010 - Software Quality Product Standard}}
      \field{type}{standard}
      \field{year}{2019}
      \verb{urlraw}
      \verb https://iso25000.com/index.php/en/iso-25000-standards/iso-25010?limit=3\&limitstart=0
      \endverb
      \verb{url}
      \verb https://iso25000.com/index.php/en/iso-25000-standards/iso-25010?limit=3%5C&limitstart=0
      \endverb
    \endentry
    \entry{iso9241}{report}{}
      \name{author}{1}{}{%
        {{hash=5b512ee8a59deb284ad0a6a035ba10b1}{%
           family={ISO},
           familyi={I\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {International Standard Organization}%
      }
      \list{location}{1}{%
        {Geneva}%
      }
      \strng{namehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{fullhash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{bibnamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authorbibnamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authornamehash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \strng{authorfullhash}{5b512ee8a59deb284ad0a6a035ba10b1}
      \field{extraname}{2}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{ISO/IEC 9241, Ergonomics of human-system interaction — Part 11: Usability: Definitions and concepts}}
      \field{type}{standard}
      \field{year}{2018}
      \verb{urlraw}
      \verb https://www.iso.org/obp/ui/\#iso:std:iso:9241:-11:en
      \endverb
      \verb{url}
      \verb https://www.iso.org/obp/ui/%5C#iso:std:iso:9241:-11:en
      \endverb
    \endentry
    \entry{Jakobsen:2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=b3169754f246069a906224fc06b9b0c3}{%
           family={Jakobsen},
           familyi={J\bibinitperiod},
           given={Mikkel\bibnamedelima R.},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=44da6cf633db46703fefa96d020190c5}{%
           family={Jansen},
           familyi={J\bibinitperiod},
           given={Yvonne},
           giveni={Y\bibinitperiod}}}%
        {{hash=8bfcc80add2547187c4b651524dbb073}{%
           family={Boring},
           familyi={B\bibinitperiod},
           given={Sebastian},
           giveni={S\bibinitperiod}}}%
        {{hash=b3cb3dac3773372c10c6c79a6a132235}{%
           family={Hornbæk},
           familyi={H\bibinitperiod},
           given={Kasper},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{09725f3de33a1a7b2e71f8bd8da83690}
      \strng{fullhash}{8b2031efdcef6c8580a5ad44228412a0}
      \strng{bibnamehash}{09725f3de33a1a7b2e71f8bd8da83690}
      \strng{authorbibnamehash}{09725f3de33a1a7b2e71f8bd8da83690}
      \strng{authornamehash}{09725f3de33a1a7b2e71f8bd8da83690}
      \strng{authorfullhash}{8b2031efdcef6c8580a5ad44228412a0}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Users can interact with large displays in many ways, including touch and mid-air gestures. However, it remains unclear how these ways compare and when users choose one over the other. In a first experiment, we compare touch and mid-air gestures to identify their relative performance for target acquisition. In a second experiment, participants choose freely between touch and mid-air gestures and we artificially require movement to simulate situations where mid-air is considered beneficial. Results from the first experiment show mid-air to be overall slower than touch depending on the task; in the second experiment, participants mostly chose touch in particular for selecting small targets and they rarely switched between mid-air and touch. Results also show that when faced with an increasing cost of using touch in the form of movement, participants chose mid-air over touch; touch remains as fast as mid-air on average.}
      \field{booktitle}{Human-Computer Interaction – INTERACT 2015}
      \field{isbn}{978-3-319-22697-2}
      \field{title}{{Should I Stay or Should I Go? Selecting Between Touch and Mid-Air Gestures for Large-Display Interaction}}
      \field{year}{2015}
      \field{pages}{455\bibrangedash 473}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1007/978-3-319-22698-9_31
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/978-3-319-22698-9_31
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/978-3-319-22698-9_31
      \endverb
      \keyw{Freehand gestures,Touch,Large display,User study,Mid-air}
    \endentry
    \entry{Jang:2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=03ed153f61e421f987584555cb62b704}{%
           family={Jang},
           familyi={J\bibinitperiod},
           given={Sujin},
           giveni={S\bibinitperiod}}}%
        {{hash=dfd8d46efe53918c4bab79ba6fbed371}{%
           family={Stuerzlinger},
           familyi={S\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
        {{hash=95ebc2eebe483ea1f4c42c074afc3e3a}{%
           family={Ambike},
           familyi={A\bibinitperiod},
           given={Satyajit},
           giveni={S\bibinitperiod}}}%
        {{hash=b430276910c009f6a55cdc6422be2e1d}{%
           family={Ramani},
           familyi={R\bibinitperiod},
           given={Karthik},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Denver, Colorado, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b111aca836411338852bb3f9372b899c}
      \strng{fullhash}{16666909c20c42d962295840c11a97d9}
      \strng{bibnamehash}{b111aca836411338852bb3f9372b899c}
      \strng{authorbibnamehash}{b111aca836411338852bb3f9372b899c}
      \strng{authornamehash}{b111aca836411338852bb3f9372b899c}
      \strng{authorfullhash}{16666909c20c42d962295840c11a97d9}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Quantifying cumulative arm muscle fatigue is a critical factor in understanding, evaluating, and optimizing user experience during prolonged mid-air interaction. A reasonably accurate estimation of fatigue requires an estimate of an individual's strength. However, there is no easy-to-access method to measure individual strength to accommodate inter-individual differences. Furthermore, fatigue is influenced by both psychological and physiological factors, but no current HCI model provides good estimates of cumulative subjective fatigue. We present a new, simple method to estimate the maximum shoulder torque through a mid-air pointing task, which agrees with direct strength measurements. We then introduce a cumulative fatigue model informed by subjective and biomechanical measures. We evaluate the performance of the model in estimating cumulative subjective fatigue in mid-air interaction by performing multiple cross-validations and a comparison with an existing fatigue metric. Finally, we discuss the potential of our approach for real-time evaluation of subjective fatigue as well as future challenges.}
      \field{booktitle}{Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450346559}
      \field{series}{CHI '17}
      \field{title}{{Modeling Cumulative Arm Fatigue in Mid-Air Interaction based on Perceived Exertion and Kinetics of Arm Motion}}
      \field{year}{2017}
      \field{pages}{3328\bibrangedash 3339}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3025453.3025523
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3025453.3025523
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3025453.3025523
      \endverb
      \keyw{perceived exertion,mid-air interaction,maximum arm strength,cumulative fatigue model,biomechanical arm model}
    \endentry
    \entry{Jiang:2018}{article}{}
      \name{author}{3}{}{%
        {{hash=633bd56e6898148330ea6180c6ec1b15}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Xianta},
           giveni={X\bibinitperiod}}}%
        {{hash=d046e9f8b86a64c128ef9b05e6afd2c7}{%
           family={Xiao},
           familyi={X\bibinitperiod},
           given={Zhen\bibnamedelima Gang},
           giveni={Z\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=86bf66a7688f8a8c07f2ab1507453ae3}{%
           family={Menon},
           familyi={M\bibinitperiod},
           given={Carlo},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{0a9a955473fd75266032dd7596082b85}
      \strng{fullhash}{0a9a955473fd75266032dd7596082b85}
      \strng{bibnamehash}{0a9a955473fd75266032dd7596082b85}
      \strng{authorbibnamehash}{0a9a955473fd75266032dd7596082b85}
      \strng{authornamehash}{0a9a955473fd75266032dd7596082b85}
      \strng{authorfullhash}{0a9a955473fd75266032dd7596082b85}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1359-4338}
      \field{journaltitle}{Virtual Real.}
      \field{month}{11}
      \field{number}{4}
      \field{title}{{Virtual Grasps Recognition Using Fusion of Leap Motion and Force Myography}}
      \field{volume}{22}
      \field{year}{2018}
      \field{pages}{297\bibrangedash 308}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1007/s10055-018-0339-2
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10055-018-0339-2
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10055-018-0339-2
      \endverb
      \keyw{Leap Motion,Hand gesture recognition,VR,Grasp classification,Force myography}
    \endentry
    \entry{Kang:2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=ad7dcb135c1f83ad36ee17160a97c115}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={Zhang},
           giveni={Z\bibinitperiod}}}%
        {{hash=023be330b99d39f63179511150c7883c}{%
           family={Shengchang},
           familyi={S\bibinitperiod},
           given={Lan},
           giveni={L\bibinitperiod}}}%
        {{hash=1bb19db50a7f76ae1dadfd076c4536fd}{%
           family={Guiyuan},
           familyi={G\bibinitperiod},
           given={Zhang},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{4c0f483f99ebe2af0e9f17f38952634b}
      \strng{fullhash}{4c0f483f99ebe2af0e9f17f38952634b}
      \strng{bibnamehash}{4c0f483f99ebe2af0e9f17f38952634b}
      \strng{authorbibnamehash}{4c0f483f99ebe2af0e9f17f38952634b}
      \strng{authornamehash}{4c0f483f99ebe2af0e9f17f38952634b}
      \strng{authorfullhash}{4c0f483f99ebe2af0e9f17f38952634b}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Human gesture recognition is a new way of interaction and a new application direction of millimeter wave radar. Compared with Doppler radar, FMCW radar can eliminate Doppler frequency interference of moving targets at different distances and accurately obtain the velocity-range information during gesture motion. In this paper, we use the 77GHz millimeter wave radar to extract the time variation characteristics of the Doppler frequency of the gesture. The convolutional neural network was selected to classify the gesture mining spatiotemporal features of the five volunteers. The experimental results show that the feature can describe the gesture velocity change information well and can significantly improve the versatility of the network by adding small amount data of more volunteers data to establish a personal dataset.}
      \field{booktitle}{2019 {IEEE} {Asia}-{Pacific} {Microwave} {Conference} ({APMC})}
      \field{month}{12}
      \field{title}{Mining {Spatio}-{Temporal} {Features} from {mmW} {Radar} echoes for {Hand} {Gesture} {Recognition}}
      \field{year}{2019}
      \field{pages}{93\bibrangedash 95}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1109/APMC46564.2019.9038713
      \endverb
      \keyw{application direction,convolutional neural nets,convolutional neural network,CW radar,data mining,Doppler effect,doppler frequency,Doppler radar,feature extraction,Feature extraction,FM radar,FMCW radar,gesture motion,gesture recognition,Gesture recognition,gesture velocity change information,hand gesture recognition,human gesture recognition,image classification,image motion analysis,millimeter wave radar,Millimeter wave radar,mmW radar echoes,personal dataset,radar computing,radar cross-sections,Radar imaging,spatio-temporal feature mining,time variation characteristics,velocity-range information}
    \endentry
    \entry{Kendon:1980}{inbook}{}
      \name{author}{1}{}{%
        {{hash=2512b39e214f27cb2b9e3dc6913f7f9a}{%
           family={Kendon},
           familyi={K\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, New York}%
      }
      \list{publisher}{1}{%
        {De Gruyter Mouton}%
      }
      \strng{namehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{fullhash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{bibnamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authorbibnamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authornamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authorfullhash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{The Relationship of Verbal and Nonverbal Communication}
      \field{isbn}{9783110813098}
      \field{title}{{Gesticulation and Speech: Two Aspects of the Process of Utterance}}
      \field{year}{1980}
      \field{pages}{207\bibrangedash 228}
      \range{pages}{22}
      \verb{doi}
      \verb doi:10.1515/9783110813098.207
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1515/9783110813098.207
      \endverb
      \verb{url}
      \verb https://doi.org/10.1515/9783110813098.207
      \endverb
    \endentry
    \entry{Kendon:1988}{article}{}
      \name{author}{1}{}{%
        {{hash=2512b39e214f27cb2b9e3dc6913f7f9a}{%
           family={Kendon},
           familyi={K\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{fullhash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{bibnamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authorbibnamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authornamehash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \strng{authorfullhash}{2512b39e214f27cb2b9e3dc6913f7f9a}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Crosscultural Perspectives in Nonverbal Communication}
      \field{month}{1}
      \field{title}{{How gestures can become like words}}
      \field{year}{1988}
      \field{pages}{131\bibrangedash 141}
      \range{pages}{11}
    \endentry
    \entry{Kern:2020}{article}{}
      \name{author}{4}{}{%
        {{hash=44292497ca43a7a71e3e1b0fc614477b}{%
           family={Kern},
           familyi={K\bibinitperiod},
           given={Nicolai},
           giveni={N\bibinitperiod}}}%
        {{hash=fe26fb5df6f316e468d0cd934905fd69}{%
           family={Steiner},
           familyi={S\bibinitperiod},
           given={Maximilian},
           giveni={M\bibinitperiod}}}%
        {{hash=c8c6bc021a74cb4cfd11d27baa170d2f}{%
           family={Lorenzin},
           familyi={L\bibinitperiod},
           given={Ramona},
           giveni={R\bibinitperiod}}}%
        {{hash=89042ea1ee9e986b1f6d3a92ad45f9a5}{%
           family={Waldschmidt},
           familyi={W\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{302d2d165ac92a3410d4b92c24bb06d9}
      \strng{fullhash}{7174d3334f945bc44bd3fa5a8bc85c07}
      \strng{bibnamehash}{302d2d165ac92a3410d4b92c24bb06d9}
      \strng{authorbibnamehash}{302d2d165ac92a3410d4b92c24bb06d9}
      \strng{authornamehash}{302d2d165ac92a3410d4b92c24bb06d9}
      \strng{authorfullhash}{7174d3334f945bc44bd3fa5a8bc85c07}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this letter, the capabilities of an incoherent radar sensor network for robust Doppler-based gesture recognition are investigated, and a significant performance boost is demonstrated. A comprehensive dataset is recorded with an incoherent sensor network consisting of three time-synchronized 77GHz frequency-modulated continuous wave radars. Based on this dataset, we show that differential Doppler features obtained from the varying viewing angles result in a significant multistatic gain for classification, particularly for high intraclass variations and low Doppler frequencies. For the most complex dataset, cross-user validation accuracy of a convolutional neural network with optimized data fusion is improved by 7.4\% to an overall value of 87.1\%, which we regard to be high as gestures are not designed for distinguishability but reflect everyday control and communication signals.}
      \field{issn}{2475-1472}
      \field{journaltitle}{IEEE Sensors Letters}
      \field{month}{11}
      \field{number}{11}
      \field{title}{Robust {Doppler}-{Based} {Gesture} {Recognition} {With} {Incoherent} {Automotive} {Radar} {Sensor} {Networks}}
      \field{volume}{4}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/LSENS.2020.3033586
      \endverb
      \keyw{autonomous driving,Chirp,Doppler effect,Doppler radar,gesture recognition,Microwave/millimeter wave sensors,multistatic radar,radar sensor network,Sensor systems,Spectrogram}
    \endentry
    \entry{Khalaf:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=8b216ae2f6c897703fcf4639630a7b00}{%
           family={Khalaf},
           familyi={K\bibinitperiod},
           given={Ahmed\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=df5ef16b6d725309f5fedcc849de3336}{%
           family={Alharthi},
           familyi={A\bibinitperiod},
           given={Sultan\bibnamedelima A.},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=7b00176bc67aa09d61250a9c5e7259fe}{%
           family={Dolgov},
           familyi={D\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod}}}%
        {{hash=f6a358051fb7adaf4a5027b0c64afcdd}{%
           family={Toups},
           familyi={T\bibinitperiod},
           given={Z\bibnamedelima O.},
           giveni={Z\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{1a0b397d423b79db055e403511bf4928}
      \strng{fullhash}{0d5dbf56fd97e5721840db45dde54d26}
      \strng{bibnamehash}{1a0b397d423b79db055e403511bf4928}
      \strng{authorbibnamehash}{1a0b397d423b79db055e403511bf4928}
      \strng{authornamehash}{1a0b397d423b79db055e403511bf4928}
      \strng{authorfullhash}{0d5dbf56fd97e5721840db45dde54d26}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture recognition devices provide a new means for natural human-computer interaction. However, when selecting these devices for games, designers might find it challenging to decide which gesture recognition device will work best. In the present research, we compare three vision-based, hand gesture devices: Leap Motion, Microsoft's Kinect, and Intel's RealSense. We developed a simple hand-gesture based game to evaluate performance, cognitive demand, comfort, and player experience of using these gesture devices. We found that participants' preferred and performed much better using Leap Motion and Kinect compared to using RealSense. Leap Motion also outperformed or was equivalent to Kinect. These findings suggest that not all gesture recognition devices can be suitable for games and that designers need to make better decisions when selecting gesture recognition devices and designing gesture based games to insure the usability, accuracy, and comfort of such games.}
      \field{booktitle}{Proceedings of the 2019 ACM International Conference on Interactive Surfaces and Spaces}
      \field{isbn}{9781450368919}
      \field{series}{ISS '19}
      \field{title}{{A Comparative Study of Hand Gesture Recognition Devices in the Context of Game Design}}
      \field{venue}{Daejeon, Republic of Korea}
      \field{year}{2019}
      \field{pages}{397\bibrangedash 402}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3343055.3360758
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3343055.3360758
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3343055.3360758
      \endverb
      \keyw{realsense.,games,gesture recognition devices,kinect,hand gesture,leap motion}
    \endentry
    \entry{Khan:2017}{article}{}
      \name{author}{3}{}{%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=6ffdd21adefe126cf67fc199c79479c6}{%
           family={Leem},
           familyi={L\bibinitperiod},
           given={Seong\bibnamedelima Kyu},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{fullhash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{bibnamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authorbibnamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authornamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authorfullhash}{4406d801da44ce53f71d93d4be15a8a0}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Modern cars continue to offer more and more functionalities due to which they need a growing number of commands. As the driver tries to monitor the road and the graphic user interface simultaneously, his/her overall efficiency is reduced. In order to reduce the visual attention necessary for monitoring, a gesture-based user interface is very important. In this paper, gesture recognition for a vehicle through impulse radio ultra-wideband (IR-UWB) radar is discussed. The gestures can be used to control different electronic devices inside a vehicle. The gestures are based on human hand and finger motion. We have implemented a real-time version using only one radar sensor. Studies on gesture recognition using IR-UWB radar have rarely been carried out, and some studies are merely simple methods using the magnitude of the reflected signal or those whose performance deteriorates largely due to changes in distance or direction. In this study, we propose a new hand-based gesture recognition algorithm that works robustly against changes in distance or direction while responding only to defined gestures by ignoring meaningless motions. We used three independent features, i.e., variance of the probability density function (pdf) of the magnitude histogram, time of arrival (TOA) variation and the frequency of the reflected signal, to classify the gestures. A data fitting method is included to differentiate between gesture signals and unintended hand or body motions. We have used the clustering technique for the classification of the gestures. Moreover, the distance information is used as an additional input parameter to the clustering algorithm, such that the recognition technique will not be vulnerable to distance change. The hand-based gesture recognition proposed in this paper would be a key technology of future automobile user interfaces.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{4}
      \field{title}{Hand-{Based} {Gesture} {Recognition} for {Vehicular} {Applications} {Using} {IR}-{UWB} {Radar}}
      \field{volume}{17}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{doi}
      \verb 10.3390/s17040833
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/17/4/833
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/17/4/833
      \endverb
    \endentry
    \entry{Khan:2020}{article}{}
      \name{author}{3}{}{%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=6ffdd21adefe126cf67fc199c79479c6}{%
           family={Leem},
           familyi={L\bibinitperiod},
           given={Seong\bibnamedelima Kyu},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{fullhash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{bibnamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authorbibnamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authornamehash}{4406d801da44ce53f71d93d4be15a8a0}
      \strng{authorfullhash}{4406d801da44ce53f71d93d4be15a8a0}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We developed an impulse radio ultra-wideband (IR-UWB) radar-based system that can recognize alphanumeric characters in midair without the need for any handheld device. The hardware consists of four IR-UWB radar sensors set up with a rectangular geometry. Writing a single character in midair results in artifacts that make some characters look similar on a position trajectory-based (x, y) plane, which makes them difficult to classify. Thus, we developed an algorithm that transforms 2D coordinate image data into trigonometric ratios (i.e., tangents) and plots them against the time axis to obtain unique images for training a convolutional neural network. An extended Kalman filter is used to obtain the 2D trajectories of hand motions. To evaluate our proposed method, we first applied it to characters that may be written in midair very simply without creating artifacts and compared its performance with that of a state-of-the-art digit classification algorithm. Then, we considered combining characters written midair with and without artifacts. After the individual character recognition, we combined the characters into words. We defined a specific marker based on an energy threshold to detect the start and end of a character for midair writing. The energy level was found to change drastically when the hand is pulled in and out of the radar plane. The proposed method was found to outperform the current state of the art at character classification when artifacts are present in the images.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{In-{Air} {Continuous} {Writing} {Using} {UWB} {Impulse} {Radar} {Sensors}}
      \field{volume}{8}
      \field{year}{2020}
      \field{pages}{99302\bibrangedash 99311}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ACCESS.2020.2994281
      \endverb
      \keyw{2D coordinate image data,2D trajectories,alphabet writing,alphanumeric character recognition,character classification,character recognition,Clutter,convolutional neural nets,convolutional neural network,digit classification algorithm,energy level,energy threshold,extended Kalman filter,gesture recognition,Gesture recognition,hand motions,handheld device,image classification,image filtering,image motion analysis,impulse radio ultra-wideband,impulse radio ultrawideband radar-based system,in-air continuous writing,in-air writing,IR-UWB radar sensors,Kalman filters,midair writing,nonlinear filters,pattern analysis,position trajectory-based (x,radar computing,Radar cross-sections,radar imaging,radar plane,rectangular geometry,Sensors,single character,specific marker,Trajectory,trigonometric ratios,ultra wideband radar,UWB impulse radar sensors,Writing,y) plane}
    \endentry
    \entry{Kim:2017b}{article}{}
      \name{author}{5}{}{%
        {{hash=a56a3d44be9fb5b46c1cc2729a92623c}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Seo\bibnamedelima Yul},
           giveni={S\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
        {{hash=5e0aa69ccc346aa0417c58a50484e075}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Hong\bibnamedelima Gul},
           giveni={H\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=b2191ef213bb80bd80e51ab1957d32a2}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Jin\bibnamedelima Woo},
           giveni={J\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=c5e1e20034e4dee2e05c4ea21880e901}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Sanghoon},
           giveni={S\bibinitperiod}}}%
        {{hash=c9ed163b894ef089ef348f8a8a45b48d}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Tae\bibnamedelima Wook},
           giveni={T\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \strng{namehash}{45ca4c344783b85ab58710643d90db65}
      \strng{fullhash}{bd800c67fcf5f50abadd898030b86dc3}
      \strng{bibnamehash}{45ca4c344783b85ab58710643d90db65}
      \strng{authorbibnamehash}{45ca4c344783b85ab58710643d90db65}
      \strng{authornamehash}{45ca4c344783b85ab58710643d90db65}
      \strng{authorfullhash}{bd800c67fcf5f50abadd898030b86dc3}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduces a hand gesture recognition sensor using ultra-wideband impulse signals, which are reflected from a hand. The reflected waveforms in time domain are determined by the reflection surface of a target. Thus every gesture has its own reflected waveform. Thus we propose to use machine learning, such as convolutional neural network (CNN) for the gesture classification. The CNN extracts its own feature and constructs classification model then classifies the reflected waveforms. Six hand gestures from american sign language (ASL) are used for an experiment and the result shows more than 90\% recognition accuracy. For fine movements, a rotating plaster model is measured with 10° step. An average recognition accuracy is also above 90\%.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{5}
      \field{number}{10}
      \field{title}{A {Hand} {Gesture} {Recognition} {Sensor} {Using} {Reflected} {Impulses}}
      \field{volume}{17}
      \field{year}{2017}
      \field{pages}{2975\bibrangedash 2976}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1109/JSEN.2017.2679220
      \endverb
      \keyw{american sign language,Antenna measurements,CNN,convolutional neural network,detection,gesture classification,gesture recognition,Gesture recognition,Gesture sensor,hand gesture recognition sensor,image sensors,impulse radio,Intelligent sensors,neural nets,palmprint recognition,reflected impulses,reflection surface,rotating plaster model,Shape,Support vector machines,time domain,Time-domain analysis,ultra-wideband impulse signals}
    \endentry
    \entry{Kim:2017a}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=87cdc5e1c98297b2d39a303238324992}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Youngwook},
           giveni={Y\bibinitperiod}}}%
        {{hash=ca18bab772baab4b039410615bdd3843}{%
           family={Toomajian},
           familyi={T\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{fullhash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{bibnamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authorbibnamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authornamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authorfullhash}{9865d5ed4e85432c9182925a42d4de9e}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we investigate the optimal structure of deep convolutional neural networks for classifying human hand gestures using Doppler radar. When hand motions are captured by Doppler radar, the unique micro-Doppler signatures can be observed in the spectrogram. If the signature is distinguishable by a classifier, then the hand gesture can be used for controlling electronics and as an input modality for a human-computer interface. To classiiy signatures in the spectrogram, we propose the use of a deep convolutional neural network (DCNN) as a classifier. DCNN is a powerful classifier that extracts features as well as class boundaries through a training process. We measured seven hand gestures performed in front of Doppler radar while generating spectrograms. To identify an optimal structure, we trained several DCNNs by changing hyperparameters, such as the number of convolutional layers, the number of filters, and the filter size. The classification accuracy obtained from the optimal DCNN structure was approximately 87\%.}
      \field{booktitle}{2017 11th {European} {Conference} on {Antennas} and {Propagation} ({EUCAP})}
      \field{month}{3}
      \field{title}{Application of {Doppler} radar for the recognition of hand gestures using optimized deep convolutional neural networks}
      \field{year}{2017}
      \field{pages}{1258\bibrangedash 1260}
      \range{pages}{3}
      \verb{doi}
      \verb 10.23919/EuCAP.2017.7928465
      \endverb
      \keyw{Convolution,convolutional layers,deep convolutional neural networks,Doppler effect,Doppler radar,feature extraction,filters,gesture recognition,Gesture recognition,hand gesture,hand gesture recognition,human hand gesture classification,human-computer interface,hyperparameters,image classification,micro-Doppler signatures,neural nets,Neural networks,radar imaging,sensing,spectrogram,Spectrogram}
    \endentry
    \entry{Kim:2016}{article}{}
      \name{author}{2}{}{%
        {{hash=87cdc5e1c98297b2d39a303238324992}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Youngwook},
           giveni={Y\bibinitperiod}}}%
        {{hash=ca18bab772baab4b039410615bdd3843}{%
           family={Toomajian},
           familyi={T\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{fullhash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{bibnamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authorbibnamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authornamehash}{9865d5ed4e85432c9182925a42d4de9e}
      \strng{authorfullhash}{9865d5ed4e85432c9182925a42d4de9e}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we investigate the feasibility of recognizing human hand gestures using micro-Doppler signatures measured by Doppler radar with a deep convolutional neural network (DCNN). Hand gesture recognition using radar can be applied to control electronic appliances. Compared with an optical recognition system, radar can work regardless of light conditions and it can be embedded in a case. We classify ten different hand gestures, with only micro-Doppler signatures on spectrograms without range information. The ten gestures, which included swiping from left to right, swiping from right to left, rotating clockwise, rotating counterclockwise, pushing, double pushing, holding, and double holding, were measured using Doppler radar and their spectrograms investigated. A DCNN was employed to classify the spectrograms, with 90\% of the data utilized for training and the remaining 10\% for validation. After five-fold validation, the classification accuracy of the proposed method was found to be 85.6\%. With seven gestures, the accuracy increased to 93.1\%.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Hand {Gesture} {Recognition} {Using} {Micro}-{Doppler} {Signatures} {With} {Convolutional} {Neural} {Network}}
      \field{volume}{4}
      \field{year}{2016}
      \field{pages}{7125\bibrangedash 7130}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ACCESS.2016.2617282
      \endverb
      \keyw{deep convolutional neural network,deep convolutional neural networks,Doppler radar,electronic appliances,gesture recognition,Gesture recognition,Hand gesture,hand gesture recognition,Laser radar,micro-Doppler signatures,microDoppler signatures,neural nets,Neural networks,radar computing,radar imaging,Spectrogram,Spectrograms}
    \endentry
    \entry{Kiselev:2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=a0b6820981c3788cb322e0ec87080a93}{%
           family={Kiselev},
           familyi={K\bibinitperiod},
           given={Vasilij},
           giveni={V\bibinitperiod}}}%
        {{hash=a65046a208d85692e4d4c13bcea597ae}{%
           family={Khlamov},
           familyi={K\bibinitperiod},
           given={Maxim},
           giveni={M\bibinitperiod}}}%
        {{hash=62d19dbd51c00d5aeb123db7b4cd8c37}{%
           family={Chuvilin},
           familyi={C\bibinitperiod},
           given={Kirill},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Helsinki, Uusimaa, FIN}%
      }
      \list{publisher}{1}{%
        {FRUCT Oy}%
      }
      \strng{namehash}{55e414f336e6961ad4c0e9e27277f1a0}
      \strng{fullhash}{55e414f336e6961ad4c0e9e27277f1a0}
      \strng{bibnamehash}{55e414f336e6961ad4c0e9e27277f1a0}
      \strng{authorbibnamehash}{55e414f336e6961ad4c0e9e27277f1a0}
      \strng{authornamehash}{55e414f336e6961ad4c0e9e27277f1a0}
      \strng{authorfullhash}{55e414f336e6961ad4c0e9e27277f1a0}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 24th Conference of Open Innovations Association FRUCT}
      \field{series}{FRUCT'24}
      \field{title}{{Hand Gesture Recognition with Multiple Leap Motion Devices}}
      \field{venue}{Moscow, Russia}
      \field{year}{2019}
      \keyw{leap motion,unity,Human computer interaction (HCI),gesture recognition,vr interfaces,Tracking}
    \endentry
    \entry{Kitchenham:2010}{article}{}
      \name{author}{7}{}{%
        {{hash=19919e365e4f12f6028593c952a9bacf}{%
           family={Kitchenham},
           familyi={K\bibinitperiod},
           given={Barbara},
           giveni={B\bibinitperiod}}}%
        {{hash=226f847e74817dba049b4bcd5f8ab0d9}{%
           family={Pretorius},
           familyi={P\bibinitperiod},
           given={Rialette},
           giveni={R\bibinitperiod}}}%
        {{hash=c3879154809891887a27016663fe556f}{%
           family={Budgen},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=9be35e32c47d0f046d7ec681286a7a7c}{%
           family={Brereton},
           familyi={B\bibinitperiod},
           given={O.\bibnamedelimi Pearl},
           giveni={O\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=5a8d8b77cef37ded3cef9f4690d80b5a}{%
           family={Turner},
           familyi={T\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=ac61cadb9275e7bffd61615cd14bb27f}{%
           family={Niazi},
           familyi={N\bibinitperiod},
           given={Mahmood},
           giveni={M\bibinitperiod}}}%
        {{hash=cce706e69ca1e8779190328485df9f12}{%
           family={Linkman},
           familyi={L\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{627d879eb7e32c946f726138157eda31}
      \strng{fullhash}{77bad07ef6175ba4ea297a63d3a53232}
      \strng{bibnamehash}{627d879eb7e32c946f726138157eda31}
      \strng{authorbibnamehash}{627d879eb7e32c946f726138157eda31}
      \strng{authornamehash}{627d879eb7e32c946f726138157eda31}
      \strng{authorfullhash}{77bad07ef6175ba4ea297a63d3a53232}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0950-5849}
      \field{journaltitle}{Information and Software Technology}
      \field{number}{8}
      \field{title}{Systematic literature reviews in software engineering -- A tertiary study}
      \field{volume}{52}
      \field{year}{2010}
      \field{pages}{792\bibrangedash 805}
      \range{pages}{14}
      \verb{doi}
      \verb https://doi.org/10.1016/j.infsof.2010.03.006
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S0950584910000467
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S0950584910000467
      \endverb
      \keyw{Systematic literature review,Mapping study,Software engineering,Tertiary study}
    \endentry
    \entry{Kohlsdorf:2013}{article}{}
      \name{author}{2}{}{%
        {{hash=d5cfded33bb9558311338df02773c255}{%
           family={Kohlsdorf},
           familyi={K\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=1d565170ecf8d34a6fb9cce4c9017f55}{%
           family={Starner},
           familyi={S\bibinitperiod},
           given={Thad\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \strng{namehash}{b6619a6c266a2e3b137660323e9f792f}
      \strng{fullhash}{b6619a6c266a2e3b137660323e9f792f}
      \strng{bibnamehash}{b6619a6c266a2e3b137660323e9f792f}
      \strng{authorbibnamehash}{b6619a6c266a2e3b137660323e9f792f}
      \strng{authornamehash}{b6619a6c266a2e3b137660323e9f792f}
      \strng{authorfullhash}{b6619a6c266a2e3b137660323e9f792f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Gestures for interfaces should be short, pleasing, intuitive, and easily recognized by a computer. However, it is a challenge for interface designers to create gestures easily distinguishable from users' normal movements. Our tool MAGIC Summoning addresses this problem. Given a specific platform and task, we gather a large database of unlabeled sensor data captured in the environments in which the system will be used (an "Everyday Gesture Library" or EGL). The EGL is quantized and indexed via multi-dimensional Symbolic Aggregate approXimation (SAX) to enable quick searching. MAGIC exploits the SAX representation of the EGL to suggest gestures with a low likelihood of false triggering. Suggested gestures are ordered according to brevity and simplicity, freeing the interface designer to focus on the user experience. Once a gesture is selected, MAGIC can output synthetic examples of the gesture to train a chosen classifier (for example, with a hidden Markov model). If the interface designer suggests his own gesture and provides several examples, MAGIC estimates how accurately that gesture can be recognized and estimates its false positive rate by comparing it against the natural movements in the EGL. We demonstrate MAGIC's effectiveness in gesture selection and helpfulness in creating accurate gesture recognizers.}
      \field{issn}{1532-4435}
      \field{journaltitle}{The Journal of Machine Learning Research}
      \field{month}{1}
      \field{number}{1}
      \field{shorttitle}{{MAGIC} summoning}
      \field{title}{{MAGIC} summoning: towards automatic suggesting and testing of gestures with low probability of false positives during use}
      \field{volume}{14}
      \field{year}{2013}
      \field{pages}{209\bibrangedash 242}
      \range{pages}{34}
      \keyw{continuous recognition,false positives,gesture recognition,gesture spotting}
    \endentry
    \entry{Kohlsdorf:2011}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=d5cfded33bb9558311338df02773c255}{%
           family={Kohlsdorf},
           familyi={K\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=1d565170ecf8d34a6fb9cce4c9017f55}{%
           family={Starner},
           familyi={S\bibinitperiod},
           given={Thad\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=b1062551ea473fdddc844c1ea8a68371}{%
           family={Ashbrook},
           familyi={A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{314a674d66556b45b287643d1fe87e8c}
      \strng{fullhash}{314a674d66556b45b287643d1fe87e8c}
      \strng{bibnamehash}{314a674d66556b45b287643d1fe87e8c}
      \strng{authorbibnamehash}{314a674d66556b45b287643d1fe87e8c}
      \strng{authornamehash}{314a674d66556b45b287643d1fe87e8c}
      \strng{authorfullhash}{314a674d66556b45b287643d1fe87e8c}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Face and Gesture 2011}
      \field{title}{{MAGIC 2.0: A web tool for false positive prediction and prevention for gesture recognition systems}}
      \field{year}{2011}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
    \endentry
    \entry{Koutsabasis:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=4e11216a6d3135760052f5a69e0b46df}{%
           family={Koutsabasis},
           familyi={K\bibinitperiod},
           given={Panayiotis},
           giveni={P\bibinitperiod}}}%
        {{hash=cc1f9d3464dbca966798b8e44d9cd196}{%
           family={Domouzis},
           familyi={D\bibinitperiod},
           given={Chris\bibnamedelima K.},
           giveni={C\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{7db4c32fff6b436d9197a6d6e365558a}
      \strng{fullhash}{7db4c32fff6b436d9197a6d6e365558a}
      \strng{bibnamehash}{7db4c32fff6b436d9197a6d6e365558a}
      \strng{authorbibnamehash}{7db4c32fff6b436d9197a6d6e365558a}
      \strng{authornamehash}{7db4c32fff6b436d9197a6d6e365558a}
      \strng{authorfullhash}{7db4c32fff6b436d9197a6d6e365558a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Image collections are a common interaction pattern for 2D interfaces, however mid-air user interaction with collections has received little attention. We present a controlled experiment (within-groups, n=24) comparing three sets of hand gestures for mid-air browsing and selection in image collections, that were identified out of an elicitation study, using MS Kinect. Each set includes cursor-less gestures for browsing (sideways hand extension, wheel and swipe) and for selection/deselection (hand-up/hand-down). Task success was universal with high accuracy and few errors for all gestures. Sideways extension outperforms swipe and perceived effort for this gesture is significantly lower. Both gestures outperform wheel. We suggest that from a usability perspective, sideways hand extension should be preferred for browsing image galleries, if no other contextual factors apply. Also, the results of the elicitation study, in which most users proposed the swipe gesture for browsing, were not confirmed by the controlled usability experiment. This suggests a combined use of elicitation studies with rigorous usability testing, especially when gestures for particular user interface design patterns are sought.}
      \field{booktitle}{Proceedings of the International Working Conference on Advanced Visual Interfaces}
      \field{isbn}{9781450341318}
      \field{series}{AVI '16}
      \field{title}{{Mid-Air Browsing and Selection in Image Collections}}
      \field{venue}{Bari, Italy}
      \field{year}{2016}
      \field{pages}{21\bibrangedash 27}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1145/2909132.2909248
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2909132.2909248
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2909132.2909248
      \endverb
      \keyw{Browsing,Usability,Mid-Air Interaction,Selection,Gestures,Kinect,Elicitation,Image Collections}
    \endentry
    \entry{Koutsabasis:2019}{article}{}
      \name{author}{2}{}{%
        {{hash=4e11216a6d3135760052f5a69e0b46df}{%
           family={Koutsabasis},
           familyi={K\bibinitperiod},
           given={Panayiotis},
           giveni={P\bibinitperiod}}}%
        {{hash=5c8fbdee829718fcc2eb3f267d8a01a6}{%
           family={Vogiatzidakis},
           familyi={V\bibinitperiod},
           given={Panagiotis},
           giveni={P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Taylor \& Francis}%
      }
      \strng{namehash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \strng{fullhash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \strng{bibnamehash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \strng{authorbibnamehash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \strng{authornamehash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \strng{authorfullhash}{747c6dead3bd5d07e0ddfb0ca112365e}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Journal of Human–Computer Interaction}
      \field{number}{18}
      \field{title}{{Empirical Research in Mid-Air Interaction: A Systematic Review}}
      \field{volume}{35}
      \field{year}{2019}
      \field{pages}{1747\bibrangedash 1768}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1080/10447318.2019.1572352
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1080/10447318.2019.1572352
      \endverb
      \verb{url}
      \verb https://doi.org/10.1080/10447318.2019.1572352
      \endverb
    \endentry
    \entry{Kratz:2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0277a74ec85e0182761f9120184b99b7}{%
           family={Kratz},
           familyi={K\bibinitperiod},
           given={Sven},
           giveni={S\bibinitperiod}}}%
        {{hash=4c529da201fdae7fce9cf6213760cb1c}{%
           family={Back},
           familyi={B\bibinitperiod},
           given={Maribeth},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{854319eb0ee60c3586a4936af21cbd7b}
      \strng{fullhash}{854319eb0ee60c3586a4936af21cbd7b}
      \strng{bibnamehash}{854319eb0ee60c3586a4936af21cbd7b}
      \strng{authorbibnamehash}{854319eb0ee60c3586a4936af21cbd7b}
      \strng{authornamehash}{854319eb0ee60c3586a4936af21cbd7b}
      \strng{authorfullhash}{854319eb0ee60c3586a4936af21cbd7b}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems}
      \field{isbn}{9781450331463}
      \field{series}{CHI EA ’15}
      \field{title}{{Towards Accurate Automatic Segmentation of IMU-Tracked Motion Gestures}}
      \field{venue}{Seoul, Republic of Korea}
      \field{year}{2015}
      \field{pages}{1337\bibrangedash 1342}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/2702613.2732922
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2702613.2732922
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2702613.2732922
      \endverb
      \keyw{gesture annotation,motion gestures,gesture recognition,gesture segmentation,IMU,motion data}
    \endentry
    \entry{Kratz:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0277a74ec85e0182761f9120184b99b7}{%
           family={Kratz},
           familyi={K\bibinitperiod},
           given={Sven},
           giveni={S\bibinitperiod}}}%
        {{hash=9f26cd4d773c8372cdb529c2d2359c5a}{%
           family={Wiese},
           familyi={W\bibinitperiod},
           given={Jason},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \strng{fullhash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \strng{bibnamehash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \strng{authorbibnamehash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \strng{authornamehash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \strng{authorfullhash}{1c4d51e13dbf6e53b2bf5e6efa0e60e9}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 8th ACM SIGCHI Symposium on Engineering Interactive Computing Systems}
      \field{isbn}{9781450343220}
      \field{series}{EICS ’16}
      \field{title}{{GestureSeg: Developing a Gesture Segmentation System Using Gesture Execution Phase Labeling by Crowd Workers}}
      \field{venue}{Brussels, Belgium}
      \field{year}{2016}
      \field{pages}{61\bibrangedash 72}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/2933242.2933261
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2933242.2933261
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2933242.2933261
      \endverb
    \endentry
    \entry{Krishnamurthy:2015}{article}{}
      \name{author}{2}{}{%
        {{hash=4b1c9daca0a7ba00e63e536ae5cc7e33}{%
           family={Krishnamurthy},
           familyi={K\bibinitperiod},
           given={Vinayak},
           giveni={V\bibinitperiod}}}%
        {{hash=b430276910c009f6a55cdc6422be2e1d}{%
           family={Ramani},
           familyi={R\bibinitperiod},
           given={Karthik},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{e859424a60a4ea069138306f57524a7d}
      \strng{fullhash}{e859424a60a4ea069138306f57524a7d}
      \strng{bibnamehash}{e859424a60a4ea069138306f57524a7d}
      \strng{authorbibnamehash}{e859424a60a4ea069138306f57524a7d}
      \strng{authornamehash}{e859424a60a4ea069138306f57524a7d}
      \strng{authorfullhash}{e859424a60a4ea069138306f57524a7d}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The advent of depth cameras has enabled mid-air interactions for shape modeling with bare hands. Typically, these interactions employ a finite set of pre-defined hand gestures to allow users to specify modeling operations in virtual space. However, human interactions in real world shaping processes (such as pottery or sculpting) are complex, iterative, and continuous. In this paper, we show that the expression of user intent in shaping processes can be derived from the geometry of contact between the hand and the manipulated object. Specifically, we describe the design and evaluation of a geometric interaction technique for bare-hand mid-air virtual pottery. We model the shaping of a pot as a gradual and progressive convergence of the pot’s profile to the shape of the user’s hand represented as a point-cloud (PCL). Thus, a user does not need to learn, know, or remember any gestures to interact with our system. Our choice of pottery simplifies the geometric representation, allowing us to systematically study how users use their hands and fingers to express the intent of deformation during a shaping process. Our evaluations demonstrate that it is possible to enable users to express their intent for shape deformation without the need for a fixed set of gestures for clutching and deforming a shape.}
      \field{issn}{0010-4485}
      \field{journaltitle}{Computer-Aided Design}
      \field{title}{{A gesture-free geometric approach for mid-air expression of design intent in 3D virtual pottery}}
      \field{volume}{69}
      \field{year}{2015}
      \field{pages}{11\bibrangedash 24}
      \range{pages}{14}
      \verb{doi}
      \verb https://doi.org/10.1016/j.cad.2015.06.006
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S001044851500086X
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S001044851500086X
      \endverb
      \keyw{Hand-based shape modeling,Mid-air interactions,Virtual pottery,Gestures,Natural user interfaces,Mesh deformation}
    \endentry
    \entry{Kristensson:2011}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=db3b6a3624f37d3c580dff8ae2a9c807}{%
           family={Kristensson},
           familyi={K\bibinitperiod},
           given={Per\bibnamedelima Ola},
           giveni={P\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=431ddbe2bf7f23fac4e96d6cf4c5b838}{%
           family={Denby},
           familyi={D\bibinitperiod},
           given={Leif\bibnamedelima C.},
           giveni={L\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=260981a99c276f2a8c91b8bfff2e9039}{%
           family={Hammond},
           familyi={H\bibinitperiod},
           given={Tracy},
           giveni={T\bibinitperiod}}}%
        {{hash=a031ee908c16ce53d951d4b6ec88a741}{%
           family={Nealen},
           familyi={N\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Eurographics Association}%
      }
      \strng{namehash}{ac500fcbcf61245292382d67d6bde009}
      \strng{fullhash}{ac500fcbcf61245292382d67d6bde009}
      \strng{bibnamehash}{ac500fcbcf61245292382d67d6bde009}
      \strng{authorbibnamehash}{ac500fcbcf61245292382d67d6bde009}
      \strng{authornamehash}{ac500fcbcf61245292382d67d6bde009}
      \strng{authorfullhash}{ac500fcbcf61245292382d67d6bde009}
      \strng{editorbibnamehash}{005a21131707be69e691f964d74cd2b9}
      \strng{editornamehash}{005a21131707be69e691f964d74cd2b9}
      \strng{editorfullhash}{005a21131707be69e691f964d74cd2b9}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Sketch Based Interfaces and Modeling, Vancouver, BC, Canada, 5-7 August 2011. Proceedings}
      \field{title}{{Continuous Recognition and Visualization of Pen Strokes and Touch-Screen Gestures}}
      \field{year}{2011}
      \field{pages}{95\bibrangedash 102}
      \range{pages}{8}
      \verb{doi}
      \verb 10.2312/SBM/SBM11/095-102
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.2312/SBM/SBM11/095-102
      \endverb
      \verb{url}
      \verb https://doi.org/10.2312/SBM/SBM11/095-102
      \endverb
    \endentry
    \entry{Kulhandjian:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=c313e88bd938cc247371e90ea50d84ba}{%
           family={Kulhandjian},
           familyi={K\bibinitperiod},
           given={Hovannes},
           giveni={H\bibinitperiod}}}%
        {{hash=27a3fae8db1c763f7e9a05a742a52117}{%
           family={Sharma},
           familyi={S\bibinitperiod},
           given={Prakshi},
           giveni={P\bibinitperiod}}}%
        {{hash=62cbd84b607c2ee5b76d9842f5bd3bfd}{%
           family={Kulhandjian},
           familyi={K\bibinitperiod},
           given={Michel},
           giveni={M\bibinitperiod}}}%
        {{hash=9d4057c0341111ca14bb6b77240a1539}{%
           family={D'Amours},
           familyi={D\bibinitperiod},
           given={Claude},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{a84871d9eb9a5d2da79948badf53f365}
      \strng{fullhash}{f6c0b56ca816bc9b11202d474ba717f6}
      \strng{bibnamehash}{a84871d9eb9a5d2da79948badf53f365}
      \strng{authorbibnamehash}{a84871d9eb9a5d2da79948badf53f365}
      \strng{authornamehash}{a84871d9eb9a5d2da79948badf53f365}
      \strng{authorfullhash}{f6c0b56ca816bc9b11202d474ba717f6}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we study American sign language (ASL) hand gesture recognition using Doppler radar. A set of ASL hand gesture motions are captured as micro- Doppler signals using a microwave X-band Doppler radar transceiver. We apply joint time-frequency analysis and observe the presence of the micro- Doppler signatures in the spectrogram. The micro- Doppler signatures of different hand gestures are analyzed using Matlab. Each hand gesture is observed to contain unique spectral characteristics. Based on unique spectral characteristics, we investigate the classification of ASL essential short phrases including emergency signals. For recognizing and characterizing the presence of micro-Doppler signatures in spectrogram we explore deep convolution neural network (DCNN) algorithm. We show that the DCNN algorithm can classify different sign language gestures based on the presence of micro- Doppler signatures in the spectrogram with fairly high accuracy. Experimental results reveal that utilizing 80\% of data for training, and the remaining 20\% for validation purposes in DCNN algorithm a validation accuracy of 87.5\% is achieved. To further improve the recognition system, we apply a very deep learning algorithm VGG-16 using transfer learning, which improves the validation accuracy to 95\%.}
      \field{booktitle}{2019 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})}
      \field{month}{12}
      \field{title}{Sign {Language} {Gesture} {Recognition} {Using} {Doppler} {Radar} and {Deep} {Learning}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/GCWkshps45667.2019.9024607
      \endverb
      \keyw{American sign language hand gesture recognition,ASL hand gesture motions,Assistive technology,Classification algorithms,Convolution,convolutional neural nets,deep convolution neural network algorithm,Doppler radar,feature extraction,gesture recognition,Gesture recognition,hand gestures,image classification,learning (artificial intelligence),micro Doppler signals,micro Doppler signatures,microDoppler signatures,microwave X-band Doppler radar transceiver,natural language processing,radar computing,sign language gesture recognition,sign language recognition,Signal processing algorithms,Spectrogram,time-frequency analysis,transceivers,unique spectral characteristics}
    \endentry
    \entry{Kumar:2018}{article}{}
      \name{author}{3}{}{%
        {{hash=4392c24056e374c67f95c980012b0523}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Pradeep},
           giveni={P\bibinitperiod}}}%
        {{hash=50b08b39eb33aeea18b7ca1d5528c508}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Partha\bibnamedelima Pratim},
           giveni={P\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=16e1434adbb32d04bc2b19e19358c674}{%
           family={Dogra},
           familyi={D\bibinitperiod},
           given={Debi\bibnamedelima Prosad},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Elsevier Science Inc.}%
      }
      \strng{namehash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \strng{fullhash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \strng{bibnamehash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \strng{authorbibnamehash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \strng{authornamehash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \strng{authorfullhash}{f61bb3c99b0f64f3f6d6ce30e3d6c21a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0020-0255}
      \field{journaltitle}{Inf. Sci.}
      \field{month}{2}
      \field{number}{C}
      \field{title}{{Independent Bayesian Classifier Combination Based Sign Language Recognition Using Facial Expression}}
      \field{volume}{428}
      \field{year}{2018}
      \field{pages}{30\bibrangedash 48}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1016/j.ins.2017.10.046
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.ins.2017.10.046
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.ins.2017.10.046
      \endverb
      \keyw{Sign language recognition,Hidden Markov model (HMM),Depth sensors,Bayesian combination}
    \endentry
    \entry{Kumar:2017a}{article}{}
      \name{author}{4}{}{%
        {{hash=4392c24056e374c67f95c980012b0523}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Pradeep},
           giveni={P\bibinitperiod}}}%
        {{hash=59167fd05298d04d3138a371d7fde359}{%
           family={Saini},
           familyi={S\bibinitperiod},
           given={Rajkumar},
           giveni={R\bibinitperiod}}}%
        {{hash=50b08b39eb33aeea18b7ca1d5528c508}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Partha\bibnamedelima Pratim},
           giveni={P\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=16e1434adbb32d04bc2b19e19358c674}{%
           family={Dogra},
           familyi={D\bibinitperiod},
           given={Debi\bibnamedelima Prosad},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{fullhash}{2d27104e9477a6caceece4cf0ed508b3}
      \strng{bibnamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authorbibnamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authornamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authorfullhash}{2d27104e9477a6caceece4cf0ed508b3}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{8}
      \field{number}{15}
      \field{title}{{3D Text Segmentation and Recognition Using Leap Motion}}
      \field{volume}{76}
      \field{year}{2017}
      \field{pages}{16491\bibrangedash 16510}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1007/s11042-016-3923-z
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11042-016-3923-z
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11042-016-3923-z
      \endverb
      \keyw{3D air-writing,Gesture on air,Written text segmentation,Dynamic features,Touchless interfaces}
    \endentry
    \entry{Kumar:2017b}{article}{}
      \name{author}{4}{}{%
        {{hash=4392c24056e374c67f95c980012b0523}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Pradeep},
           giveni={P\bibinitperiod}}}%
        {{hash=7ee39bccbf68a8b3d1cc94797bb3d756}{%
           family={Gauba},
           familyi={G\bibinitperiod},
           given={Himaanshu},
           giveni={H\bibinitperiod}}}%
        {{hash=50b08b39eb33aeea18b7ca1d5528c508}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Partha\bibnamedelima Pratim},
           giveni={P\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=16e1434adbb32d04bc2b19e19358c674}{%
           family={Dogra},
           familyi={D\bibinitperiod},
           given={Debi\bibnamedelima Prosad},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Elsevier Science Inc.}%
      }
      \strng{namehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{fullhash}{d92a720e8c27515a2dee5cf961e07a45}
      \strng{bibnamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authorbibnamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authornamehash}{9907ab20cb1d44c67024c4ebb7143ac6}
      \strng{authorfullhash}{d92a720e8c27515a2dee5cf961e07a45}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0167-8655}
      \field{journaltitle}{Pattern Recogn. Lett.}
      \field{month}{1}
      \field{number}{C}
      \field{title}{{Coupled HMM-Based Multi-Sensor Data Fusion for Sign Language Recognition}}
      \field{volume}{86}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \keyw{Bayesian classification,Depth sensors,Hidden Markov model (Coupled HMM,HMM),Sign language recognition}
    \endentry
    \entry{Kurtenbach:1997}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=7158a0b804fdd98d0995be06a25f31f2}{%
           family={Kurtenbach},
           familyi={K\bibinitperiod},
           given={Gordon},
           giveni={G\bibinitperiod}}}%
        {{hash=9041f8bd7fae18f7a07af70501e6bf14}{%
           family={Fitzmaurice},
           familyi={F\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=e30fcadf55f31d7c3fd117d6a6bd6cdb}{%
           family={Baudel},
           familyi={B\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=93299a02e7b94c43debf02ca6980dd79}{%
           family={Buxton},
           familyi={B\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{84b69407228139e77c640632ac4b8827}
      \strng{fullhash}{5fb06a6b46a0697c17af0df144cdea6f}
      \strng{bibnamehash}{84b69407228139e77c640632ac4b8827}
      \strng{authorbibnamehash}{84b69407228139e77c640632ac4b8827}
      \strng{authornamehash}{84b69407228139e77c640632ac4b8827}
      \strng{authorfullhash}{5fb06a6b46a0697c17af0df144cdea6f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the ACM International Conference on Human Factors in Computing Systems}
      \field{isbn}{0-89791-802-9}
      \field{series}{CHI '97}
      \field{title}{{The Design of a GUI Paradigm Based on Tablets, Two-hands, and Transparency}}
      \field{venue}{Atlanta, Georgia, USA}
      \field{year}{1997}
      \field{pages}{35\bibrangedash 42}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/258549.258574
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/258549.258574
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/258549.258574
      \endverb
      \keyw{divided attention,marking menus,tablets,task integration,toolglass,transparency,two-handed input}
    \endentry
    \entry{Kysh:2013}{article}{}
      \name{author}{1}{}{%
        {{hash=22f5cd36fec0afad447d2d35c3a1766f}{%
           family={Kysh},
           familyi={K\bibinitperiod},
           given={Lynn},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{22f5cd36fec0afad447d2d35c3a1766f}
      \strng{fullhash}{22f5cd36fec0afad447d2d35c3a1766f}
      \strng{bibnamehash}{22f5cd36fec0afad447d2d35c3a1766f}
      \strng{authorbibnamehash}{22f5cd36fec0afad447d2d35c3a1766f}
      \strng{authornamehash}{22f5cd36fec0afad447d2d35c3a1766f}
      \strng{authorfullhash}{22f5cd36fec0afad447d2d35c3a1766f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{8}
      \field{title}{{Difference between a systematic review and a literature review}}
      \field{year}{2013}
      \verb{doi}
      \verb 10.6084/m9.figshare.766364.v1
      \endverb
      \verb{urlraw}
      \verb https://figshare.com/articles/Difference_between_a_systematic_review_and_a_literature_review/766364
      \endverb
      \verb{url}
      \verb https://figshare.com/articles/Difference_between_a_systematic_review_and_a_literature_review/766364
      \endverb
    \endentry
    \entry{Lahousse:2022}{thesis}{}
      \name{author}{1}{}{%
        {{hash=06b8014e713ba3747f6f429d78dcdb2a}{%
           family={Lahousse},
           familyi={L\bibinitperiod},
           given={Arnaud},
           giveni={A\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{06b8014e713ba3747f6f429d78dcdb2a}
      \strng{fullhash}{06b8014e713ba3747f6f429d78dcdb2a}
      \strng{bibnamehash}{06b8014e713ba3747f6f429d78dcdb2a}
      \strng{authorbibnamehash}{06b8014e713ba3747f6f429d78dcdb2a}
      \strng{authornamehash}{06b8014e713ba3747f6f429d78dcdb2a}
      \strng{authorfullhash}{06b8014e713ba3747f6f429d78dcdb2a}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Since the beginning of the computer age, interaction with the computer has been a challenge. The coming of artificial intelligence, and moreover, machine learning, have created new possible computer interfaces like gesture recognition. This field started with 2D gestures, but this part of gesture recognition has already been extensively studied. The researchers now focus on the 3D gestures. However, the devices used for those studies often are expensive and cumbersome for end-users. It is in this context that this work takes place. We have found an easier and cheaper sensor that can record 3D gestures; an accelerometer mounted on a ring. The goal is to find a way to use hand gesture recognition with this cheap and user-friendly device to see if it could be used in an end-user application.}
      \field{title}{{Ring-based gestural interaction: from elicitation to recognition}}
      \field{type}{phdthesis}
      \field{year}{2022}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:36013
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:36013
      \endverb
      \keyw{Ring Gesture,QuantumLeap,Recognition,Jackknife,$P3,Elicitation,Ring-Based}
    \endentry
    \entry{Lambot:2014}{article}{}
      \name{author}{2}{}{%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
        {{hash=823695f6acd02a8d141a6d3c6ef34745}{%
           family={André},
           familyi={A\bibinitperiod},
           given={Frédéric},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{a70df0b3b7a503124b48259bcaf3871f}
      \strng{fullhash}{a70df0b3b7a503124b48259bcaf3871f}
      \strng{bibnamehash}{a70df0b3b7a503124b48259bcaf3871f}
      \strng{authorbibnamehash}{a70df0b3b7a503124b48259bcaf3871f}
      \strng{authornamehash}{a70df0b3b7a503124b48259bcaf3871f}
      \strng{authorfullhash}{a70df0b3b7a503124b48259bcaf3871f}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Geoscience and Remote Sensing}
      \field{number}{5}
      \field{title}{{Full-Wave Modeling of Near-Field Radar Data for Planar Layered Media Reconstruction}}
      \field{volume}{52}
      \field{year}{2014}
      \field{pages}{2295\bibrangedash 2303}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/TGRS.2013.2259243
      \endverb
    \endentry
    \entry{Lambot:2006}{article}{}
      \name{author}{6}{}{%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
        {{hash=41aef028189c7182eb57e58d5639d640}{%
           family={Weihermüller},
           familyi={W\bibinitperiod},
           given={L.},
           giveni={L\bibinitperiod}}}%
        {{hash=a6633f1e15d11ab4f0ec94148b4bc5eb}{%
           family={Huisman},
           familyi={H\bibinitperiod},
           given={J.\bibnamedelimi A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=2fc53495d341e3855b4b0c71d1c852b0}{%
           family={Vereecken},
           familyi={V\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
        {{hash=46b65c8e53f3f8807894a0a8f73945fc}{%
           family={Vanclooster},
           familyi={V\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=2b4d9f0a581a925bc31a398e82f93045}{%
           family={Slob},
           familyi={S\bibinitperiod},
           given={Evert\bibnamedelima C.},
           giveni={E\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{fullhash}{82a756f71ed94e840955d0a2023bdd72}
      \strng{bibnamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authorbibnamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authornamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authorfullhash}{82a756f71ed94e840955d0a2023bdd72}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Water Resources Research}
      \field{title}{{Analysis of air-launched ground-penetrating radar techniques to measure the soil surface water content}}
      \field{volume}{42}
      \field{year}{2006}
      \verb{doi}
      \verb 10.1029/2006WR005097
      \endverb
    \endentry
    \entry{Lambot:2004}{article}{}
      \name{author}{5}{}{%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
        {{hash=2b4d9f0a581a925bc31a398e82f93045}{%
           family={Slob},
           familyi={S\bibinitperiod},
           given={Evert\bibnamedelima C.},
           giveni={E\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=1754ef3e3cb5cb9b839d924aa7961df1}{%
           family={Bosch},
           familyi={B\bibinitperiod},
           given={Idesbald},
           giveni={I\bibinitperiod},
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=a4979dec097294138d78126cae166abf}{%
           family={Stockbroeckx},
           familyi={S\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod}}}%
        {{hash=ea6ed5477fbfcf252bc07cc5af138e97}{%
           family={Vanclooster},
           familyi={V\bibinitperiod},
           given={Marnik},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{fullhash}{87daf56e2b24ad2347a5c59d560d1cda}
      \strng{bibnamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authorbibnamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authornamehash}{881cd5c6d5a0c57f05f32f460f925ab0}
      \strng{authorfullhash}{87daf56e2b24ad2347a5c59d560d1cda}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Geoscience and Remote Sensing}
      \field{number}{11}
      \field{title}{{Modeling of ground-penetrating Radar for accurate characterization of subsurface electric properties}}
      \field{volume}{42}
      \field{year}{2004}
      \field{pages}{2555\bibrangedash 2568}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TGRS.2004.834800
      \endverb
    \endentry
    \entry{Lan:2017}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=38b2cef845bc169f5dc21c8c936a7c8f}{%
           family={Lan},
           familyi={L\bibinitperiod},
           given={Shengchang},
           giveni={S\bibinitperiod}}}%
        {{hash=3a59bea90024eb73714efde231363589}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Zonglong},
           giveni={Z\bibinitperiod}}}%
        {{hash=12ea35b9f83d673b8e43ee7f01787218}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Haoyu},
           giveni={H\bibinitperiod}}}%
        {{hash=3b3b78fce1abb76e9d2eb9469b29c0e1}{%
           family={Yao},
           familyi={Y\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
        {{hash=ae2bfb6ecec5b83cde05da73340521fb}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Wenshuang},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{61534ca122e62303290ef76decfae456}
      \strng{fullhash}{f7bfb5249d1adefdca3255e5c84f359d}
      \strng{bibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorbibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authornamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorfullhash}{f7bfb5249d1adefdca3255e5c84f359d}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presented a gesture recognition system for human-computer interaction based on 24GHz radars. We describe this system designed for frequently used gesture detection like hand pushing, hand pulling, hand lifting and hand shaking. Decision tree was established to classify these original signals into the four sets of gestures. Through a set of tests on this gesture-recognition system, we proposed that this system could achieve an overall accuracy rate higher than 92\%.}
      \field{booktitle}{2017 {International} {Symposium} on {Antennas} and {Propagation} ({ISAP})}
      \field{month}{10}
      \field{title}{A hand gesture recognition system based on {24GHz} radars}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 2}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1109/ISANP.2017.8228827
      \endverb
      \keyw{24GHz radar,24GHz radars,Classification algorithms,decision tree,decision trees,Decision trees,Doppler effect,Doppler radar,frequency 24.0 GHz,frequently used gesture detection,gesture recognition,Gesture recognition,hand gesture recognition system,human computer interaction,Human computer interaction,human-computer interaction,radar signal processing,signal classification}
    \endentry
    \entry{Lan:2018b}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=38b2cef845bc169f5dc21c8c936a7c8f}{%
           family={Lan},
           familyi={L\bibinitperiod},
           given={Shengchang},
           giveni={S\bibinitperiod}}}%
        {{hash=3a59bea90024eb73714efde231363589}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Zonglong},
           giveni={Z\bibinitperiod}}}%
        {{hash=3b3b78fce1abb76e9d2eb9469b29c0e1}{%
           family={Yao},
           familyi={Y\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
        {{hash=10eaa900a144f0f63acd3deeab7a8e34}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Weichu},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{61534ca122e62303290ef76decfae456}
      \strng{fullhash}{9e86ee036d92d2bccff5a4d0a655aeec}
      \strng{bibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorbibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authornamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorfullhash}{9e86ee036d92d2bccff5a4d0a655aeec}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper proposed a hand gesture recognition method using a three-dimensional radar array. This array consisted of three radars to transmit and receive 24 GHz continuous electromagnetic (EM) wave. The integrated mixer heterodyned the scattered EM wave to the intermediate frequency (IF) with a local oscillator. Temporal and frequency signatures including I/Q signal magnitude difference, phase difference and spectra power integral were proposed as the features of recognition. A decision tree algorithm was constructed as the recognition classifier. 2000 training samples and 4000 untrained samples were used in the experiment. Results showed that this system could achieve a high recognition accuracy rate higher than 92\%.}
      \field{booktitle}{2018 {IEEE}/{MTT}-{S} {International} {Microwave} {Symposium} - {IMS}}
      \field{month}{6}
      \field{note}{ISSN: 2576-7216}
      \field{title}{Hand {Gesture} {Recognition} using a {Three}-dimensional 24 {GHz} {Radar} {Array}}
      \field{year}{2018}
      \field{pages}{138\bibrangedash 140}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1109/MWSYM.2018.8439658
      \endverb
      \keyw{24 GHz radar array,continuous electromagnetic wave,Decision tree,decision trees,Decision trees,Doppler frequency,Doppler radar,frequency 24.0 GHz,Frequency modulation,frequency signatures,gesture recognition,Hand gesture recognition,hand gesture recognition method,high recognition accuracy rate,I/Q signal magnitude difference,Indexes,integrated mixer,intermediate frequency,local oscillator,microwave oscillators,phase difference,Radar,radar signal processing,recognition classifier,Sensors,signal classification,spectra power integral,three-dimensional radar array,Thumb}
    \endentry
    \entry{Lan:2018a}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=38b2cef845bc169f5dc21c8c936a7c8f}{%
           family={Lan},
           familyi={L\bibinitperiod},
           given={Shengchang},
           giveni={S\bibinitperiod}}}%
        {{hash=3a59bea90024eb73714efde231363589}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Zonglong},
           giveni={Z\bibinitperiod}}}%
        {{hash=10eaa900a144f0f63acd3deeab7a8e34}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Weichu},
           giveni={W\bibinitperiod}}}%
        {{hash=1015eddf57af875874176f0bb5324c60}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Lijia},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{61534ca122e62303290ef76decfae456}
      \strng{fullhash}{e33c4a285e04a4ac58f0e7b67fd98545}
      \strng{bibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorbibnamehash}{61534ca122e62303290ef76decfae456}
      \strng{authornamehash}{61534ca122e62303290ef76decfae456}
      \strng{authorfullhash}{e33c4a285e04a4ac58f0e7b67fd98545}
      \field{extraname}{3}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduced a hand gesture recognition method based on convolutional neural networks (CNNs). The recognition scenario consisted in a three dimensional radar array to transmit and receive 24GHz continuous electromagnetic (EM) wave, and convert the scattered EM wave to the intermediate frequency (IF) signals. This paper used the the processed frequency spectrum as the input to the CNN. Then the CNN feature detection layer learned through data training, avoiding supervised feature extraction while learning implicitly from training data. It highlighted these features through convolution operating, pooling and a softmax function. Results showed that this system could achieve a high recognition accuracy rate higher than 96\%.}
      \field{booktitle}{2018 {USNC}-{URSI} {Radio} {Science} {Meeting} ({Joint} with {AP}-{S} {Symposium})}
      \field{month}{7}
      \field{title}{Hand {Gesture} {Recognition} {Using} {Convolutional} {Neural} {Networks}}
      \field{year}{2018}
      \field{pages}{147\bibrangedash 148}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1109/USNC-URSI.2018.8602809
      \endverb
      \keyw{24GHz continuous electromagnetic wave,CNN feature detection layer,Convolution,convolutional neural nets,convolutional neural networks,Convolutional neural networks,data training,EM wave scattering,feature extraction,frequency 24.0 GHz,Frequency modulation,frequency spectrum,gesture recognition,Gesture recognition,hand gesture recognition method,learning (artificial intelligence),Neurons,Radar,recognition scenario,Sensors,spectral analysis}
    \endentry
    \entry{LaViola:2013}{article}{}
      \name{author}{1}{}{%
        {{hash=ba77fe1a51bbe7ce7bccddc9627e2bfe}{%
           family={LaViola},
           familyi={L\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {London, UK}%
      }
      \list{publisher}{1}{%
        {Hindawi}%
      }
      \strng{namehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{fullhash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{bibnamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authorbibnamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authornamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authorfullhash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Scholarly Research Notices}
      \field{title}{{3D Gestural Interaction: The State of the Field}}
      \field{volume}{2013}
      \field{year}{2013}
      \verb{doi}
      \verb 10.1155/2013/514641
      \endverb
      \verb{urlraw}
      \verb https://www.hindawi.com/journals/isrn/2013/514641/
      \endverb
      \verb{url}
      \verb https://www.hindawi.com/journals/isrn/2013/514641/
      \endverb
    \endentry
    \entry{LaViola:2003}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=ba77fe1a51bbe7ce7bccddc9627e2bfe}{%
           family={LaViola},
           familyi={L\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{fullhash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{bibnamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authorbibnamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authornamehash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \strng{authorfullhash}{ba77fe1a51bbe7ce7bccddc9627e2bfe}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present novel algorithms for predictive tracking of user position and orientation based on double exponential smoothing. These algorithms, when compared against Kalman and extended Kalman filter-based predictors with derivative free measurement models, run approximately 135 times faster with equivalent prediction performance and simpler implementations. This paper describes these algorithms in detail along with the Kalman and extended Kalman Filter predictors tested against. In addition, we describe the details of a predictor experiment and present empirical results supporting the validity of our claims that these predictors are faster, easier to implement, and perform equivalently to the Kalman and extended Kalman filtering predictors.}
      \field{booktitle}{Proceedings of the workshop on {Virtual} environments 2003}
      \field{isbn}{978-1-58113-686-9}
      \field{month}{5}
      \field{series}{{EGVE} '03}
      \field{shorttitle}{Double exponential smoothing}
      \field{title}{Double exponential smoothing: an alternative to {Kalman} filter-based predictive tracking}
      \field{urlday}{29}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2003}
      \field{urldateera}{ce}
      \field{pages}{199\bibrangedash 206}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/769953.769976
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/769953.769976
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/769953.769976
      \endverb
    \endentry
    \entry{Lee:2020}{article}{}
      \name{author}{3}{}{%
        {{hash=f67a0e75e92498b83c0c719fed1dcd37}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyo\bibnamedelima Ryun},
           giveni={H\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=5a6e7881e13f8b1712ac39fc465cc96e}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Jihun},
           giveni={J\bibinitperiod}}}%
        {{hash=92101c6261e41f5e84e5a9af2a65d747}{%
           family={Suh},
           familyi={S\bibinitperiod},
           given={Young-Joo},
           giveni={Y\bibinithyphendelim J\bibinitperiod}}}%
      }
      \strng{namehash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \strng{fullhash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \strng{bibnamehash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \strng{authorbibnamehash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \strng{authornamehash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \strng{authorfullhash}{4ffb4b3242e1370c85cb3654fc3c52e6}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the recent development of small radars with high resolution, various human-computer interaction (HCI) applications using them have been developed. In particular, a method of applying a user's hand gesture recognition using a short-range radar to an electronic device is being actively studied. In general, the time delay and Doppler shift characteristics that occur when a transmitted signal that is reflected off an object returns are classified through deep learning to recognize the motion. However, the main obstacle in the commercialization of radar-based hand gesture recognition is that even for the same type of hand gesture, recognition accuracy is degraded due to a slight difference in movement for each individual user. To solve this problem, in this paper, the domain adaptation is applied to hand gesture recognition to minimize the differences among users' gesture information in the learning and the use stage. To verify the effectiveness of domain adaptation, a domain discriminator that cheats the classifier was applied to a deep learning network with a convolutional neural network (CNN) structure. Seven different hand gesture data were collected for 10 participants and used for learning, and the hand gestures of 10 users that were not included in the training data were input to confirm the recognition accuracy of an average of 98.8\%.}
      \field{issn}{2079-9292}
      \field{journaltitle}{Electronics}
      \field{number}{12}
      \field{title}{Improving {Classification} {Accuracy} of {Hand} {Gesture} {Recognition} {Based} on 60 {GHz} {FMCW} {Radar} with {Deep} {Learning} {Domain} {Adaptation}}
      \field{volume}{9}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 24}
      \range{pages}{24}
      \verb{doi}
      \verb 10.3390/electronics9122140
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2079-9292/9/12/2140
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2079-9292/9/12/2140
      \endverb
    \endentry
    \entry{Leem:2020a}{article}{}
      \name{author}{3}{}{%
        {{hash=6ffdd21adefe126cf67fc199c79479c6}{%
           family={Leem},
           familyi={L\bibinitperiod},
           given={Seong\bibnamedelima Kyu},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{fullhash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{bibnamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authorbibnamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authornamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authorfullhash}{f55952c9e34f0216d3d32eea95760d36}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we classify digits written in mid-air using hand gestures. Impulse radio ultrawideband (IR-UWB) radar sensors are used for data acquisition, with three radar sensors placed in a triangular geometry. Conventional radar-based gesture recognition methods use whole raw data matrices or a group of features for gesture classification using convolutional neural networks (CNNs) or other machine learning algorithms. However, if the training and testing data differ in distance, orientation, hand shape, hand size, or even gesture speed or the radar setup environment, these methods become less accurate. To develop a more robust gesture recognition method, we propose not using raw data for the CNN classifier, but instead employing the hand's mid-air trajectory for classification. The hand trajectory has a stereotypical shape for a given digit, regardless of the hand's orientation or speed, making its classification easy and robust. Our proposed method consists of three stages: signal preprocessing, hand motion localization, and tracking and transforming the trajectory data into an image to classify it using a CNN. Our proposed method outperforms conventional approaches because it is robust to changes in orientation, distance, and hand shape and size. Moreover, this method does not require building a huge training database of digits drawn by different users in different orientations; rather, we can use training databases already available in the image processing field. Overall, the proposed mid-air handwritten digit recognition system provides a user-friendly and accurate mid-air handwriting modality that does not place restrictions on users.}
      \field{issn}{1557-9662}
      \field{journaltitle}{IEEE Transactions on Instrumentation and Measurement}
      \field{month}{4}
      \field{number}{4}
      \field{title}{Detecting {Mid}-{Air} {Gestures} for {Digit} {Writing} {With} {Radio} {Sensors} and a {CNN}}
      \field{volume}{69}
      \field{year}{2020}
      \field{pages}{1066\bibrangedash 1081}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TIM.2019.2909249
      \endverb
      \keyw{Clutter,CNN classifier,conventional radar-based gesture recognition methods,convolutional neural nets,Convolutional neural network (CNN),data acquisition,digit writing,feature extraction,gesture classification,gesture recognition,Gesture recognition,gesture speed,hand motion localization,hand shape,hand size,hand trajectory,handwritten character recognition,human computer interaction,human???computer interaction,image,image classification,image motion analysis,impulse radio ultrawideband (IR-UWB) radar,impulse radio ultrawideband radar sensors,IR-UWB,learning (artificial intelligence),localization,machine learning algorithms,mid-air gesture detection,mid-air handwriting,mid-air handwriting modality,mid-air handwritten digit recognition system,mid-air trajectory,object tracking,Radar imaging,radar setup environment,radio sensors,raw data matrices,robust gesture recognition method,sensor,Sensors,stereotypical shape,testing data,Training,Trajectory,trajectory data,triangular geometry,ultra wideband radar,wireless sensor networks}
    \endentry
    \entry{Leem:2020b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=6ffdd21adefe126cf67fc199c79479c6}{%
           family={Leem},
           familyi={L\bibinitperiod},
           given={Seong\bibnamedelima Kyu},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=04d2499b33f00970fb66acdeb3a1ed25}{%
           family={Khan},
           familyi={K\bibinitperiod},
           given={Faheem},
           giveni={F\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{fullhash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{bibnamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authorbibnamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authornamehash}{f55952c9e34f0216d3d32eea95760d36}
      \strng{authorfullhash}{f55952c9e34f0216d3d32eea95760d36}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose three new authentication methods using ultra-wideband (UWB) radio frequency (RF) signals. These mid-air-based authentication techniques are different from the conventional touch-based authentication approaches and provide a more convenient and safer user experience. In these methods, the impulse radio UWB transceiver receives the reflected RF signal corresponding to the movement pattern of the user, extracts the pattern information after noise removal, and converts it into image data suitable for use as classifier input through image signal processing. After that, it verifies whether the pattern is the authentication pattern of the user by employing a convolutional neural network and a one-class support vector machine. This report describes the three proposed authentication methods using the advantages of UWB RF signals, as well as their experimental verification. In the first authentication method, ShapeSec, authentication is performed by writing a simple shape pattern in the air. This technique is simple but very convenient. The second method, SignSec, correctly detects the handwriting of different users when signing and overcomes the security vulnerability of signing with the existing pens. Finally, BreatheSec is based on breathing patterns and takes advantage of the ability of a UWB RF transceiver to detect minute breath movements. The authentication pattern could not be imitated even after it was watched from the side, proving that the proposed method has excellent security characteristics. Experiments showed that each method has over 95\% accuracy.}
      \field{booktitle}{2020 {IEEE} 17th {Annual} {Consumer} {Communications} {Networking} {Conference} ({CCNC})}
      \field{month}{1}
      \field{note}{ISSN: 2331-9860}
      \field{title}{Remote {Authentication} {Using} an {Ultra}-{Wideband} {Radio} {Frequency} {Transceiver}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/CCNC46108.2020.9045438
      \endverb
      \keyw{authentication method,authentication pattern,authorisation,BreatheSec,breathing patterns,CNN,conventional touch-based authentication approaches,convolutional neural nets,convolutional neural network,image classification,image denoising,image signal processing,impulse radio UWB transceiver,IR-UWB,mid-air-based authentication techniques,movement pattern,noise removal,one-class support vector machine,pattern,pattern information extraction,Radio sensor,radio transceivers,reflected RF signal,remote authentication,security characteristics,ShapeSec,simple shape pattern,support vector machines,SVM,telecommunication computing,ultra wideband communication,ultra-wideband radio frequency signals,ultra-wideband radio frequency transceiver,user experience,UWB RF signals,UWB RF transceiver}
    \endentry
    \entry{Leiva:2015}{article}{}
      \name{author}{3}{}{%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=308d2a3c55fa9ee453c227bcb5fcc5da}{%
           family={Martín-Albo},
           familyi={M\bibinithyphendelim A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=b235e5ca7defc80f55a03a3daa2252d3}{%
           family={Plamondon},
           familyi={P\bibinitperiod},
           given={Réjean},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{673f5b823fda80095f4458cf8c2c92ee}
      \strng{fullhash}{673f5b823fda80095f4458cf8c2c92ee}
      \strng{bibnamehash}{673f5b823fda80095f4458cf8c2c92ee}
      \strng{authorbibnamehash}{673f5b823fda80095f4458cf8c2c92ee}
      \strng{authornamehash}{673f5b823fda80095f4458cf8c2c92ee}
      \strng{authorfullhash}{673f5b823fda80095f4458cf8c2c92ee}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2157-6904}
      \field{journaltitle}{ACM Transactions on Intelligent Systems Technology}
      \field{month}{11}
      \field{number}{2}
      \field{title}{{Gestures à Go Go: Authoring Synthetic Human-Like Stroke Gestures Using the Kinematic Theory of Rapid Movements}}
      \field{volume}{7}
      \field{year}{2015}
      \verb{doi}
      \verb 10.1145/2799648
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2799648
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2799648
      \endverb
      \keyw{user interfaces,bootstrapping,unistrokes,gesture recognition,multistrokes,kinematics,multitouch,marks,rapid prototyping,strokes,Gesture synthesis,symbols}
    \endentry
    \entry{Leiva:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=308d2a3c55fa9ee453c227bcb5fcc5da}{%
           family={Martín-Albo},
           familyi={M\bibinithyphendelim A\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{838e6a5f0193334f97e1346a834bebcc}
      \strng{fullhash}{838e6a5f0193334f97e1346a834bebcc}
      \strng{bibnamehash}{838e6a5f0193334f97e1346a834bebcc}
      \strng{authorbibnamehash}{838e6a5f0193334f97e1346a834bebcc}
      \strng{authornamehash}{838e6a5f0193334f97e1346a834bebcc}
      \strng{authorfullhash}{838e6a5f0193334f97e1346a834bebcc}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 20th ACM International Conference on Human-Computer Interaction with Mobile Devices and Services}
      \field{isbn}{9781450358989}
      \field{series}{MobileHCI ’18}
      \field{title}{{GATO: Predicting Human Performance with Multistroke and Multitouch Gesture Input}}
      \field{venue}{Barcelona, Spain}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3229434.3229478
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3229434.3229478
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3229434.3229478
      \endverb
      \keyw{gesture input,touch gestures,stroke gestures,human performance,production time,kinematic theory}
    \endentry
    \entry{Leiva:2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=c81693beede01e4b9b543d359a34b585}{%
           family={Kljun},
           familyi={K\bibinitperiod},
           given={Matjaz},
           giveni={M\bibinitperiod}}}%
        {{hash=4c3694e09d08b9f465f39a6d87e75425}{%
           family={Sandor},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=032ac48dc4410bf1b68f333b5754a3e6}{%
           family={Copic\bibnamedelima Pucihar},
           familyi={C\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Klen},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{0eed29b01e8a1a3ad2a5357edc53e966}
      \strng{fullhash}{cff491493faa49f79e91bb6a4e3607d3}
      \strng{bibnamehash}{0eed29b01e8a1a3ad2a5357edc53e966}
      \strng{authorbibnamehash}{0eed29b01e8a1a3ad2a5357edc53e966}
      \strng{authornamehash}{0eed29b01e8a1a3ad2a5357edc53e966}
      \strng{authorfullhash}{cff491493faa49f79e91bb6a4e3607d3}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, millimeter-wave radar-on-chip sensors such as Google Soli have become readily available in the mobile ecosystem. We envision such radar technology to be integrated into wearables to enable gesture-based interaction possibilities for users ‘on the go’, e.g. to control various devices such as phone, car infotainment system, etc. even when the sensor is occluded by some material such as fabrics. Towards achieving this vision, we developed a hybrid CNN+LSTM deep learning model, and conducted a systematic study investigating mid-air gesture recognition performance when the radar sensor was covered by three different fabrics (leather, wool, and cotton). We show that, when trained on no occluding material, the model performed worse than if trained with each of the three fabrics; however, this is only valid in the small data regime (N=20). When trained with large samples (N=200) on no occluding material, the model achieved remarkable performance also when the sensor was covered by each of the fabrics (95\% avg. accuracy, 99\% AUC). Our results show that sensing mid-air gestures through fabrics is both feasible and ready for practical applications, since it is not necessary to train a dedicated model for each type of fabric available in the market. We also contribute a repeatable procedure to systematically test mid-air gestures with radar technology, enabled by an experimental platform that we release with this paper.}
      \field{booktitle}{22nd International Conference on Human-Computer Interaction with Mobile Devices and Services}
      \field{isbn}{9781450380522}
      \field{series}{MobileHCI '20}
      \field{title}{{The Wearable Radar: Sensing Gestures Through Fabrics}}
      \field{venue}{Oldenburg, Germany}
      \field{year}{2020}
      \verb{doi}
      \verb 10.1145/3406324.3410720
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3406324.3410720
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3406324.3410720
      \endverb
      \keyw{Gestures,Radar,Soli,Wearables,Deep Learning,Fabrics}
    \endentry
    \entry{Lewis:2009}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=f106a761a58d4041d103c16ce4f11cf1}{%
           family={Lewis},
           familyi={L\bibinitperiod},
           given={James\bibnamedelima R.},
           giveni={J\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=f24e1723133e0393dfd185716f640bed}{%
           family={Sauro},
           familyi={S\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=b0725de4e772bb9584c48141c1cd1fe8}{%
           family={Kurosu},
           familyi={K\bibinitperiod},
           given={Masaaki},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{fullhash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{bibnamehash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{authorbibnamehash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{authornamehash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{authorfullhash}{aa5a5c3e3802ee22e51a0aad4e0f9e34}
      \strng{editorbibnamehash}{b0725de4e772bb9584c48141c1cd1fe8}
      \strng{editornamehash}{b0725de4e772bb9584c48141c1cd1fe8}
      \strng{editorfullhash}{b0725de4e772bb9584c48141c1cd1fe8}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Since its introduction in 1986, the 10-item System Usability Scale (SUS) has been assumed to be unidimensional. Factor analysis of two independent SUS data sets reveals that the SUS actually has two factors -- Usable (8 items) and Learnable (2 items -- specifically, Items 4 and 10). These new scales have reasonable reliability (coefficient alpha of .91 and .70, respectively). They correlate highly with the overall SUS (r = .985 and .784, respectively) and correlate significantly with one another (r = .664), but at a low enough level to use as separate scales. A sensitivity analysis using data from 19 tests had a significant Test by Scale interaction, providing additional evidence of the differential utility of the new scales. Practitioners can continue to use the current SUS as is, but, at no extra cost, can also take advantage of these new scales to extract additional information from their SUS data. The data support the use of ``awkward'' rather than ``cumbersome'' in Item 8.}
      \field{booktitle}{Human Centered Design}
      \field{isbn}{978-3-642-02806-9}
      \field{title}{The Factor Structure of the System Usability Scale}
      \field{year}{2009}
      \field{pages}{94\bibrangedash 103}
      \range{pages}{10}
    \endentry
    \entry{Li:2019}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=65dc7c16174f4ebc47ccdc01e74939f2}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Feifei},
           giveni={F\bibinitperiod}}}%
        {{hash=03f04d1309fec3b5ce07e6c1e5df77ed}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yujun},
           giveni={Y\bibinitperiod}}}%
        {{hash=2665c98504d1bca4574dd754692741f8}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Baozhen},
           giveni={B\bibinitperiod}}}%
        {{hash=7ccdbc81f1666d6d34dff3668a59f5e3}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Hongji},
           giveni={H\bibinitperiod}}}%
        {{hash=43e5deda481febaa98df0b2b77ac3816}{%
           family={Xiong},
           familyi={X\bibinitperiod},
           given={Hailiang},
           giveni={H\bibinitperiod}}}%
        {{hash=fb194450e9046854896c4ca5f2dc8d01}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{3c62a58b780d6b2588d1317e07f835ee}
      \strng{fullhash}{5a3b4a84adac26094b7ac8cdbe84fb0b}
      \strng{bibnamehash}{3c62a58b780d6b2588d1317e07f835ee}
      \strng{authorbibnamehash}{3c62a58b780d6b2588d1317e07f835ee}
      \strng{authornamehash}{3c62a58b780d6b2588d1317e07f835ee}
      \strng{authorfullhash}{5a3b4a84adac26094b7ac8cdbe84fb0b}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2019 4th International Conference on Mathematics and Artificial Intelligence}
      \field{isbn}{9781450362580}
      \field{series}{ICMAI 2019}
      \field{title}{{A Gesture Interaction System Based on Improved Finger Feature and WE-KNN}}
      \field{venue}{Chegndu, China}
      \field{year}{2019}
      \field{pages}{39\bibrangedash 43}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1145/3325730.3325759
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3325730.3325759
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3325730.3325759
      \endverb
      \keyw{Virtual interaction,Gesture recognition,K-nearest neighbor classifier based on entropy-weight allocation,Feature extraction}
    \endentry
    \entry{Li:2018b}{article}{}
      \name{author}{4}{}{%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=1c81a6b30005f498eb8a6d6ec6446bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Shimeng},
           giveni={S\bibinitperiod}}}%
        {{hash=d271b8d79d135292f5569754056368a8}{%
           family={Fioranelli},
           familyi={F\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
        {{hash=4e97f6c29f732a77ae7d4a2e90e1474d}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{fullhash}{ff3862073a42f4e7a537ad8e2c543461}
      \strng{bibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorbibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authornamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorfullhash}{ff3862073a42f4e7a537ad8e2c543461}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Dynamic hand gesture recognition is of great importance in human-computer interaction. In this study, the authors investigate the effect of sparsity-driven time-frequency analysis on hand gesture classification. The time-frequency spectrogram is first obtained by sparsity-driven time-frequency analysis. Then three empirical micro-Doppler features are extracted from the time-frequency spectrogram and a support vector machine is used to classify six kinds of dynamic hand gestures. The experimental results on measured data demonstrate that, compared to traditional time-frequency analysis techniques, sparsity-driven time-frequency analysis provides improved accuracy and robustness in dynamic hand gesture classification.}
      \field{issn}{1751-8792}
      \field{journaltitle}{IET Radar, Sonar Navigation}
      \field{number}{8}
      \field{title}{Effect of sparsity-aware time–frequency analysis on dynamic hand gesture classification with radar micro-{Doppler} signatures}
      \field{volume}{12}
      \field{year}{2018}
      \field{pages}{815\bibrangedash 820}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1049/iet-rsn.2017.0570
      \endverb
      \keyw{Doppler radar,dynamic hand gesture classification,dynamic hand gesture recognition,empirical microDoppler feature,feature extraction,gesture recognition,human-computer interaction,image classification,radar computing,radar imaging,radar microDoppler signature,sparse-aware time-frequency analysis,sparsity-driven time-frequency analysis,support vector machine,support vector machines,time-frequency analysis,time-frequency spectrogram extraction}
    \endentry
    \entry{Li:2017a}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=0672466dc7c3a8cec050e5ac091fd0ac}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Rui},
           giveni={R\bibinitperiod}}}%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=4e97f6c29f732a77ae7d4a2e90e1474d}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{fullhash}{96687079c357524004e820c210476a26}
      \strng{bibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorbibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authornamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorfullhash}{96687079c357524004e820c210476a26}
      \field{extraname}{3}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a sparsity-driven method of micro-Doppler analysis is proposed for dynamic hand gesture recognition with radar sensor. The sparse representation of the radar signal in the time-frequency domain is achieved through the Gabor dictionary, and then the micro-Doppler features are extracted by using the orthogonal matching pursuit (OMP) algorithm and fed into classifiers for dynamic hand gesture recognition. The proposed method is validated with real data measured with a K-band radar. Experiment results show that the proposed method outperforms the principal component analysis (PCA) algorithm, with the recognition accuracy higher than 90\%.}
      \field{booktitle}{2017 {IEEE} {Radar} {Conference} ({RadarConf})}
      \field{month}{5}
      \field{note}{ISSN: 2375-5318}
      \field{title}{Sparsity-based dynamic hand gesture recognition using micro-{Doppler} signatures}
      \field{year}{2017}
      \field{pages}{0928\bibrangedash 0931}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/RADAR.2017.7944336
      \endverb
      \keyw{Doppler radar,dynamic hand gesture recognition,feature extraction,Feature extraction,Gabor dictionary,gesture recognition,Gesture recognition,image classification,iterative methods,K-band radar,Matching pursuit algorithms,micro-Doppler analysis,micro-Doppler feature extraction,micro-Doppler signatures,OMP algorithm,orthogonal matching pursuit algorithm,palmprint recognition,PCA algorithm,principal component analysis,principal component analysis algorithm,Radar,radar receivers,radar sensor,radar signal sparse representation,sparse signal representation,sparsity-based dynamic hand gesture recognition,Thumb,time-frequency analysis,Time-frequency analysis,time-frequency domain}
    \endentry
    \entry{Li:2018a}{article}{}
      \name{author}{4}{}{%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=0672466dc7c3a8cec050e5ac091fd0ac}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Rui},
           giveni={R\bibinitperiod}}}%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=4e97f6c29f732a77ae7d4a2e90e1474d}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{fullhash}{96687079c357524004e820c210476a26}
      \strng{bibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorbibnamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authornamehash}{4bc5fe7e313cd37e7052af92d5b78ecd}
      \strng{authorfullhash}{96687079c357524004e820c210476a26}
      \field{extraname}{4}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a sparsity-driven method of micro-Doppler analysis is proposed for dynamic hand gesture recognition with radar sensors. First, sparse representations of the echoes reflected from dynamic hand gestures are achieved through the Gaussian-windowed Fourier dictionary. Second, the micro-Doppler features of dynamic hand gestures are extracted using the orthogonal matching pursuit algorithm. Finally, the nearest neighbor classifier is combined with the modified Hausdorff distance to recognize dynamic hand gestures based on the sparse micro-Doppler features. Experiments with real radar data show that the recognition accuracy produced by the proposed method exceeds 96\% under moderate noise, and the proposed method outperforms the approaches based on principal component analysis and deep convolutional neural network with small training dataset.}
      \field{issn}{1557-9603}
      \field{journaltitle}{IEEE Transactions on Aerospace and Electronic Systems}
      \field{month}{4}
      \field{number}{2}
      \field{title}{Sparsity-{Driven} {Micro}-{Doppler} {Feature} {Extraction} for {Dynamic} {Hand} {Gesture} {Recognition}}
      \field{volume}{54}
      \field{year}{2018}
      \field{pages}{655\bibrangedash 665}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TAES.2017.2761229
      \endverb
      \keyw{Aerodynamics,deep convolutional neural network,Doppler radar,dynamic hand gesture recognition,feature extraction,Feature extraction,Fourier transforms,Gaussian-windowed Fourier dictionary,gesture recognition,Gesture recognition,iterative methods,micro-Doppler analysis,micro-Doppler feature extraction,modified Hausdorff distance,nearest neighbor classifier,nearest neighbour methods,neural nets,orthogonal matching pursuit algorithm,principal component analysis,Radar,radar sensors,radar target recognition,sparse micro-Doppler features,sparse signal representation,sparsity-driven method,Thumb,Time-frequency analysis}
    \endentry
    \entry{Li:2020b}{article}{}
      \name{author}{8}{}{%
        {{hash=a32ea4c0331aabc77b294ab6d3916941}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hao-Yang},
           giveni={H\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=babf1886201cd3e0cd5e06a4116b31ca}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Han-Ting},
           giveni={H\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=da2073733f43f0ced6de55a9a80177d7}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Meng-Lin},
           giveni={M\bibinithyphendelim L\bibinitperiod}}}%
        {{hash=c1efe6cce24decdc35d416ed13bf75b9}{%
           family={Ruan},
           familyi={R\bibinitperiod},
           given={Heng-Xin},
           giveni={H\bibinithyphendelim X\bibinitperiod}}}%
        {{hash=8f98144d2d141c224c5e1ff0ce297451}{%
           family={Shuang},
           familyi={S\bibinitperiod},
           given={Ya},
           giveni={Y\bibinitperiod}}}%
        {{hash=16f4675d720575c39525f8cb4256717a}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Tie\bibnamedelima Jun},
           giveni={T\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=03d3b78f49e14607af03281972f7aab0}{%
           family={Hougne},
           familyi={H\bibinitperiod},
           given={Philipp\bibnamedelima del},
           giveni={P\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=da0a4939306cc1bc599b1cfed3466267}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Lianlin},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{91b92e8a8ef8d2b3393750ae3eecdbee}
      \strng{fullhash}{16ed239e1af950da568c20c22e719ceb}
      \strng{bibnamehash}{91b92e8a8ef8d2b3393750ae3eecdbee}
      \strng{authorbibnamehash}{91b92e8a8ef8d2b3393750ae3eecdbee}
      \strng{authornamehash}{91b92e8a8ef8d2b3393750ae3eecdbee}
      \strng{authorfullhash}{16ed239e1af950da568c20c22e719ceb}
      \field{extraname}{5}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Summary Electromagnetic (EM) sensing is a widespread contactless examination technique with applications in areas such as health care and the internet of things. Most conventional sensing systems lack intelligence, which not only results in expensive hardware and complicated computational algorithms but also poses important challenges for real-time in situ sensing. To address this shortcoming, we propose the concept of intelligent sensing by designing a programmable metasurface for data-driven learnable data acquisition and integrating it into a data-driven learnable data-processing pipeline. Thereby, a measurement strategy can be learned jointly with a matching data post-processing scheme, optimally tailored to the specific sensing hardware, task, and scene, allowing us to perform high-quality imaging and high-accuracy recognition with a remarkably reduced number of measurements. We report the first experimental demonstration of “learned sensing” applied to microwave imaging and gesture recognition. Our results pave the way for learned EM sensing with low latency and computational burden.}
      \field{issn}{2666-3899}
      \field{journaltitle}{Patterns}
      \field{number}{1}
      \field{title}{Intelligent {Electromagnetic} {Sensing} with {Learnable} {Data} {Acquisition} and {Processing}}
      \field{volume}{1}
      \field{year}{2020}
      \field{pages}{100006}
      \range{pages}{1}
      \verb{doi}
      \verb https://doi.org/10.1016/j.patter.2020.100006
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S2666389920300064
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S2666389920300064
      \endverb
      \keyw{artificial neural network,intelligent electromagnetic,programmable metamaterials}
    \endentry
    \entry{Li:2020a}{article}{}
      \name{author}{7}{}{%
        {{hash=fe5913d8c5e4a79edf6a6eb78482dfb3}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haobo},
           giveni={H\bibinitperiod}}}%
        {{hash=5c17f16cb8eab6fdc93d64295785abc9}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Xiangpeng},
           giveni={X\bibinitperiod}}}%
        {{hash=87ff077dbee3eb2055371f9729a8036f}{%
           family={Shrestha},
           familyi={S\bibinitperiod},
           given={Aman},
           giveni={A\bibinitperiod}}}%
        {{hash=2b3912198e1665c77cdcf4b52d43a8fd}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yuchi},
           giveni={Y\bibinitperiod}}}%
        {{hash=ac6098651d53893b05d0c7a6e1a3706e}{%
           family={Heidari},
           familyi={H\bibinitperiod},
           given={Hadi},
           giveni={H\bibinitperiod}}}%
        {{hash=3048f9102f0fe16533bcd052d9fb14a4}{%
           family={Le\bibnamedelima Kernec},
           familyi={L\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={Julien},
           giveni={J\bibinitperiod}}}%
        {{hash=d271b8d79d135292f5569754056368a8}{%
           family={Fioranelli},
           familyi={F\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{ce03b0dda24d513c9662f5090d264a52}
      \strng{fullhash}{8dc1dbf7500c5735461a286ba91f7bcf}
      \strng{bibnamehash}{ce03b0dda24d513c9662f5090d264a52}
      \strng{authorbibnamehash}{ce03b0dda24d513c9662f5090d264a52}
      \strng{authornamehash}{ce03b0dda24d513c9662f5090d264a52}
      \strng{authorfullhash}{8dc1dbf7500c5735461a286ba91f7bcf}
      \field{extraname}{6}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents a hierarchical sensor fusion approach for human micro-gesture recognition by combining an Ultra Wide Band (UWB) Doppler radar and wearable pressure sensors. First, the wrist-worn pressure sensor array (PSA) and Doppler radar are used to respectively identify static and dynamic gestures through a Quadratic-kernel SVM (Support Vector Machine) classifier. Then, a robust wrapper method is applied on the features from both sensors to search the optimal combination. Subsequently, two hierarchical approaches where one sensor acts as “enhancer” of the other are explored. In the first case, scores from Doppler radar related to the confidence level of its classifier and the prediction label corresponding to the posterior probabilities are utilized to maximize the static hand gestures classification performance by hierarchical combination with PSA data. In the second case, the PSA acts as an “enhancer” for radar to improve the dynamic gesture recognition. In this regard, different weights of the “enhancer” sensor in the fusion process have been evaluated and compared in terms of classification accuracy. A realistic cross-validation method is chosen to test one unknown participant with the model trained by data from others, demonstrating that this hierarchical fusion approach for static and dynamic gestures yields approximately 15\% improvement in classification accuracy in the best cases.}
      \field{issn}{2469-7257}
      \field{journaltitle}{IEEE Journal of Electromagnetics, RF and Microwaves in Medicine and Biology}
      \field{month}{9}
      \field{number}{3}
      \field{title}{Hierarchical {Sensor} {Fusion} for {Micro}-{Gesture} {Recognition} {With} {Pressure} {Sensor} {Array} and {Radar}}
      \field{volume}{4}
      \field{year}{2020}
      \field{pages}{225\bibrangedash 232}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/JERM.2019.2949456
      \endverb
      \keyw{classification accuracy,Doppler effect,Doppler radar,dynamic gesture recognition,dynamic gestures,enhancer sensor,feature extraction,Feature extraction,fusion process,gesture classification,gesture recognition,hierarchical combination,hierarchical fusion approach,hierarchical sensor fusion approach,image classification,machine learning,microgesture recognition,Multimodal sensing,pressure sensors,Pressure sensors,PSA data,Quadratic-kernel SVM classifier,radar computing,robust wrapper method,sensor arrays,Sensor arrays,sensor fusion,static gestures,static hand gestures classification performance,Support Vector Machine,support vector machines,Support vector machines,Ultra Wide Band Doppler radar,ultra wideband radar,UWB Doppler radar,wearable pressure sensors,wrist-worn pressure sensor array}
    \endentry
    \entry{Li:2022}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=506d59206598c14cf9512fdbb8a4fb52}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Mingxue},
           giveni={M\bibinitperiod}}}%
        {{hash=42c804d59275678409e1e37d89cc1fd8}{%
           family={Cong},
           familyi={C\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
        {{hash=6420a2c16a560f33994ee2c003b2e1ed}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yuyang},
           giveni={Y\bibinitperiod}}}%
        {{hash=0ec145b39de6f19433a64c8230a9ad49}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Gan},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{65e219e7c7b2756325490a2340187812}
      \strng{fullhash}{8ff8e38eedf7fab5dde11924bcdf6cb0}
      \strng{bibnamehash}{65e219e7c7b2756325490a2340187812}
      \strng{authorbibnamehash}{65e219e7c7b2756325490a2340187812}
      \strng{authornamehash}{65e219e7c7b2756325490a2340187812}
      \strng{authorfullhash}{8ff8e38eedf7fab5dde11924bcdf6cb0}
      \field{extraname}{7}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}
      \field{title}{{Class-Incremental Gesture Recognition Learning with Out-of-Distribution Detection}}
      \field{year}{2022}
      \field{pages}{1503\bibrangedash 1508}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/IROS47612.2022.9981167
      \endverb
      \keyw{Training;Human computer interaction;Memory management;Fitting;Gesture recognition;Medical services;Task analysis}
    \endentry
    \entry{Li:2017c}{article}{}
      \name{author}{6}{}{%
        {{hash=d2df59751529e400cd88115dcb00be8c}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Qiming},
           giveni={Q\bibinitperiod}}}%
        {{hash=1bd49eb4c6192a4275de364675f1d9b6}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Chen},
           giveni={C\bibinitperiod}}}%
        {{hash=7df9638ddfafce2572b7c781a9caf088}{%
           family={Lv},
           familyi={L\bibinitperiod},
           given={Shengqing},
           giveni={S\bibinitperiod}}}%
        {{hash=7d3cef8f9964814559baa471fb94da91}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zeyu},
           giveni={Z\bibinitperiod}}}%
        {{hash=0927c843a3da6bc94ede85e4bcba90f9}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Yimin},
           giveni={Y\bibinitperiod}}}%
        {{hash=6a9cd771a478bc28737144acc18175da}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Lizhuang},
           giveni={L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Plenum Press}%
      }
      \strng{namehash}{47e0a72aedcefc4e1fe1be76aff3a8c4}
      \strng{fullhash}{877fdf541e3810dd78d628f13ed092dd}
      \strng{bibnamehash}{47e0a72aedcefc4e1fe1be76aff3a8c4}
      \strng{authorbibnamehash}{47e0a72aedcefc4e1fe1be76aff3a8c4}
      \strng{authornamehash}{47e0a72aedcefc4e1fe1be76aff3a8c4}
      \strng{authorfullhash}{877fdf541e3810dd78d628f13ed092dd}
      \field{extraname}{8}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0148-5598}
      \field{journaltitle}{J. Med. Syst.}
      \field{month}{10}
      \field{number}{10}
      \field{title}{{An Human-Computer Interactive Augmented Reality System for Coronary Artery Diagnosis Planning and Training}}
      \field{volume}{41}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 11}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1007/s10916-017-0805-5
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10916-017-0805-5
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10916-017-0805-5
      \endverb
      \keyw{Trainning,Coronary artery,Augmented reality,Diagnosis and preoperative planning,Human computer interaction}
    \endentry
    \entry{Li:2017b}{article}{}
      \name{author}{6}{}{%
        {{hash=a1c37d1221ce11dca998241101c55409}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Tianxing},
           giveni={T\bibinitperiod}}}%
        {{hash=c4231831756edbbea80229c1c4a1088c}{%
           family={Xiong},
           familyi={X\bibinitperiod},
           given={Xi},
           giveni={X\bibinitperiod}}}%
        {{hash=7c5efc8c354106a357365d5affb5fe74}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Yifei},
           giveni={Y\bibinitperiod}}}%
        {{hash=5eb11af6f12eab0c68e10d520964c1f3}{%
           family={Hito},
           familyi={H\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=788e21061368f288724159c5854276f2}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xing-Dong},
           giveni={X\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=7c3ecfe7f16b5bce17e6e06d3dab7719}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Xia},
           giveni={X\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{12cb4253b51f816aded622f2086d41c7}
      \strng{fullhash}{5e3f3166a4d8abd89c58a1f16a489f9f}
      \strng{bibnamehash}{12cb4253b51f816aded622f2086d41c7}
      \strng{authorbibnamehash}{12cb4253b51f816aded622f2086d41c7}
      \strng{authornamehash}{12cb4253b51f816aded622f2086d41c7}
      \strng{authorfullhash}{5e3f3166a4d8abd89c58a1f16a489f9f}
      \field{extraname}{9}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Free-hand gestural input is essential for emerging user interactions. We present Aili, a table lamp reconstructing a 3D hand skeleton in real time, requiring neither cameras nor on-body sensing devices. Aili consists of an LED panel in a lampshade and a few low-cost photodiodes embedded in the lamp base. To reconstruct a hand skeleton, Aili combines 2D binary blockage maps from vantage points of different photodiodes, which describe whether a hand blocks light rays from individual LEDs to all photodiodes. Empowering a table lamp with sensing capability, Aili can be seamlessly integrated into the existing environment. Relying on such low-level cues, Aili entails lightweight computation and is inherently privacy-preserving. We build and evaluate an Aili prototype. Results show that Aili’s algorithm reconstructs a hand pose within 7.2 ms on average, with 10.2° mean angular deviation and 2.5-mm mean translation deviation in comparison to Leap Motion. We also conduct user studies to examine the privacy issues of Leap Motion and solicit feedback on Aili’s privacy protection. We conclude by demonstrating various interaction applications Aili enables.}
      \field{journaltitle}{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}
      \field{month}{9}
      \field{number}{3}
      \field{title}{{Reconstructing Hand Poses Using Visible Light}}
      \field{volume}{1}
      \field{year}{2017}
      \verb{doi}
      \verb 10.1145/3130937
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3130937
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3130937
      \endverb
      \keyw{Gestural input,3D hand reconstruction,visible light sensing}
    \endentry
    \entry{Li:2009}{article}{}
      \name{author}{2}{}{%
        {{hash=6c504e4927fc0520713bead27a9b567d}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Tuanjie},
           giveni={T\bibinitperiod}}}%
        {{hash=3d438c130ccb96d97928c61a8073e6b9}{%
           family={Ge},
           familyi={G\bibinitperiod},
           given={Mengmeng},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{2246ccd84d67ece80e16d4695f875b8d}
      \strng{fullhash}{2246ccd84d67ece80e16d4695f875b8d}
      \strng{bibnamehash}{2246ccd84d67ece80e16d4695f875b8d}
      \strng{authorbibnamehash}{2246ccd84d67ece80e16d4695f875b8d}
      \strng{authornamehash}{2246ccd84d67ece80e16d4695f875b8d}
      \strng{authorfullhash}{2246ccd84d67ece80e16d4695f875b8d}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1006-4982, 1995-8196}
      \field{journaltitle}{Transactions of Tianjin University}
      \field{month}{10}
      \field{number}{5}
      \field{title}{{Human motion recognition using ultra-wideband radar and cameras on mobile robot}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{15}
      \field{year}{2009}
      \field{urldateera}{ce}
      \field{pages}{381\bibrangedash 387}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1007/s12209-009-0067-5
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/s12209-009-0067-5
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/s12209-009-0067-5
      \endverb
    \endentry
    \entry{Liang:2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=af4d9af003f171097563a9cefa5251f0}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Huaiyuan},
           giveni={H\bibinitperiod}}}%
        {{hash=c1aad26961f7b50a06e80a1bfb22cd43}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiangrong},
           giveni={X\bibinitperiod}}}%
        {{hash=0a4a4ba9a981bd1c5afca81cf67f1c67}{%
           family={Greco},
           familyi={G\bibinitperiod},
           given={Maria\bibnamedelima S.},
           giveni={M\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=e0fab53717eeb340ca8fd3a9d80ec63a}{%
           family={Gini},
           familyi={G\bibinitperiod},
           given={Fulvio},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{7f8d91fa89a2973799d09742ab7c9c74}
      \strng{fullhash}{bb041bcbbafaf5ab8564ff6d1cef7317}
      \strng{bibnamehash}{7f8d91fa89a2973799d09742ab7c9c74}
      \strng{authorbibnamehash}{7f8d91fa89a2973799d09742ab7c9c74}
      \strng{authornamehash}{7f8d91fa89a2973799d09742ab7c9c74}
      \strng{authorfullhash}{bb041bcbbafaf5ab8564ff6d1cef7317}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, radar micro-Doppler signatures have been extensively utilized for hand gesture recognition. As reported by existing works, recognition accuracy of different hand gestures is heavily affected by the aspect angle. In general, the accuracy deteriorates significantly with the increasing aspect angle. To solve this problem, we propose to utilize interferometric radar for hand gesture recognition in this paper, which is capable of providing two-dimensional micro-motions information, referred to as radial and transversal micro-motions. We record data of 9 different hand gestures in 4 aspect angles, where three empirical features are extracted from both Doppler and interferometric spectrograms and fed into support vector machine classifier for recognition. The experimental results demonstrate that hand gesture recognition using interferometric radar, 1) enhances recognition accuracy, 2) exhibits robustness against aspect angle, 3) recognizes horizontally symmetric gestures, by providing transversal micro-motion information and increasing spatial resolution.}
      \field{booktitle}{2020 {IEEE} {International} {Radar} {Conference} ({RADAR})}
      \field{month}{4}
      \field{note}{ISSN: 2640-7736}
      \field{title}{Enhanced {Hand} {Gesture} {Recognition} using {Continuous} {Wave} {Interferometric} {Radar}}
      \field{year}{2020}
      \field{pages}{226\bibrangedash 231}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/RADAR42522.2020.9114807
      \endverb
      \keyw{aspect angles,continuous wave interferometric radar,Doppler radar,Doppler spectrograms,enhanced hand gesture recognition,feature extraction,gesture recognition,hand gesture recognition,interferometric radar,interferometric spectrograms,interferometric spectrum,micro-Doppler spectrum,micromotion information,radar computing,radar imaging,radar microDoppler signatures,radar target recognition,radial micromotions,recognition accuracy,spatial resolution,support vector machine classifier,support vector machines,SVM,symmetric gestures,transversal micromotions,two-dimensional micromotions information}
    \endentry
    \entry{Liang:2017}{article}{}
      \name{author}{5}{}{%
        {{hash=c943a1c31e21d996501f6e7f4028b34b}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Hui},
           giveni={H\bibinitperiod}}}%
        {{hash=531840fb2f26d84260af1c6189db29ad}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
        {{hash=8bb568747270c0ccfae19f58f8c9ab61}{%
           family={Kazmi},
           familyi={K\bibinitperiod},
           given={Ismail\bibnamedelima K.},
           giveni={I\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=da8ae459c864be85276df939eea11d5e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jian\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=80f752991d440833d808698be11c09b8}{%
           family={Jiao},
           familyi={J\bibinitperiod},
           given={Peifeng},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{e36b2c188efa8adb5b56a1e2a793c6ef}
      \strng{fullhash}{094e7235a8a816445ef26bd45ac21200}
      \strng{bibnamehash}{e36b2c188efa8adb5b56a1e2a793c6ef}
      \strng{authorbibnamehash}{e36b2c188efa8adb5b56a1e2a793c6ef}
      \strng{authornamehash}{e36b2c188efa8adb5b56a1e2a793c6ef}
      \strng{authorfullhash}{094e7235a8a816445ef26bd45ac21200}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0178-2789}
      \field{journaltitle}{Vis. Comput.}
      \field{month}{4}
      \field{number}{4}
      \field{title}{{Hand Gesture-Based Interactive Puppetry System to Assist Storytelling for Children}}
      \field{volume}{33}
      \field{year}{2017}
      \field{pages}{517\bibrangedash 531}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/s00371-016-1272-6
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s00371-016-1272-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s00371-016-1272-6
      \endverb
      \keyw{Serious game,Virtual puppet,Hand gesture recognizing,Digital storytelling}
    \endentry
    \entry{Lien:2016}{article}{}
      \name{author}{8}{}{%
        {{hash=5858a49df4f45760271051cb85536f29}{%
           family={Lien},
           familyi={L\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod}}}%
        {{hash=9461d29e911cdf4cf0bf584d64a40d4a}{%
           family={Gillian},
           familyi={G\bibinitperiod},
           given={Nicholas},
           giveni={N\bibinitperiod}}}%
        {{hash=3a44d1971b3dde5ba66af8b19b5155de}{%
           family={Karagozler},
           familyi={K\bibinitperiod},
           given={M.\bibnamedelimi Emre},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=480097a22480aad8bc89e17cc26f34b1}{%
           family={Amihood},
           familyi={A\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
        {{hash=018a6ee2eac2d955bb7982ed92040959}{%
           family={Schwesig},
           familyi={S\bibinitperiod},
           given={Carsten},
           giveni={C\bibinitperiod}}}%
        {{hash=c840d770e4c65ad2c92e352aacfccfc3}{%
           family={Olson},
           familyi={O\bibinitperiod},
           given={Erik},
           giveni={E\bibinitperiod}}}%
        {{hash=d638965527c97a24884d587f5677bfe3}{%
           family={Raja},
           familyi={R\bibinitperiod},
           given={Hakim},
           giveni={H\bibinitperiod}}}%
        {{hash=e1b6c7b998ff4368f042c24f7c1b6350}{%
           family={Poupyrev},
           familyi={P\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
      }
      \strng{namehash}{9646c49bb65a4a13cbd73ae592751916}
      \strng{fullhash}{23330157b5d75fb2ec97c6c313974407}
      \strng{bibnamehash}{9646c49bb65a4a13cbd73ae592751916}
      \strng{authorbibnamehash}{9646c49bb65a4a13cbd73ae592751916}
      \strng{authornamehash}{9646c49bb65a4a13cbd73ae592751916}
      \strng{authorfullhash}{23330157b5d75fb2ec97c6c313974407}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents Soli, a new, robust, high-resolution, low-power, miniature gesture sensing technology for human-computer interaction based on millimeter-wave radar. We describe a new approach to developing a radar-based sensor optimized for human-computer interaction, building the sensor architecture from the ground up with the inclusion of radar design principles, high temporal resolution gesture tracking, a hardware abstraction layer (HAL), a solid-state radar chip and system architecture, interaction models and gesture vocabularies, and gesture recognition. We demonstrate that Soli can be used for robust gesture recognition and can track gestures with sub-millimeter accuracy, running at over 10,000 frames per second on embedded hardware.}
      \field{issn}{0730-0301}
      \field{journaltitle}{ACM Transactions on Graphics}
      \field{month}{7}
      \field{number}{4}
      \field{shorttitle}{Soli}
      \field{title}{{Soli: ubiquitous gesture sensing with millimeter wave radar}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{35}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{142:1\bibrangedash 142:19}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/2897824.2925953
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2897824.2925953
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2897824.2925953
      \endverb
      \keyw{gestures,interaction,radar,RF,sensors}
    \endentry
    \entry{Liu:2019}{article}{}
      \name{author}{4}{}{%
        {{hash=1f043346093286f1eaf0490801115088}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Changjiang},
           giveni={C\bibinitperiod}}}%
        {{hash=df85f1478946f6ccdbf3cf2714448550}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yuanhao},
           giveni={Y\bibinitperiod}}}%
        {{hash=2d1a780def6e6ef83c684c535d90707a}{%
           family={Ao},
           familyi={A\bibinitperiod},
           given={Dongyang},
           giveni={D\bibinitperiod}}}%
        {{hash=86fe2d9e55964eb7e5443e0ae7ac7cd5}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Haiyan},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{3a66f7f295624dca342f39de0c6ca575}
      \strng{fullhash}{20b70517c766ad50e5060eb047e54b4b}
      \strng{bibnamehash}{3a66f7f295624dca342f39de0c6ca575}
      \strng{authorbibnamehash}{3a66f7f295624dca342f39de0c6ca575}
      \strng{authornamehash}{3a66f7f295624dca342f39de0c6ca575}
      \strng{authorfullhash}{20b70517c766ad50e5060eb047e54b4b}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar sensors offer several advantages over optical sensors in the gesture recognition for remote control of electronic devices. In this paper, we investigate the feasibility of human gesture recognition using the spectra of radar measurement parameters. With the combination of radar theory and classification methods, we found that the frequencies of different gestures' parameters could be utilized as features for gesture recognition. Six kinds of periodic dynamic gestures are designed to avoid the complexity of defining and extracting the start and end of the dynamic gesture. In addition to the frequency ratio, we also extracted some features related to motion range and detection coherence to eliminate the interferences brought by the unintended gestures. The decision tree classifier designed on the basis of experimental phenomena can guarantee effective classification between different gestures, and in general, the correct recognition rate of each gesture is higher than 90\%. Finally, we collected the position and the Doppler velocity information of hand for classification by a W-band millimeter wave radar in the experiment and verified the usability of the proposed method.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Spectrum-{Based} {Hand} {Gesture} {Recognition} {Using} {Millimeter}-{Wave} {Radar} {Parameter} {Measurements}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{79147\bibrangedash 79158}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2923122
      \endverb
      \keyw{correct recognition rate,decision tree,decision tree classifier,decision trees,Doppler radar,Doppler velocity information,dynamic gesture,electronic devices,feature extraction,Feature extraction,gesture recognition,Gesture recognition,human gesture recognition,image classification,Millimeter wave radar,millimeter-wave,millimeter-wave radar parameter measurements,millimetre wave measurement,millimetre wave radar,motion detection,motion range,optical sensors,periodic dynamic gestures,Radar antennas,radar imaging,Radar measurements,radar sensors,radar theory,remote control,spectrum-based hand gesture recognition,unintended gestures,W-band millimeter wave radar}
    \endentry
    \entry{Liu:2020b}{article}{}
      \name{author}{10}{}{%
        {{hash=7fe4001ec30625259adab5f1d8029256}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Haipeng},
           giveni={H\bibinitperiod}}}%
        {{hash=1d901ddb7bdf5826d4fad9c9539b6c48}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yuheng},
           giveni={Y\bibinitperiod}}}%
        {{hash=72680ae3926b84b83761d20ce343d6d4}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Anfu},
           giveni={A\bibinitperiod}}}%
        {{hash=e258513c5aeb659e990705974a1a60b7}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Hanyue},
           giveni={H\bibinitperiod}}}%
        {{hash=f27ec46ccd272a021fd78bdac92dd490}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=d577a18d69b1839d244102b15b6f7ce2}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Kunpeng},
           giveni={K\bibinitperiod}}}%
        {{hash=e18aff315b1d0ba7e365e7bd346eb808}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Peilin},
           giveni={P\bibinitperiod}}}%
        {{hash=f8eb3e2c27726d39e00508882d1e19f1}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Yixuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=883bc21bc18b1ae1bf85c3afcd6e584a}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Liang},
           giveni={L\bibinitperiod}}}%
        {{hash=91b31c4e00d5e12d1f8af50834da3669}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Huadong},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{8150b8e387bd6af65305275ff2fb4a31}
      \strng{fullhash}{9a75743e3968eac2bcee2719c1d0be3e}
      \strng{bibnamehash}{8150b8e387bd6af65305275ff2fb4a31}
      \strng{authorbibnamehash}{8150b8e387bd6af65305275ff2fb4a31}
      \strng{authornamehash}{8150b8e387bd6af65305275ff2fb4a31}
      \strng{authorfullhash}{9a75743e3968eac2bcee2719c1d0be3e}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{"In air" gesture recognition using millimeter wave (mmWave) radar and its applications in natural human-computer-interaction for smart home has shown its potential. However, the state-of-the-art works still fall short in terms of limited gesture space, vulnerable to surrounding interference, and off-line recognition. In this paper, we propose mHomeGes, a real-time mmWave arm gesture recognition system for practical smart home-usage. To this end, we first distill arm gesture's position and dynamic variation, and then custom-design a lightweight convolution neural network to recognize fine-grained gestures. Next, we propose a user discovery method to focus on the target human gesture, thus eliminating the adverse impact of surrounding interference. Finally, we design a hidden Markov model-based voting mechanism to handle continuous gesture signals at run-time, which leads to continuous gesture recognition in real-time. We implement mHomeGes on a commodity mmWave radar and also perform a user study, which demonstrates that mHomeGes achieves high recognition accuracy above 95.30\% in real-time across various smart home scenarios, regardless of the impact of surrounding movements, concurrent gestures, human physiological conditions, and outer packing materials. Moreover, we have also publicly archived a mmWave gesture data-set collected during developing mHomeGes, which consists of about 22,000 instances from 25 persons and may have an independent value of facilitating future research.}
      \field{journaltitle}{Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}
      \field{month}{12}
      \field{number}{4}
      \field{title}{Real-time {Arm} {Gesture} {Recognition} in {Smart} {Home} {Scenarios} via {Millimeter} {Wave} {Sensing}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{4}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{140:1\bibrangedash 140:28}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/3432235
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3432235
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3432235
      \endverb
      \keyw{Gesture Recognition,Human-Computer Interaction,Millimeter Wave Sensing,Smart Home}
    \endentry
    \entry{Liu:2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=c887da1be0ad3ffd2de8fdb37e5b44b4}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Mingyu},
           giveni={M\bibinitperiod}}}%
        {{hash=381e4495f0601024537a44d371cc5716}{%
           family={Nancel},
           familyi={N\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
        {{hash=f94f65826718458aba9a7e2ee4834749}{%
           family={Vogel},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Charlotte, NC, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \strng{fullhash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \strng{bibnamehash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \strng{authorbibnamehash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \strng{authornamehash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \strng{authorfullhash}{22d09d4a6c4dc0b8ca4e5725f9d9e432}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe Gunslinger, a mid-air interaction technique using barehand postures and gestures. Unlike past work, we explore a relaxed arms-down position with both hands interacting at the sides of the body. It features "hand-cursor" feedback to communicate recognized hand posture, command mode and tracking quality; and a simple, but flexible hand posture recognizer. Although Gunslinger is suitable for many usage contexts, we focus on integrating mid-air gestures with large display touch input. We show how the Gunslinger form factor enables an interaction language that is equivalent, coherent, and compatible with large display touch input. A four-part study evaluates Midas Touch, posture recognition feedback, pointing and clicking, and general usability.}
      \field{booktitle}{Proceedings of the 28th Annual ACM Symposium on User Interface Software \& Technology}
      \field{isbn}{9781450337793}
      \field{series}{UIST '15}
      \field{title}{Gunslinger: Subtle Arms-down Mid-air Interaction}
      \field{year}{2015}
      \field{pages}{63\bibrangedash 71}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/2807442.2807489
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2807442.2807489
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2807442.2807489
      \endverb
      \keyw{wearable,touch,large displays,gestures,barehand}
    \endentry
    \entry{Liu:2020a}{incollection}{}
      \name{author}{6}{}{%
        {{hash=93c82128aca25c57cfb17e90d02136d5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=1d901ddb7bdf5826d4fad9c9539b6c48}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yuheng},
           giveni={Y\bibinitperiod}}}%
        {{hash=7fe4001ec30625259adab5f1d8029256}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Haipeng},
           giveni={H\bibinitperiod}}}%
        {{hash=72680ae3926b84b83761d20ce343d6d4}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Anfu},
           giveni={A\bibinitperiod}}}%
        {{hash=a68462e1c4f3ef845672005132266771}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Jianhua},
           giveni={J\bibinitperiod}}}%
        {{hash=d9125b7654a1ab28a3224e1f04fd09ed}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=65ae00ff52a1f9d8174ffcad07d13bfd}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Zhiwen},
           giveni={Z\bibinitperiod}}}%
        {{hash=e64d357dccbf270f516a9a4a2b193599}{%
           family={Becker},
           familyi={B\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=88f4e6322e06b62cc115a3bcfad5bbdb}{%
           family={Xing},
           familyi={X\bibinitperiod},
           given={Guoliang},
           giveni={G\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{9e1be451eb802292c7c1ac04e6e14a1e}
      \strng{fullhash}{2d48293368652efeba8b5fa39947fcc6}
      \strng{bibnamehash}{9e1be451eb802292c7c1ac04e6e14a1e}
      \strng{authorbibnamehash}{9e1be451eb802292c7c1ac04e6e14a1e}
      \strng{authornamehash}{9e1be451eb802292c7c1ac04e6e14a1e}
      \strng{authorfullhash}{2d48293368652efeba8b5fa39947fcc6}
      \strng{editorbibnamehash}{8bb9db644af46cf61e9fbc2ce8dc48d7}
      \strng{editornamehash}{8bb9db644af46cf61e9fbc2ce8dc48d7}
      \strng{editorfullhash}{8bb9db644af46cf61e9fbc2ce8dc48d7}
      \field{extraname}{3}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Green, {Pervasive}, and {Cloud} {Computing}}
      \field{isbn}{978-3-030-64242-6 978-3-030-64243-3}
      \field{note}{Series Title: Lecture Notes in Computer Science}
      \field{title}{Long-{Range} {Gesture} {Recognition} {Using} {Millimeter} {Wave} {Radar}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{12398}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{30\bibrangedash 44}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/978-3-030-64243-3_3
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-030-64243-3_3
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-030-64243-3_3
      \endverb
    \endentry
    \entry{Lopera:2007}{article}{}
      \name{author}{4}{}{%
        {{hash=0c08d8525a7a6d86d61b6cd25930b316}{%
           family={Lopera},
           familyi={L\bibinitperiod},
           given={Olga},
           giveni={O\bibinitperiod}}}%
        {{hash=2b4d9f0a581a925bc31a398e82f93045}{%
           family={Slob},
           familyi={S\bibinitperiod},
           given={Evert\bibnamedelima C.},
           giveni={E\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=a797aa0dfce3f3557cb1a44bef51042c}{%
           family={Milisavljevic},
           familyi={M\bibinitperiod},
           given={Nada},
           giveni={N\bibinitperiod}}}%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{de5377269b15fad45da032816d81758a}
      \strng{fullhash}{7300a8f817118b35ca4083bf4bc992e7}
      \strng{bibnamehash}{de5377269b15fad45da032816d81758a}
      \strng{authorbibnamehash}{de5377269b15fad45da032816d81758a}
      \strng{authornamehash}{de5377269b15fad45da032816d81758a}
      \strng{authorfullhash}{7300a8f817118b35ca4083bf4bc992e7}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Geoscience and Remote Sensing}
      \field{month}{3}
      \field{number}{3}
      \field{title}{{Filtering Soil Surface and Antenna Effects From GPR Data to Enhance Landmine Detection}}
      \field{volume}{45}
      \field{year}{2007}
      \field{pages}{707\bibrangedash 717}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TGRS.2006.888136
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/4106057
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/4106057
      \endverb
    \endentry
    \entry{Lopez:2015}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=d65d8574ead2fd93e99aaaf10e441a5c}{%
           family={López},
           familyi={L\bibinitperiod},
           given={Gustavo},
           giveni={G\bibinitperiod}}}%
        {{hash=b46ad3b48ab26032f0e648c058a3b848}{%
           family={Quesada},
           familyi={Q\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod}}}%
        {{hash=4ab9fd77d8891e940d094084f6fa7e19}{%
           family={Guerrero},
           familyi={G\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=b642c33276a8708d190d71c17df91795}{%
           family={Cleland},
           familyi={C\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=47dbb1dc050ad7cba960cb05bef8dde6}{%
           family={Guerrero},
           familyi={G\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod}}}%
        {{hash=f3e70bf682822e03690b724e91972bdb}{%
           family={Bravo},
           familyi={B\bibinitperiod},
           given={José},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{12331f252328e0684a9d085e87bee936}
      \strng{fullhash}{12331f252328e0684a9d085e87bee936}
      \strng{bibnamehash}{12331f252328e0684a9d085e87bee936}
      \strng{authorbibnamehash}{12331f252328e0684a9d085e87bee936}
      \strng{authornamehash}{12331f252328e0684a9d085e87bee936}
      \strng{authorfullhash}{12331f252328e0684a9d085e87bee936}
      \strng{editorbibnamehash}{133c5f7882d8da02eb4a9fbfe23fc9fd}
      \strng{editornamehash}{133c5f7882d8da02eb4a9fbfe23fc9fd}
      \strng{editorfullhash}{133c5f7882d8da02eb4a9fbfe23fc9fd}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Ambient Assisted Living. ICT-based Solutions in Real Life Situations}
      \field{isbn}{978-3-319-26410-3}
      \field{title}{A Gesture-Based Interaction Approach for Manipulating Augmented Objects Using Leap Motion}
      \field{year}{2015}
      \field{pages}{231\bibrangedash 243}
      \range{pages}{13}
    \endentry
    \entry{Lou:2018}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=380c8705fa630530c27c5974669fb0de}{%
           family={Lou},
           familyi={L\bibinitperiod},
           given={Xinye},
           giveni={X\bibinitperiod}}}%
        {{hash=65ae00ff52a1f9d8174ffcad07d13bfd}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Zhiwen},
           giveni={Z\bibinitperiod}}}%
        {{hash=53f6f613453932e8b9d343ec613acfde}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhu},
           giveni={Z\bibinitperiod}}}%
        {{hash=370d19824818ff77df0edac5f5f57ee6}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Kaijie},
           giveni={K\bibinitperiod}}}%
        {{hash=ac04bd00a003f7c5bed63f9b75fa0c88}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{5699ee09d4879be6cf4137987c6d4353}
      \strng{fullhash}{ffb0758bcb28bd757354e514c7d7a64f}
      \strng{bibnamehash}{5699ee09d4879be6cf4137987c6d4353}
      \strng{authorbibnamehash}{5699ee09d4879be6cf4137987c6d4353}
      \strng{authornamehash}{5699ee09d4879be6cf4137987c6d4353}
      \strng{authorfullhash}{ffb0758bcb28bd757354e514c7d7a64f}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Human behavior recognition is an effective way to realize natural human-computer interactions. Existing wireless sensing enabled gesture recognition technologies require a single person environment or an absolutely fixed position between the device and the user, which is not practical for daily use. In this paper, we present a non-contact radar-based gesture recognition system, named Gesture-Radar, which is able to capture arm gestures with low environmental dependence using a single Doppler radar. Our prototype design of Gesture-Radar is based on the dual channel Doppler information which contains specific Doppler shift and some other information reflected from the user while performing a certain gesture, and concretely we propose a two-stage classification method to identify arm gestures. Experimental result shows while in a single user environment, Gesture-Radar achieves up to 96.4\% average classification accuracy for recognizing 5 different kinds of gestures and can work effectively while the distance between the user and the radar is within 3 meters. We also demonstrate that Gesture-Radar can be well adapted to multi-person environments.}
      \field{booktitle}{2018 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})}
      \field{month}{10}
      \field{note}{ISSN: 2577-1655}
      \field{title}{Gesture-{Radar}: {Enabling} {Natural} {Human}-{Computer} {Interactions} with {Radar}-{Based} {Adaptive} and {Robust} {Arm} {Gesture} {Recognition}}
      \field{year}{2018}
      \field{pages}{4291\bibrangedash 4297}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1109/SMC.2018.00726
      \endverb
      \keyw{behavioural sciences computing,Conferences,Cybernetics,Doppler radar,Doppler shift,dual channel Doppler information,Dual channel information,gesture recognition,Gesture recognition,gesture recognition technologies,Gesture-Radar,human behavior recognition,human computer interaction,Humancomputer Interaction,image classification,natural human-computer interactions,noncontact radar-based gesture recognition system,radar-based adaptive recognition,robust arm Gesture recognition,two-stage classification method,wireless sensing,Wireless sensing}
    \endentry
    \entry{vanderMaaten:2009}{article}{}
      \name{author}{3}{}{%
        {{hash=47fbe2837893a84fb516e9e85ba7aa36}{%
           family={Maaten},
           familyi={M\bibinitperiod},
           given={Laurens},
           giveni={L\bibinitperiod},
           prefix={van\bibnamedelima der},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=42ac0ed20b82df7a89b9a9f44b0cfa07}{%
           family={Postma},
           familyi={P\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=c6572efc996949c5693e8faea9617576}{%
           family={Herik},
           familyi={H\bibinitperiod},
           given={Jaap},
           giveni={J\bibinitperiod},
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
      }
      \strng{namehash}{eab8feca8e185b9c53b13d60a74fad93}
      \strng{fullhash}{eab8feca8e185b9c53b13d60a74fad93}
      \strng{bibnamehash}{eab8feca8e185b9c53b13d60a74fad93}
      \strng{authorbibnamehash}{eab8feca8e185b9c53b13d60a74fad93}
      \strng{authornamehash}{eab8feca8e185b9c53b13d60a74fad93}
      \strng{authorfullhash}{eab8feca8e185b9c53b13d60a74fad93}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{month}{1}
      \field{title}{{Dimensionality Reduction: A Comparative Review}}
      \field{volume}{10}
      \field{year}{2009}
      \field{pages}{66\bibrangedash 71}
      \range{pages}{6}
      \verb{urlraw}
      \verb https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf
      \endverb
      \verb{url}
      \verb https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf
      \endverb
    \endentry
    \entry{Maghoumi:2019}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=c90fc658d0ad6672733c19d1db437678}{%
           family={Maghoumi},
           familyi={M\bibinitperiod},
           given={Mehran},
           giveni={M\bibinitperiod}}}%
        {{hash=ba77fe1a51bbe7ce7bccddc9627e2bfe}{%
           family={LaViola},
           familyi={L\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \name{editor}{12}{}{%
        {{hash=841fed534c8d9df7d15bb6bceffdd967}{%
           family={Bebis},
           familyi={B\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=306e1840f3e9ffde5f1a736befe3168f}{%
           family={Boyle},
           familyi={B\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=c302a205d04df281e26654b279b28108}{%
           family={Parvin},
           familyi={P\bibinitperiod},
           given={Bahram},
           giveni={B\bibinitperiod}}}%
        {{hash=f55ce36fbbd6713d96120f753a7df2b4}{%
           family={Koracin},
           familyi={K\bibinitperiod},
           given={Darko},
           giveni={D\bibinitperiod}}}%
        {{hash=ea8f76f9b3516c15dfe27819d825ae7b}{%
           family={Ushizima},
           familyi={U\bibinitperiod},
           given={Daniela},
           giveni={D\bibinitperiod}}}%
        {{hash=fa51b6aa4d536b9dc5560f04ead7ee86}{%
           family={Chai},
           familyi={C\bibinitperiod},
           given={Sek},
           giveni={S\bibinitperiod}}}%
        {{hash=675125cd30e1e77ce93e7c9bb7a97359}{%
           family={Sueda},
           familyi={S\bibinitperiod},
           given={Shinjiro},
           giveni={S\bibinitperiod}}}%
        {{hash=4009e963a9f7a218cfa1e91b974fefa0}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod}}}%
        {{hash=5637256da54aaaca5c0bc09382318d93}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Aidong},
           giveni={A\bibinitperiod}}}%
        {{hash=24f20de24938c18a3655f419579d0900}{%
           family={Thalmann},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=8b85f03ba7454732881a835a7999d7d5}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Chaoli},
           giveni={C\bibinitperiod}}}%
        {{hash=3da8d20aacc3473dbe2b1ad7ba82ccd1}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Panpan},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{fullhash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{bibnamehash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{authorbibnamehash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{authornamehash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{authorfullhash}{9f4150aded73e723fb6f26b5a23d0883}
      \strng{editorbibnamehash}{4488e2fe959aa0f239685415b32a561c}
      \strng{editornamehash}{4488e2fe959aa0f239685415b32a561c}
      \strng{editorfullhash}{814cbf72f0217470221dcdf71d2bbc7c}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose DeepGRU, a novel end-to-end deep network model informed by recent developments in deep learning for gesture and action recognition, that is streamlined and device-agnostic. DeepGRU, which uses only raw skeleton, pose or vector data is quickly understood, implemented, and trained, and yet achieves state-of-the-art results on challenging datasets. At the heart of our method lies a set of stacked gated recurrent units (GRU), two fully-connected layers and a novel global attention model. We evaluate our method on seven publicly available datasets, containing various number of samples and spanning over a broad range of interactions (full-body, multi-actor, hand gestures, etc.). In all but one case we outperform the state-of-the-art pose-based methods. For instance, we achieve a recognition accuracy of 84.9{\%} and 92.3{\%} on cross-subject and cross-view tests of the NTURGB+D dataset respectively, and also 100{\%} recognition accuracy on the UT-Kinect dataset. We show that even in the absence of powerful hardware, or a large amount of training data, and with as little as four samples per class, DeepGRU can be trained in under 10min while beating traditional methods specifically designed for small training sets, making it an enticing choice for rapid application prototyping and development.}
      \field{booktitle}{Advances in Visual Computing}
      \field{isbn}{978-3-030-33720-9}
      \field{title}{DeepGRU: Deep Gesture Recognition Utility}
      \field{year}{2019}
      \field{pages}{16\bibrangedash 31}
      \range{pages}{16}
    \endentry
    \entry{Magrofuoco:2021}{article}{}
      \name{author}{3}{}{%
        {{hash=fa01b7ea0d6587d21e78591bd3ea6825}{%
           family={Magrofuoco},
           familyi={M\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=f822d8f741e1aed7d9b7872fe72da592}{%
           family={Roselli},
           familyi={R\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{ee0d751531ccf718c18da2a2251858b0}
      \strng{fullhash}{ee0d751531ccf718c18da2a2251858b0}
      \strng{bibnamehash}{ee0d751531ccf718c18da2a2251858b0}
      \strng{authorbibnamehash}{ee0d751531ccf718c18da2a2251858b0}
      \strng{authornamehash}{ee0d751531ccf718c18da2a2251858b0}
      \strng{authorfullhash}{ee0d751531ccf718c18da2a2251858b0}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The expansion of touch-sensitive technologies, ranging from smartwatches to wall screens, triggered a wider use of gesture-based user interfaces and encouraged researchers to invent recognizers that are fast and accurate for end-users while being simple enough for practitioners. Since the pioneering work on two-dimensional (2D) stroke gesture recognition based on feature extraction and classification, numerous approaches and techniques have been introduced to classify uni- and multi-stroke gestures, satisfying various properties of articulation-, rotation-, scale-, and translation-invariance. As the domain abounds in different recognizers, it becomes difficult for the practitioner to choose the right recognizer, depending on the application and for the researcher to understand the state-of-the-art. To address these needs, a targeted literature review identified 16 significant 2D stroke gesture recognizers that were submitted to a descriptive analysis discussing their algorithm, performance, and properties, and a comparative analysis discussing their similarities and differences. Finally, some opportunities for expanding 2D stroke gesture recognition are drawn from these analyses.}
      \field{issn}{0360-0300}
      \field{journaltitle}{ACM Comput. Surv.}
      \field{month}{7}
      \field{number}{7}
      \field{title}{{Two-Dimensional Stroke Gesture Recognition: A Survey}}
      \field{volume}{54}
      \field{year}{2021}
      \verb{doi}
      \verb 10.1145/3465400
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3465400
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3465400
      \endverb
      \keyw{Gesture-based interfaces,stroke gestures,gesture recognition,touch gestures}
    \endentry
    \entry{Magrofuoco:2019a}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=fa01b7ea0d6587d21e78591bd3ea6825}{%
           family={Magrofuoco},
           familyi={M\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=f822d8f741e1aed7d9b7872fe72da592}{%
           family={Roselli},
           familyi={R\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=684d5d4196dce70788bcfc1098df0c34}{%
           family={Pérez-Medina},
           familyi={P\bibinithyphendelim M\bibinitperiod},
           given={Jorge\bibnamedelima Luis},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{3f31f879ef7e8ae5d10afd3ef51761d7}
      \strng{fullhash}{5f4bfca133cc2bd35ebc8281f5d85086}
      \strng{bibnamehash}{3f31f879ef7e8ae5d10afd3ef51761d7}
      \strng{authorbibnamehash}{3f31f879ef7e8ae5d10afd3ef51761d7}
      \strng{authornamehash}{3f31f879ef7e8ae5d10afd3ef51761d7}
      \strng{authorfullhash}{5f4bfca133cc2bd35ebc8281f5d85086}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce GestMan, a cloud-based GESTure MANagement tool to support the acquisition, design, and management of stroke-gesture datasets for interactive applications. GestMan stores stroke-gestures at multiple levels of representation, from individual samples to classes, clusters, and vocabularies and enables practitioners to process, analyze, classify, compile, and reconfigure sets of gesture commands according to the specific requirements of their applications, prototypes, and interactive systems. Our online tool enables acquisition of 2-D stroke-gestures via a HTML5-based user interface as well as 3-D touch+air and webcam-based gestures via dedicated mappers. GestMan implements five software quality characteristics of the ISO-25010 standard and employs a new mathematical formalization of stroke-gestures as vectors to support efficient computation of various gesture features.}
      \field{booktitle}{Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems}
      \field{isbn}{9781450367455}
      \field{series}{EICS '19}
      \field{title}{{GestMan: A Cloud-Based Tool for Stroke-Gesture Datasets}}
      \field{venue}{Valencia, Spain}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1145/3319499.3328227
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3319499.3328227
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3319499.3328227
      \endverb
      \keyw{stroke-gestures,cloud computing,isoparameterization,gesture sets,gesture data management,tool,isometricity,isochronicity}
    \endentry
    \entry{Malysa:2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=f3a5de67bb8642c59c975f5a9e79a988}{%
           family={Malysa},
           familyi={M\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod}}}%
        {{hash=50e578209e59a4d498fdb91091525255}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
        {{hash=93bbc3506f7e14ed53939fe5bfdb6a25}{%
           family={Netsch},
           familyi={N\bibinitperiod},
           given={Lorin},
           giveni={L\bibinitperiod}}}%
        {{hash=a0dd43ca371380a5c2dbd8d62ec71030}{%
           family={Ali},
           familyi={A\bibinitperiod},
           given={Murtaza},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{0f1dc893a03780cb32f693e824238b10}
      \strng{fullhash}{598d5d43ae56c5af716ed30eeed343ca}
      \strng{bibnamehash}{0f1dc893a03780cb32f693e824238b10}
      \strng{authorbibnamehash}{0f1dc893a03780cb32f693e824238b10}
      \strng{authornamehash}{0f1dc893a03780cb32f693e824238b10}
      \strng{authorfullhash}{598d5d43ae56c5af716ed30eeed343ca}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we present experimental results for the development of a gesture recognition system using a 77 GHz FMCW radar system. We measure the micro-Doppler signature of a gesturing hand to construct an energy distribution in velocity space over time. A gesturing hand is fundamentally a dynamical system with unobservable “state” (i.e. the name of the gesture) which determines the sequence of associated observable velocity-energy distributions, so a Hidden Markov Model is used to for gesture recognition, a more tailored approach than the SVM classifiers used in previous work. We also describe a method for reducing the length of our feature vectors by a factor of 12 without hurting the recognition performance, by reparameterizing them in terms of a sum of Gaussians.}
      \field{booktitle}{2016 {IEEE} {Global} {Conference} on {Signal} and {Information} {Processing} ({GlobalSIP})}
      \field{month}{12}
      \field{title}{Hidden {Markov} model-based gesture recognition with {FMCW} radar}
      \field{year}{2016}
      \field{pages}{1017\bibrangedash 1021}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/GlobalSIP.2016.7905995
      \endverb
      \keyw{associated observable velocity-energy distribution,Chirp,CW radar,Feature extraction,FM radar,FMCW radar system,Gaussian sum,gesture recognition,Gesture recognition,gesturing hand,hidden Markov model-based gesture recognition,hidden Markov models,Hidden Markov models,microDoppler signature,millimeter wave radar,radar computing,radar imaging,Radar imaging,support vector machines,SVM classifiers,Training,unobservable state}
    \endentry
    \entry{Mapari:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=237fee5eaa16851aa3c5d8869e5f560a}{%
           family={Mapari},
           familyi={M\bibinitperiod},
           given={Rajesh\bibnamedelima B.},
           giveni={R\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=0bb999dcf8e9245109a4e4808473b65d}{%
           family={Kharat},
           familyi={K\bibinitperiod},
           given={Govind},
           giveni={G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{86a8f5baaf86a4423188aa32bda21f45}
      \strng{fullhash}{86a8f5baaf86a4423188aa32bda21f45}
      \strng{bibnamehash}{86a8f5baaf86a4423188aa32bda21f45}
      \strng{authorbibnamehash}{86a8f5baaf86a4423188aa32bda21f45}
      \strng{authornamehash}{86a8f5baaf86a4423188aa32bda21f45}
      \strng{authorfullhash}{86a8f5baaf86a4423188aa32bda21f45}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proc. of the Second International Conference on Information and Communication Technology for Competitive Strategies}
      \field{isbn}{9781450339629}
      \field{series}{ICTCS '16}
      \field{title}{{American Static Signs Recognition Using Leap Motion Sensor}}
      \field{venue}{Udaipur, India}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1145/2905055.2905125
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2905055.2905125
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2905055.2905125
      \endverb
      \keyw{Leap Motion Sensor,MLP,ASL}
    \endentry
    \entry{Marin:2016}{article}{}
      \name{author}{3}{}{%
        {{hash=ff62ecf7eb8f0795ddd86aa1ce8044e5}{%
           family={Marin},
           familyi={M\bibinitperiod},
           given={Giulio},
           giveni={G\bibinitperiod}}}%
        {{hash=c8290ea9b1725747a20c9c4bcd26c437}{%
           family={Dominio},
           familyi={D\bibinitperiod},
           given={Fabio},
           giveni={F\bibinitperiod}}}%
        {{hash=e18106b8323e7ea91c3e008c278cc843}{%
           family={Zanuttigh},
           familyi={Z\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{5eb914ed06095c515e90c906dc101237}
      \strng{fullhash}{5eb914ed06095c515e90c906dc101237}
      \strng{bibnamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authorbibnamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authornamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authorfullhash}{5eb914ed06095c515e90c906dc101237}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{11}
      \field{number}{22}
      \field{title}{{Hand Gesture Recognition with Jointly Calibrated Leap Motion and Depth Sensor}}
      \field{volume}{75}
      \field{year}{2016}
      \field{pages}{14991\bibrangedash 15015}
      \range{pages}{25}
      \verb{doi}
      \verb 10.1007/s11042-015-2451-6
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11042-015-2451-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11042-015-2451-6
      \endverb
      \keyw{Calibration,Kinect,Gesture recognition,SVM,Depth,Leap Motion}
    \endentry
    \entry{Marin:2014}{article}{}
      \name{author}{3}{}{%
        {{hash=ff62ecf7eb8f0795ddd86aa1ce8044e5}{%
           family={Marin},
           familyi={M\bibinitperiod},
           given={Giulio},
           giveni={G\bibinitperiod}}}%
        {{hash=c8290ea9b1725747a20c9c4bcd26c437}{%
           family={Dominio},
           familyi={D\bibinitperiod},
           given={Fabio},
           giveni={F\bibinitperiod}}}%
        {{hash=e18106b8323e7ea91c3e008c278cc843}{%
           family={Zanuttigh},
           familyi={Z\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{5eb914ed06095c515e90c906dc101237}
      \strng{fullhash}{5eb914ed06095c515e90c906dc101237}
      \strng{bibnamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authorbibnamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authornamehash}{5eb914ed06095c515e90c906dc101237}
      \strng{authorfullhash}{5eb914ed06095c515e90c906dc101237}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{2014 IEEE International Conference on Image Processing, ICIP 2014}
      \field{title}{{Hand gesture recognition with Leap Motion and Kinect devices}}
      \field{year}{2014}
      \field{pages}{1565\bibrangedash 1569}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICIP.2014.7025313
      \endverb
    \endentry
    \entry{Marquardt:1963}{article}{}
      \name{author}{1}{}{%
        {{hash=a028cbf46bc69c4cff5800c4c8030f09}{%
           family={Marquardt},
           familyi={M\bibinitperiod},
           given={Donald\bibnamedelima W.},
           giveni={D\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \strng{namehash}{a028cbf46bc69c4cff5800c4c8030f09}
      \strng{fullhash}{a028cbf46bc69c4cff5800c4c8030f09}
      \strng{bibnamehash}{a028cbf46bc69c4cff5800c4c8030f09}
      \strng{authorbibnamehash}{a028cbf46bc69c4cff5800c4c8030f09}
      \strng{authornamehash}{a028cbf46bc69c4cff5800c4c8030f09}
      \strng{authorfullhash}{a028cbf46bc69c4cff5800c4c8030f09}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of the Society for Industrial and Applied Mathematics}
      \field{number}{2}
      \field{title}{{An Algorithm for Least-Squares Estimation of Nonlinear Parameters}}
      \field{volume}{11}
      \field{year}{1963}
      \field{pages}{431\bibrangedash 441}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1137/0111030
      \endverb
      \verb{eprint}
      \verb https://doi.org/10.1137/0111030
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1137/0111030
      \endverb
      \verb{url}
      \verb https://doi.org/10.1137/0111030
      \endverb
    \endentry
    \entry{Mcintosh:2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=9be407a207b02a3141bcf6a503b9c77d}{%
           family={McIntosh},
           familyi={M\bibinitperiod},
           given={Jess},
           giveni={J\bibinitperiod}}}%
        {{hash=f94c0b4c479e5b726a4fbf7cda0f648c}{%
           family={Fraser},
           familyi={F\bibinitperiod},
           given={Mike},
           giveni={M\bibinitperiod}}}%
        {{hash=e26fefe3bddfb6169bc8b8d4db0951bc}{%
           family={Worgan},
           familyi={W\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=c374e91883c876e70ed58f65a3e59ea0}{%
           family={Marzo},
           familyi={M\bibinitperiod},
           given={Asier},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6ed033c977437bad493f362549e82739}
      \strng{fullhash}{8b79e9e400175982104f80a0ebda5e43}
      \strng{bibnamehash}{6ed033c977437bad493f362549e82739}
      \strng{authorbibnamehash}{6ed033c977437bad493f362549e82739}
      \strng{authornamehash}{6ed033c977437bad493f362549e82739}
      \strng{authorfullhash}{8b79e9e400175982104f80a0ebda5e43}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Microwaves are a type of electromagnetic radiation that can pass through a variety of commonly found materials but partially reflect off human bodies. Microwaves are non-ionizing and at controlled levels do not pose a danger. A wave that is capable of passing through materials and image humans could have useful applications in human-computer-interaction. However, only recently the full potential of microwaves for interactive devices has begun to be explored. Here, we present a scalable, low-cost system using an array of off-the-shelf microwave Doppler sensors and explore its potential for tabletop interactions. The arrays are installed beneath a desk, making it an ubiquitous device that enables a wide range of interactions such as 3D hand tracking, gesture recognition and different forms of tangible interaction. Given the low cost and availability of these sensors, we expect that this work will stimulate future interactive devices that employ microwave sensors.}
      \field{booktitle}{Proceedings of the 2017 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}}
      \field{isbn}{978-1-4503-4656-6}
      \field{month}{5}
      \field{series}{{CHI} {EA} '17}
      \field{shorttitle}{{DeskWave}}
      \field{title}{{DeskWave}: {Desktop} {Interactions} using {Low}-cost {Microwave} {Doppler} {Arrays}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{1885\bibrangedash 1892}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/3027063.3053152
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3027063.3053152
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3027063.3053152
      \endverb
      \keyw{3D tracking,gesture recognition,microwave sensors,tabletops,wireless power transfer}
    \endentry
    \entry{McNeill:1995}{article}{}
      \name{author}{1}{}{%
        {{hash=3ccf5b8aeb22bbe688614d1e72c13c21}{%
           family={McNeill},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \strng{fullhash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \strng{bibnamehash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \strng{authorbibnamehash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \strng{authornamehash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \strng{authorfullhash}{3ccf5b8aeb22bbe688614d1e72c13c21}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{The University of Chicago Press}
      \field{title}{{Hand and Mind: What Gestures Reveal About Thought}}
      \field{volume}{27}
      \field{year}{1995}
      \verb{doi}
      \verb 10.2307/1576015
      \endverb
    \endentry
    \entry{Mendez:2018}{article}{}
      \name{author}{4}{}{%
        {{hash=a76cdfaaf6d74dd67f341a0f82653098}{%
           family={Méndez},
           familyi={M\bibinitperiod},
           given={Roi},
           giveni={R\bibinitperiod}}}%
        {{hash=7cdaa1cef56fe3eb6f426cd3f4194d79}{%
           family={Flores},
           familyi={F\bibinitperiod},
           given={Julián},
           giveni={J\bibinitperiod}}}%
        {{hash=d9ca747a1da31f96305595fa670ea431}{%
           family={Castelló},
           familyi={C\bibinitperiod},
           given={Enrique},
           giveni={E\bibinitperiod}}}%
        {{hash=51aca79ff4ed299e3a67b6f167875462}{%
           family={Viqueira},
           familyi={V\bibinitperiod},
           given={José\bibnamedelima Ramón},
           giveni={J\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{70760147736b1b935b6448afee4da123}
      \strng{fullhash}{fff3206e211272b79bc4f0680ebafd65}
      \strng{bibnamehash}{70760147736b1b935b6448afee4da123}
      \strng{authorbibnamehash}{70760147736b1b935b6448afee4da123}
      \strng{authornamehash}{70760147736b1b935b6448afee4da123}
      \strng{authorfullhash}{fff3206e211272b79bc4f0680ebafd65}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{8}
      \field{number}{15}
      \field{title}{{New Distributed Virtual TV Set Architecture for a Synergistic Operation of Sensors and Improved Interaction between Real and Virtual Worlds}}
      \field{volume}{77}
      \field{year}{2018}
      \field{pages}{18999\bibrangedash 19025}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1007/s11042-017-5353-y
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11042-017-5353-y
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11042-017-5353-y
      \endverb
      \keyw{Human computer interaction,Virtual reality,TV broadcasting,Virtual TV sets,TV}
    \endentry
    \entry{Michalski:1990}{article}{}
      \name{author}{2}{}{%
        {{hash=7e4e4bcdd18a83625ce4a13ac357deeb}{%
           family={Michalski},
           familyi={M\bibinitperiod},
           given={Krzysztof\bibnamedelima A.},
           giveni={K\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=9e08797784e1f5ec9f1c0514e13a1753}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Dalian},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{4b31ad588ad56b901f2c1a9813c272a0}
      \strng{fullhash}{4b31ad588ad56b901f2c1a9813c272a0}
      \strng{bibnamehash}{4b31ad588ad56b901f2c1a9813c272a0}
      \strng{authorbibnamehash}{4b31ad588ad56b901f2c1a9813c272a0}
      \strng{authornamehash}{4b31ad588ad56b901f2c1a9813c272a0}
      \strng{authorfullhash}{4b31ad588ad56b901f2c1a9813c272a0}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Antennas and Propagation}
      \field{title}{{Electromagnetic scattering and radiation by subsurfaces of arbitrary shape in layered media: Parts I and II}}
      \field{volume}{38}
      \field{year}{1990}
      \field{pages}{335\bibrangedash 352}
      \range{pages}{18}
    \endentry
    \entry{Miller:2020}{article}{}
      \name{author}{6}{}{%
        {{hash=faac851ed1d889d89e2e4112fee87c4f}{%
           family={Miller},
           familyi={M\bibinitperiod},
           given={Elishiah},
           giveni={E\bibinitperiod}}}%
        {{hash=80c88b1c7cc92f9bcb33605a25e00dab}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=124b35dce7db547e0b930bf8cf6903fc}{%
           family={Mentis},
           familyi={M\bibinitperiod},
           given={Helena},
           giveni={H\bibinitperiod}}}%
        {{hash=04510bf0e1d07da397827947eef44f66}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
        {{hash=e93c42ce5f173b7986bddf7030aca3da}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Ting},
           giveni={T\bibinitperiod}}}%
        {{hash=589bcb9af6cd0063eee1ffbb86352277}{%
           family={Banerjee},
           familyi={B\bibinitperiod},
           given={Nilanjan},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{0242209f1c95d0bf6f2435e6c632ebdd}
      \strng{fullhash}{1905452734666fabab5f66edcaffacf3}
      \strng{bibnamehash}{0242209f1c95d0bf6f2435e6c632ebdd}
      \strng{authorbibnamehash}{0242209f1c95d0bf6f2435e6c632ebdd}
      \strng{authornamehash}{0242209f1c95d0bf6f2435e6c632ebdd}
      \strng{authorfullhash}{1905452734666fabab5f66edcaffacf3}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we show how surgeons can interact with medical images using finger and hand gestures in two situations: one hand-free and no hands-free interaction. We explain how interaction with only one hand or a couple of fingers is beneficial and can help surgeons have continuous interaction, without the need to release their tools and leave the operating table, saving valuable patient time. To this end, we present RadSense, an end-to-end and unobtrusive system that uses Doppler radar-sensing to recognize hand and finger gestures when either one or both hands are busy. Our system permits the following important capabilities: (1) touch-less input for sterile interaction with connected health applications, (2) hand and finger gesture recognition when either one or both hands are busy holding tools, extending multitasking capabilities for health professionals, and (3) mobile and networked, allowing for custom wearable and non-wearable configurations. We evaluated our system in a simulated operating room to manipulate preoperative images using four gestures: circle, double tap, swipe, and finger click. We collected data from five subjects and trained a K-Nearest-Neighbor multi-class classifier using 15-fold cross validation, achieving a 94.5\% precision for gesture classification. We conclude that our system performs with high accuracy and is useful in cases where only one hand or a few fingers are free to interact when the hands are busy.}
      \field{issn}{2352-6483}
      \field{journaltitle}{Smart Health}
      \field{title}{{RadSense}: {Enabling} one hand and no hands interaction for sterile manipulation of medical images using {Doppler} radar}
      \field{volume}{15}
      \field{year}{2020}
      \field{pages}{100089}
      \range{pages}{1}
      \verb{doi}
      \verb https://doi.org/10.1016/j.smhl.2019.100089
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S2352648319300534
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S2352648319300534
      \endverb
      \keyw{Busy hand interaction,Gesture recognition,Healthcare,Human centered computing,Wearable devices}
    \endentry
    \entry{Moinnet:2022}{thesis}{}
      \name{author}{2}{}{%
        {{hash=5c59f1d4ec335dd0d1f3936563809421}{%
           family={Moinnet},
           familyi={M\bibinitperiod},
           given={Adrien},
           giveni={A\bibinitperiod}}}%
        {{hash=38ff19e6c5ba838d872effe94b390885}{%
           family={Gosselin},
           familyi={G\bibinitperiod},
           given={Benoît},
           giveni={B\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{b58de9a6377b6f8460eca98b5afe1bef}
      \strng{fullhash}{b58de9a6377b6f8460eca98b5afe1bef}
      \strng{bibnamehash}{b58de9a6377b6f8460eca98b5afe1bef}
      \strng{authorbibnamehash}{b58de9a6377b6f8460eca98b5afe1bef}
      \strng{authornamehash}{b58de9a6377b6f8460eca98b5afe1bef}
      \strng{authorfullhash}{b58de9a6377b6f8460eca98b5afe1bef}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{For a long time, the main technique for executing a command has been point and click. However, due to the increasing need to execute commands quickly, shortcuts are becoming more and more popular, as is the case with point and click. Many studies have improved the shortcut system by developing 2D shortcuts. Unfortunately, keyboard shortcuts and 2D shortcuts involve a one-to-one gesture-command mapping. This leads to many memorability problems which are mainly because it is necessary to assign a new gesture to each new command and also, after a certain number of shortcuts, some gestures become more and more abstract. To address this issue, we decided to explore the concept of combining 2D gestures when interacting in smart environments. To achieve this, we have created an application allowing to realize shortcuts using macro-commands or a combination of 2D gestures which are congruent and hierarchic. This application will aim to visualize interactions with connected objects in a smart environment named EMERITI. To better understand the EMERITI environment, we will detail its grammatical structure, its functioning, and its advantages.}
      \field{title}{{Composition of strokes gestures into system instructions}}
      \field{type}{phdthesis}
      \field{year}{2022}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:37872
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:37872
      \endverb
      \keyw{EMERITI,Instructions,Strokes Gestures,QuantumLeap,Recognizer,$P+,Combination of gestures,2D shortcut,Smart environment}
    \endentry
    \entry{Molchanov:2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=8ac65f0c6a6050a1bdbe904e1f4a1cf9}{%
           family={Molchanov},
           familyi={M\bibinitperiod},
           given={Pavlo},
           giveni={P\bibinitperiod}}}%
        {{hash=fde76ab23544e4e1bf0c0f4ab32ac833}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Shalini},
           giveni={S\bibinitperiod}}}%
        {{hash=7cbc691b0743a71b8a8d6c557b3b931b}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Kihwan},
           giveni={K\bibinitperiod}}}%
        {{hash=e427a227c39ff15e725716775899bd4f}{%
           family={Pulli},
           familyi={P\bibinitperiod},
           given={Kari},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{055d297369a35d168e27eaaedf364f12}
      \strng{fullhash}{28a83258a414a684592a1a1eb6cc9a96}
      \strng{bibnamehash}{055d297369a35d168e27eaaedf364f12}
      \strng{authorbibnamehash}{055d297369a35d168e27eaaedf364f12}
      \strng{authornamehash}{055d297369a35d168e27eaaedf364f12}
      \strng{authorfullhash}{28a83258a414a684592a1a1eb6cc9a96}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a novel multi-sensor system for accurate and power-efficient dynamic car-driver hand-gesture recognition, using a short-range radar, a color camera, and a depth camera, which together make the system robust against variable lighting conditions. We present a procedure to jointly calibrate the radar and depth sensors. We employ convolutional deep neural networks to fuse data from multiple sensors and to classify the gestures. Our algorithm accurately recognizes 10 different gestures acquired indoors and outdoors in a car during the day and at night. It consumes significantly less power than purely vision-based systems.}
      \field{booktitle}{2015 11th {IEEE} {International} {Conference} and {Workshops} on {Automatic} {Face} and {Gesture} {Recognition} ({FG})}
      \field{month}{5}
      \field{title}{{Multi-sensor system for driver's hand-gesture recognition}}
      \field{volume}{1}
      \field{year}{2015}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/FG.2015.7163132
      \endverb
      \keyw{Cameras,car-driver hand-gesture recognition,color camera,convolutional deep neural networks,data fusion,depth camera,depth sensors,gesture classification,gesture recognition,Gesture recognition,image classification,Image color analysis,multisensor system,neural nets,radar,Radar imaging,sensor fusion,Sensor systems,short-range radar,traffic engineering computing}
    \endentry
    \entry{Morris:2012}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=5283a53c5c081c04252a659743f886e1}{%
           family={Morris},
           familyi={M\bibinitperiod},
           given={Meredith\bibnamedelima Ringel},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{5283a53c5c081c04252a659743f886e1}
      \strng{fullhash}{5283a53c5c081c04252a659743f886e1}
      \strng{bibnamehash}{5283a53c5c081c04252a659743f886e1}
      \strng{authorbibnamehash}{5283a53c5c081c04252a659743f886e1}
      \strng{authornamehash}{5283a53c5c081c04252a659743f886e1}
      \strng{authorfullhash}{5283a53c5c081c04252a659743f886e1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{New sensing technologies like Microsoft's Kinect provide a low-cost way to add interactivity to large display surfaces, such as TVs. In this paper, we interview 25 participants to learn about scenarios in which they would like to use a web browser on their living room TV. We then conduct an interaction-elicitation study in which users suggested speech and gesture interactions for fifteen common web browser functions. We present the most popular suggested interactions, and supplement these findings with observational analyses of common gesture and speech conventions adopted by our participants. We also reflect on the design of multimodal, multi-user interaction-elicitation studies, and introduce new metrics for interpreting user-elicitation study findings.}
      \field{booktitle}{Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces}
      \field{isbn}{9781450312097}
      \field{series}{ITS '12}
      \field{title}{{Web on the Wall: Insights from a Multimodal Interaction Elicitation Study}}
      \field{venue}{Cambridge, Massachusetts, USA}
      \field{year}{2012}
      \field{pages}{95\bibrangedash 104}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2396636.2396651
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2396636.2396651
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2396636.2396651
      \endverb
      \keyw{user-defined gestures,gestures,web browsers,participatory design,speech,interactive walls,multimodal input}
    \endentry
    \entry{Morris:2010}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=5283a53c5c081c04252a659743f886e1}{%
           family={Morris},
           familyi={M\bibinitperiod},
           given={Meredith\bibnamedelima Ringel},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=44a173a4c0ff442bac216e39b38cfc82}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Andrew\bibnamedelima D.},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {CAN}%
      }
      \list{publisher}{1}{%
        {Canadian Information Processing Society}%
      }
      \strng{namehash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \strng{fullhash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \strng{bibnamehash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \strng{authorbibnamehash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \strng{authornamehash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \strng{authorfullhash}{0eea9d16f0e62d7d8fd9134ef1c0224f}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We compare two gesture sets for interactive surfaces---a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures' authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.}
      \field{booktitle}{Proceedings of Graphics Interface 2010}
      \field{isbn}{9781568817125}
      \field{series}{GI '10}
      \field{title}{{Understanding Users' Preferences for Surface Gestures}}
      \field{venue}{Ottawa, Ontario, Canada}
      \field{year}{2010}
      \field{pages}{261\bibrangedash 268}
      \range{pages}{8}
      \keyw{interactive tabletops,surface computing,gestures}
    \endentry
    \entry{Munroe:2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=8eb439b21961c8038b5ac57dd4bb354f}{%
           family={Munroe},
           familyi={M\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=1cbb5d013d1f5650e76fd4ffd7a67a75}{%
           family={Meng},
           familyi={M\bibinitperiod},
           given={Yuanliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=37603763b153321ac76a88a9d9ec67ed}{%
           family={Yanco},
           familyi={Y\bibinitperiod},
           given={Holly},
           giveni={H\bibinitperiod}}}%
        {{hash=e89546ba4a2aa31508581677d1e1b7c9}{%
           family={Begum},
           familyi={B\bibinitperiod},
           given={Momotaz},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{8a8ea194506db33467b93facff3c7bd5}
      \strng{fullhash}{fa97c2fc985b3c1d9d44def260d11ab3}
      \strng{bibnamehash}{8a8ea194506db33467b93facff3c7bd5}
      \strng{authorbibnamehash}{8a8ea194506db33467b93facff3c7bd5}
      \strng{authornamehash}{8a8ea194506db33467b93facff3c7bd5}
      \strng{authorfullhash}{fa97c2fc985b3c1d9d44def260d11ab3}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}
      \field{title}{{Augmented reality eyeglasses for promoting home-based rehabilitation for children with cerebral palsy}}
      \field{year}{2016}
      \field{pages}{565\bibrangedash 565}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1109/HRI.2016.7451858
      \endverb
      \keyw{Glass;Electromyography;Augmented reality;Electronic mail;Games;Accelerometers}
    \endentry
    \entry{Nacenta:2013}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=f483c1ba76e286def20f9438b4b6ba7c}{%
           family={Nacenta},
           familyi={N\bibinitperiod},
           given={Miguel\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=6fd48e7216f2d1a7c1a8626ae71b82fa}{%
           family={Kamber},
           familyi={K\bibinitperiod},
           given={Yemliha},
           giveni={Y\bibinitperiod}}}%
        {{hash=fd7a369c237f4519fdc46fd4d2bd2fc8}{%
           family={Qiang},
           familyi={Q\bibinitperiod},
           given={Yizhou},
           giveni={Y\bibinitperiod}}}%
        {{hash=db3b6a3624f37d3c580dff8ae2a9c807}{%
           family={Kristensson},
           familyi={K\bibinitperiod},
           given={Per\bibnamedelima Ola},
           giveni={P\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{9a60c26393172ad28a4fcbeb7435390f}
      \strng{fullhash}{e38eddb81fca954ac7b3dcd64c01ec25}
      \strng{bibnamehash}{9a60c26393172ad28a4fcbeb7435390f}
      \strng{authorbibnamehash}{9a60c26393172ad28a4fcbeb7435390f}
      \strng{authornamehash}{9a60c26393172ad28a4fcbeb7435390f}
      \strng{authorfullhash}{e38eddb81fca954ac7b3dcd64c01ec25}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24\% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450318990}
      \field{series}{CHI '13}
      \field{title}{{Memorability of Pre-Designed and User-Defined Gesture Sets}}
      \field{venue}{Paris, France}
      \field{year}{2013}
      \field{pages}{1099\bibrangedash 1108}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2470654.2466142
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2470654.2466142
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2470654.2466142
      \endverb
      \keyw{gesture memorability,gesture sets,user-defined gestures}
    \endentry
    \entry{Nancel:2011}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=381e4495f0601024537a44d371cc5716}{%
           family={Nancel},
           familyi={N\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
        {{hash=9c50391dfae95d794c4ce6ab452ad4af}{%
           family={Wagner},
           familyi={W\bibinitperiod},
           given={Julie},
           giveni={J\bibinitperiod}}}%
        {{hash=1cde187bb8bd61391ee694bf2e686ad0}{%
           family={Pietriga},
           familyi={P\bibinitperiod},
           given={Emmanuel},
           giveni={E\bibinitperiod}}}%
        {{hash=e51fdfe8a946a726b9ee900a23d47866}{%
           family={Chapuis},
           familyi={C\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
        {{hash=d47b1c860fcb37dc66f5f35e0de02865}{%
           family={Mackay},
           familyi={M\bibinitperiod},
           given={Wendy},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b782d7b9bb5daab4839f503c2b4d5298}
      \strng{fullhash}{cd93eb7e029667d54d6a34ff8981ee9a}
      \strng{bibnamehash}{b782d7b9bb5daab4839f503c2b4d5298}
      \strng{authorbibnamehash}{b782d7b9bb5daab4839f503c2b4d5298}
      \strng{authornamehash}{b782d7b9bb5daab4839f503c2b4d5298}
      \strng{authorfullhash}{cd93eb7e029667d54d6a34ff8981ee9a}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Very-high-resolution wall-sized displays offer new opportunities for interacting with large data sets. While pointing on this type of display has been studied extensively, higher-level, more complex tasks such as pan-zoom navigation have received little attention. It thus remains unclear which techniques are best suited to perform multiscale navigation in these environments. Building upon empirical data gathered from studies of pan-and-zoom on desktop computers and studies of remote pointing, we identified three key factors for the design of mid-air pan-and-zoom techniques: uni- vs. bimanual interaction, linear vs. circular movements, and level of guidance to accomplish the gestures in mid-air. After an extensive phase of iterative design and pilot testing, we ran a controlled experiment aimed at better understanding the influence of these factors on task performance. Significant effects were obtained for all three factors: bimanual interaction, linear gestures and a high level of guidance resulted in significantly improved performance. Moreover, the interaction effects among some of the dimensions suggest possible combinations for more complex, real-world tasks.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450302289}
      \field{series}{CHI '11}
      \field{title}{{Mid-Air Pan-and-Zoom on Wall-Sized Displays}}
      \field{venue}{Vancouver, BC, Canada}
      \field{year}{2011}
      \field{pages}{177\bibrangedash 186}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1978942.1978969
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1978942.1978969
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1978942.1978969
      \endverb
      \keyw{pan \& zoom,navigation,wall-sized displays,multi-scale interfaces,mid-air interaction techniques}
    \endentry
    \entry{Neuville:2021}{thesis}{}
      \name{author}{1}{}{%
        {{hash=d4f23bdfb242f82843cf6ea6c3233c68}{%
           family={Neuville},
           familyi={N\bibinitperiod},
           given={Romain},
           giveni={R\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \strng{fullhash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \strng{bibnamehash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \strng{authorbibnamehash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \strng{authornamehash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \strng{authorfullhash}{d4f23bdfb242f82843cf6ea6c3233c68}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Human Computer Interaction became omnipresent in recent years, especially gesture recognition. Thanks to major advances in machine learning, gesture recognition has become an everyday tool. Currently, almost everybody has mastered 2D gestures with the use of smartphones. However, limits of these 2D gestures have emerged which has led researchers to focus on 3D gesture recognition. These two types of gesture enable to create Air+Touch recognition. It simply consists in an environment where gestures can be 2D or 3D. We have decided to deal with Air+Touch gesture recognition for this thesis. There is a clear lack of research on this subject. A problem related to this lack is that devices that can sense and retrieve data for the two types of gestures, are quite rare. The 3DTouchpad device can sense Air+Touch gestures. Therefore, we can build our own gestures set based on this device and on all the Air+Touch gestures gathered from the literature. Once it was defined, we integrated the 3DTouchpad inside the QuantumLeap framework where we tested all their different recognizers to see which one fits the best with Air+Touch gestures. Each test was performed according to two scenarios: User-Independent, User-Dependent. We also analyzed two gestures elicitation studies based on the 3DTouchpad to confirm that our Air+Touch assumptions were corresponding to 60 participants feelings. To conclude, we are going to discuss about the benefits and contributions of our work before suggesting some future promising works.}
      \field{title}{{Air+Touch gesture recognition : algorithms, software, and experiment}}
      \field{type}{phdthesis}
      \field{year}{2021}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:33024
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:33024
      \endverb
      \keyw{HCI,Gesture recognition,Air+Touch gesture recognition,3DTouchpad,Gesture elicitation study,QuantumLeap}
    \endentry
    \entry{Nguyen:2018a}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=470f6725aaea5800190011ce7683af55}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Minh\bibnamedelima Q.},
           giveni={M\bibinitperiod\bibinitdelim Q\bibinitperiod}}}%
        {{hash=ba5e9ba371f6475275c608356b0ca4fa}{%
           family={Flores-Nigaglioni},
           familyi={F\bibinithyphendelim N\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod}}}%
        {{hash=67e9c36fef6ea4addab61a305213f659}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Changzhi},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{9e712d14d54c102ea4f69e9e2530be3a}
      \strng{fullhash}{9e712d14d54c102ea4f69e9e2530be3a}
      \strng{bibnamehash}{9e712d14d54c102ea4f69e9e2530be3a}
      \strng{authorbibnamehash}{9e712d14d54c102ea4f69e9e2530be3a}
      \strng{authornamehash}{9e712d14d54c102ea4f69e9e2530be3a}
      \strng{authorfullhash}{9e712d14d54c102ea4f69e9e2530be3a}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Touchless hand gesture using portable millimeter-wave radar sensors an enabling technology for Internet of Things (IoT) applications. In this paper, we investigate the feasibility of using a frequency modulated continuous wave (FMCW) radar with noise removal and range gating method to recognize human hand gesture for a user moving in the radar's field of view. These detected hand gestures will be applied to remote control of computers or smart TVs at a distance from 0.3 m to 1.2 m.}
      \field{booktitle}{2018 {IEEE} {MTT}-{S} {International} {Wireless} {Symposium} ({IWS})}
      \field{month}{5}
      \field{title}{{Range-gating technology for millimeter-wave radar remote gesture control in {IoT} applications}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/IEEE-IWS.2018.8400811
      \endverb
      \keyw{CW radar,Doppler radar,Estimation,FM radar,FMCW radar,frequency modulated continuous wave radar,gesture recognition,Gesture recognition,human hand gesture,Internet of Things,Internet of Things applications,IoT applications,millimeter-wave radar remote gesture control,millimetre wave radar,noise removal,noise removal method,portable millimeter-wave radar sensors,Radar detection,range gating method,range-gating technology,Sensors,size 0.3 m to 1.2 m,touchless hand gesture,Touchless hand gesture}
    \endentry
    \entry{Nguyen:2018b}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=470f6725aaea5800190011ce7683af55}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Minh\bibnamedelima Q.},
           giveni={M\bibinitperiod\bibinitdelim Q\bibinitperiod}}}%
        {{hash=67e9c36fef6ea4addab61a305213f659}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Changzhi},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \strng{fullhash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \strng{bibnamehash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \strng{authorbibnamehash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \strng{authornamehash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \strng{authorfullhash}{e0bdae6ba438cb1e0ca13f9e456903c1}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Touchless hand gesture is one emerging technology for human computer interaction. In this paper, we investigate the feasibility of a hybrid system using frequency modulated continuous wave (FMCW) radar and ultrasound sensors with one transmitter and one receiver to detect hand movement for controlling a computer. Ultrasound will be used for near range application (1 cm to 30 cm) based on range estimation. FMCW radar, on the other hand, will be used for far range application (30 cm to 120 cm) based on range, velocity, and angle of arrival estimation. Leveraging these advantages of combining both ultrasound and FMCW radar will facilitate human hand for interacting computer with better performance.}
      \field{booktitle}{2018 {IEEE} {Radar} {Conference} ({RadarConf18})}
      \field{month}{4}
      \field{note}{ISSN: 2375-5318}
      \field{title}{{Radar and ultrasound hybrid system for human computer interaction}}
      \field{year}{2018}
      \field{pages}{1476\bibrangedash 1480}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/RADAR.2018.8378783
      \endverb
      \keyw{Angle of Arrival,angle of arrival estimation,Chirp,CW radar,direction-of-arrival estimation,Doppler effect,Estimation,FM radar,FMCW radar,FMCW Radar,frequency modulated continuous wave radar,gesture recognition,hand movement,human computer interaction,human hand,Radar,radar computing,Range Estimation,Receivers,Sensors,touchless hand gesture,Touchless hand gesture,Ultrasonic imaging,Ultrasound,ultrasound hybrid system,ultrasound sensors,Velocity Estimation}
    \endentry
    \entry{Nielsen:1994}{book}{}
      \name{author}{1}{}{%
        {{hash=753054f71283d85f82cda8e35daf6bac}{%
           family={Nielsen},
           familyi={N\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier Science}%
      }
      \strng{namehash}{753054f71283d85f82cda8e35daf6bac}
      \strng{fullhash}{753054f71283d85f82cda8e35daf6bac}
      \strng{bibnamehash}{753054f71283d85f82cda8e35daf6bac}
      \strng{authorbibnamehash}{753054f71283d85f82cda8e35daf6bac}
      \strng{authornamehash}{753054f71283d85f82cda8e35daf6bac}
      \strng{authorfullhash}{753054f71283d85f82cda8e35daf6bac}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{9780125184069}
      \field{series}{Interactive Technologies}
      \field{title}{{Usability Engineering}}
      \field{year}{1994}
      \verb{urlraw}
      \verb https://books.google.be/books?id=95As2OF67f0C
      \endverb
      \verb{url}
      \verb https://books.google.be/books?id=95As2OF67f0C
      \endverb
    \endentry
    \entry{Norman:1999}{article}{}
      \name{author}{1}{}{%
        {{hash=6c785cec3b28d28af91696b6a6db5b78}{%
           family={Norman},
           familyi={N\bibinitperiod},
           given={Donald\bibnamedelima A.},
           giveni={D\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{fullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{bibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorbibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authornamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorfullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \field{extraname}{1}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1072-5520}
      \field{journaltitle}{Interactions}
      \field{month}{5}
      \field{number}{3}
      \field{title}{Affordance, conventions, and design}
      \field{volume}{6}
      \field{year}{1999}
      \field{pages}{38\bibrangedash 43}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/301153.301168
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/301153.301168
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/301153.301168
      \endverb
    \endentry
    \entry{Norman:2010}{article}{}
      \name{author}{1}{}{%
        {{hash=6c785cec3b28d28af91696b6a6db5b78}{%
           family={Norman},
           familyi={N\bibinitperiod},
           given={Donald\bibnamedelima A.},
           giveni={D\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{fullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{bibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorbibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authornamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorfullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \field{extraname}{2}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1072-5520}
      \field{journaltitle}{Interactions}
      \field{month}{5}
      \field{number}{3}
      \field{title}{{Natural user interfaces are not natural}}
      \field{volume}{17}
      \field{year}{2010}
      \field{pages}{6\bibrangedash 10}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1145/1744161.1744163
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1744161.1744163
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1744161.1744163
      \endverb
    \endentry
    \entry{Norman:2008}{article}{}
      \name{author}{1}{}{%
        {{hash=6c785cec3b28d28af91696b6a6db5b78}{%
           family={Norman},
           familyi={N\bibinitperiod},
           given={Donald\bibnamedelima A.},
           giveni={D\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{fullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{bibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorbibnamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authornamehash}{6c785cec3b28d28af91696b6a6db5b78}
      \strng{authorfullhash}{6c785cec3b28d28af91696b6a6db5b78}
      \field{extraname}{3}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1072-5520}
      \field{journaltitle}{Interactions}
      \field{month}{11}
      \field{number}{6}
      \field{title}{{Signifiers, not affordances}}
      \field{volume}{15}
      \field{year}{2008}
      \field{pages}{18\bibrangedash 19}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1145/1409040.1409044
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1409040.1409044
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1409040.1409044
      \endverb
    \endentry
    \entry{Oberhammer:2013}{incollection}{}
      \name{author}{4}{}{%
        {{hash=ed6a183e70ffb7d5a82eab6431f04175}{%
           family={Oberhammer},
           familyi={O\bibinitperiod},
           given={Joachim},
           giveni={J\bibinitperiod}}}%
        {{hash=d8ffb6e5b790681dc6662e4b68581338}{%
           family={Somjit},
           familyi={S\bibinitperiod},
           given={Nutapong},
           giveni={N\bibinitperiod}}}%
        {{hash=749d38e08c9527216142af0e1b30dd3c}{%
           family={Shah},
           familyi={S\bibinitperiod},
           given={Umer},
           giveni={U\bibinitperiod}}}%
        {{hash=45a34ca51f6bd729529260cee1fad7d7}{%
           family={Baghchehsaraei},
           familyi={B\bibinitperiod},
           given={Zargham},
           giveni={Z\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=5172fefb2b443ee414416cd75fb775a4}{%
           family={Uttamchandani},
           familyi={U\bibinitperiod},
           given={Deepak},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Woodhead Publishing}%
      }
      \strng{namehash}{4cc19100b4a9cb20b6cc64796a0f29dc}
      \strng{fullhash}{3c4169eca3bf54feb6f879e7c20f007e}
      \strng{bibnamehash}{4cc19100b4a9cb20b6cc64796a0f29dc}
      \strng{authorbibnamehash}{4cc19100b4a9cb20b6cc64796a0f29dc}
      \strng{authornamehash}{4cc19100b4a9cb20b6cc64796a0f29dc}
      \strng{authorfullhash}{3c4169eca3bf54feb6f879e7c20f007e}
      \strng{editorbibnamehash}{5172fefb2b443ee414416cd75fb775a4}
      \strng{editornamehash}{5172fefb2b443ee414416cd75fb775a4}
      \strng{editorfullhash}{5172fefb2b443ee414416cd75fb775a4}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Abstract: Radio-frequency microelectromechanical systems (RF MEMS) devices and circuits have attracted interest in applications such as car radar systems, particularly in the 76–81GHz frequency band, due to their near ideal signal performance and compatibility with semiconductor fabrication technology. This chapter gives an introduction to state-of-the-art car radar sensors and architectures, describes the most commonly engaged RF MEMS components and circuits, and gives examples of RF MEMS-based automotive radar prototypes.}
      \field{booktitle}{Handbook of Mems for Wireless and Mobile Applications}
      \field{isbn}{978-0-85709-271-7}
      \field{series}{Woodhead Publishing Series in Electronic and Optical Materials}
      \field{title}{{RF MEMS for automotive radar}}
      \field{year}{2013}
      \field{pages}{518\bibrangedash 549}
      \range{pages}{32}
      \verb{doi}
      \verb https://doi.org/10.1533/9780857098610.2.518
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/B9780857092717500165
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/B9780857092717500165
      \endverb
      \keyw{RF,MEMS,car radar,automotive radar,phase shifter}
    \endentry
    \entry{Oh:2013}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=823a144395fefa5b93a5ccce6e3bdaf4}{%
           family={Oh},
           familyi={O\bibinitperiod},
           given={Uran},
           giveni={U\bibinitperiod}}}%
        {{hash=d04bd9d6170d17397e611dafa981f9a2}{%
           family={Findlater},
           familyi={F\bibinitperiod},
           given={Leah},
           giveni={L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Paris, France}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b65657048ddefc76315ee3f65efe730d}
      \strng{fullhash}{b65657048ddefc76315ee3f65efe730d}
      \strng{bibnamehash}{b65657048ddefc76315ee3f65efe730d}
      \strng{authorbibnamehash}{b65657048ddefc76315ee3f65efe730d}
      \strng{authornamehash}{b65657048ddefc76315ee3f65efe730d}
      \strng{authorfullhash}{b65657048ddefc76315ee3f65efe730d}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The vast majority of work on understanding and supporting the gesture creation process has focused on professional designers. In contrast, gesture customization by end users' - which may offer better memorability, efficiency and accessibility than pre-defined gestures - has received little attention. To understand the end-user gesture creation process, we conducted a study where 20 participants were asked to: (1) exhaustively create new gestures for an open-ended use case; (2) exhaustively create new gestures for 12 specific use cases; (3) judge the saliency of different touchscreen gesture features. Our findings showed that even when asked to create novel gestures, participants tended to focus on the familiar. Misconceptions about the gesture recognizer's abilities were also evident, and in some cases constrained the range of gestures that participants created. Finally, as a calibration point for future research, we used a simple gesture recognizer ($N) to analyze recognition accuracy of the participants' custom gesture sets: accuracy was 68-88\% on average, depending on the amount of training and the customization scenario. We conclude with implications for the design of a mixed-initiative approach to support custom gesture creation.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450318990}
      \field{series}{CHI '13}
      \field{title}{{The challenges and potential of end-user gesture customization}}
      \field{year}{2013}
      \field{pages}{1129\bibrangedash 1138}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2470654.2466145
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2470654.2466145
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2470654.2466145
      \endverb
      \keyw{customization,gestures,personalization,touchscreen}
    \endentry
    \entry{Ortega:2017}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=c99755bae587190c79d95e319e20f8a1}{%
           family={Ortega},
           familyi={O\bibinitperiod},
           given={Francisco\bibnamedelima R.},
           giveni={F\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=260301a73f3424a90dcde4b92c74a5e8}{%
           family={Galvan},
           familyi={G\bibinitperiod},
           given={Alain},
           giveni={A\bibinitperiod}}}%
        {{hash=b62cffc4a6be558abe3ec53e2085ecdf}{%
           family={Tarre},
           familyi={T\bibinitperiod},
           given={Katherine},
           giveni={K\bibinitperiod}}}%
        {{hash=1e17c2c3b03c8140ae3c4471bdad7d82}{%
           family={Barreto},
           familyi={B\bibinitperiod},
           given={Armando},
           giveni={A\bibinitperiod}}}%
        {{hash=5d9618a4ba0349827ed635d06567af9b}{%
           family={Rishe},
           familyi={R\bibinitperiod},
           given={Naphtali},
           giveni={N\bibinitperiod}}}%
        {{hash=5041a9cfa38a572b9d7adc55b8375690}{%
           family={Bernal},
           familyi={B\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=49cecd2606187eadb9d192bde033707e}{%
           family={Balcazar},
           familyi={B\bibinitperiod},
           given={Ruben},
           giveni={R\bibinitperiod}}}%
        {{hash=b455f2cc50a465ffb92e6191a610f1da}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Jason-Lee},
           giveni={J\bibinithyphendelim L\bibinitperiod}}}%
      }
      \strng{namehash}{155c9040cb9fe05b9d395f1aba8daf95}
      \strng{fullhash}{4bb1813efa9fbc63bb555eed336f754c}
      \strng{bibnamehash}{155c9040cb9fe05b9d395f1aba8daf95}
      \strng{authorbibnamehash}{155c9040cb9fe05b9d395f1aba8daf95}
      \strng{authornamehash}{155c9040cb9fe05b9d395f1aba8daf95}
      \strng{authorfullhash}{4bb1813efa9fbc63bb555eed336f754c}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2017 IEEE Symposium on 3D User Interfaces (3DUI)}
      \field{title}{{Gesture elicitation for 3D travel via multi-touch and mid-Air systems for procedurally generated pseudo-universe}}
      \field{year}{2017}
      \field{pages}{144\bibrangedash 153}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/3DUI.2017.7893331
      \endverb
    \endentry
    \entry{Ousmer:2020}{article}{}
      \name{author}{5}{}{%
        {{hash=50206389921773df61bbe2a79d4d004b}{%
           family={Ousmer},
           familyi={O\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod}}}%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=fa01b7ea0d6587d21e78591bd3ea6825}{%
           family={Magrofuoco},
           familyi={M\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=f822d8f741e1aed7d9b7872fe72da592}{%
           family={Roselli},
           familyi={R\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{d701c5537311cc92f780cef35e6a216c}
      \strng{fullhash}{1610a16022298e14d5aae2a9a5c6ac2f}
      \strng{bibnamehash}{d701c5537311cc92f780cef35e6a216c}
      \strng{authorbibnamehash}{d701c5537311cc92f780cef35e6a216c}
      \strng{authornamehash}{d701c5537311cc92f780cef35e6a216c}
      \strng{authorfullhash}{1610a16022298e14d5aae2a9a5c6ac2f}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While end users can acquire full 3D gestures with many input devices, they often capture only 3D trajectories, which are 3D uni-path, uni-stroke single-point gestures performed in thin air. Such trajectories with their $(x,y,z)$ coordinates could be interpreted as three 2D stroke gestures projected on three planes,ie, $XY$, $YZ$, and $ZX$, thus making them admissible for established 2D stroke gesture recognizers. To investigate whether 3D trajectories could be effectively and efficiently recognized, four 2D stroke gesture recognizers, ie, Rubine3D, another extension of Rubine for 3D which projects the 3D gesture on three orthogonal planes, is also included. These seven recognizers are compared against three challenging datasets containing 3D trajectories, ie, SHREC2019 and 3DTCGS, in a user-independent scenario, and 3DMadLabSD with its four domains, in both user-dependent and user-independent scenarios, with varying number of templates and sampling. Individual recognition rates and execution times per dataset and aggregated ones on all datasets show a highly significant difference of $P+^3$ over its competitors. The potential effects of the dataset, the number of templates, and the sampling are also studied.}
      \field{journaltitle}{Proc. ACM Hum.-Comput. Interact.}
      \field{month}{11}
      \field{number}{ISS}
      \field{title}{{Recognizing 3D Trajectories as 2D Multi-Stroke Gestures}}
      \field{volume}{4}
      \field{year}{2020}
      \verb{doi}
      \verb 10.1145/3427326
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3427326
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3427326
      \endverb
      \keyw{gesture recognition,large display interfaces and multi-display environments,gesture-based interfaces,mid-air gestural interaction,stroke gestures,surface computing,3d trajectory}
    \endentry
    \entry{Ouyang:2012}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=ad6988686d0f3855e3a6f62c70eb122d}{%
           family={Ouyang},
           familyi={O\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=2af761d9bef859ea29248418adce0dd7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Austin, Texas, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{390ea4014e7feca8330f176f445a051e}
      \strng{fullhash}{390ea4014e7feca8330f176f445a051e}
      \strng{bibnamehash}{390ea4014e7feca8330f176f445a051e}
      \strng{authorbibnamehash}{390ea4014e7feca8330f176f445a051e}
      \strng{authornamehash}{390ea4014e7feca8330f176f445a051e}
      \strng{authorfullhash}{390ea4014e7feca8330f176f445a051e}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Personal user-defined gesture shortcuts have shown great potential for accessing the ever-growing amount of data and computing power on touchscreen mobile devices. However, their lack of scalability is a major challenge for their wide adoption. In this paper, we present Gesture Marks, a novel approach to touch-gesture interaction that allows a user to access applications and websites using gestures without having to define them first. It offers two distinctive solutions to address the problem of scalability. First, it leverages the "wisdom of the crowd", a continually evolving library of gesture shortcuts that are collected from the user population, to infer the meaning of gestures that a user never defined himself. Second, it combines an extensible template-based gesture recognizer with a specialized handwriting recognizer to even better address handwriting-based gestures, which are a common form of gesture shortcut. These approaches effectively bootstrap a user's personal gesture library, alleviating the need to define most gestures manually. Our work was motivated and validated via a series of user studies, and the findings from these studies add to the body of knowledge on gesture-based interaction.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450310154}
      \field{series}{CHI '12}
      \field{title}{{Bootstrapping personal gesture shortcuts with the wisdom of the crowd and handwriting recognition}}
      \field{year}{2012}
      \field{pages}{2895\bibrangedash 2904}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2207676.2208695
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2207676.2208695
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2207676.2208695
      \endverb
      \keyw{search,mobile computing,gesture-based interaction}
    \endentry
    \entry{Ovur:2021}{article}{}
      \name{author}{5}{}{%
        {{hash=cfadaab5d1932a9223a44263500dca5a}{%
           family={Ovur},
           familyi={O\bibinitperiod},
           given={Salih\bibnamedelima Ertug},
           giveni={S\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=3768537b732a0e6eeac046def7c74b4c}{%
           family={Su},
           familyi={S\bibinitperiod},
           given={Hang},
           giveni={H\bibinitperiod}}}%
        {{hash=8cc178e1a79bd5699c9172cb681809b0}{%
           family={Qi},
           familyi={Q\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod}}}%
        {{hash=d408d12ba50e521a406df3b393de520d}{%
           family={De\bibnamedelima Momi},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Elena},
           giveni={E\bibinitperiod}}}%
        {{hash=92121220ce240935f52be61770f14990}{%
           family={Ferrigno},
           familyi={F\bibinitperiod},
           given={Giancarlo},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{3f569dbec770ac2dd406e4ca5bd7b553}
      \strng{fullhash}{5bb76d7c215b1a46eb3f3c578bab7d33}
      \strng{bibnamehash}{3f569dbec770ac2dd406e4ca5bd7b553}
      \strng{authorbibnamehash}{3f569dbec770ac2dd406e4ca5bd7b553}
      \strng{authornamehash}{3f569dbec770ac2dd406e4ca5bd7b553}
      \strng{authorfullhash}{5bb76d7c215b1a46eb3f3c578bab7d33}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Instrumentation and Measurement}
      \field{title}{{Novel Adaptive Sensor Fusion Methodology for Hand Pose Estimation With Multileap Motion}}
      \field{volume}{70}
      \field{year}{2021}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/TIM.2021.3063752
      \endverb
      \keyw{Sensor fusion;Kalman filters;Calibration;Position measurement;Human computer interaction;Real-time systems;Adaptive sensor fusion;human–computer interaction (HCI);Kalman filter;leap motion;mutisensor fusion}
    \endentry
    \entry{Page:2021}{article}{}
      \name{author}{26}{}{%
        {{hash=016b86afb0a98379bf77b3f074f34761}{%
           family={Page},
           familyi={P\bibinitperiod},
           given={Matthew\bibnamedelima J},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=af56ff14657d1110bff4b784198b0505}{%
           family={Moher},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=c342b2f9e98d8bcaabcbd5ec10522ad4}{%
           family={Bossuyt},
           familyi={B\bibinitperiod},
           given={Patrick\bibnamedelima M},
           giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=fa885033d820893c45692b99c8b4bbc6}{%
           family={Boutron},
           familyi={B\bibinitperiod},
           given={Isabelle},
           giveni={I\bibinitperiod}}}%
        {{hash=8fd2430e75c6bb84661c811e408f6377}{%
           family={Hoffmann},
           familyi={H\bibinitperiod},
           given={Tammy\bibnamedelima C},
           giveni={T\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=9da5818ae381747539d8a98ecf2d13b1}{%
           family={Mulrow},
           familyi={M\bibinitperiod},
           given={Cynthia\bibnamedelima D},
           giveni={C\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=d1c6b0b224969ed1ccfe648b31dc7de4}{%
           family={Shamseer},
           familyi={S\bibinitperiod},
           given={Larissa},
           giveni={L\bibinitperiod}}}%
        {{hash=640f8392f6a7388c779d2b60fdd93350}{%
           family={Tetzlaff},
           familyi={T\bibinitperiod},
           given={Jennifer\bibnamedelima M},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=4ca61686dc125837a0d9741be62f3427}{%
           family={Akl},
           familyi={A\bibinitperiod},
           given={Elie\bibnamedelima A},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=e822c8724e88eb518ec5eb8015bbaab0}{%
           family={Brennan},
           familyi={B\bibinitperiod},
           given={Sue\bibnamedelima E},
           giveni={S\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=01e789422f68da54234ac2f1e791eac4}{%
           family={Chou},
           familyi={C\bibinitperiod},
           given={Roger},
           giveni={R\bibinitperiod}}}%
        {{hash=19c8626c5dbf0aaa5ca05c6fa19ad49f}{%
           family={Glanville},
           familyi={G\bibinitperiod},
           given={Julie},
           giveni={J\bibinitperiod}}}%
        {{hash=18acccd95580a48bd6c5f4010bb058a7}{%
           family={Grimshaw},
           familyi={G\bibinitperiod},
           given={Jeremy\bibnamedelima M},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=aa6b6295cc5b496c1858297b2a62fa5f}{%
           family={Hróbjartsson},
           familyi={H\bibinitperiod},
           given={Asbj{ø}rn},
           giveni={A\bibinitperiod}}}%
        {{hash=0a2541509ccb6793b91fce2cf0f72dcc}{%
           family={Lalu},
           familyi={L\bibinitperiod},
           given={Manoj\bibnamedelima M},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=0100456cf4ced53a2aab31f2c3055f6a}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Tianjing},
           giveni={T\bibinitperiod}}}%
        {{hash=6e270d436c864242b119a3605283c8bf}{%
           family={Loder},
           familyi={L\bibinitperiod},
           given={Elizabeth\bibnamedelima W},
           giveni={E\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=d149e7026acd95db856d30314dba9a9e}{%
           family={Mayo-Wilson},
           familyi={M\bibinithyphendelim W\bibinitperiod},
           given={Evan},
           giveni={E\bibinitperiod}}}%
        {{hash=4ed61e5ea9f906c20e5e737e3d84c854}{%
           family={McDonald},
           familyi={M\bibinitperiod},
           given={Steve},
           giveni={S\bibinitperiod}}}%
        {{hash=b7314b4cde4c01764b4b3580e015b768}{%
           family={McGuinness},
           familyi={M\bibinitperiod},
           given={Luke\bibnamedelima A},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=d600e9a8a01053464e53fc2aadeb009b}{%
           family={Stewart},
           familyi={S\bibinitperiod},
           given={Lesley\bibnamedelima A},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=1ad8d835a95f8df394e6faf5d8e0548f}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=0b396572e13e5a8b08e1ee1d493aaa2a}{%
           family={Tricco},
           familyi={T\bibinitperiod},
           given={Andrea\bibnamedelima C},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=75fdbaed8e43fddb210da313631d8639}{%
           family={Welch},
           familyi={W\bibinitperiod},
           given={Vivian\bibnamedelima A},
           giveni={V\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=792d7051a4c2169e6aac0073ce62ba8e}{%
           family={Whiting},
           familyi={W\bibinitperiod},
           given={Penny},
           giveni={P\bibinitperiod}}}%
        {{hash=8c647eae0c93ec008ebe092eb144eeee}{%
           family={McKenzie},
           familyi={M\bibinitperiod},
           given={Joanne\bibnamedelima E},
           giveni={J\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {BMJ Publishing Group Ltd}%
      }
      \strng{namehash}{69c1efa4f6ab0deea3df12876fea0709}
      \strng{fullhash}{95da0662bd7f8a855af307b9f5baa381}
      \strng{bibnamehash}{69c1efa4f6ab0deea3df12876fea0709}
      \strng{authorbibnamehash}{69c1efa4f6ab0deea3df12876fea0709}
      \strng{authornamehash}{69c1efa4f6ab0deea3df12876fea0709}
      \strng{authorfullhash}{95da0662bd7f8a855af307b9f5baa381}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{BMJ}
      \field{title}{{PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews}}
      \field{volume}{372}
      \field{year}{2021}
      \field{pages}{1\bibrangedash 36}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1136/bmj.n160
      \endverb
      \verb{eprint}
      \verb https://www.bmj.com/content/372/bmj.n160.full.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.bmj.com/content/372/bmj.n160
      \endverb
      \verb{url}
      \verb https://www.bmj.com/content/372/bmj.n160
      \endverb
    \endentry
    \entry{Palipana:2021}{article}{}
      \name{author}{4}{}{%
        {{hash=464c48b3c6f56f5081da02f968b7e91d}{%
           family={Palipana},
           familyi={P\bibinitperiod},
           given={Sameera},
           giveni={S\bibinitperiod}}}%
        {{hash=ff90c3da57b0b4459877f4027a94b27b}{%
           family={Salami},
           familyi={S\bibinitperiod},
           given={Dariush},
           giveni={D\bibinitperiod}}}%
        {{hash=beb8309d01d6a74ec6ae3672219eb8af}{%
           family={Leiva},
           familyi={L\bibinitperiod},
           given={Luis\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=a1a61ffeb2d53ee0a8d3fe5166d02654}{%
           family={Sigg},
           familyi={S\bibinitperiod},
           given={Stephan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{c59276770938246967a03fe5ea668fbf}
      \strng{fullhash}{03bcfb7adeab59560e962e27924bee11}
      \strng{bibnamehash}{c59276770938246967a03fe5ea668fbf}
      \strng{authorbibnamehash}{c59276770938246967a03fe5ea668fbf}
      \strng{authornamehash}{c59276770938246967a03fe5ea668fbf}
      \strng{authorfullhash}{03bcfb7adeab59560e962e27924bee11}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce Pantomime, a novel mid-air gesture recognition system exploiting spatio-temporal properties of millimeter-wave radio frequency (RF) signals. Pantomime is positioned in a unique region of the RF landscape: mid-resolution mid-range high-frequency sensing, which makes it ideal for motion gesture interaction. We configure a commercial frequency-modulated continuous-wave radar device to promote spatial information over the temporal resolution by means of sparse 3D point clouds and contribute a deep learning architecture that directly consumes the point cloud, enabling real-time performance with low computational demands. Pantomime achieves 95\% accuracy and 99\% AUC in a challenging set of 21 gestures articulated by 41 participants in two indoor environments, outperforming four state-of-the-art 3D point cloud recognizers. We further analyze the effect of the environment in 5 different indoor environments, the effect of articulation speed, angle, and the distance of the person up to 5m. We have publicly made available the collected mmWave gesture dataset consisting of nearly 22,000 gesture instances along with our radar sensor configuration, trained models, and source code for reproducibility. We conclude that pantomime is resilient to various input conditions and that it may enable novel applications in industrial, vehicular, and smart home scenarios.}
      \field{journaltitle}{Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}
      \field{month}{3}
      \field{number}{1}
      \field{shorttitle}{Pantomime}
      \field{title}{Pantomime: {Mid}-{Air} {Gesture} {Recognition} with {Sparse} {Millimeter}-{Wave} {Radar} {Point} {Clouds}}
      \field{urlday}{25}
      \field{urlmonth}{5}
      \field{urlyear}{2021}
      \field{volume}{5}
      \field{year}{2021}
      \field{urldateera}{ce}
      \field{pages}{27:1\bibrangedash 27:27}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/3448110
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3448110
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3448110
      \endverb
      \keyw{gesture recognition,deep learning,radar sensing}
    \endentry
    \entry{Park:2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=8e3c30f7f193c73c0ce4a7e46cc9728a}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Chanho},
           giveni={C\bibinitperiod}}}%
        {{hash=9822bcf778eea41330a2d0d7d564e6ea}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Hyunwoo},
           giveni={H\bibinitperiod}}}%
        {{hash=549ac3d4afe8e8738cd265ac2b4728a6}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Sangheon},
           giveni={S\bibinitperiod}}}%
        {{hash=261fa8c60a19e9dc37cfee5f478f2e2e}{%
           family={Yoon},
           familyi={Y\bibinitperiod},
           given={Young-Suk},
           giveni={Y\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=6dba95743075a69ea6dc14216613e84a}{%
           family={Jung},
           familyi={J\bibinitperiod},
           given={Sung-Uk},
           giveni={S\bibinithyphendelim U\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{2173bda7cc6c1e33c453df30a20cd97b}
      \strng{fullhash}{4ebd372c8f1dcc955dff22376e284d35}
      \strng{bibnamehash}{2173bda7cc6c1e33c453df30a20cd97b}
      \strng{authorbibnamehash}{2173bda7cc6c1e33c453df30a20cd97b}
      \strng{authornamehash}{2173bda7cc6c1e33c453df30a20cd97b}
      \strng{authorfullhash}{4ebd372c8f1dcc955dff22376e284d35}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2019 ACM International Conference on Interactive Surfaces and Spaces}
      \field{isbn}{9781450368919}
      \field{series}{ISS '19}
      \field{title}{{HandPoseMenu: Hand Posture-Based Virtual Menus for Changing Interaction Mode in 3D Space}}
      \field{venue}{Daejeon, Republic of Korea}
      \field{year}{2019}
      \field{pages}{361\bibrangedash 366}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3343055.3360752
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3343055.3360752
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3343055.3360752
      \endverb
      \keyw{gesture recognition,graphical menu,hand posture,virtual reality,head-mounted display.,mixed reality}
    \endentry
    \entry{Park:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=6b136b8e41fadd29e6a1898631fe5e97}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Junbum},
           giveni={J\bibinitperiod}}}%
        {{hash=9c3e292cb9d908f64abb130161dc591e}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Sung\bibnamedelima Ho},
           giveni={S\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \strng{namehash}{ed134c09aad2c31c565ab448003612c7}
      \strng{fullhash}{ed134c09aad2c31c565ab448003612c7}
      \strng{bibnamehash}{ed134c09aad2c31c565ab448003612c7}
      \strng{authorbibnamehash}{ed134c09aad2c31c565ab448003612c7}
      \strng{authornamehash}{ed134c09aad2c31c565ab448003612c7}
      \strng{authorfullhash}{ed134c09aad2c31c565ab448003612c7}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a human gesture recognition algorithm using impulse radio ultra-wideband (IR-UWB) radar. The radar signal is transmitted into a three dimensional space, however, the received signal is only expressed in one dimensional. Therefore, it is difficult to classify 3-D gestures by analyzing specific features, such as power, peak value, index of peak value, and other values of received signal. To resolve this problem, a new human gesture recognition algorithm using machine learning is proposed. Two machine learning technics are used in this paper. One is unsupervised learning technic which is used for extracting features from received radar signal is principal component analysis, and the other one is supervised learning which is used for classifying gestures. The features are extracted by using the principal component analysis (PCA) method, then neural network method is used for training and classifying gestures using the extracted features. In training and classifying step, other method can be used, such as supporting vector machine (SVM), however, this method is hard to recognize noise gesture which means untrained gesture. To resolve this problem, we use neural network method in this paper, then in order to classy noise gestures and trained gestures, a noise determining algorithm is used.}
      \field{booktitle}{2016 {IEEE} 18th {International} {Conference} on {High} {Performance} {Computing} and {Communications}; {IEEE} 14th {International} {Conference} on {Smart} {City}; {IEEE} 2nd {International} {Conference} on {Data} {Science} and {Systems} ({HPCC}/{SmartCity}/{DSS})}
      \field{month}{12}
      \field{title}{{IR}-{UWB} {Radar} {Sensor} for {Human} {Gesture} {Recognition} by {Using} {Machine} {Learning}}
      \field{year}{2016}
      \field{pages}{1246\bibrangedash 1249}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/HPCC-SmartCity-DSS.2016.0176
      \endverb
      \keyw{3D gestures classification,feature extraction,Feature extraction,gesture recognition,Gesture recognition,hand gesture recognition,human gesture recognition,impulse radio ultra-wideband (IR-UWB),impulse radio ultra-wideband radar,IR-UWB radar sensor,machine learning,Machine learning algorithms,motion recognition,neural nets,neural network,Neural networks,noise determining algorithm,PCA,principal component analysis,Principal component analysis,Radar,radar receivers,radar sensor,radar signal processing,received radar signal,Training,ultra wideband radar,unsupervised learning}
    \endentry
    \entry{Park:2020}{article}{}
      \name{author}{6}{}{%
        {{hash=ea2cab5f2437b3b04fe92081d7839421}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Jungwoon},
           giveni={J\bibinitperiod}}}%
        {{hash=3b8e178f3dc9981ae95b7038eb8fcacf}{%
           family={Jang},
           familyi={J\bibinitperiod},
           given={Junyoung},
           giveni={J\bibinitperiod}}}%
        {{hash=4078a2d5be636881f804211f38b8e2e0}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Geunhaeng},
           giveni={G\bibinitperiod}}}%
        {{hash=940a216e136c0fb1685e5b820c1c6a94}{%
           family={Koh},
           familyi={K\bibinitperiod},
           given={Hyunmin},
           giveni={H\bibinitperiod}}}%
        {{hash=6c3719a36e3921c49639619c3d904f7a}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Changhwan},
           giveni={C\bibinitperiod}}}%
        {{hash=c9ed163b894ef089ef348f8a8a45b48d}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Tae\bibnamedelima Wook},
           giveni={T\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \strng{namehash}{2e04cb907ad47862ebfb011c2def4d46}
      \strng{fullhash}{946ea5425f5d656f93b0f421c8809a9e}
      \strng{bibnamehash}{2e04cb907ad47862ebfb011c2def4d46}
      \strng{authorbibnamehash}{2e04cb907ad47862ebfb011c2def4d46}
      \strng{authornamehash}{2e04cb907ad47862ebfb011c2def4d46}
      \strng{authorfullhash}{946ea5425f5d656f93b0f421c8809a9e}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article introduces a time-domain-based artificial intelligence (AI) radar system for gesture recognition using 33-GS/s direct sampling technique. High-speed sampling using a time-extension method allows AI learning to be applied to a time-domain radar signal reflecting information on both dynamic and static gestures, and thus can recognize not only dynamic but also static gestures. The Vernier clock generators and high-speed active samplers applied with the time-extension technique makes sampling at 33 GS/s possible. A 1-D convolutional neural network and long short-term memory are employed for both static and dynamic gestures and recognition rates of 93.2\% and 90.5\% are obtained, respectively. The radar system is implemented using a 65-nm CMOS process with a power consumption of 95 mW.}
      \field{issn}{1558-173X}
      \field{journaltitle}{IEEE Journal of Solid-State Circuits}
      \field{month}{4}
      \field{number}{4}
      \field{title}{A {Time} {Domain} {Artificial} {Intelligence} {Radar} {System} {Using} 33-{GHz} {Direct} {Sampling} for {Hand} {Gesture} {Recognition}}
      \field{volume}{55}
      \field{year}{2020}
      \field{pages}{879\bibrangedash 888}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/JSSC.2020.2967547
      \endverb
      \keyw{1-D convolutional neural network,AI learning,Artificial intelligence,Artificial intelligence (AI) radar,Capacitors,clocks,Clocks,convolutional neural nets,direct sampling technique,dynamic gestures,Generators,gesture recognition,hand gesture recognition,high-speed sampling,impulse radar ultra-wideband (IR-UWB),learning (artificial intelligence),long short-term memory,power 95.0 mW,radar,Radar,radar computing,radar signal processing,recognition rates,recurrent neural nets,sampler,signal sampling,static gestures,time domain artificial intelligence radar system,time-domain analysis,Time-domain analysis,time-domain radar signal,time-domain-based artificial intelligence radar system,time-extension,time-extension method,time-extension technique,time-to-digital converter (TDC),Timing,transceiver,Vernier clock generators,wireless sensing}
    \endentry
    \entry{Parsons:1999}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=f4c2b1196f679576ba6273abeca3322f}{%
           family={Parsons},
           familyi={P\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=6fbb994c4b349970220221a07464c436}{%
           family={Rashid},
           familyi={R\bibinitperiod},
           given={Awais},
           giveni={A\bibinitperiod}}}%
        {{hash=6d9cc6656e7289eda623200427c61fb7}{%
           family={Speck},
           familyi={S\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=a6f0e902a737bda7f3f2dd51302d09c8}{%
           family={Telea},
           familyi={T\bibinitperiod},
           given={Alexandru\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{20563a079778b396131b7590f18f0c89}
      \strng{fullhash}{26ac2fd09b9aef5e9e233f6f335a381e}
      \strng{bibnamehash}{20563a079778b396131b7590f18f0c89}
      \strng{authorbibnamehash}{20563a079778b396131b7590f18f0c89}
      \strng{authornamehash}{20563a079778b396131b7590f18f0c89}
      \strng{authorfullhash}{26ac2fd09b9aef5e9e233f6f335a381e}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings Technology of Object-Oriented Languages and Systems. TOOLS 29 (Cat. No.PR00275)}
      \field{title}{{A "framework" for object oriented frameworks design}}
      \field{year}{1999}
      \field{pages}{141\bibrangedash 151}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TOOLS.1999.779007
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/author/37268563800
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/author/37268563800
      \endverb
    \endentry
    \entry{Parthiban:2019}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=b70ec80fe0586da49b51076bf4a9a3d5}{%
           family={Parthiban},
           familyi={P\bibinitperiod},
           given={Vik},
           giveni={V\bibinitperiod}}}%
        {{hash=411474f646ea08e8c25bad574eccf9b6}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Ashley\bibnamedelima Jieun},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{f23273c840caed950118f7a81eddb42c}
      \strng{fullhash}{f23273c840caed950118f7a81eddb42c}
      \strng{bibnamehash}{f23273c840caed950118f7a81eddb42c}
      \strng{authorbibnamehash}{f23273c840caed950118f7a81eddb42c}
      \strng{authornamehash}{f23273c840caed950118f7a81eddb42c}
      \strng{authorfullhash}{f23273c840caed950118f7a81eddb42c}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{The 17th International Conference on Virtual-Reality Continuum and Its Applications in Industry}
      \field{isbn}{9781450370028}
      \field{series}{VRCAI ’19}
      \field{title}{{LUI: A Multimodal, Intelligent Interface for Large Displays}}
      \field{venue}{Brisbane, QLD, Australia}
      \field{year}{2019}
      \verb{doi}
      \verb 10.1145/3359997.3365743
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3359997.3365743
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3359997.3365743
      \endverb
      \keyw{large displays,gestures,human-computer interaction,augmented reality,voice}
    \endentry
    \entry{Patra:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=1ccf2690aad199720bb3f12ea3bf208b}{%
           family={Patra},
           familyi={P\bibinitperiod},
           given={Avishek},
           giveni={A\bibinitperiod}}}%
        {{hash=9c9132c73fc5cb447245e81c18537210}{%
           family={Geuer},
           familyi={G\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod}}}%
        {{hash=dd7414899d2e33e232dbc0ffb98c206b}{%
           family={Munari},
           familyi={M\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
        {{hash=511f33a36ba86a9675308a8b7989843c}{%
           family={Mähönen},
           familyi={M\bibinitperiod},
           given={Petri},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{c23cc5a8f2c73e01c906de4468b9a6e1}
      \strng{fullhash}{85d6b8543debfb43f73f86e0a15cc644}
      \strng{bibnamehash}{c23cc5a8f2c73e01c906de4468b9a6e1}
      \strng{authorbibnamehash}{c23cc5a8f2c73e01c906de4468b9a6e1}
      \strng{authornamehash}{c23cc5a8f2c73e01c906de4468b9a6e1}
      \strng{authorfullhash}{85d6b8543debfb43f73f86e0a15cc644}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Gesture recognition is gaining attention as an attractive feature for the development of ubiquitous, context-aware, IoT applications. Use of radars as a primary or secondary system is tempting, as they can operate in darkness, high light intensity environments, and longer distances than many competitor systems. Starting from this observation, we present a generic, low-cost, mm-wave radar-based gesture recognition system. Among potential benefits of mm-wave radars are a high spatial resolution due to small wavelength, the availability of multiple antennas in a small area and the low interference due to the natural attenuation of mm-wave radiation. We experimentally evaluate our COTS solution considering eight different gestures and using two low-complexity classification algorithms: the unsupervised Self Organized Map (SOM) and the supervised Learning Vector Quantization (LVQ). To test robustness, we consider gestures performed by a human hand and a human body, at short and long distance. From our preliminary evaluations, we observe that LVQ and SOM correctly detect 75\% and 60\% of all gestures, respectively, from the raw, unprocessed data. The detection rate is significantly higher ({>}90\%) for selected gesture groups. We argue that performance suffers due to inaccurate AoA estimation. Accordingly, we evaluate our system employing a two-radar setup that increases the estimation accuracy by 8-9\%.}
      \field{booktitle}{Proceedings of the 2nd {ACM} {Workshop} on {Millimeter} {Wave} {Networks} and {Sensing} {Systems}}
      \field{isbn}{978-1-4503-5928-3}
      \field{month}{10}
      \field{series}{{mmNets} '18}
      \field{shorttitle}{mm-{Wave} {Radar} {Based} {Gesture} {Recognition}}
      \field{title}{mm-{Wave} {Radar} {Based} {Gesture} {Recognition}: {Development} and {Evaluation} of a {Low}-{Power}, {Low}-{Complexity} {System}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{51\bibrangedash 56}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3264492.3264501
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3264492.3264501
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3264492.3264501
      \endverb
      \keyw{gesture recognition,machine learning,mm-wave,radar}
    \endentry
    \entry{Pavlovych:2009}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=929bed8b6ad423dba57f73e1853c2203}{%
           family={Pavlovych},
           familyi={P\bibinitperiod},
           given={Andriy},
           giveni={A\bibinitperiod}}}%
        {{hash=dfd8d46efe53918c4bab79ba6fbed371}{%
           family={Stuerzlinger},
           familyi={S\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{578f4c5a00699594f9e65804dcda4001}
      \strng{fullhash}{578f4c5a00699594f9e65804dcda4001}
      \strng{bibnamehash}{578f4c5a00699594f9e65804dcda4001}
      \strng{authorbibnamehash}{578f4c5a00699594f9e65804dcda4001}
      \strng{authornamehash}{578f4c5a00699594f9e65804dcda4001}
      \strng{authorfullhash}{578f4c5a00699594f9e65804dcda4001}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Interactive computing systems frequently use pointing as an input modality, while also supporting other forms of input such as alphanumeric, voice, gesture, and force. We focus on pointing and investigate the effects of input device latency and spatial jitter on 2D pointing speed and accuracy. First, we characterize the latency and jitter of several common input devices. Then we present an experiment, based on ISO 9241-9, where we systematically explore combinations of latency and jitter on a desktop mouse to measure how these factors affect human performance. The results indicate that, while latency has a stronger effect on human performance compared to low amounts of spatial jitter, jitter dramatically increases the error rate, roughly inversely proportional to the target size. The findings can be used in the design of pointing devices for interactive systems, by providing a guideline for choosing parameters of spatial filtering to compensate for jitter, since stronger filtering typically also increases lag. We also describe target sizes at which error rates start to increase notably, as this is relevant for user interfaces where hand tremor or similar factors play a major role.}
      \field{booktitle}{Proceedings of the 1st {ACM} {SIGCHI} symposium on {Engineering} interactive computing systems}
      \field{isbn}{978-1-60558-600-7}
      \field{month}{7}
      \field{series}{{EICS} '09}
      \field{title}{{The tradeoff between spatial jitter and latency in pointing tasks}}
      \field{urlday}{7}
      \field{urlmonth}{1}
      \field{urlyear}{2021}
      \field{year}{2009}
      \field{urldateera}{ce}
      \field{pages}{187\bibrangedash 196}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1570433.1570469
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1570433.1570469
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1570433.1570469
      \endverb
      \keyw{fitts' law,jitter,latency,pointing}
    \endentry
    \entry{Pham:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=7e5dfab3466e3942e29650a8bb97d5bd}{%
           family={Pham},
           familyi={P\bibinitperiod},
           given={Tran},
           giveni={T\bibinitperiod}}}%
        {{hash=b03798777c34671ca8efcba15a8f3710}{%
           family={Vermeulen},
           familyi={V\bibinitperiod},
           given={Jo},
           giveni={J\bibinitperiod}}}%
        {{hash=d40bbfaa08c4d334f7db220898692040}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod}}}%
        {{hash=2824b474985886420a667008d6f91a6d}{%
           family={MacDonald\bibnamedelima Vermeulen},
           familyi={M\bibinitperiod\bibinitdelim V\bibinitperiod},
           given={Lindsay},
           giveni={L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{da792eba0a73331339ac02fee96b02d5}
      \strng{fullhash}{411c14a357364cf4bb8718492d6698c3}
      \strng{bibnamehash}{da792eba0a73331339ac02fee96b02d5}
      \strng{authorbibnamehash}{da792eba0a73331339ac02fee96b02d5}
      \strng{authornamehash}{da792eba0a73331339ac02fee96b02d5}
      \strng{authorfullhash}{411c14a357364cf4bb8718492d6698c3}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Because gesture design for augmented reality (AR) remains idiosyncratic, people cannot necessarily use gestures learned in one AR application in another. To design discoverable gestures, we need to understand what gestures people expect to use. We explore how the scale of AR affects the gestures people expect to use to interact with 3D holograms. Using an elicitation study, we asked participants to generate gestures in response to holographic task referents, where we varied the scale of holograms from desktop-scale to room-scale objects. We found that the scale of objects and scenes in the AR experience moderates the generated gestures. Most gestures were informed by physical interaction, and when people interacted from a distance, they sought a good perspective on the target object before and during the interaction. These results suggest that gesture designers need to account for scale, and should not simply reuse gestures across different hologram sizes.}
      \field{booktitle}{Proceedings of the 2018 Designing Interactive Systems Conference}
      \field{isbn}{9781450351980}
      \field{series}{DIS '18}
      \field{title}{{Scale Impacts Elicited Gestures for Manipulating Holograms: Implications for AR Gesture Design}}
      \field{venue}{Hong Kong, China}
      \field{year}{2018}
      \field{pages}{227\bibrangedash 240}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1145/3196709.3196719
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3196709.3196719
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3196709.3196719
      \endverb
      \keyw{gestures,hololens,augmented reality,gesture elicitation}
    \endentry
    \entry{Piumsomboon:2013}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=0fc90431ba71b7341990200176296a40}{%
           family={Piumsomboon},
           familyi={P\bibinitperiod},
           given={Thammathip},
           giveni={T\bibinitperiod}}}%
        {{hash=397a40f3a8c30fbe20a4682b1610f0e2}{%
           family={Clark},
           familyi={C\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
        {{hash=ebb11475827ce7b6b5609294d4e15d5b}{%
           family={Billinghurst},
           familyi={B\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=99db9681218f9f3b317f9a5aa016d284}{%
           family={Cockburn},
           familyi={C\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{5}{}{%
        {{hash=a932c98beecedaa44d7a9b9b77811a09}{%
           family={Kotzé},
           familyi={K\bibinitperiod},
           given={Paula},
           giveni={P\bibinitperiod}}}%
        {{hash=f8eb0bc279833f69290de9a97c488d70}{%
           family={Marsden},
           familyi={M\bibinitperiod},
           given={Gary},
           giveni={G\bibinitperiod}}}%
        {{hash=3664b6c5d9fc3f0be13b1eabf5d90d92}{%
           family={Lindgaard},
           familyi={L\bibinitperiod},
           given={Gitte},
           giveni={G\bibinitperiod}}}%
        {{hash=f1e2d4ef1bbe15b3caf611d7ba9ed1a4}{%
           family={Wesson},
           familyi={W\bibinitperiod},
           given={Janet},
           giveni={J\bibinitperiod}}}%
        {{hash=b01e3ac9fd360e086fd265423db98670}{%
           family={Winckler},
           familyi={W\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{a08fb9d52034e2598ac774e841edef2d}
      \strng{fullhash}{09ef66e99437dd0e9261983efac1b47b}
      \strng{bibnamehash}{a08fb9d52034e2598ac774e841edef2d}
      \strng{authorbibnamehash}{a08fb9d52034e2598ac774e841edef2d}
      \strng{authornamehash}{a08fb9d52034e2598ac774e841edef2d}
      \strng{authorfullhash}{09ef66e99437dd0e9261983efac1b47b}
      \strng{editorbibnamehash}{c042fad884b439b6a3bcab3ecfef177a}
      \strng{editornamehash}{c042fad884b439b6a3bcab3ecfef177a}
      \strng{editorfullhash}{5d90f729558ca8b8709e59db947e9d50}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently there has been an increase in research towards using hand gestures for interaction in the field of Augmented Reality (AR). These works have primarily focused on researcher designed gestures, while little is known about user preference and behavior for gestures in AR. In this paper, we present our guessability study for hand gestures in AR in which 800 gestures were elicited for 40 selected tasks from 20 participants. Using the agreement found among gestures, a user-defined gesture set was created to guide designers to achieve consistent user-centered gestures in AR. Wobbrock’s surface taxonomy has been extended to cover dimensionalities in AR and with it, characteristics of collected gestures have been derived. Common motifs which arose from the empirical findings were applied to obtain a better understanding of users’ thought and behavior. This work aims to lead to consistent user-centered designed gestures in AR.}
      \field{booktitle}{Human-{Computer} {Interaction} – {INTERACT} 2013}
      \field{isbn}{978-3-642-40480-1}
      \field{series}{Lecture {Notes} in {Computer} {Science}}
      \field{title}{User-{Defined} {Gestures} for {Augmented} {Reality}}
      \field{year}{2013}
      \field{pages}{282\bibrangedash 299}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1007/978-3-642-40480-1_18
      \endverb
      \keyw{Augmented reality,gestures,guessability}
    \endentry
    \entry{Ponraj:2018}{article}{}
      \name{author}{2}{}{%
        {{hash=e2a2c395d84c61b898cfdce19935d0da}{%
           family={Ponraj},
           familyi={P\bibinitperiod},
           given={Godwin},
           giveni={G\bibinitperiod}}}%
        {{hash=ffccc523ab91742706d9148ed07b2959}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \strng{fullhash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \strng{bibnamehash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \strng{authorbibnamehash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \strng{authornamehash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \strng{authorfullhash}{a1a7a1ffdb1d949536e1ca688012ddb1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{number}{5}
      \field{title}{{Sensor Fusion of Leap Motion Controller and Flex Sensors Using Kalman Filter for Human Finger Tracking}}
      \field{volume}{18}
      \field{year}{2018}
      \field{pages}{2042\bibrangedash 2049}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/JSEN.2018.2790801
      \endverb
      \keyw{Sensor fusion;Thumb;Tracking;Kalman filters;Joints;Leap motion controller;flex sensors;sensor fusion;Kalman filter}
    \endentry
    \entry{Pree:1994}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=e3212a42fa00b39b266f54e11534687f}{%
           family={Pree},
           familyi={P\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{e3212a42fa00b39b266f54e11534687f}
      \strng{fullhash}{e3212a42fa00b39b266f54e11534687f}
      \strng{bibnamehash}{e3212a42fa00b39b266f54e11534687f}
      \strng{authorbibnamehash}{e3212a42fa00b39b266f54e11534687f}
      \strng{authornamehash}{e3212a42fa00b39b266f54e11534687f}
      \strng{authorfullhash}{e3212a42fa00b39b266f54e11534687f}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 8th European Conference on Object-Oriented Programming}
      \field{isbn}{3540582029}
      \field{series}{ECOOP ’94}
      \field{title}{{Meta Patterns - A Means For Capturing the Essentials of Reusable Object-Oriented Design}}
      \field{year}{1994}
      \field{pages}{150\bibrangedash 162}
      \range{pages}{13}
    \endentry
    \entry{Preventis:2014}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=0f2707c307a8084651b9c1db713219a2}{%
           family={Preventis},
           familyi={P\bibinitperiod},
           given={Alexandros},
           giveni={A\bibinitperiod}}}%
        {{hash=a3995aa7fc1d57a4d481a0800e2491f9}{%
           family={Stravoskoufos},
           familyi={S\bibinitperiod},
           given={Kostas},
           giveni={K\bibinitperiod}}}%
        {{hash=d0301ca0b478759242a75d9ae44c44f7}{%
           family={Sotiriadis},
           familyi={S\bibinitperiod},
           given={Stelios},
           giveni={S\bibinitperiod}}}%
        {{hash=99844b7d2b6c323c44dec60ec5306a3c}{%
           family={Petrakis},
           familyi={P\bibinitperiod},
           given={Euripides\bibnamedelimb G.\bibnamedelimi M.},
           giveni={E\bibinitperiod\bibinitdelim G\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {IEEE Computer Society}%
      }
      \strng{namehash}{8ff8a6ba0a80b2778b4be45134fb9a82}
      \strng{fullhash}{ed4c8ac7c001771f01efaeacb3cc43e0}
      \strng{bibnamehash}{8ff8a6ba0a80b2778b4be45134fb9a82}
      \strng{authorbibnamehash}{8ff8a6ba0a80b2778b4be45134fb9a82}
      \strng{authornamehash}{8ff8a6ba0a80b2778b4be45134fb9a82}
      \strng{authorfullhash}{ed4c8ac7c001771f01efaeacb3cc43e0}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}
      \field{isbn}{9781479978816}
      \field{series}{UCC '14}
      \field{title}{{Interact: Gesture Recognition in the Cloud}}
      \field{year}{2014}
      \field{pages}{501\bibrangedash 502}
      \range{pages}{2}
      \verb{doi}
      \verb 10.1109/UCC.2014.71
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/UCC.2014.71
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/UCC.2014.71
      \endverb
      \keyw{Cloud computing,gesture recognition,FI-WARE}
    \endentry
    \entry{Rawart:2023}{misc}{}
      \name{author}{1}{}{%
        {{hash=61da56243321fd0a8ed643ff648f828e}{%
           family={Rawart},
           familyi={R\bibinitperiod},
           given={Isabelle},
           giveni={I\bibinitperiod}}}%
      }
      \strng{namehash}{61da56243321fd0a8ed643ff648f828e}
      \strng{fullhash}{61da56243321fd0a8ed643ff648f828e}
      \strng{bibnamehash}{61da56243321fd0a8ed643ff648f828e}
      \strng{authorbibnamehash}{61da56243321fd0a8ed643ff648f828e}
      \strng{authornamehash}{61da56243321fd0a8ed643ff648f828e}
      \strng{authorfullhash}{61da56243321fd0a8ed643ff648f828e}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{howpublished}{\url{https://www.digitalwallonia.be/fr/publications/citizens-of-wallonia-2023-9-projets-innovants/}}
      \field{note}{[Online; accessed 20-November-2023]}
      \field{title}{{Citizens of Wallonia 2023. 9 projets innovants récompensés}}
      \field{year}{2023}
    \endentry
    \entry{Ren:2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=2f887b2df15cc517294b4d30a98ebc4c}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Aihu},
           giveni={A\bibinitperiod}}}%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=6ed83e16ea05fe9df91b898ed1a30a4c}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaobo},
           giveni={X\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{e35a96569df7d35aa468ae2476a88ed3}
      \strng{fullhash}{844333586119bd15ba893ec8e492bdca}
      \strng{bibnamehash}{e35a96569df7d35aa468ae2476a88ed3}
      \strng{authorbibnamehash}{e35a96569df7d35aa468ae2476a88ed3}
      \strng{authornamehash}{e35a96569df7d35aa468ae2476a88ed3}
      \strng{authorfullhash}{844333586119bd15ba893ec8e492bdca}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a continuous dynamic hand gesture detection and recognition method is proposed using a frequency modulated continuous wave (FMCW) radar. Specifically, we collect the raw radar data to estimate the radar intermediate frequency (IF) signal, and construct the range-time map (RTM) and Doppler-time map (DTM) with 2-Dimensional Fast Fourier Transform (2D-FFT). Then, we propose a hand gesture detection method, which obtains the amplitude of the normalized hand gesture and uses a threshold to effectively segment the continuous hand gesture. Finally, the hand gesture is recognized by the proposed Fusion Dynamic Time Warping (FDTW) algorithm based on the central time-frequency trajectory. Experiments with radar data show that the accuracy of the proposed hand gesture detection method can reach 96.17\%, and compared with the traditional recognition algorithm, the proposed recognition algorithm can significantly improve the recognition accuracy rate (hand gesture average recognition accuracy rate can reach 94.50\%) with the time complexity reduced by more than 50\%.}
      \field{booktitle}{2020 {IEEE}/{CIC} {International} {Conference} on {Communications} in {China} ({ICCC})}
      \field{month}{8}
      \field{note}{ISSN: 2377-8644}
      \field{title}{A {Dynamic} {Continuous} {Hand} {Gesture} {Detection} and {Recognition} {Method} with {FMCW} {Radar}}
      \field{year}{2020}
      \field{pages}{1208\bibrangedash 1213}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ICCC49849.2020.9238935
      \endverb
      \keyw{continuous hand gesture recognition,detection,Doppler,FDTW,FMCW radar,real time process}
    \endentry
    \entry{Ritchie:2020}{article}{}
      \name{author}{3}{}{%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=8966dc82be6e614bf5f0eaa6607b5795}{%
           family={Capraru},
           familyi={C\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=d271b8d79d135292f5569754056368a8}{%
           family={Fioranelli},
           familyi={F\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{e616cc47b683f1436cbe582f334e0956}
      \strng{fullhash}{e616cc47b683f1436cbe582f334e0956}
      \strng{bibnamehash}{e616cc47b683f1436cbe582f334e0956}
      \strng{authorbibnamehash}{e616cc47b683f1436cbe582f334e0956}
      \strng{authornamehash}{e616cc47b683f1436cbe582f334e0956}
      \strng{authorfullhash}{e616cc47b683f1436cbe582f334e0956}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Radar sensors have a new growing application area of dynamic hand gesture recognition. Traditionally radar systems are considered to be very large, complex and focused on detecting targets at long ranges. With modern electronics and signal processing it is now possible to create small compact RF sensors that can sense subtle movements over short ranges. For such applications, access to comprehensive databases of signatures is critical to enable the effective training of classification algorithms and to provide a common baseline for benchmarking purposes. This Letter introduces the Dop-NET radar micro-Doppler database and data challenge to the radar and machine learning communities. Dop-NET is a database of radar micro-Doppler signatures that are shareable and distributed with the purpose of improving micro-Doppler classification techniques. A continuous wave 24 GHz radar module is used to capture the first contributions to the Dop-NET database and classification results based on discriminating these hand gestures as shown.}
      \field{issn}{0013-5194}
      \field{journaltitle}{Electronics Letters}
      \field{number}{11}
      \field{title}{Dop-{NET}: a micro-{Doppler} radar data challenge}
      \field{volume}{56}
      \field{year}{2020}
      \field{pages}{568\bibrangedash 570}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1049/el.2019.4153
      \endverb
      \keyw{compact RF sensors,continuous wave radar module,CW radar,Dop-NET database,Dop-NET radar microDoppler database,Doppler radar,dynamic hand gesture recognition,frequency 24.0 GHz,learning (artificial intelligence),machine learning communities,microDoppler classification techniques,microDoppler radar data challenge,radar microDoppler signatures,radar sensors,radar signal processing,signal classification,signal processing}
    \endentry
    \entry{Ritchie:2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=540cdd13b96ebe8a6352345eccc518c6}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
        {{hash=25289088678a4ae9c74df9275c8ab269}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
        {{hash=66c5719530c7ee6ce430b377a1668ff7}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh\bibnamedelima D.},
           giveni={H\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \strng{namehash}{22e397b0e7939345a3796676f603b410}
      \strng{fullhash}{b49ab6bf488697d8054813445a2ea9d4}
      \strng{bibnamehash}{22e397b0e7939345a3796676f603b410}
      \strng{authorbibnamehash}{22e397b0e7939345a3796676f603b410}
      \strng{authornamehash}{22e397b0e7939345a3796676f603b410}
      \strng{authorfullhash}{b49ab6bf488697d8054813445a2ea9d4}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper evaluates the classification performance of a dual polarised on receive, 24 GHz Frequency Modulated Continuous Wave (FMCW) radar system to autonomously identify micro-Doppler signatures of unique hand gestures. We employ an Eigen subspace feature selection technique on the calculated signal subspace in order to classify each gesture. Measurements using the dual polarised radar, permitting simultaneous recording of both the co-pol and cross-pol returns, are evaluated with this processing technique and results are reported herein. Our analysis displays the challenges presented by the high variance in individuals gestures and the limited additional information the cross polarised returns have provided to the classifier. Classification performance comparisons are presented when co, cross and dual polarised data are provided to the classifier. With this technique we achieve autonomous classification performance of up to 84.6\% when Eigenvalue derived features are used for classification.}
      \field{booktitle}{International {Conference} on {Radar} {Systems} ({Radar} 2017)}
      \field{month}{10}
      \field{title}{{Hand gesture classification using 24 {GHz} {FMCW} dual polarised radar}}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1049/cp.2017.0482
      \endverb
      \keyw{autonomous classification performance,Autonomy,Classification,cross-pol returns,CW radar,Doppler radar,dual polarised data,Eigen subspace feature selection technique,eigenvalues and eigenfunctions,electromagnetic wave polarisation,FM radar,FMCW dual polarised radar,FMCW Radar,frequency 24.0 GHz,Frequency Modulated Continuous Wave radar system,frequency modulation,gesture recognition,hand gesture classification,Machine Learning,Micro-Doppler,microDoppler signatures,unique hand gestures}
    \endentry
    \entry{Rose:2012}{article}{}
      \name{author}{4}{}{%
        {{hash=f280bae8222f1c27535952e9609f8c78}{%
           family={Rose},
           familyi={R\bibinitperiod},
           given={Susan},
           giveni={S\bibinitperiod}}}%
        {{hash=b0d0ed9c4ec1b8af4ecd5acda7108d9e}{%
           family={Clark},
           familyi={C\bibinitperiod},
           given={Moira},
           giveni={M\bibinitperiod}}}%
        {{hash=b33a20ffb5f39b2ef8b04635b14533dc}{%
           family={Samouel},
           familyi={S\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod}}}%
        {{hash=51d16f38f86aa8ed883466b35edfdcd4}{%
           family={Hair},
           familyi={H\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{be37e0d507e6e9388ddafb50a79a328f}
      \strng{fullhash}{6d013c02a6b4999ed7753aa994662ca0}
      \strng{bibnamehash}{be37e0d507e6e9388ddafb50a79a328f}
      \strng{authorbibnamehash}{be37e0d507e6e9388ddafb50a79a328f}
      \strng{authornamehash}{be37e0d507e6e9388ddafb50a79a328f}
      \strng{authorfullhash}{6d013c02a6b4999ed7753aa994662ca0}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Retailing}
      \field{month}{06}
      \field{title}{{Online Customer Experience in e-Retailing: An empirical model of Antecedents and Outcomes}}
      \field{volume}{88}
      \field{year}{2012}
      \field{pages}{308\bibrangedash 322}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1016/j.jretai.2012.03.001
      \endverb
    \endentry
    \entry{Rovelo:2015}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=350f7ebe4f6867812d62783736cd827f}{%
           family={Rovelo},
           familyi={R\bibinitperiod},
           given={Gustavo},
           giveni={G\bibinitperiod}}}%
        {{hash=28b8dc2125f162cfcf13306467a36edb}{%
           family={Degraen},
           familyi={D\bibinitperiod},
           given={Donald},
           giveni={D\bibinitperiod}}}%
        {{hash=db6185a436e758c48042b71983ebab9f}{%
           family={Vanacken},
           familyi={V\bibinitperiod},
           given={Davy},
           giveni={D\bibinitperiod}}}%
        {{hash=eaedc4c9047adbd7811b2d7176c3f4ea}{%
           family={Luyten},
           familyi={L\bibinitperiod},
           given={Kris},
           giveni={K\bibinitperiod}}}%
        {{hash=fdcdbf70ab8110e6c8c0377e76c57943}{%
           family={Coninx},
           familyi={C\bibinitperiod},
           given={Karin},
           giveni={K\bibinitperiod}}}%
      }
      \name{editor}{6}{}{%
        {{hash=4f1268978d2059c4d9c2006944abe14e}{%
           family={Abascal},
           familyi={A\bibinitperiod},
           given={Julio},
           giveni={J\bibinitperiod}}}%
        {{hash=c0873fb0f4c286fedffb2a7399861fa0}{%
           family={Barbosa},
           familyi={B\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
        {{hash=c7f901812ac00710510bfef933952f84}{%
           family={Fetter},
           familyi={F\bibinitperiod},
           given={Mirko},
           giveni={M\bibinitperiod}}}%
        {{hash=3e527e16ebad7513b14e79589da2a516}{%
           family={Gross},
           familyi={G\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=91779e8d5b875867d491385500e54a30}{%
           family={Palanque},
           familyi={P\bibinitperiod},
           given={Philippe},
           giveni={P\bibinitperiod}}}%
        {{hash=b01e3ac9fd360e086fd265423db98670}{%
           family={Winckler},
           familyi={W\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{f1a26dc978867d47374aaea022fd21f4}
      \strng{fullhash}{a518aabc4074743483f67cbd6346b31e}
      \strng{bibnamehash}{f1a26dc978867d47374aaea022fd21f4}
      \strng{authorbibnamehash}{f1a26dc978867d47374aaea022fd21f4}
      \strng{authornamehash}{f1a26dc978867d47374aaea022fd21f4}
      \strng{authorfullhash}{a518aabc4074743483f67cbd6346b31e}
      \strng{editorbibnamehash}{b41aaf246c8e0d3dd66ccb1ce2182406}
      \strng{editornamehash}{b41aaf246c8e0d3dd66ccb1ce2182406}
      \strng{editorfullhash}{49d791fa5e2d6f313c1c7673ae970721}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present Gestu-Wan, an intelligible gesture guidance system designed to support mid-air gesture-based interaction for walk-up-and-use displays. Although gesture-based interfaces have become more prevalent, there is currently very little uniformity with regard to gesture sets and the way gestures can be executed. This leads to confusion, bad user experiences and users who rather avoid than engage in interaction using mid-air gesturing. Our approach improves the visibility of gesture-based interfaces and facilitates execution of mid-air gestures without prior training. We compare Gestu-Wan with a static gesture guide, which shows that it can help users with both performing complex gestures as well as understanding how the gesture recognizer works.}
      \field{booktitle}{Human-Computer Interaction -- INTERACT 2015}
      \field{isbn}{978-3-319-22668-2}
      \field{title}{{Gestu-Wan - An Intelligible Mid-Air Gesture Guidance System for Walk-up-and-Use Displays}}
      \field{year}{2015}
      \field{pages}{368\bibrangedash 386}
      \range{pages}{19}
    \endentry
    \entry{Roy:2013}{inbook}{}
      \name{author}{5}{}{%
        {{hash=e64cb7fa3e628c42e4f690c425db34c9}{%
           family={Roy},
           familyi={R\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=051c412b8725f741cd2a161ae05c9dd1}{%
           family={Malacria},
           familyi={M\bibinitperiod},
           given={Sylvain},
           giveni={S\bibinitperiod}}}%
        {{hash=06f21b7eac9abae799d3d5357e617685}{%
           family={Guiard},
           familyi={G\bibinitperiod},
           given={Yves},
           giveni={Y\bibinitperiod}}}%
        {{hash=38f0959fca525c7e663bd8795c1e53f0}{%
           family={Lecolinet},
           familyi={L\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=a65f03e6604ebd26e823e2f7cabf7e06}{%
           family={Eagan},
           familyi={E\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{f5e406e857dc47331749641c500ed772}
      \strng{fullhash}{b186a4fe2e609d73d30ef31a00d2bd57}
      \strng{bibnamehash}{f5e406e857dc47331749641c500ed772}
      \strng{authorbibnamehash}{f5e406e857dc47331749641c500ed772}
      \strng{authornamehash}{f5e406e857dc47331749641c500ed772}
      \strng{authorfullhash}{b186a4fe2e609d73d30ef31a00d2bd57}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus [9] by giving them natural, mnemonic associations. Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail. We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user's recall at no speed cost, and supports fluid transition from novice to expert mode. An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450318990}
      \field{title}{{Augmented Letters: Mnemonic Gesture-Based Shortcuts}}
      \field{year}{2013}
      \field{pages}{2325\bibrangedash 2328}
      \range{pages}{4}
      \verb{urlraw}
      \verb https://doi.org/10.1145/2470654.2481321
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2470654.2481321
      \endverb
    \endentry
    \entry{Rozman:2020}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=e377d6330335222d475eeef6bbfa220e}{%
           family={Rožman},
           familyi={R\bibinitperiod},
           given={Josip},
           giveni={J\bibinitperiod}}}%
        {{hash=f3f7bdaa0d4a024d3365ba80030be4dc}{%
           family={Hagras},
           familyi={H\bibinitperiod},
           given={Hani},
           giveni={H\bibinitperiod}}}%
        {{hash=f72dff9931fd1cc5058b5b16a515545b}{%
           family={Perez},
           familyi={P\bibinitperiod},
           given={Javier\bibnamedelima Andreu},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=58806c2190bcb686baf32b0d1e75256f}{%
           family={Clarke},
           familyi={C\bibinitperiod},
           given={Damien},
           giveni={D\bibinitperiod}}}%
        {{hash=9d870af63a6451d1629df69570442a52}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Beate},
           giveni={B\bibinitperiod}}}%
        {{hash=26bb841b8338e08af7b7548d88d2a570}{%
           family={Data},
           familyi={D\bibinitperiod},
           given={Steve\bibnamedelima Fitz},
           giveni={S\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{4e2e0fec36274577ef605d686694b5ca}
      \strng{fullhash}{f405414e4ff36f3d9dc8316ffe4ec6e0}
      \strng{bibnamehash}{4e2e0fec36274577ef605d686694b5ca}
      \strng{authorbibnamehash}{4e2e0fec36274577ef605d686694b5ca}
      \strng{authornamehash}{4e2e0fec36274577ef605d686694b5ca}
      \strng{authorfullhash}{f405414e4ff36f3d9dc8316ffe4ec6e0}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Smart homes are a growing market in need of privacy preserving sensors paired with explainable, interpretable and reliable control systems. The recent boom in Artificial Intelligence (AI) has seen an ever-growing persistence to incorporate it in all spheres of human life including the household. This growth in AI has been met with reciprocal concern for the privacy impacts and reluctance to introduce sensors, such as cameras, into homes. This concern has led to research of sensors not traditionally found in households, mainly short range radar. There has been also increasing awareness of AI transparency and explainability. Traditional AI black box models are not trusted, despite boasting high accuracy scores, due to the inability to understand what the decisions were based on. Interval Type-2 Fuzzy Logic offers a powerful alternative, achieving close to black box levels of performance while remaining completely interpretable. This paper presents a privacy preserving short range radar sensor coupled with an Explainable AI system employing a Big Bang Big Crunch (BB-BC) Interval Type-2 Fuzzy Logic System (FLS) to classify gestures performed in an indoor environment.}
      \field{booktitle}{2020 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})}
      \field{month}{7}
      \field{note}{ISSN: 1558-4739}
      \field{title}{Privacy-{Preserving} {Gesture} {Recognition} with {Explainable} {Type}-2 {Fuzzy} {Logic} {Based} {Systems}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/FUZZ48607.2020.9177768
      \endverb
      \keyw{artificial intelligence,Artificial intelligence,Big Bang - Big Crunch,big bang big crunch interval type-2 fuzzy logic system,cameras,data privacy,explainability,explainable AI system,Explainable Artificial Intelligence (XAI),explainable control systems,explainable type-2 fuzzy logic based systems,fuzzy logic,Fuzzy logic,fuzzy set theory,gesture recognition,growing market,high accuracy scores,human life,image classification,interpretable control systems,Privacy,privacy impacts,Privacy Preserving Sensing,privacy preserving sensors,privacy-preserving gesture recognition,Radar,reciprocal concern,reliable control systems,Sensors,short range radar sensor,smart homes,Three-dimensional displays,traditional AI black box models,Type-2 Fuzzy Logic,Uncertainty}
    \endentry
    \entry{Rubine:1991}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=df2eb0c25fb52838fa439d4541f5dcf3}{%
           family={Rubine},
           familyi={R\bibinitperiod},
           given={Dean},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \strng{fullhash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \strng{bibnamehash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \strng{authorbibnamehash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \strng{authornamehash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \strng{authorfullhash}{df2eb0c25fb52838fa439d4541f5dcf3}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques}
      \field{isbn}{0-89791-436-8}
      \field{series}{SIGGRAPH '91}
      \field{title}{{Specifying Gestures by Example}}
      \field{year}{1991}
      \field{pages}{329\bibrangedash 337}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/122718.122753
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/122718.122753
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/122718.122753
      \endverb
      \keyw{gesture,interaction techniques,statistical pattern recognition,user interface toolkits}
    \endentry
    \entry{Ruiz:2011}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=ff2387ab3a653bfbfb16efaf60b87362}{%
           family={Ruiz},
           familyi={R\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod}}}%
        {{hash=2af761d9bef859ea29248418adce0dd7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
        {{hash=00a0c9b4b79ef7bb84706b326b322efc}{%
           family={Lank},
           familyi={L\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \strng{fullhash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \strng{bibnamehash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \strng{authorbibnamehash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \strng{authornamehash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \strng{authorfullhash}{ce9274c8d4370cab68a8949b3b9a5d90}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Modern smartphones contain sophisticated sensors to monitor three-dimensional movement of the device. These sensors permit devices to recognize motion gestures - deliberate movements of the device by end-users to invoke commands. However, little is known about best-practices in motion gesture design for the mobile computing paradigm. To address this issue, we present the results of a guessability study that elicits end-user motion gestures to invoke commands on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally, we argue that our results influence best practices in design for all gestural interfaces.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450302289}
      \field{series}{CHI '11}
      \field{title}{{User-Defined Motion Gestures for Mobile Interaction}}
      \field{venue}{Vancouver, BC, Canada}
      \field{year}{2011}
      \field{pages}{197\bibrangedash 206}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1978942.1978971
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1978942.1978971
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1978942.1978971
      \endverb
      \keyw{mobile interaction,motion gestures,sensors}
    \endentry
    \entry{Ryu:2018}{article}{}
      \name{author}{5}{}{%
        {{hash=10de65e45d48cdb0e510fc58e9022061}{%
           family={Ryu},
           familyi={R\bibinitperiod},
           given={Si-Jung},
           giveni={S\bibinithyphendelim J\bibinitperiod}}}%
        {{hash=10fad9b7852e420f207c53deb05800c0}{%
           family={Suh},
           familyi={S\bibinitperiod},
           given={Jun-Seuk},
           giveni={J\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=5f464a95b336dde1f2724947235d4800}{%
           family={Baek},
           familyi={B\bibinitperiod},
           given={Seung-Hwan},
           giveni={S\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=d47fcf23af3fa855a5d5dfffde635a07}{%
           family={Hong},
           familyi={H\bibinitperiod},
           given={Songcheol},
           giveni={S\bibinitperiod}}}%
        {{hash=d736303e6fdf4a44d4d501a0f1e14c5b}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Jong-Hwan},
           giveni={J\bibinithyphendelim H\bibinitperiod}}}%
      }
      \strng{namehash}{7c5706b0541b305156b94e1f5f7bb0a9}
      \strng{fullhash}{876e1b72b474b42ed7b713e594ab1cee}
      \strng{bibnamehash}{7c5706b0541b305156b94e1f5f7bb0a9}
      \strng{authorbibnamehash}{7c5706b0541b305156b94e1f5f7bb0a9}
      \strng{authornamehash}{7c5706b0541b305156b94e1f5f7bb0a9}
      \strng{authorfullhash}{876e1b72b474b42ed7b713e594ab1cee}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, feature-based gesture recognition in a frequency modulated continuous wave (FMCW) radar system is introduced. We obtain a range-Doppler map (RDM) from raw signals of FMCW radar and generate a variety of features from the RDM. The features are broadly defined to reflect radar-specific characteristics as well as statistical values commonly used in machine learning. Among these radar features, those that are highly correlated with gesture recognition are selected by the proposed feature selection algorithm, which is a wrapper-based feature selection algorithm incorporated with a quantum-inspired evolutionary algorithm (QEA). Furthermore, the information factor based on the minimum redundancy maximum relevance criterion is applied to QEA in order to find feature subsets effectively. The proposed algorithm is able to extract from all feature sets feature subsets related to gesture recognition, and improves the gesture recognition accuracy of the FMCW radar system. In addition, we analyze which features of the radar are helpful for gesture recognition and perform effective gesture recognition using the features determined through feature analysis.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{9}
      \field{number}{18}
      \field{title}{Feature-{Based} {Hand} {Gesture} {Recognition} {Using} an {FMCW} {Radar} and its {Temporal} {Feature} {Analysis}}
      \field{volume}{18}
      \field{year}{2018}
      \field{pages}{7593\bibrangedash 7602}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/JSEN.2018.2859815
      \endverb
      \keyw{continuous wave radar system,CW radar,evolutionary algorithm,evolutionary computation,feature analysis,feature extraction,Feature extraction,feature selection,feature subsets,feature-based hand gesture recognition,FM radar,FMCW radar,FMCW radar system,gesture recognition,Gesture recognition,gesture recognition accuracy,learning (artificial intelligence),Machine learning,military computing,minimum redundancy maximum relevance criterion,quantum-inspired evolutionary algorithm,Radar,Radar antennas,radar features,radar-specific characteristics,range-Doppler map,RDM,Sensors,temporal feature,Two dimensional displays,wrapper-based feature selection algorithm}
    \endentry
    \entry{Sadik:2017}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=e105cb17993dff2526428c0303621775}{%
           family={Sadik},
           familyi={S\bibinitperiod},
           given={Ahmed\bibnamedelima R.},
           giveni={A\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=daff10afccca6dc559ddfa452d1dbdd4}{%
           family={Urban},
           familyi={U\bibinitperiod},
           given={Bodo},
           giveni={B\bibinitperiod}}}%
        {{hash=2c16c33456720bb3414ad200fe829b56}{%
           family={Adel},
           familyi={A\bibinitperiod},
           given={Omar},
           giveni={O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{cc598ad4f8507b4d91b70e88d1433576}
      \strng{fullhash}{cc598ad4f8507b4d91b70e88d1433576}
      \strng{bibnamehash}{cc598ad4f8507b4d91b70e88d1433576}
      \strng{authorbibnamehash}{cc598ad4f8507b4d91b70e88d1433576}
      \strng{authornamehash}{cc598ad4f8507b4d91b70e88d1433576}
      \strng{authorfullhash}{cc598ad4f8507b4d91b70e88d1433576}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 3rd International Conference on Mechatronics and Robotics Engineering}
      \field{isbn}{9781450352802}
      \field{series}{ICMRE 2017}
      \field{title}{{Using Hand Gestures to Interact with an Industrial Robot in a Cooperative Flexible Manufacturing Scenario}}
      \field{venue}{Paris, France}
      \field{year}{2017}
      \field{pages}{11\bibrangedash 16}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3068796.3068801
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3068796.3068801
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3068796.3068801
      \endverb
      \keyw{Flexible Manufacturing Paradigm,Worker-Industrial Robot Cooperation,Semi-Autonomous Systems}
    \endentry
    \entry{Sakamoto:2018}{article}{}
      \name{author}{6}{}{%
        {{hash=6c0a4406620c7203af08f3939fc44d0f}{%
           family={Sakamoto},
           familyi={S\bibinitperiod},
           given={Takuya},
           giveni={T\bibinitperiod}}}%
        {{hash=6460e8596f0a49a541d07e2368038b6f}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Xiaomeng},
           giveni={X\bibinitperiod}}}%
        {{hash=66f7e9b25a67f10425dd9123c44080a6}{%
           family={Yavari},
           familyi={Y\bibinitperiod},
           given={Ehsan},
           giveni={E\bibinitperiod}}}%
        {{hash=1153940308b1083f537810d734a3949e}{%
           family={Rahman},
           familyi={R\bibinitperiod},
           given={Ashikur},
           giveni={A\bibinitperiod}}}%
        {{hash=5b162d31f69edcbe64837b5856c0532f}{%
           family={Boric-Lubecke},
           familyi={B\bibinithyphendelim L\bibinitperiod},
           given={Olga},
           giveni={O\bibinitperiod}}}%
        {{hash=2d8fae27aa57bc2ef21a9c4ad46461df}{%
           family={Lubecke},
           familyi={L\bibinitperiod},
           given={Victor\bibnamedelima M.},
           giveni={V\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{fullhash}{26eccffb68eff53ace7689224d306787}
      \strng{bibnamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authorbibnamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authornamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authorfullhash}{26eccffb68eff53ace7689224d306787}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a hand gesture recognition technique using a convolutional neural network applied to radar echo inphase/quadrature (I/Q) plot trajectories. The proposed technique is demonstrated to accurately recognize six types of hand gestures for ten participants. The system consists of a low-cost 2.4-GHz continuous-wave monostatic radar with a single antenna. The radar echo trajectories are converted to low-resolution images and are used for the training and evaluation of the proposed technique. Results indicate that the proposed technique can recognize hand gestures with average accuracy exceeding 90\%.}
      \field{issn}{2475-1472}
      \field{journaltitle}{IEEE Sensors Letters}
      \field{month}{9}
      \field{number}{3}
      \field{title}{Hand {Gesture} {Recognition} {Using} a {Radar} {Echo} {I}–{Q} {Plot} and a {Convolutional} {Neural} {Network}}
      \field{volume}{2}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/LSENS.2018.2866371
      \endverb
      \keyw{Atmospheric measurements,continuous-wave monostatic radar,convolutional neural network,CW radar,echo,feedforward neural nets,frequency 2.4 GHz,gesture recognition,Gesture recognition,hand gesture recognition technique,low-resolution images,machine learning,neural network,Particle measurements,radar,radar antenna,radar antennas,Radar antennas,radar echo I-Q plot,radar echo inphase-quadrature plot trajectories,radar echo trajectories,Radar imaging,radar resolution,Sensor signals processing,Training,UHF antennas}
    \endentry
    \entry{Sakamoto:2017}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=6c0a4406620c7203af08f3939fc44d0f}{%
           family={Sakamoto},
           familyi={S\bibinitperiod},
           given={Takuya},
           giveni={T\bibinitperiod}}}%
        {{hash=6460e8596f0a49a541d07e2368038b6f}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Xiaomeng},
           giveni={X\bibinitperiod}}}%
        {{hash=66f7e9b25a67f10425dd9123c44080a6}{%
           family={Yavari},
           familyi={Y\bibinitperiod},
           given={Ehsan},
           giveni={E\bibinitperiod}}}%
        {{hash=1153940308b1083f537810d734a3949e}{%
           family={Rahman},
           familyi={R\bibinitperiod},
           given={Ashikur},
           giveni={A\bibinitperiod}}}%
        {{hash=5b162d31f69edcbe64837b5856c0532f}{%
           family={Boric-Lubecke},
           familyi={B\bibinithyphendelim L\bibinitperiod},
           given={Olga},
           giveni={O\bibinitperiod}}}%
        {{hash=2d8fae27aa57bc2ef21a9c4ad46461df}{%
           family={Lubecke},
           familyi={L\bibinitperiod},
           given={Victor\bibnamedelima M.},
           giveni={V\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{fullhash}{26eccffb68eff53ace7689224d306787}
      \strng{bibnamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authorbibnamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authornamehash}{b06c02ea56e57f21a8a39e5843a7f71b}
      \strng{authorfullhash}{26eccffb68eff53ace7689224d306787}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The present paper proposes a technique for the automatic recognition of hand gestures using a 2.4-GHz continuous radar and a convolutional neural network. The proposed technique applies the neural network to the time-domain I-Q plot of radar echoes. The accurate recognition capability of the technique was established with a set of radar data for three types of hand gesture performed by a participant. The radar echo trajectories were converted to low-resolution images to achieve fast signal processing, and the neural network was trained using the images. Another set of I-Q plot images were used for the evaluation of the recognition accuracy. The results indicate that the proposed technique is able to recognize hand gestures with accuracy exceeding 90\%.}
      \field{booktitle}{2017 {IEEE} {Conference} on {Antenna} {Measurements} {Applications} ({CAMA})}
      \field{month}{12}
      \field{title}{{Radar-based hand gesture recognition using {I}-{Q} echo plot and convolutional neural network}}
      \field{year}{2017}
      \field{pages}{393\bibrangedash 395}
      \range{pages}{3}
      \verb{doi}
      \verb 10.1109/CAMA.2017.8273461
      \endverb
      \keyw{Atmospheric measurements,automatic recognition,classification,continuous radar,convolutional neural network,echo,gesture recognition,Gesture recognition,hand gesture,hand gesture recognition,image resolution,low-resolution images,neural nets,Particle measurements,radar,radar computing,radar data,radar echo trajectories,radar echoes,radar imaging,Radar imaging,recognition accuracy,recognition capability,Sensors,signal processing,Time-domain analysis,time-domain I-Q plot}
    \endentry
    \entry{Santhalingam:2020a}{inproceedings}{}
      \name{author}{8}{}{%
        {{hash=9dfc0ecdbece18fb6328d3cd07896e01}{%
           family={Santhalingam},
           familyi={S\bibinitperiod},
           given={Panneer\bibnamedelima Selvam},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=16ba464b4b0d4d57bcb1466a73a1b7ba}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Yuanqi},
           giveni={Y\bibinitperiod}}}%
        {{hash=f91adb1b28b8035cc896642a5ca06619}{%
           family={Wilkerson},
           familyi={W\bibinitperiod},
           given={Riley},
           giveni={R\bibinitperiod}}}%
        {{hash=ac2c7e0b1ac8932229dac434ccbd1d6c}{%
           family={Hosain},
           familyi={H\bibinitperiod},
           given={Al\bibnamedelima Amin},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=ef27c8582388b1eabd145df2e5fd1e03}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ding},
           giveni={D\bibinitperiod}}}%
        {{hash=8b389c989cd4570cd60badf5ec671d65}{%
           family={Pathak},
           familyi={P\bibinitperiod},
           given={Parth},
           giveni={P\bibinitperiod}}}%
        {{hash=0ff90664306811aa5274b0953c6c1e09}{%
           family={Rangwala},
           familyi={R\bibinitperiod},
           given={Huzefa},
           giveni={H\bibinitperiod}}}%
        {{hash=471a72c0219f7bfc466e510e64bfea97}{%
           family={Kushalnagar},
           familyi={K\bibinitperiod},
           given={Raja},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{fullhash}{220197d7bb0aa967dfd4c1c6b95649e4}
      \strng{bibnamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authorbibnamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authornamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authorfullhash}{220197d7bb0aa967dfd4c1c6b95649e4}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Over half a million people in the United States use American Sign Language (ASL) as their primary mode of communication. Automatic ASL recognition would enable Deaf and Hard of Hearing (DHH) users to interact with others who are not familiar with ASL as well as voice-controlled digital assistants (e.g., Alexa, Siri, etc.). While ASL recognition has been extensively studied, there is a little attention given to recognition of ASL non-manual body markers. The non-manual markers are typically expressed through head, torso and shoulder movements, and add essential meaning and context to the signed sentences. In this work, we present ExASL, a sentence-level ASL recognition system using millimeter-wave radars. ExASL can recognize manual markers (hand gestures) and non-manual markers (head and torso movements). It utilizes multi-distance clustering to recognize body parts and cluster mmWave point clouds. We then present a multi-view deep learning algorithm that can learn from clustered body part representation for an expressive sentence-level recognition. Our evaluation shows that ExASL can recognize ASL sentences with a word error rate of 0.79\%, sentence error rate of 1.25\%, and non-manual markers with an accuracy of 83.5\%.}
      \field{booktitle}{2020 17th {Annual} {IEEE} {International} {Conference} on {Sensing}, {Communication}, and {Networking} ({SECON})}
      \field{month}{6}
      \field{note}{ISSN: 2155-5494}
      \field{title}{Expressive {ASL} {Recognition} using {Millimeter}-wave {Wireless} {Signals}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 9}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/SECON48991.2020.9158441
      \endverb
      \keyw{American Sign Language,ASL nonmanual body markers,ASL sentences,automatic ASL recognition,body parts,Chirp,clustered body part representation,ExASL,expressive ASL recognition,expressive sentence-level recognition,feature extraction,gesture recognition,half a million people,handicapped aids,knowledge based systems,learning (artificial intelligence),Machine learning,manual markers,Manuals,millimeter-wave radars,millimeter-wave wireless signals,nonmanual markers,Radar,Sensors,sentence-level ASL recognition,shoulder movements,signed sentences,Three-dimensional displays,Torso,torso movements,United States,voice-controlled digital assistants}
    \endentry
    \entry{Santhalingam:2020b}{article}{}
      \name{author}{6}{}{%
        {{hash=9dfc0ecdbece18fb6328d3cd07896e01}{%
           family={Santhalingam},
           familyi={S\bibinitperiod},
           given={Panneer\bibnamedelima Selvam},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=ac2c7e0b1ac8932229dac434ccbd1d6c}{%
           family={Hosain},
           familyi={H\bibinitperiod},
           given={Al\bibnamedelima Amin},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=ef27c8582388b1eabd145df2e5fd1e03}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ding},
           giveni={D\bibinitperiod}}}%
        {{hash=8b389c989cd4570cd60badf5ec671d65}{%
           family={Pathak},
           familyi={P\bibinitperiod},
           given={Parth},
           giveni={P\bibinitperiod}}}%
        {{hash=0ff90664306811aa5274b0953c6c1e09}{%
           family={Rangwala},
           familyi={R\bibinitperiod},
           given={Huzefa},
           giveni={H\bibinitperiod}}}%
        {{hash=471a72c0219f7bfc466e510e64bfea97}{%
           family={Kushalnagar},
           familyi={K\bibinitperiod},
           given={Raja},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{fullhash}{dfe035c0530bcc3bb0cfce5897c0ba76}
      \strng{bibnamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authorbibnamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authornamehash}{fe41085603a4e067ca389c1533a36ffd}
      \strng{authorfullhash}{dfe035c0530bcc3bb0cfce5897c0ba76}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Home assistant devices such as Amazon Echo and Google Home have become tremendously popular in the last couple of years. However, due to their voice-controlled functionality, these devices are not accessible to Deaf and Hard-of-Hearing (DHH) people. Given that over half a million people in the United States communicate using American Sign Language (ASL), there is a need of a home assistant system that can recognize ASL. The objective of this work is to design a home assistant system for DHH users (referred to as mmASL) that can perform ASL recognition using 60 GHz millimeter-wave wireless signals. mmASL has two important components. First, it can perform reliable wake-word detection using spatial spectrograms. Second, using a scalable and extensible multi-task deep learning model, mmASL can learn the phonological properties of ASL signs and use them to accurately recognize the ASL signs. We implement mmASL on 60 GHz software radio platform with phased array, and evaluate it using a large-scale data collection from 15 signers, 50 ASL signs and over 12K sign instances. We show that mmASL is tolerant to the presence of other interfering users and their activities, change of environment and different user positions. We compare mmASL with a well-studied Kinect and RGB camera based ASL recognition systems, and find that it can achieve a comparable performance (87\% average accuracy of sign recognition), validating the feasibility of using 60 GHz mmWave system for ASL sign recognition.}
      \field{journaltitle}{Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}
      \field{month}{3}
      \field{number}{1}
      \field{shorttitle}{{mmASL}}
      \field{title}{{mmASL}: {Environment}-{Independent} {ASL} {Gesture} {Recognition} {Using} 60 {GHz} {Millimeter}-wave {Signals}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{4}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{26:1\bibrangedash 26:30}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1145/3381010
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3381010
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3381010
      \endverb
      \keyw{60 GHz milli-meter wave wireless,accessible computing,gesture recognition,personal digital assistants,sign language recognition}
    \endentry
    \entry{Sauro:2010}{book}{}
      \name{author}{1}{}{%
        {{hash=f24e1723133e0393dfd185716f640bed}{%
           family={Sauro},
           familyi={S\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Measuring Usability LCC}%
      }
      \strng{namehash}{f24e1723133e0393dfd185716f640bed}
      \strng{fullhash}{f24e1723133e0393dfd185716f640bed}
      \strng{bibnamehash}{f24e1723133e0393dfd185716f640bed}
      \strng{authorbibnamehash}{f24e1723133e0393dfd185716f640bed}
      \strng{authornamehash}{f24e1723133e0393dfd185716f640bed}
      \strng{authorfullhash}{f24e1723133e0393dfd185716f640bed}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{A practical guide to measuring usability: 72 answers to the most common questions about quantifying the usability of websites and software}}
      \field{year}{2010}
    \endentry
    \entry{Schak:2019}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=ecfeafe3f1284443fe22d74de06c8058}{%
           family={Schak},
           familyi={S\bibinitperiod},
           given={Monika},
           giveni={M\bibinitperiod}}}%
        {{hash=1cef476a3dbd4ce41e80c4b77903d3f5}{%
           family={Gepperth},
           familyi={G\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=c352624b4978fab7d1398673d0c37ce6}{%
           family={Tetko},
           familyi={T\bibinitperiod},
           given={Igor\bibnamedelima V.},
           giveni={I\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=13b2985652b3c9d12bb44aaca31036a8}{%
           family={Kůrková},
           familyi={K\bibinitperiod},
           given={Věra},
           giveni={V\bibinitperiod}}}%
        {{hash=5f11541c7d016622a20f905eff3aaee7}{%
           family={Karpov},
           familyi={K\bibinitperiod},
           given={Pavel},
           giveni={P\bibinitperiod}}}%
        {{hash=24d199cc8e29bf565fa2f1514d969e86}{%
           family={Theis},
           familyi={T\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{fab868df14922153229b111dd6407c0e}
      \strng{fullhash}{fab868df14922153229b111dd6407c0e}
      \strng{bibnamehash}{fab868df14922153229b111dd6407c0e}
      \strng{authorbibnamehash}{fab868df14922153229b111dd6407c0e}
      \strng{authornamehash}{fab868df14922153229b111dd6407c0e}
      \strng{authorfullhash}{fab868df14922153229b111dd6407c0e}
      \strng{editorbibnamehash}{5ba39431eb34e691b81fd88651fbcb7f}
      \strng{editornamehash}{5ba39431eb34e691b81fd88651fbcb7f}
      \strng{editorfullhash}{5c7d8521c1da983f8f3e97b639e8ebce}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a systematic study of Catastrophic Forgetting (CF), i.e., the abrupt loss of previously acquired knowledge, when retraining deep recurrent LSTM networks with new samples. CF has recently received renewed attention in the case of feed-forward DNNs, and this article is the first work that aims to rigorously establish whether deep LSTM networks are afflicted by CF as well, and to what degree. In order to test this fully, training is conducted using a wide variety of high-dimensional image-based sequence classification tasks derived from established visual classification benchmarks (MNIST, Devanagari, FashionMNIST and EMNIST). We find that the CF effect occurs universally, without exception, for deep LSTM-based sequence classifiers, regardless of the construction and provenance of sequences. This leads us to conclude that LSTMs, just like DNNs, are fully affected by CF, and that further research work needs to be conducted in order to determine how to avoid this effect (which is not a goal of this study).}
      \field{booktitle}{Artificial Neural Networks and Machine Learning -- ICANN 2019: Deep Learning}
      \field{isbn}{978-3-030-30484-3}
      \field{title}{A Study on Catastrophic Forgetting in Deep LSTM Networks}
      \field{year}{2019}
      \field{pages}{714\bibrangedash 728}
      \range{pages}{15}
    \endentry
    \entry{Schioppo:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=ec02314c2a8359a189de9394ce5a20b8}{%
           family={Schioppo},
           familyi={S\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod}}}%
        {{hash=9d0d5cd1f8319267f1f08f3c2377cbb9}{%
           family={Meyer},
           familyi={M\bibinitperiod},
           given={Zachary},
           giveni={Z\bibinitperiod}}}%
        {{hash=176d941aee540d6a2eb46510297cb02e}{%
           family={Fabiano},
           familyi={F\bibinitperiod},
           given={Diego},
           giveni={D\bibinitperiod}}}%
        {{hash=73e222983122e08f00a10f0ea7f1536f}{%
           family={Canavan},
           familyi={C\bibinitperiod},
           given={Shaun},
           giveni={S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{785e50f2008175ad7e11d07faa7747db}
      \strng{fullhash}{83785a2dcab9f47168b7be9c0c005120}
      \strng{bibnamehash}{785e50f2008175ad7e11d07faa7747db}
      \strng{authorbibnamehash}{785e50f2008175ad7e11d07faa7747db}
      \strng{authornamehash}{785e50f2008175ad7e11d07faa7747db}
      \strng{authorfullhash}{83785a2dcab9f47168b7be9c0c005120}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Extended Abstracts of the ACM Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450359719}
      \field{series}{CHI EA '19}
      \field{title}{{Sign Language Recognition: Learning American Sign Language in a Virtual Environment}}
      \field{venue}{Glasgow, Scotland Uk}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3290607.3313025
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3290607.3313025
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3290607.3313025
      \endverb
      \keyw{classification,sign language,gesture,virtual reality}
    \endentry
    \entry{Schrepp:2017}{article}{}
      \name{author}{3}{}{%
        {{hash=131c7fe2089d9229c28f4e7a09b3a096}{%
           family={Schrepp},
           familyi={S\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
        {{hash=9aa46ba977c60b7e085ab820b41df600}{%
           family={Hinderks},
           familyi={H\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=f3bf7546743b7280490d85d6c7818717}{%
           family={Thomaschewski},
           familyi={T\bibinitperiod},
           given={Jörg},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{446252976774aa02d4e2b844f472a622}
      \strng{fullhash}{446252976774aa02d4e2b844f472a622}
      \strng{bibnamehash}{446252976774aa02d4e2b844f472a622}
      \strng{authorbibnamehash}{446252976774aa02d4e2b844f472a622}
      \strng{authornamehash}{446252976774aa02d4e2b844f472a622}
      \strng{authorfullhash}{446252976774aa02d4e2b844f472a622}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Journal of Interactive Multimedia and Artificial Intelligence}
      \field{month}{06}
      \field{title}{{Construction of a Benchmark for the User Experience Questionnaire (UEQ)}}
      \field{volume}{4}
      \field{year}{2017}
      \field{pages}{40\bibrangedash 44}
      \range{pages}{5}
      \verb{doi}
      \verb 10.9781/ijimai.2017.445
      \endverb
    \endentry
    \entry{Pandian:2020}{misc}{}
      \name{author}{2}{}{%
        {{hash=c054deee01e297b1962dfe28044f91c0}{%
           family={Sermuga\bibnamedelima Pandian},
           familyi={S\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Vinoth\bibnamedelima Pandian},
           giveni={V\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=dabed0eeaedbe6599e8c693cb343def7}{%
           family={Suleri},
           familyi={S\bibinitperiod},
           given={Sarah},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \strng{fullhash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \strng{bibnamehash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \strng{authorbibnamehash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \strng{authornamehash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \strng{authorfullhash}{bf59e1c2a636e94d191c2f323e0cf04b}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.HC}
      \field{eprinttype}{arXiv}
      \field{title}{{NASA-TLX Web App: An Online Tool to Analyse Subjective Workload}}
      \field{year}{2020}
      \verb{eprint}
      \verb 2001.09963
      \endverb
    \endentry
    \entry{Sheng:2004}{report}{}
      \name{author}{1}{}{%
        {{hash=f7f40a5c1ca043360503126ca6d69477}{%
           family={Sheng},
           familyi={S\bibinitperiod},
           given={Jia},
           giveni={J\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {Department of Computer Science, University of Toronto}%
      }
      \strng{namehash}{f7f40a5c1ca043360503126ca6d69477}
      \strng{fullhash}{f7f40a5c1ca043360503126ca6d69477}
      \strng{bibnamehash}{f7f40a5c1ca043360503126ca6d69477}
      \strng{authorbibnamehash}{f7f40a5c1ca043360503126ca6d69477}
      \strng{authornamehash}{f7f40a5c1ca043360503126ca6d69477}
      \strng{authorfullhash}{f7f40a5c1ca043360503126ca6d69477}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{number}{CSC2515}
      \field{title}{{A Study of AdaBoost in 3D Gesture Recognition}}
      \field{type}{technical report}
      \field{year}{2004}
      \verb{urlraw}
      \verb http://www.dgp.toronto.edu/~jsheng/doc/CSC2515/Report.pdf
      \endverb
      \verb{url}
      \verb http://www.dgp.toronto.edu/~jsheng/doc/CSC2515/Report.pdf
      \endverb
    \endentry
    \entry{Shneiderman:1992}{article}{}
      \name{author}{1}{}{%
        {{hash=39afccc0f55ae7821df79ffd677c90b0}{%
           family={Shneiderman},
           familyi={S\bibinitperiod},
           given={Ben},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{39afccc0f55ae7821df79ffd677c90b0}
      \strng{fullhash}{39afccc0f55ae7821df79ffd677c90b0}
      \strng{bibnamehash}{39afccc0f55ae7821df79ffd677c90b0}
      \strng{authorbibnamehash}{39afccc0f55ae7821df79ffd677c90b0}
      \strng{authornamehash}{39afccc0f55ae7821df79ffd677c90b0}
      \strng{authorfullhash}{39afccc0f55ae7821df79ffd677c90b0}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0730-0301}
      \field{journaltitle}{ACM Trans. Graph.}
      \field{month}{1}
      \field{number}{1}
      \field{title}{{Tree Visualization with Tree-Maps: 2-d Space-Filling Approach}}
      \field{volume}{11}
      \field{year}{1992}
      \field{pages}{92\bibrangedash 99}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/102377.115768
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/102377.115768
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/102377.115768
      \endverb
    \endentry
    \entry{Siddhpuria:2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=9a4ed9b21b5216e72ebb6ef2595a2087}{%
           family={Siddhpuria},
           familyi={S\bibinitperiod},
           given={Shaishav},
           giveni={S\bibinitperiod}}}%
        {{hash=b290fe36a1bb49c9047099b7d418dbc0}{%
           family={Katsuragawa},
           familyi={K\bibinitperiod},
           given={Keiko},
           giveni={K\bibinitperiod}}}%
        {{hash=15f67efe2da5190bd0a9cc5850532aa2}{%
           family={Wallace},
           familyi={W\bibinitperiod},
           given={James\bibnamedelima R.},
           giveni={J\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=00a0c9b4b79ef7bb84706b326b322efc}{%
           family={Lank},
           familyi={L\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{0ec5824653f9635cbefcabe23d5de269}
      \strng{fullhash}{6a82db23d6af29ec28a60ed8c80bbf2d}
      \strng{bibnamehash}{0ec5824653f9635cbefcabe23d5de269}
      \strng{authorbibnamehash}{0ec5824653f9635cbefcabe23d5de269}
      \strng{authornamehash}{0ec5824653f9635cbefcabe23d5de269}
      \strng{authorfullhash}{6a82db23d6af29ec28a60ed8c80bbf2d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Free-space gestural systems are faced with two major issues: a lack of subtlety due to explicit mid-air arm movements, and the highly effortful nature of such interactions. With an ever-growing ubiquity of interactive devices, displays, and appliances with non-standard interfaces, lower-effort and more socially acceptable interaction paradigms are essential. To address these issues, we explore at-one's-side gestural input. Within this space, we present the results of two studies that investigate the use of side-gesture input for interaction. First, we investigate end-user preference through a gesture elicitation study, present a gesture set, and validate the need for dynamic, diverse, and variable-length gestures. We then explore the feasibility of designing such a gesture recognition system, dubbed WatchTrace, which supports alphanumeric gestures of up to length three with an average accuracy of up to 82\%, providing a rich, dynamic, and feasible gestural vocabulary.}
      \field{booktitle}{Proceedings of the 2017 Conference on Designing Interactive Systems}
      \field{isbn}{9781450349222}
      \field{series}{DIS '17}
      \field{title}{{Exploring At-Your-Side Gestural Interaction for Ubiquitous Environments}}
      \field{venue}{Edinburgh, United Kingdom}
      \field{year}{2017}
      \field{pages}{1111\bibrangedash 1122}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3064663.3064695
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3064663.3064695
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3064663.3064695
      \endverb
      \keyw{ubiquitous computing,gestures,large displays,smartwatch}
    \endentry
    \entry{Siean:2022}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=679a5fa1a7137e0aee75ea6cf922198f}{%
           family={Siean},
           familyi={S\bibinitperiod},
           given={Alexandru-Ionut},
           giveni={A\bibinithyphendelim I\bibinitperiod}}}%
        {{hash=0cbbdc249b513a00f7751a9d9bdaf73f}{%
           family={Pamparău},
           familyi={P\bibinitperiod},
           given={Cristian},
           giveni={C\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{2934a8f84181cc979cdf60ef17eb9927}
      \strng{fullhash}{2934a8f84181cc979cdf60ef17eb9927}
      \strng{bibnamehash}{2934a8f84181cc979cdf60ef17eb9927}
      \strng{authorbibnamehash}{2934a8f84181cc979cdf60ef17eb9927}
      \strng{authornamehash}{2934a8f84181cc979cdf60ef17eb9927}
      \strng{authorfullhash}{2934a8f84181cc979cdf60ef17eb9927}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We address gesture input for TV control, for which we examine mid-air free-hand interactions that can be detected via radar sensing. We adopt a scenario-based design approach to explore possible locations from the living room where to integrate radar sensors, e.g., in the TV set, the couch armrest, or the user’s smartphone, and we contribute a four-level taxonomy of locations relative to the TV set, the user, personal robot assistants, and the living room environment, respectively. We also present preliminary results about an interactive system using a 15-antenna ultra-wideband 3D radar, for which we implemented a dictionary of six directional swipe gestures for the control of dichotomous TV system functions.}
      \field{booktitle}{Proceedings of ACM International Conference on Interactive Media Experiences}
      \field{isbn}{9781450392129}
      \field{series}{IMX '22}
      \field{title}{{Scenario-Based Exploration of Integrating Radar Sensing into Everyday Objects for Free-Hand Television Control}}
      \field{venue}{Aveiro, JB, Portugal}
      \field{year}{2022}
      \field{pages}{357\bibrangedash 362}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1145/3505284.3532982
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3505284.3532982
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3505284.3532982
      \endverb
      \keyw{mid-air gestures,free-hand input,Gesture input,remote control,TV}
    \endentry
    \entry{Siean:2023}{article}{}
      \name{author}{5}{}{%
        {{hash=679a5fa1a7137e0aee75ea6cf922198f}{%
           family={Siean},
           familyi={S\bibinitperiod},
           given={Alexandru-Ionut},
           giveni={A\bibinithyphendelim I\bibinitperiod}}}%
        {{hash=0cbbdc249b513a00f7751a9d9bdaf73f}{%
           family={Pamparău},
           familyi={P\bibinitperiod},
           given={Cristian},
           giveni={C\bibinitperiod}}}%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{9ebb4cb7af38de6fcf2f399092650232}
      \strng{fullhash}{35796bb20e73113c597409b8e2133c06}
      \strng{bibnamehash}{9ebb4cb7af38de6fcf2f399092650232}
      \strng{authorbibnamehash}{9ebb4cb7af38de6fcf2f399092650232}
      \strng{authornamehash}{9ebb4cb7af38de6fcf2f399092650232}
      \strng{authorfullhash}{35796bb20e73113c597409b8e2133c06}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Ambient Intelligence and Humanized Computing}
      \field{title}{{Flexible gesture input with radars: systematic literature review and taxonomy of radar sensing integration in ambient intelligence environments}}
      \field{year}{2023}
      \verb{doi}
      \verb 10.1007/s12652-023-04606-9
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/article/10.1007/s12652-023-04606-9
      \endverb
      \verb{url}
      \verb https://link.springer.com/article/10.1007/s12652-023-04606-9
      \endverb
    \endentry
    \entry{Signer:2007}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=a18da28eb6ccc0ba30dd9e4d58dda3e5}{%
           family={Signer},
           familyi={S\bibinitperiod},
           given={Beat},
           giveni={B\bibinitperiod}}}%
        {{hash=0ae0649fdf88e136f490cf5c71d234f6}{%
           family={Kurmann},
           familyi={K\bibinitperiod},
           given={Ueli},
           giveni={U\bibinitperiod}}}%
        {{hash=88e22618df6cb769735eacd5a19e7f4b}{%
           family={Norrie},
           familyi={N\bibinitperiod},
           given={Moira\bibnamedelima C.},
           giveni={M\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {{IEEE} Computer Society}%
      }
      \strng{namehash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \strng{fullhash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \strng{bibnamehash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \strng{authorbibnamehash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \strng{authornamehash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \strng{authorfullhash}{d01a69c36f2f2d5e80d637eae2d5ac25}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{9th International Conference on Document Analysis and Recognition {(ICDAR} 2007), 23-26 September, Curitiba, Paraná, Brazil}
      \field{title}{{iGesture: A General Gesture Recognition Framework}}
      \field{year}{2007}
      \field{pages}{954\bibrangedash 958}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICDAR.2007.4377056
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1109/ICDAR.2007.4377056
      \endverb
      \verb{url}
      \verb https://doi.org/10.1109/ICDAR.2007.4377056
      \endverb
    \endentry
    \entry{Simos:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=6b210046fdc9f5ac24430feac4cda824}{%
           family={Simos},
           familyi={S\bibinitperiod},
           given={Merkourios},
           giveni={M\bibinitperiod}}}%
        {{hash=c5fdc11682c4ce963117c8a846bff805}{%
           family={Nikolaidis},
           familyi={N\bibinitperiod},
           given={Nikolaos},
           giveni={N\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \strng{fullhash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \strng{bibnamehash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \strng{authorbibnamehash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \strng{authornamehash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \strng{authorfullhash}{c8bcf872dc96d1e42ed4fa0948076ed3}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 9th Hellenic Conference on Artificial Intelligence}
      \field{isbn}{9781450337342}
      \field{series}{SETN '16}
      \field{title}{{Greek Sign Language Alphabet Recognition Using the Leap Motion Device}}
      \field{venue}{Thessaloniki, Greece}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1145/2903220.2903249
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2903220.2903249
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2903220.2903249
      \endverb
      \keyw{Greek Sign language Recognition,Support Vector Machines,Leap Motion}
    \endentry
    \entry{Skaria:2020a}{article}{}
      \name{author}{3}{}{%
        {{hash=a7800212b535265d9d24a8d8a06488e9}{%
           family={Skaria},
           familyi={S\bibinitperiod},
           given={Sruthy},
           giveni={S\bibinitperiod}}}%
        {{hash=16a5e1000b27333c7b09a14308067993}{%
           family={Al-Hourani},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Akram},
           giveni={A\bibinitperiod}}}%
        {{hash=f9b901055dfcef13d4fc6121a0435227}{%
           family={Evans},
           familyi={E\bibinitperiod},
           given={Robin\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \strng{fullhash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \strng{bibnamehash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \strng{authorbibnamehash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \strng{authornamehash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \strng{authorfullhash}{c40b1868d8fd93ef74ba7576b91c0ecc}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Using deep-learning techniques for analyzing radar signatures has opened new possibilities in the field of smart-sensing, especially in the applications of hand-gesture recognition. In this paper, we present a framework, using deep-learning techniques, to classify hand-gesture signatures generated from an ultra-wideband (UWB) impulse radar. We extract the signals of 14 different hand-gestures and represent each signature as a 3-dimensional tensor consisting of range-Doppler frame sequence. These signatures are passed to a convolutional neural network (CNN) to extract the unique features of each gesture, and are then fed to a classifier. We compare 4 different classification architectures to predict the gesture class, namely; (i) fully connected neural network (FCNN), (ii) \$k\$ -Nearest Neighbours ( \$k\$ -NN), (iii) support vector machine (SVM), (iv) long short term memory (LSTM) network. The shape of the range-Doppler-frame tensor and the parameters of the classifiers are optimized in order to maximize the classification accuracy. The classification results of the proposed architectures show a high level of accuracy above 96 \% and a very low confusion probability even between similar gestures.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{Deep-{Learning} {Methods} for {Hand}-{Gesture} {Recognition} {Using} {Ultra}-{Wideband} {Radar}}
      \field{volume}{8}
      \field{year}{2020}
      \field{pages}{203580\bibrangedash 203590}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/ACCESS.2020.3037062
      \endverb
      \keyw{deep-learning,Doppler radar,Feature extraction,Hand-gesture recognition,Radar,Radar antennas,radar sensors,radar signal processing,Sensors,Tensors,Ultra wideband radar,UWB impulse radar}
    \endentry
    \entry{Skaria:2020b}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=a7800212b535265d9d24a8d8a06488e9}{%
           family={Skaria},
           familyi={S\bibinitperiod},
           given={Sruthy},
           giveni={S\bibinitperiod}}}%
        {{hash=f0c99293dcb20fbaf37752a495c75df3}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Da},
           giveni={D\bibinitperiod}}}%
        {{hash=16a5e1000b27333c7b09a14308067993}{%
           family={Al-Hourani},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Akram},
           giveni={A\bibinitperiod}}}%
        {{hash=f9b901055dfcef13d4fc6121a0435227}{%
           family={Evans},
           familyi={E\bibinitperiod},
           given={Robin\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=78ca1136aa4546a230452fba153cbb95}{%
           family={Lech},
           familyi={L\bibinitperiod},
           given={Margaret},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{fullhash}{1e5e471da1670266018f2f5ad5fca9d2}
      \strng{bibnamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authorbibnamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authornamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authorfullhash}{1e5e471da1670266018f2f5ad5fca9d2}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we present a framework for integrating two different types of sensors for hand-gesture recognition using deep-learning. The two sensors utilize completely different approaches for detecting the signal, namely; an ultra-wideband (UWB) impulse radar sensor and a thermal sensor. For robust gesture classification two parallel paths are utilized, each employs a combination of a convolutional neural network (CNN) and a long short-term memory (LSTM) network on both the radar signal and the thermal signal. The classification results from the two paths are then fused to improve the overall detection probability. The two sensors compliment the capability of each other; while the UWB radar is accurate for radial movement and less accurate for lateral movement, the thermal sensor is vice-versa. Thus, we find that combining both sensors produces near perfect classification accuracy of 99 \% for 14 different hand-gestures.}
      \field{booktitle}{2020 {IEEE} {Sensors}}
      \field{month}{10}
      \field{note}{ISSN: 2168-9229}
      \field{title}{Deep-{Learning} for {Hand}-{Gesture} {Recognition} with {Simultaneous} {Thermal} and {Radar} {Sensors}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/SENSORS47125.2020.9278683
      \endverb
      \keyw{Conferences,Doppler radar,Radar,Radar detection,Sensors,Thermal sensors,Ultra wideband radar}
    \endentry
    \entry{Skaria:2019}{article}{}
      \name{author}{4}{}{%
        {{hash=a7800212b535265d9d24a8d8a06488e9}{%
           family={Skaria},
           familyi={S\bibinitperiod},
           given={Sruthy},
           giveni={S\bibinitperiod}}}%
        {{hash=16a5e1000b27333c7b09a14308067993}{%
           family={Al-Hourani},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Akram},
           giveni={A\bibinitperiod}}}%
        {{hash=78ca1136aa4546a230452fba153cbb95}{%
           family={Lech},
           familyi={L\bibinitperiod},
           given={Margaret},
           giveni={M\bibinitperiod}}}%
        {{hash=f9b901055dfcef13d4fc6121a0435227}{%
           family={Evans},
           familyi={E\bibinitperiod},
           given={Robin\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{fullhash}{9fb1f2593c0a39da020ede5d7761e994}
      \strng{bibnamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authorbibnamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authornamehash}{b2f3b88ff535bf74965b75d087965303}
      \strng{authorfullhash}{9fb1f2593c0a39da020ede5d7761e994}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Low-cost consumer radar integrated circuits combined with recent advances in machine learning have opened up a range of new possibilities in smart sensing. In this paper, we use a miniature radar sensor to capture Doppler signatures of 14 different hand gestures and train a deep convolutional neural network (DCNN) to classify these captured gestures. We utilize two receiving antennas of a continuous-wave Doppler radar capable of producing the in-phase and quadrature components of the beat signals. We map these two beat signals into three input channels of a DCNN as two spectrograms and an angle of arrival matrix. The classification results of the proposed architecture show a gesture classification accuracy exceeding 95\% and a very low confusion between different gestures. This is almost 10\% improvement over the single-channel Doppler methods reported in the literature.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{4}
      \field{number}{8}
      \field{title}{Hand-{Gesture} {Recognition} {Using} {Two}-{Antenna} {Doppler} {Radar} {With} {Deep} {Convolutional} {Neural} {Networks}}
      \field{volume}{19}
      \field{year}{2019}
      \field{pages}{3041\bibrangedash 3048}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/JSEN.2019.2892073
      \endverb
      \keyw{beat signals,captured gestures,continuous-wave Doppler radar,convolutional neural nets,DCNN,deep convolutional neural network,deep convolutional neural networks,Doppler effect,Doppler radar,Doppler signatures,feature extraction,gesture classification accuracy,gesture recognition,Gesture recognition,hand-gesture recognition,image classification,learning (artificial intelligence),low-cost consumer radar integrated circuits,machine learning,millimeter-wave radar,miniature radar sensor,multi-antenna radar,quadrature components,radar antennas,radar imaging,Radar sensors,radar signal processing,receiving antennas,Receiving antennas,Sensors,single-channel Doppler methods,smart sensing,Spectrogram,two-antenna doppler radar}
    \endentry
    \entry{Slob:2002}{article}{}
      \name{author}{2}{}{%
        {{hash=db873f53d0a05fe5e31b8fae152b13db}{%
           family={Slob},
           familyi={S\bibinitperiod},
           given={Evert},
           giveni={E\bibinitperiod}}}%
        {{hash=92c4e4f888d32d16f82c818b4f767688}{%
           family={Fokkema},
           familyi={F\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{237135306dd1a4d14c2b98059de647bf}
      \strng{fullhash}{237135306dd1a4d14c2b98059de647bf}
      \strng{bibnamehash}{237135306dd1a4d14c2b98059de647bf}
      \strng{authorbibnamehash}{237135306dd1a4d14c2b98059de647bf}
      \strng{authornamehash}{237135306dd1a4d14c2b98059de647bf}
      \strng{authorfullhash}{237135306dd1a4d14c2b98059de647bf}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Radio Science}
      \field{number}{5}
      \field{title}{{Coupling effects of two electric dipoles on an interface}}
      \field{volume}{37}
      \field{year}{2002}
      \field{pages}{1\bibrangedash 10}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1029/2001RS2529
      \endverb
    \endentry
    \entry{Sluyters:2022:IUI}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{7bf8da24216469df0005de23bab53298}
      \strng{fullhash}{7bf8da24216469df0005de23bab53298}
      \strng{bibnamehash}{7bf8da24216469df0005de23bab53298}
      \strng{authorbibnamehash}{7bf8da24216469df0005de23bab53298}
      \strng{authornamehash}{7bf8da24216469df0005de23bab53298}
      \strng{authorfullhash}{7bf8da24216469df0005de23bab53298}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Microwave radar sensors in human-computer interactions have several advantages compared to wearable and image-based sensors, such as privacy preservation, high reliability regardless of the ambient and lighting conditions, and larger field of view. However, the raw signals produced by such radars are high-dimension and relatively complex to interpret. Advanced data processing, including machine learning techniques, is therefore necessary for gesture recognition. While these approaches can reach high gesture recognition accuracy, using artificial neural networks requires a significant amount of gesture templates for training and calibration is radar-specific. To address these challenges, we present a novel data processing pipeline for hand gesture recognition that combines advanced full-wave electromagnetic modelling and inversion with machine learning. In particular, the physical model accounts for the radar source, radar antennas, radar-target interactions and target itself, i.e.,, the hand in our case. To make this processing feasible, the hand is emulated by an equivalent infinite planar reflector, for which analytical Green’s functions exist. The apparent dielectric permittivity, which depends on the hand size, electric properties, and orientation, determines the wave reflection amplitude based on the distance from the hand to the radar. Through full-wave inversion of the radar data, the physical distance as well as this apparent permittivity are retrieved, thereby reducing by several orders of magnitude the dimension of the radar dataset, while keeping the essential information. Finally, the estimated distance and apparent permittivity as a function of gesture time are used to train the machine learning algorithm for gesture recognition. This physically-based dimension reduction enables the use of simple gesture recognition algorithms, such as template-matching recognizers, that can be trained in real time and provide competitive accuracy with only a few samples. We evaluate significant stages of our pipeline on a dataset of 16 gesture classes, with 5 templates per class, recorded with the Walabot, a lightweight, off-the-shelf array radar. We also compare these results with an ultra wideband radar made of a single horn antenna and lightweight vector network analyzer, and a Leap Motion Controller.}
      \field{booktitle}{Proceedings of 27th International ACM Conference on Intelligent User Interfaces}
      \field{isbn}{9781450391443}
      \field{series}{IUI '22}
      \field{title}{{Hand Gesture Recognition for an Off-the-Shelf Radar by Electromagnetic Modeling and Inversion}}
      \field{venue}{Helsinki, Finland}
      \field{year}{2022}
      \field{pages}{506\bibrangedash 522}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1145/3490099.3511107
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3490099.3511107
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3490099.3511107
      \endverb
      \keyw{Gesture-based interfaces,Radar-based interaction.,Mid-air gestural interaction,Dimension reduction,New datasets,Hand gesture recognition}
    \endentry
    \entry{Sluyters:2022:LUI}{article}{}
      \name{author}{5}{}{%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=a14c6e30906cb862955c905a9902d5ca}{%
           family={Sellier},
           familyi={S\bibinitperiod},
           given={Quentin},
           giveni={Q\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=b70ec80fe0586da49b51076bf4a9a3d5}{%
           family={Parthiban},
           familyi={P\bibinitperiod},
           given={Vik},
           giveni={V\bibinitperiod}}}%
        {{hash=2f8f33c85296fc648721ff66ab814d0a}{%
           family={Maes},
           familyi={M\bibinitperiod},
           given={Pattie},
           giveni={P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Taylor \& Francis}%
      }
      \strng{namehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{fullhash}{e0cf97d18cd3c406183f2385e4cfeec2}
      \strng{bibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorbibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authornamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorfullhash}{e0cf97d18cd3c406183f2385e4cfeec2}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Journal of Human–Computer Interaction}
      \field{title}{{Consistent, Continuous, and Customizable Mid-Air Gesture Interaction for Browsing Multimedia Objects on Large Displays}}
      \field{year}{2022}
      \field{pages}{1\bibrangedash 32}
      \range{pages}{32}
      \verb{doi}
      \verb 10.1080/10447318.2022.2078464
      \endverb
      \verb{eprint}
      \verb https://doi.org/10.1080/10447318.2022.2078464
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1080/10447318.2022.2078464
      \endverb
      \verb{url}
      \verb https://doi.org/10.1080/10447318.2022.2078464
      \endverb
    \endentry
    \entry{Sluyters:2022:EICS}{article}{}
      \name{author}{4}{}{%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=50206389921773df61bbe2a79d4d004b}{%
           family={Ousmer},
           familyi={O\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod}}}%
        {{hash=f822d8f741e1aed7d9b7872fe72da592}{%
           family={Roselli},
           familyi={R\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{fullhash}{783f934fc3abde8488c9207430c92dbe}
      \strng{bibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorbibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authornamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorfullhash}{783f934fc3abde8488c9207430c92dbe}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Proc. {ACM} Human-Computer Interaction}
      \field{month}{6}
      \field{number}{{EICS}}
      \field{title}{{QuantumLeap, a Framework for Engineering Gestural User Interfaces based on the Leap Motion Controller}}
      \field{volume}{6}
      \field{year}{2022}
      \field{pages}{1\bibrangedash 47}
      \range{pages}{47}
      \verb{doi}
      \verb 10.1145/3532211
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3532211
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3532211
      \endverb
    \endentry
    \entry{Sluyters:2023}{article}{}
      \name{author}{4}{}{%
        {{hash=245d763a904d1936d6d73d39bdd1b90b}{%
           family={Sluÿters},
           familyi={S\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{fullhash}{ea272a938d5de5b6a0dbc92a061bdf7d}
      \strng{bibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorbibnamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authornamehash}{a796e44a0fd711c8b28ff96da68c13d8}
      \strng{authorfullhash}{ea272a938d5de5b6a0dbc92a061bdf7d}
      \field{extraname}{3}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Microwave radars bring many benefits to mid-air gesture sensing due to their large field of view and independence from environmental conditions, such as ambient light and occlusion. However, radar signals are highly dimensional and usually require complex deep learning approaches. To understand this landscape, we report results from a systematic literature review of (N = 118) scientific papers on radar sensing, unveiling a large variety of radar technology of different operating frequencies and bandwidths, antenna configurations, but also various gesture recognition techniques. Although highly accurate, these techniques require a large amount of training data that depend on the type of radar. Therefore, the training results cannot be easily transferred to other radars. To address this aspect, we introduce a new gesture recognition pipeline that implements advanced full-wave electromagnetic modeling and inversion to retrieve physical characteristics of gestures that are radar independent, i.e., independent of the source, antennas, and radar-hand interactions. Inversion of radar signals further reduces the size of the dataset by several orders of magnitude, while preserving the essential information. This approach is compatible with conventional gesture recognizers, such as those based on template matching, which only need a few training examples to deliver high recognition accuracy rates. To evaluate our gesture recognition pipeline, we conducted user-dependent and user-independent evaluations on a dataset of 16 gesture types collected with the Walabot, a low-cost off-the-shelf array radar. We contrast these results with those obtained for the same gesture types collected with an ultra-wideband radar made of a vector network analyzer with a single horn antenna and with a computer vision sensor, respectively. Based on our findings, we suggest some design implications to support future development in radar-based gesture recognition.}
      \field{issn}{2160-6455}
      \field{journaltitle}{ACM Transactions on Interactive Intelligent Systems}
      \field{month}{3}
      \field{title}{{RadarSense: Accurate Recognition of Mid-Air Hand Gestures with Radar Sensing and Few Training Examples}}
      \field{year}{2023}
      \verb{doi}
      \verb 10.1145/3589645
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3589645
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3589645
      \endverb
      \keyw{Hand gesture recognition,Dimension reduction,Radar-based interaction.}
    \endentry
    \entry{Smith:2018}{article}{}
      \name{author}{4}{}{%
        {{hash=97712ea1a193d694564d03dd99124223}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Karly\bibnamedelima A.},
           giveni={K\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=dda70087d64e6872820976eecdf24bb7}{%
           family={Csech},
           familyi={C\bibinitperiod},
           given={Clément},
           giveni={C\bibinitperiod}}}%
        {{hash=4129ab2603f8ca3f63f3d092551d9f06}{%
           family={Murdoch},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=6cda7e13062091562f92a7fc7790df70}{%
           family={Shaker},
           familyi={S\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{dabb65fc36da5c6bb9d7077c1dc40b1c}
      \strng{fullhash}{22e701395fed25b657d01bf6ae34136a}
      \strng{bibnamehash}{dabb65fc36da5c6bb9d7077c1dc40b1c}
      \strng{authorbibnamehash}{dabb65fc36da5c6bb9d7077c1dc40b1c}
      \strng{authornamehash}{dabb65fc36da5c6bb9d7077c1dc40b1c}
      \strng{authorfullhash}{22e701395fed25b657d01bf6ae34136a}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article details the development of a gesture recognition technique using a mm-wave radar sensor for in-car infotainment control. Gesture recognition is becoming a more prominent form of human-computer interaction and can be used in the automotive industry to provide a safe and intuitive control interface that will limit driver distraction. We use a 60 GHz mm-wave radar sensor to detect precise features of fine motion. Specific gesture features are extracted and used to build a machine learning engine that can perform real-time gesture recognition. This article discusses the user requirements and in-car environmental constraints that influenced design decisions. Accuracy results of the technique are presented, and recommendations for further research and improvements are made.}
      \field{issn}{2475-1472}
      \field{journaltitle}{IEEE Sensors Letters}
      \field{month}{6}
      \field{number}{2}
      \field{title}{Gesture {Recognition} {Using} mm-{Wave} {Sensor} for {Human}-{Car} {Interface}}
      \field{volume}{2}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/LSENS.2018.2810093
      \endverb
      \keyw{60 GHz mm-wave radar,60 GHz mm-wave radar sensor,Automobiles,automotive industry,Cameras,feature extraction,gesture feature extraction,gesture recognition,gesture sensing,human-car interface,human-computer interaction,in-car environmental constraints,in-car infotainment control,intuitive control interface,learning (artificial intelligence),machine learning,machine learning engine,Microwave/millimeter wave sensors,mm-wave sensor,Radar detection,random forest classifier,real-time gesture recognition,safe control interface,Sensor systems,traffic engineering computing,user interfaces}
    \endentry
    \entry{vanSomeren:1994}{book}{}
      \name{author}{3}{}{%
        {{hash=47bfa55cf6add980c29c9929269352ed}{%
           family={Someren},
           familyi={S\bibinitperiod},
           given={Maarten},
           giveni={M\bibinitperiod},
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{hash=ead425aec17097fedd582bbf7cc25b26}{%
           family={Barnard},
           familyi={B\bibinitperiod},
           given={Yvonne},
           giveni={Y\bibinitperiod}}}%
        {{hash=2c261fd30b8c428e1ca1595945b47a10}{%
           family={Sandberg},
           familyi={S\bibinitperiod},
           given={Jacobijn},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {London}%
      }
      \list{publisher}{1}{%
        {Academic Press}%
      }
      \strng{namehash}{130c6c7974190bcaceaea85b03457cdb}
      \strng{fullhash}{130c6c7974190bcaceaea85b03457cdb}
      \strng{bibnamehash}{130c6c7974190bcaceaea85b03457cdb}
      \strng{authorbibnamehash}{130c6c7974190bcaceaea85b03457cdb}
      \strng{authornamehash}{130c6c7974190bcaceaea85b03457cdb}
      \strng{authorfullhash}{130c6c7974190bcaceaea85b03457cdb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{The Think Aloud Method - A Practical Guide to Modelling Cognitive Processes}}
      \field{year}{1994}
    \endentry
    \entry{Spiegelmock:2013}{book}{}
      \name{author}{1}{}{%
        {{hash=68b53041b2527609c7a7147d9905c977}{%
           family={Spiegelmock},
           familyi={S\bibinitperiod},
           given={Mischa},
           giveni={M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Packt Publishing}%
      }
      \strng{namehash}{68b53041b2527609c7a7147d9905c977}
      \strng{fullhash}{68b53041b2527609c7a7147d9905c977}
      \strng{bibnamehash}{68b53041b2527609c7a7147d9905c977}
      \strng{authorbibnamehash}{68b53041b2527609c7a7147d9905c977}
      \strng{authornamehash}{68b53041b2527609c7a7147d9905c977}
      \strng{authorfullhash}{68b53041b2527609c7a7147d9905c977}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{edition}{1}
      \field{isbn}{978-1849697729}
      \field{month}{10}
      \field{title}{{Leap Motion Development Essentials}}
      \field{year}{2013}
      \verb{urlraw}
      \verb https://www.packtpub.com/eu/hardware-and-creative/leap-motion-development-essentials
      \endverb
      \verb{url}
      \verb https://www.packtpub.com/eu/hardware-and-creative/leap-motion-development-essentials
      \endverb
    \endentry
    \entry{Steeman:2022}{thesis}{}
      \name{author}{2}{}{%
        {{hash=8166996ebcae0e40c6d689fb084735dc}{%
           family={Steeman},
           familyi={S\bibinitperiod},
           given={Sarah},
           giveni={S\bibinitperiod}}}%
        {{hash=3815f73974f72acb8f6aff8a9a11106f}{%
           family={Chauvaux},
           familyi={C\bibinitperiod},
           given={Chloé},
           giveni={C\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL - Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{9f8b3eed54ae058f864f96311a93f5e0}
      \strng{fullhash}{9f8b3eed54ae058f864f96311a93f5e0}
      \strng{bibnamehash}{9f8b3eed54ae058f864f96311a93f5e0}
      \strng{authorbibnamehash}{9f8b3eed54ae058f864f96311a93f5e0}
      \strng{authornamehash}{9f8b3eed54ae058f864f96311a93f5e0}
      \strng{authorfullhash}{9f8b3eed54ae058f864f96311a93f5e0}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Wrist-based gesture interaction enables end-users to interact by mid-air gestures while keeping hands and fingers free for other manual tasks. This thesis aims to investigate how wrist-based gesture interaction could be made feasible with one wrist (unimanual) or two wrists (bimanual) for one end-user (in isolation) or two (in collaboration) and how to integrate it into an interactive application. For this purpose, we adopted a development life cycle made up of the following stages: design of a set of gestures from different sources (elicitation and literature survey), acquire a dataset of these gestures to train a recognizer, compare several recognizers on this dataset with various conditions, and mapping gestures to commands into an interactive application so that they can be handled in real time. This life cycle is applied specifically to the Kinemic device and for a computer-assisted presentation application.}
      \field{title}{{Uni/Bi-manual wrist gesture interaction for one/two users : application to Kinemic}}
      \field{type}{phdthesis}
      \field{year}{2022}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:35604
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:35604
      \endverb
      \keyw{Wrist-based gesture,Gesture interaction,Kinemic,Human computer interaction}
    \endentry
    \entry{Stinghen:2018}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2b9307c61d4256b4e9940b457bf1dcd2}{%
           family={Stinghen},
           familyi={S\bibinitperiod},
           given={Ivo},
           giveni={I\bibinitperiod}}}%
        {{hash=886fa5d0cc90ee0606bdc8c5b58a3deb}{%
           family={Gatto},
           familyi={G\bibinitperiod},
           given={Bernardo},
           giveni={B\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE Computer Society}%
      }
      \strng{namehash}{77884e4232ae1f22b9d48df008c1a68f}
      \strng{fullhash}{77884e4232ae1f22b9d48df008c1a68f}
      \strng{bibnamehash}{77884e4232ae1f22b9d48df008c1a68f}
      \strng{authorbibnamehash}{77884e4232ae1f22b9d48df008c1a68f}
      \strng{authornamehash}{77884e4232ae1f22b9d48df008c1a68f}
      \strng{authorfullhash}{77884e4232ae1f22b9d48df008c1a68f}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{17th Brazilian Symposium on Computer Games and Digital Entertainment}
      \field{isbn}{978-1-5386-9605-7}
      \field{issn}{2179-2259}
      \field{month}{11}
      \field{series}{SBGames '18}
      \field{title}{{Gesture Recognition Using Leap Motion: A Machine Learning-based Controller Interface}}
      \field{venue}{Foz do Iguaçu, Brazil}
      \field{year}{2018}
    \endentry
    \entry{Suh:2018}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=b5fe498390dc8240be66105136d67554}{%
           family={Suh},
           familyi={S\bibinitperiod},
           given={Jun\bibnamedelima Seuk},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=4e543e230cd3df5f1911b891c4c14d58}{%
           family={Ryu},
           familyi={R\bibinitperiod},
           given={Siiung},
           giveni={S\bibinitperiod}}}%
        {{hash=6c6216e1316d56d677c1a54e76f8c2ab}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Bvunghun},
           giveni={B\bibinitperiod}}}%
        {{hash=e7490afcd998932eff15ca686ab86d92}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={Jaewoo},
           giveni={J\bibinitperiod}}}%
        {{hash=d736303e6fdf4a44d4d501a0f1e14c5b}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Jong-Hwan},
           giveni={J\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=d47fcf23af3fa855a5d5dfffde635a07}{%
           family={Hong},
           familyi={H\bibinitperiod},
           given={Songcheol},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{3daca00ebd2c6167a8aa9790b1d326a8}
      \strng{fullhash}{cd0676ac5790a1851ce9d5b8c95f0a52}
      \strng{bibnamehash}{3daca00ebd2c6167a8aa9790b1d326a8}
      \strng{authorbibnamehash}{3daca00ebd2c6167a8aa9790b1d326a8}
      \strng{authornamehash}{3daca00ebd2c6167a8aa9790b1d326a8}
      \strng{authorfullhash}{cd0676ac5790a1851ce9d5b8c95f0a52}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A 24 GHz frequency modulated continuous wave radar system to recognize human's hand gestures is implemented, which uses commercial off-the-shelf RF front-end IC with one transmitter and four receivers. Planar patch array antennas, signal conditioning circuits and interconnections to a PC are designed for the system. Range-Doppler maps for four receiver channels are obtained with saw-tooth chirping signals transmitted to detect hand gestures. The radar system shows real-time highly accurate gesture recognition. Long-short term memory recurrent neural network as a supervised machine learning technique is used. Seven kinds of hand gestures are recognized within 0.4 m and ±30° from the center of the transmitted antenna with above 91 \% accuracy.}
      \field{booktitle}{2018 {Asia}-{Pacific} {Microwave} {Conference} ({APMC})}
      \field{month}{11}
      \field{title}{24 {GHz} {FMCW} {Radar} {System} for {Real}-{Time} {Hand} {Gesture} {Recognition} {Using} {LSTM}}
      \field{year}{2018}
      \field{pages}{860\bibrangedash 862}
      \range{pages}{3}
      \verb{doi}
      \verb 10.23919/APMC.2018.8617375
      \endverb
      \keyw{continuous wave radar system,CW radar,FM radar,FMCW Radar,FMCW radar system,frequency 24.0 GHz,gesture recognition,Gesture recognition,Hand Gesture Recognition,hand gestures,learning (artificial intelligence),Linear antenna arrays,long-short term memory recurrent neural network,LSTM,microstrip antenna arrays,off-the-shelf RF front-end IC,planar antenna arrays,planar patch array antennas,Radar,radar antennas,Radar antennas,radar computing,Range-Doppler maps,real-time hand gesture recognition,Real-time systems,receiver channels,Receivers,recurrent neural nets,saw-tooth chirping signals,signal conditioning circuits}
    \endentry
    \entry{Sun:2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=60880f4ceef69e5a9744f47c00071f0a}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Yuliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=a4cfe48d802560e560c3a255c0fc8bbd}{%
           family={Fei},
           familyi={F\bibinitperiod},
           given={Tai},
           giveni={T\bibinitperiod}}}%
        {{hash=1b24e68feca79bad9ddc3c9a4008bc75}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Shangyin},
           giveni={S\bibinitperiod}}}%
        {{hash=cffd2762c07c4a5badd28d0c0bb43811}{%
           family={Pohl},
           familyi={P\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{63a5d02e5f13f630a834955358777137}
      \strng{fullhash}{aae1a5fd8f54eb20bb24b010e0160178}
      \strng{bibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorbibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authornamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorfullhash}{aae1a5fd8f54eb20bb24b010e0160178}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a region-based deep convolutional neural network (R-DCNN) is proposed to detect and classify gestures measured by a frequency-modulated continuous wave radar system. Micro-Doppler (μD) signatures of gestures are exploited, and the resulting spectrograms are fed into a neural network. We are the first to use the R-DCNN for radar-based gesture recognition, such that multiple gestures could be automatically detected and classified without manually clipping the data streams according to each hand movement in advance. Further, along with the μD signatures, we incorporate phase-difference information of received signals from an L-shaped antenna array to enhance the classification accuracy. Finally, the classification results show that the proposed network trained with spectrogram and phase-difference information can guarantee a promising performance for nine gestures.}
      \field{booktitle}{{ICASSP} 2019 - 2019 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})}
      \field{month}{5}
      \field{note}{ISSN: 2379-190X}
      \field{title}{Automatic {Radar}-based {Gesture} {Detection} and {Classification} via a {Region}-based {Deep} {Convolutional} {Neural} {Network}}
      \field{year}{2019}
      \field{pages}{4300\bibrangedash 4304}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2019.8682277
      \endverb
      \keyw{antenna arrays,Antenna measurements,automatic radar-based gesture detection,convolutional neural nets,CW radar,Doppler radar,Faster-RCNN,Feature extraction,FM radar,FMCW radar,Frequency measurement,frequency-modulated continuous wave radar system,gesture recognition,Gesture recognition,hand movement,L-shaped antenna array,Micro-Doppler signature,MicroDoppler signatures,Phase difference,phase-difference information,R-DCNN,Radar,radar antennas,Radar antennas,radar detection,Receiving antennas,region-based deep convolutional neural network,signal classification,Spectrogram}
    \endentry
    \entry{Sun:2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=60880f4ceef69e5a9744f47c00071f0a}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Yuliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=a4cfe48d802560e560c3a255c0fc8bbd}{%
           family={Fei},
           familyi={F\bibinitperiod},
           given={Tai},
           giveni={T\bibinitperiod}}}%
        {{hash=ec6d7c9b13c31fc38b0454ff682ba794}{%
           family={Schliep},
           familyi={S\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod}}}%
        {{hash=cffd2762c07c4a5badd28d0c0bb43811}{%
           family={Pohl},
           familyi={P\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{63a5d02e5f13f630a834955358777137}
      \strng{fullhash}{56a4bcacbd607e2aeac9e82bee2651cf}
      \strng{bibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorbibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authornamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorfullhash}{56a4bcacbd607e2aeac9e82bee2651cf}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper deals with gesture recognition using a 77 GHz FMCW radar system based on the micro-Doppler (μ D) signatures. In addition to the Doppler information, the range information is also available in the FMCW radar. Therefore, it is utilized to filter out the irrelevant targets. We have proposed five micro-Doppler based handcrafted features for gesture recognition. Finally, a simple k-nearest neighbor (k-NN) classifier is applied to evaluate the importance of the five features. The classification results demonstrate that the proposed features can guarantee a promising recognition accuracy.}
      \field{booktitle}{2018 {IEEE} {MTT}-{S} {International} {Conference} on {Microwaves} for {Intelligent} {Mobility} ({ICMIM})}
      \field{month}{4}
      \field{title}{Gesture {Classification} with {Handcrafted} {Micro}-{Doppler} {Features} using a {FMCW} {Radar}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICMIM.2018.8443507
      \endverb
      \keyw{Chirp,CW radar,Doppler effect,Doppler information,Doppler radar,feature extraction,FM radar,FMCW automotive radar,FMCW radar system,frequency 77 GHz,Frequency modulation,gesture classification,gesture recognition,handcrafted feature,handcrafted microDoppler features,image classification,k-nearest neighbor classifier,k-NN classifier,microDoppler signatures,nearest neighbour methods,range information,Sensors,Spectrogram,supervised learning,μD signature}
    \endentry
    \entry{Sun:2020b}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=60880f4ceef69e5a9744f47c00071f0a}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Yuliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=a4cfe48d802560e560c3a255c0fc8bbd}{%
           family={Fei},
           familyi={F\bibinitperiod},
           given={Tai},
           giveni={T\bibinitperiod}}}%
        {{hash=568d981fbced31f9e3fb10fc5349cf95}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xibo},
           giveni={X\bibinitperiod}}}%
        {{hash=0ba290d87f64603e393e262e196fa04e}{%
           family={Warnecke},
           familyi={W\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=12b9069ebf9d835e4e0062ef0302f131}{%
           family={Warsitz},
           familyi={W\bibinitperiod},
           given={Ernst},
           giveni={E\bibinitperiod}}}%
        {{hash=cffd2762c07c4a5badd28d0c0bb43811}{%
           family={Pohl},
           familyi={P\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{63a5d02e5f13f630a834955358777137}
      \strng{fullhash}{72127ef415637055caf4a442c53260ab}
      \strng{bibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorbibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authornamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorfullhash}{72127ef415637055caf4a442c53260ab}
      \field{extraname}{3}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a multi-feature encoder for gesture recognition based on a 60 GHz frequency-modulated continuous wave (FMCW) radar system is proposed to extract the gesture characteristics, i.e., range, Doppler, azimuth and elevation, from the low-level raw data. The radar system updates the hand information for every measurement-cycle on all the scattering centers in its field of view, and our proposed encoder is devised to only focus on those essential scattering centers. After observing the hand over several measurement-cycles, we encode the gesture characteristics sequentially into a 2-D feature matrix, which is successively fed into a shallow convolutional neural network (CNN) for classification. For the purpose of distinguishing relevant gestures, the proposed multi-feature encoder is able to efficiently extract adequate information from a multi-dimensional feature space. Thus, the proposed approach is practical for industrial applications where the available dataset is mostly small-scale. The experimental results show that the proposed multi-feature encoder could guarantee a promising performance for a gesture dataset with 12 gestures.}
      \field{booktitle}{2020 {IEEE} {International} {Radar} {Conference} ({RADAR})}
      \field{month}{4}
      \field{note}{ISSN: 2640-7736}
      \field{title}{Multi-{Feature} {Encoder} for {Radar}-{Based} {Gesture} {Recognition}}
      \field{year}{2020}
      \field{pages}{351\bibrangedash 356}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/RADAR42522.2020.9114664
      \endverb
      \keyw{2D feature matrix,CNN,convolutional neural nets,convolutional neural network,CW radar,feature extraction,FM radar,FMCW radar system,frequency 60.0 GHz,frequency-modulated continuous wave radar system,gesture dataset characteristics,gesture recognition,image classification,image coding,matrix algebra,measurement-cycle,millimetre wave radar,multidimensional feature space,multifeature encoder,radar computing,radar imaging,radar-based gesture recognition}
    \endentry
    \entry{Sun:2020a}{article}{}
      \name{author}{6}{}{%
        {{hash=60880f4ceef69e5a9744f47c00071f0a}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Yuliang},
           giveni={Y\bibinitperiod}}}%
        {{hash=a4cfe48d802560e560c3a255c0fc8bbd}{%
           family={Fei},
           familyi={F\bibinitperiod},
           given={Tai},
           giveni={T\bibinitperiod}}}%
        {{hash=568d981fbced31f9e3fb10fc5349cf95}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xibo},
           giveni={X\bibinitperiod}}}%
        {{hash=0ba290d87f64603e393e262e196fa04e}{%
           family={Warnecke},
           familyi={W\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=12b9069ebf9d835e4e0062ef0302f131}{%
           family={Warsitz},
           familyi={W\bibinitperiod},
           given={Ernst},
           giveni={E\bibinitperiod}}}%
        {{hash=cffd2762c07c4a5badd28d0c0bb43811}{%
           family={Pohl},
           familyi={P\bibinitperiod},
           given={Nils},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{63a5d02e5f13f630a834955358777137}
      \strng{fullhash}{72127ef415637055caf4a442c53260ab}
      \strng{bibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorbibnamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authornamehash}{63a5d02e5f13f630a834955358777137}
      \strng{authorfullhash}{72127ef415637055caf4a442c53260ab}
      \field{extraname}{4}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a real-time signal processing framework based on a 60 GHz frequency-modulated continuous wave (FMCW) radar system to recognize gestures is proposed. In order to improve the robustness of the radar-based gesture recognition system, the proposed framework extracts a comprehensive hand profile, including range, Doppler, azimuth and elevation, over multiple measurement-cycles and encodes them into a feature cube. Rather than feeding the range-Doppler spectrum sequence into a deep convolutional neural network (CNN) connected with recurrent neural networks, the proposed framework takes the aforementioned feature cube as input of a shallow CNN for gesture recognition to reduce the computational complexity. In addition, we develop a hand activity detection (HAD) algorithm to automatize the detection of gestures in real-time case. The proposed HAD can capture the time-stamp at which a gesture finishes and feeds the hand profile of all the relevant measurement-cycles before this time-stamp into the CNN with low latency. Since the proposed framework is able to detect and classify gestures at limited computational cost, it could be deployed in an edge-computing platform for real-time applications, whose performance is notedly inferior to a state-of-the-art personal computer. The experimental results show that the proposed framework has the capability of classifying 12 gestures in real-time with a high F1-score.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{9}
      \field{number}{18}
      \field{title}{Real-{Time} {Radar}-{Based} {Gesture} {Detection} and {Recognition} {Built} in an {Edge}-{Computing} {Platform}}
      \field{volume}{20}
      \field{year}{2020}
      \field{pages}{10706\bibrangedash 10716}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/JSEN.2020.2994292
      \endverb
      \keyw{AoA information,Azimuth,computational complexity,computational cost,CW radar,deep convolutional neural network,Doppler effect,Doppler radar,edge-computing platform,Feature extraction,FM radar,FMCW radar,FMCW radar system,frequency 60.0 GHz,frequency-modulated continuous wave radar system,gesture classification,gesture recognition,Gesture recognition,HAD algorithm,hand activity detection,hand activity detection algorithm,hand profile,personal computer,Radar,radar computing,radar detection,radar-based gesture recognition system,range-Doppler spectrum sequence,real time radar-based gesture detection,real-time,real-time signal,Real-time systems,recurrent neural nets,recurrent neural networks,Sensors,shallow CNN,signal classification,time-stamp}
    \endentry
    \entry{Tang:2020}{article}{}
      \name{author}{6}{}{%
        {{hash=a67c79879ffd1f8dcb777f88252bcc09}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
        {{hash=3c8d035e3f5fb2c7c2d63cc1d1c4b6a0}{%
           family={Carey},
           familyi={C\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=95c2713e5e49a7f6c2245cf470fefb24}{%
           family={Virbila},
           familyi={V\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod}}}%
        {{hash=28f91f3a4b62ce57b7a533e742e8aae1}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod}}}%
        {{hash=29ca41b585673e26af8572cf9983dc7d}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Rulin},
           giveni={R\bibinitperiod}}}%
        {{hash=c94739c118fc2e1395faf3b7b229662e}{%
           family={Frank\bibnamedelima Chang},
           familyi={F\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Mau-Chung},
           giveni={M\bibinithyphendelim C\bibinitperiod}}}%
      }
      \strng{namehash}{0cf7585dff1016cab427af7d4371cf1a}
      \strng{fullhash}{272475b9484b05d1fba6a6ed737c595f}
      \strng{bibnamehash}{0cf7585dff1016cab427af7d4371cf1a}
      \strng{authorbibnamehash}{0cf7585dff1016cab427af7d4371cf1a}
      \strng{authornamehash}{0cf7585dff1016cab427af7d4371cf1a}
      \strng{authorfullhash}{272475b9484b05d1fba6a6ed737c595f}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Terahertz Science and Technology}
      \field{number}{2}
      \field{title}{{A Delay-Correlating Direct-Sequence Spread-Spectrum (DS/SS) Radar System-on-Chip Operating at 183–205 GHz in 28 nm CMOS}}
      \field{volume}{10}
      \field{year}{2020}
      \field{pages}{212\bibrangedash 220}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/TTHZ.2020.2969105
      \endverb
    \endentry
    \entry{Tang:2018}{article}{}
      \name{author}{4}{}{%
        {{hash=ea814bf674e1057424fc3eaa1d951a35}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jingren},
           giveni={J\bibinitperiod}}}%
        {{hash=7f716c207f29a9f09b9764f354497a91}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Hong},
           giveni={H\bibinitperiod}}}%
        {{hash=f0e7d180081df6c4c59c600f7c044474}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
        {{hash=5432cdc4629d08ec6709d97c74539399}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{e594f43da51b2014dab37cec5855e024}
      \strng{fullhash}{0196d1553272a0b8344d72a012a926ab}
      \strng{bibnamehash}{e594f43da51b2014dab37cec5855e024}
      \strng{authorbibnamehash}{e594f43da51b2014dab37cec5855e024}
      \strng{authornamehash}{e594f43da51b2014dab37cec5855e024}
      \strng{authorfullhash}{0196d1553272a0b8344d72a012a926ab}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Continuous hand gesture recognition is an important area of HCI and challenged by various writing habits and unconstrained hand movement. In this paper, we propose a Structured Dynamic Time Warping (SDTW) approach for continuous hand trajectory recognition. We first propose an automatic continuous trajectory segmentation approach which combines templates and velocity information to spot the beginning and ending points in hand gesture trajectories. Then we assign different weights to feature sequences based on the structured information, from the positions of corner points in the arbitrary trajectories. Finally, we evaluate the SDTW on the Continuous Letter Trajectory (CLT) database. Experimental results show that the proposed approach is robust to the diversity of same handwritten letter, and significantly outperforms state-of-the-art approaches.}
      \field{issn}{0031-3203}
      \field{journaltitle}{Pattern Recognition}
      \field{title}{{Structured dynamic time warping for continuous hand trajectory gesture recognition}}
      \field{volume}{80}
      \field{year}{2018}
      \field{pages}{21\bibrangedash 31}
      \range{pages}{11}
      \verb{doi}
      \verb https://doi.org/10.1016/j.patcog.2018.02.011
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0031320318300621
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0031320318300621
      \endverb
      \keyw{Continuous hand gesture recognition,Dynamic time warping,Continuous trajectory segment,Human computer interaction}
    \endentry
    \entry{Taranta:2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=f63d0c40654aa255ec628885e67f6f82}{%
           family={Taranta},
           familyi={T\bibinitperiod},
           given={Eugene\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=c90fc658d0ad6672733c19d1db437678}{%
           family={Maghoumi},
           familyi={M\bibinitperiod},
           given={Mehran},
           giveni={M\bibinitperiod}}}%
        {{hash=74da9aa20b40d1589084c2471ec24573}{%
           family={Pittman},
           familyi={P\bibinitperiod},
           given={Corey\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=ba77fe1a51bbe7ce7bccddc9627e2bfe}{%
           family={LaViola},
           familyi={L\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{d3cf6d62656dbb7c4b69b7fa08bc2d21}
      \strng{fullhash}{db3d740fdc6a8f7f4ed31effcd5f004a}
      \strng{bibnamehash}{d3cf6d62656dbb7c4b69b7fa08bc2d21}
      \strng{authorbibnamehash}{d3cf6d62656dbb7c4b69b7fa08bc2d21}
      \strng{authornamehash}{d3cf6d62656dbb7c4b69b7fa08bc2d21}
      \strng{authorfullhash}{db3d740fdc6a8f7f4ed31effcd5f004a}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Training gesture recognizers with synthetic data generated from real gestures is a well known and powerful technique that can significantly improve recognition accuracy. In this paper we introduce a novel technique called gesture path stochastic resampling (GPSR) that is computationally efficient, has minimal coding overhead, and yet despite its simplicity is able to achieve higher accuracy than competitive, state-of-the-art approaches. GPSR generates synthetic samples by lengthening and shortening gesture subpaths within a given sample to produce realistic variations of the input via a process of nonuniform resampling. As such, GPSR is an appropriate rapid prototyping technique where ease of use, understandability, and efficiency are key. Further, through an extensive evaluation, we show that accuracy significantly improves when gesture recognizers are trained with GPSR synthetic samples. In some cases, mean recognition errors are reduced by more than 70\%, and in most cases, GPSR outperforms two other evaluated state-of-the-art methods.}
      \field{booktitle}{Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology}}
      \field{isbn}{978-1-4503-4189-9}
      \field{month}{10}
      \field{series}{{UIST} '16}
      \field{title}{A {Rapid} {Prototyping} {Approach} to {Synthetic} {Data} {Generation} for {Improved} {2D} {Gesture} {Recognition}}
      \field{urlday}{23}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{873\bibrangedash 885}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1145/2984511.2984525
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2984511.2984525
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2984511.2984525
      \endverb
      \keyw{gesture recognition,rapid prototyping,gesture path,stochastic resampling,synthetic gestures}
    \endentry
    \entry{Taranta:2017}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=49ec62c0f388ba6345aea9a21bd3e9e7}{%
           family={Taranta\bibnamedelima II},
           familyi={T\bibinitperiod\bibinitdelim I\bibinitperiod},
           given={Eugene\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=6357119a2e4518a3e612059eec77a444}{%
           family={Samiei},
           familyi={S\bibinitperiod},
           given={Amirreza},
           giveni={A\bibinitperiod}}}%
        {{hash=c90fc658d0ad6672733c19d1db437678}{%
           family={Maghoumi},
           familyi={M\bibinitperiod},
           given={Mehran},
           giveni={M\bibinitperiod}}}%
        {{hash=725b99a5888776ace3726e4501eb8319}{%
           family={Khaloo},
           familyi={K\bibinitperiod},
           given={Pooya},
           giveni={P\bibinitperiod}}}%
        {{hash=74da9aa20b40d1589084c2471ec24573}{%
           family={Pittman},
           familyi={P\bibinitperiod},
           given={Corey\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=106180b1302f004e9329ecf5926e737f}{%
           family={LaViola\bibnamedelima Jr.},
           familyi={L\bibinitperiod\bibinitdelim J\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{fullhash}{c35a849d2968baa3cc61a3899fcaebf2}
      \strng{bibnamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authorbibnamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authornamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authorfullhash}{c35a849d2968baa3cc61a3899fcaebf2}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{978-1-4503-4655-9}
      \field{series}{CHI '17}
      \field{title}{{Jackknife: A Reliable Recognizer with Few Samples and Many Modalities}}
      \field{venue}{Denver, Colorado, USA}
      \field{year}{2017}
      \field{pages}{5850\bibrangedash 5861}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1145/3025453.3026002
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/3025453.3026002
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/3025453.3026002
      \endverb
      \keyw{dynamic time warping,gesture customization,gesture recognition,rapid prototyping,user evaluation}
    \endentry
    \entry{Taranta:2021}{article}{}
      \name{author}{6}{}{%
        {{hash=49ec62c0f388ba6345aea9a21bd3e9e7}{%
           family={Taranta\bibnamedelima II},
           familyi={T\bibinitperiod\bibinitdelim I\bibinitperiod},
           given={Eugene\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=74da9aa20b40d1589084c2471ec24573}{%
           family={Pittman},
           familyi={P\bibinitperiod},
           given={Corey\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=c90fc658d0ad6672733c19d1db437678}{%
           family={Maghoumi},
           familyi={M\bibinitperiod},
           given={Mehran},
           giveni={M\bibinitperiod}}}%
        {{hash=766e7bfa5faa982b043b28ff268f24a2}{%
           family={Maslych},
           familyi={M\bibinitperiod},
           given={Mykola},
           giveni={M\bibinitperiod}}}%
        {{hash=e5fb1b6ffa558aa9473142d791ad32cc}{%
           family={Moolenaar},
           familyi={M\bibinitperiod},
           given={Yasmine\bibnamedelima M.},
           giveni={Y\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=4049f526d313931ba6c480dc7892abeb}{%
           family={Laviola\bibnamedelima Jr},
           familyi={L\bibinitperiod\bibinitdelim J\bibinitperiod},
           given={Joseph\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{fullhash}{570361ce4449d6aef5fb35ef95413939}
      \strng{bibnamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authorbibnamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authornamehash}{4d30f779671329b67506d374d7d5fd92}
      \strng{authorfullhash}{570361ce4449d6aef5fb35ef95413939}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present Machete, a straightforward segmenter one can use to isolate custom gestures in continuous input. Machete uses traditional continuous dynamic programming with a novel dissimilarity measure to align incoming data with gesture class templates in real time. Advantages of Machete over alternative techniques is that our segmenter is computationally efficient, accurate, device-agnostic, and works with a single training sample. We demonstrate Machete’s effectiveness through an extensive evaluation using four new high-activity datasets that combine puppeteering, direct manipulation, and gestures. We find that Machete outperforms three alternative techniques in segmentation accuracy and latency, making Machete the most performant segmenter. We further show that when combined with a custom gesture recognizer, Machete is the only option that achieves both high recognition accuracy and low latency in a video game application.}
      \field{issn}{1073-0516}
      \field{journaltitle}{ACM Trans. Comput.-Hum. Interact.}
      \field{month}{1}
      \field{number}{1}
      \field{title}{{Machete: Easy, Efficient, and Precise Continuous Custom Gesture Segmentation}}
      \field{volume}{28}
      \field{year}{2021}
      \verb{doi}
      \verb 10.1145/3428068
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3428068
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3428068
      \endverb
      \keyw{DTW,Continuous,segmentation,custom,CDP,gesture}
    \endentry
    \entry{Thaweesitthichat:2018}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=3df15c1bd8f52c8f119bc6844b01f7de}{%
           family={Thaweesitthichat},
           familyi={T\bibinitperiod},
           given={Pakpoom},
           giveni={P\bibinitperiod}}}%
        {{hash=0c441cf58ccdbcef2b4bc9e5bb9abb82}{%
           family={Jiamsorn},
           familyi={J\bibinitperiod},
           given={Thuchchai},
           giveni={T\bibinitperiod}}}%
        {{hash=fd779ca5336d660731fbd15d515a8c97}{%
           family={Punyabukkana},
           familyi={P\bibinitperiod},
           given={Proadpran},
           giveni={P\bibinitperiod}}}%
        {{hash=eaf2bdf383ee127ad378bdf5f20c10be}{%
           family={Chuangsuwanich},
           familyi={C\bibinitperiod},
           given={Ekapol},
           giveni={E\bibinitperiod}}}%
        {{hash=2c10ee2bb68c4ae060769db9d48d13b9}{%
           family={Suchato},
           familyi={S\bibinitperiod},
           given={Atiwong},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Midview City, SGP}%
      }
      \list{publisher}{1}{%
        {Singapore Therapeutic, Assistive \& Rehabilitative Technologies (START) Centre}%
      }
      \strng{namehash}{5ab8dfcc3469a018c00915df1f61d471}
      \strng{fullhash}{27ecb69531574ada61970785b30e3e78}
      \strng{bibnamehash}{5ab8dfcc3469a018c00915df1f61d471}
      \strng{authorbibnamehash}{5ab8dfcc3469a018c00915df1f61d471}
      \strng{authornamehash}{5ab8dfcc3469a018c00915df1f61d471}
      \strng{authorfullhash}{27ecb69531574ada61970785b30e3e78}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 12th International Convention on Rehabilitation Engineering and Assistive Technology}
      \field{series}{i-CREATe 2018}
      \field{title}{{Thai Sign Language Recognition with Leap Motion}}
      \field{venue}{Shanghai, China}
      \field{year}{2018}
      \field{pages}{47\bibrangedash 50}
      \range{pages}{4}
      \keyw{Thai Sign Language,Deep Learning,Translation Device,Gesture Recognition,Machine Learning}
    \endentry
    \entry{Theofanidis:2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=7f17848500d0f3779d26c807cad99a8e}{%
           family={Theofanidis},
           familyi={T\bibinitperiod},
           given={Michail},
           giveni={M\bibinitperiod}}}%
        {{hash=5d4d749cd81d125d52247e81a567fa28}{%
           family={Sayed},
           familyi={S\bibinitperiod},
           given={Saif\bibnamedelima Iftekar},
           giveni={S\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{hash=20a2c7c67d3fdd84692237f475186126}{%
           family={Lioulemes},
           familyi={L\bibinitperiod},
           given={Alexandros},
           giveni={A\bibinitperiod}}}%
        {{hash=de254dfde1af42d577f871cd6b140fd5}{%
           family={Makedon},
           familyi={M\bibinitperiod},
           given={Fillia},
           giveni={F\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{fd0f02e86ee801d3e84b68d77823c3f9}
      \strng{fullhash}{218248e9aed416b563ad9f94019b7748}
      \strng{bibnamehash}{fd0f02e86ee801d3e84b68d77823c3f9}
      \strng{authorbibnamehash}{fd0f02e86ee801d3e84b68d77823c3f9}
      \strng{authornamehash}{fd0f02e86ee801d3e84b68d77823c3f9}
      \strng{authorfullhash}{218248e9aed416b563ad9f94019b7748}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments}
      \field{isbn}{9781450352277}
      \field{series}{PETRA '17}
      \field{title}{{VARM: Using Virtual Reality to Program Robotic Manipulators}}
      \field{venue}{Island of Rhodes, Greece}
      \field{year}{2017}
      \field{pages}{215\bibrangedash 221}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1145/3056540.3056541
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3056540.3056541
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3056540.3056541
      \endverb
      \keyw{Robot Kinematics,Human Robot Interaction,Leap Motion Controller,Virtual Reality}
    \endentry
    \entry{Togootogtokh:2018}{article}{}
      \name{author}{6}{}{%
        {{hash=2edc39bfb2c5f4a4b21ce2a1949d2455}{%
           family={Togootogtokh},
           familyi={T\bibinitperiod},
           given={Enkhtogtokh},
           giveni={E\bibinitperiod}}}%
        {{hash=59b05d3c89cf6705cbe8c41924db5a54}{%
           family={Shih},
           familyi={S\bibinitperiod},
           given={Timothy\bibnamedelima K.},
           giveni={T\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=569c86c77a46c22f187a324ad28bc098}{%
           family={Kumara},
           familyi={K\bibinitperiod},
           given={W.\bibnamedelimi G.},
           giveni={W\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=88d56ec963bec33ab1fc2e1a65696520}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Shih-Jung},
           giveni={S\bibinithyphendelim J\bibinitperiod}}}%
        {{hash=95b1afbd041cf4e26c340939cff63007}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Shih-Wei},
           giveni={S\bibinithyphendelim W\bibinitperiod}}}%
        {{hash=30b937e7eff5a737a3966db8b6d25635}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Hon-Hang},
           giveni={H\bibinithyphendelim H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{150859e01c2c1270fa4cf971c5ca7b9f}
      \strng{fullhash}{2cfa8f5b9cff5f73b12106cda800c9c9}
      \strng{bibnamehash}{150859e01c2c1270fa4cf971c5ca7b9f}
      \strng{authorbibnamehash}{150859e01c2c1270fa4cf971c5ca7b9f}
      \strng{authornamehash}{150859e01c2c1270fa4cf971c5ca7b9f}
      \strng{authorfullhash}{2cfa8f5b9cff5f73b12106cda800c9c9}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{4}
      \field{number}{8}
      \field{title}{{3D Finger Tracking and Recognition Image Processing for Real-Time Music Playing with Depth Sensors}}
      \field{volume}{77}
      \field{year}{2018}
      \field{pages}{9233\bibrangedash 9248}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1007/s11042-017-4784-9
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11042-017-4784-9
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11042-017-4784-9
      \endverb
      \keyw{Neural network,Senz3D,3D finger tracking,Leap motion,3D finger recognition,3D finger gesture,Virtual musical instruments,Gesture recognition}
    \endentry
    \entry{Tran:2013}{article}{}
      \name{author}{4}{}{%
        {{hash=89e3298694aa904924aaaae42e704fef}{%
           family={Tran},
           familyi={T\bibinitperiod},
           given={Anh\bibnamedelima Phuong},
           giveni={A\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=848712736b47161863b9f9609f0d0363}{%
           family={André},
           familyi={A\bibinitperiod},
           given={Frederic},
           giveni={F\bibinitperiod}}}%
        {{hash=fc74f19b28c42cdb73f6a6d4f3a63c9d}{%
           family={Craeye},
           familyi={C\bibinitperiod},
           given={Christophe},
           giveni={C\bibinitperiod}}}%
        {{hash=6e90f24a074729a3fe9af8c9c9788b7d}{%
           family={Lambot},
           familyi={L\bibinitperiod},
           given={Sébastien},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{716c20ea22f830250b62acbc234b7f26}
      \strng{fullhash}{c2966ca3e7c3be5a4ec1cc6f120325ef}
      \strng{bibnamehash}{716c20ea22f830250b62acbc234b7f26}
      \strng{authorbibnamehash}{716c20ea22f830250b62acbc234b7f26}
      \strng{authornamehash}{716c20ea22f830250b62acbc234b7f26}
      \strng{authorfullhash}{c2966ca3e7c3be5a4ec1cc6f120325ef}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1559-8985}
      \field{journaltitle}{Progress in Electromagnetics Research-Pier}
      \field{title}{{Near-field or far-field full-wave ground penetrating radar modeling as a function of the antenna height above a planar layered medium}}
      \field{type}{Journal Article}
      \field{volume}{141}
      \field{year}{2013}
      \field{pages}{415\bibrangedash 430}
      \range{pages}{16}
      \verb{doi}
      \verb 10.2528/pier13053106
      \endverb
    \endentry
    \entry{Tran:2016}{article}{}
      \name{author}{4}{}{%
        {{hash=bfa4c1278f86d6253e0c98ef3a67691e}{%
           family={Tran},
           familyi={T\bibinitperiod},
           given={Van\bibnamedelima Thanh},
           giveni={V\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{hash=0ed5322f3b278e605a29ebf1181e54ff}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Jaewoon},
           giveni={J\bibinitperiod}}}%
        {{hash=730917ec2851dbdbd5ac26cf761a4dc2}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Dongho},
           giveni={D\bibinitperiod}}}%
        {{hash=765a9fb526375b724d96abb16103f1c5}{%
           family={Jeong},
           familyi={J\bibinitperiod},
           given={Young-Sik},
           giveni={Y\bibinithyphendelim S\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{7012541f1c9043330d756f74a4c5151d}
      \strng{fullhash}{8977a0c805bb4aea54093ff6f21257fd}
      \strng{bibnamehash}{7012541f1c9043330d756f74a4c5151d}
      \strng{authorbibnamehash}{7012541f1c9043330d756f74a4c5151d}
      \strng{authornamehash}{7012541f1c9043330d756f74a4c5151d}
      \strng{authorfullhash}{8977a0c805bb4aea54093ff6f21257fd}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0920-8542}
      \field{journaltitle}{J. Supercomput.}
      \field{month}{7}
      \field{number}{7}
      \field{title}{{Easy-to-Use Virtual Brick Manipulation Techniques Using Hand Gestures}}
      \field{volume}{72}
      \field{year}{2016}
      \field{pages}{2752\bibrangedash 2766}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/s11227-015-1588-4
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s11227-015-1588-4
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s11227-015-1588-4
      \endverb
      \keyw{NUI (Natural User Interface),Gesture recognition,Leap Motion,Virtual reality}
    \endentry
    \entry{Tzadok:2020}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=fdc49c5762b89163d281be3b6b65bac8}{%
           family={Tzadok},
           familyi={T\bibinitperiod},
           given={Asaf},
           giveni={A\bibinitperiod}}}%
        {{hash=eecc2f92c3a3ec6c76b097a6e7248ac2}{%
           family={Valdes-Garcia},
           familyi={V\bibinithyphendelim G\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod}}}%
        {{hash=a7f3272aea8959b64b62580557fa5136}{%
           family={Pepeljugoski},
           familyi={P\bibinitperiod},
           given={Petar},
           giveni={P\bibinitperiod}}}%
        {{hash=0d27fc24cf46e6773f0381012d808c17}{%
           family={Plouchart},
           familyi={P\bibinitperiod},
           given={J.-O.},
           giveni={J\bibinithyphendelim O\bibinitperiod}}}%
        {{hash=3f356f9febd70414efb08027edc6e87e}{%
           family={Yeck},
           familyi={Y\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=e2f7c3d82a409eff30216bd3160fb39f}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Huijuan},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{6c241fefe89dbbf6b935a8a246af0317}
      \strng{fullhash}{89a9e4ae5490f07913311543cbcf6178}
      \strng{bibnamehash}{6c241fefe89dbbf6b935a8a246af0317}
      \strng{authorbibnamehash}{6c241fefe89dbbf6b935a8a246af0317}
      \strng{authornamehash}{6c241fefe89dbbf6b935a8a246af0317}
      \strng{authorfullhash}{89a9e4ae5490f07913311543cbcf6178}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A vertically integrated antennas-to-AI system is presented. 60-GHz 16-element phased array transmitter and receiver modules, previously developed for Gb/s NLOS communications, are used to implement a 3D radar system that extracts volumetric information from a scene at a high frame rate. The system employs an FMCW signal with 1-GHz bandwidth and can process 1250 radar readouts per second. An efficient timing control scheme between the radar electronics and the phased array module control enables obtaining each of the radar readouts from a separate beam direction. The system can scan a frame of 5×5 directions 50 times per second. All the radar system components including signal generation and ADC are assembled in a single portable chassis. A camera is also included in the system to enable the simultaneous capture of radar and video streams. A DNN was developed to extract temporal and volumetric features from the 3D radar information stream and enable the automatic recognition of fast evolving events. As an application example, the DNN was trained to perform automatic hand gesture recognition. The overall radar system and the associated DNN achieved a recognition accuracy of 93\% on a set of 9 different gestures involving two hands.}
      \field{booktitle}{2020 {IEEE}/{MTT}-{S} {International} {Microwave} {Symposium} ({IMS})}
      \field{month}{8}
      \field{note}{ISSN: 2576-7216}
      \field{title}{{AI}-driven {Event} {Recognition} with a {Real}-{Time} {3D} 60-{GHz} {Radar} {System}}
      \field{year}{2020}
      \field{pages}{795\bibrangedash 798}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/IMS30576.2020.9224112
      \endverb
      \keyw{3D radar information stream,3D sensing,ADC,antenna phased arrays,antennas-to-AI system,array transmitter,automatic hand gesture recognition,beam direction,CW radar,DNN,event recognition,feature extraction,FM radar,FMCW signal,gesture recognition,hand gestures recognition,Millimeter-wave radar,millimetre wave antenna arrays,millimetre wave radar,neural nets,NLOS communications,phased array module control,radar antennas,radar electronics,radar imaging,radar readouts,radar system components,receiver modules,signal generation,stereo image processing,telecommunication control,timing control scheme,video cameras,video signal processing,video streams,volumetric information}
    \endentry
    \entry{Nothomb:2020}{thesis}{}
      \name{author}{4}{}{%
        {{hash=c475d740d1ba5bcc411d3e3fbd571fcf}{%
           family={Usuwiel},
           familyi={U\bibinitperiod},
           given={Harry},
           giveni={H\bibinitperiod}}}%
        {{hash=7510b2e0407fe6021c4dc898e4252466}{%
           family={Wilberz},
           familyi={W\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=4fc6a42aa482dc46e6ee398480130cc4}{%
           family={Lynden},
           familyi={L\bibinitperiod},
           given={Tancrède},
           giveni={T\bibinitperiod},
           prefix={d'Aspremont},
           prefixi={d\bibinitperiod}}}%
        {{hash=598b2b3cc6f6c082d54bdb176f12fe60}{%
           family={Nothomb},
           familyi={N\bibinitperiod},
           given={Bastien},
           giveni={B\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {UCL UCL UCL UCL - Louvain School of Management Louvain School of Management Faculté des sciences économiques, sociales, politiques et de communication Ecole polytechnique de Louvain}%
      }
      \list{language}{1}{%
        {Anglais}%
      }
      \strng{namehash}{cb62e6494d88050e7d560232db806008}
      \strng{fullhash}{493c6a30b86b3fa979499b58a50f5e72}
      \strng{bibnamehash}{cb62e6494d88050e7d560232db806008}
      \strng{authorbibnamehash}{cb62e6494d88050e7d560232db806008}
      \strng{authornamehash}{cb62e6494d88050e7d560232db806008}
      \strng{authorfullhash}{493c6a30b86b3fa979499b58a50f5e72}
      \field{sortinit}{U}
      \field{sortinithash}{6901a00e45705986ee5e7ca9fd39adca}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This master's thesis ambition is to study the opportunity to launch a UCLouvain spin-off specialized in the interaction between surgeons and medical imaging during operations. Guinevere will propose a software that will allow surgeons to control medical imaging in real time with simple hand gestures. This innovation will save surgeons valuable time while ensuring a sterile environment.}
      \field{title}{{Opportunity study for the implementation of gesture recognition technology in the hospital environment - Commercialization through a university spin-off}}
      \field{type}{phdthesis}
      \field{year}{2020}
      \verb{urlraw}
      \verb http://hdl.handle.net/2078.1/thesis:24615
      \endverb
      \verb{url}
      \verb http://hdl.handle.net/2078.1/thesis:24615
      \endverb
      \keyw{Touchless interaction,Surgery,Healthcare sector,Spin-off}
    \endentry
    \entry{Vanderdonckt:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=f822d8f741e1aed7d9b7872fe72da592}{%
           family={Roselli},
           familyi={R\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=684d5d4196dce70788bcfc1098df0c34}{%
           family={Pérez{-}Medina},
           familyi={P\bibinitperiod},
           given={Jorge\bibnamedelima Luis},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \name{editor}{6}{}{%
        {{hash=32d6285e726a28477d6765d58749dbad}{%
           family={D'Mello},
           familyi={D\bibinitperiod},
           given={Sidney\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=ed25c2d41b78592d152aba6c7bf9902b}{%
           family={Georgiou},
           familyi={G\bibinitperiod},
           given={Panayiotis\bibnamedelima G.},
           giveni={P\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=2602443e0a6840d51030e7287d55ce2b}{%
           family={Scherer},
           familyi={S\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=bc2ceaf5f63daedc84837c8a4893faf0}{%
           family={Provost},
           familyi={P\bibinitperiod},
           given={Emily\bibnamedelima Mower},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=102f5f953b96751cafe841ae28608655}{%
           family={Soleymani},
           familyi={S\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod}}}%
        {{hash=b95c900ef8e722c32ca82f102b869f47}{%
           family={Worsley},
           familyi={W\bibinitperiod},
           given={Marcelo},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{fullhash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{bibnamehash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{authorbibnamehash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{authornamehash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{authorfullhash}{2bae93c016411250b690ab2c27b0ddf3}
      \strng{editorbibnamehash}{de7107c7d6c72880a921ec987705078d}
      \strng{editornamehash}{de7107c7d6c72880a921ec987705078d}
      \strng{editorfullhash}{9ac6d1ec9e2602e224ca6fae4b86dc11}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the ACM International Conference on Multimodal Interaction}
      \field{series}{{ICMI} '18}
      \field{title}{{!FTL}, an Articulation-Invariant Stroke Gesture Recognizer with Controllable Position, Scale, and Rotation Invariances}
      \field{venue}{Boulder, CO, USA}
      \field{year}{2018}
      \field{pages}{125\bibrangedash 134}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/3242969.3243032
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3242969.3243032
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3242969.3243032
      \endverb
    \endentry
    \entry{Vandersmissen:2020}{article}{}
      \name{author}{6}{}{%
        {{hash=14158047c725f5ee9361e2ec441c3440}{%
           family={Vandersmissen},
           familyi={V\bibinitperiod},
           given={Baptist},
           giveni={B\bibinitperiod}}}%
        {{hash=f4ed645ac5927d883686b5ab0952d817}{%
           family={Knudde},
           familyi={K\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=de38b3d1d5b75e40e0bd0f75b2b938d4}{%
           family={Jalalvand},
           familyi={J\bibinitperiod},
           given={Azarakhsh},
           giveni={A\bibinitperiod}}}%
        {{hash=abcfed1d81508b3b77397deb08c07111}{%
           family={Couckuyt},
           familyi={C\bibinitperiod},
           given={Ivo},
           giveni={I\bibinitperiod}}}%
        {{hash=fe6fb52a5b3c044d81680c12a8c19332}{%
           family={Dhaene},
           familyi={D\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod}}}%
        {{hash=88b587b8d45c87193ef2f74352f6cfa3}{%
           family={De\bibnamedelima Neve},
           familyi={D\bibinitperiod\bibinitdelim N\bibinitperiod},
           given={Wesley},
           giveni={W\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{d76723bf43e0f3f77a7662c96c8a133a}
      \strng{fullhash}{fb65d68b3fb816abb87451c71b578f69}
      \strng{bibnamehash}{d76723bf43e0f3f77a7662c96c8a133a}
      \strng{authorbibnamehash}{d76723bf43e0f3f77a7662c96c8a133a}
      \strng{authornamehash}{d76723bf43e0f3f77a7662c96c8a133a}
      \strng{authorfullhash}{fb65d68b3fb816abb87451c71b578f69}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0941-0643, 1433-3058}
      \field{journaltitle}{Neural Computing and Applications}
      \field{month}{8}
      \field{number}{16}
      \field{title}{{Indoor human activity recognition using high-dimensional sensors and deep neural networks}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{32}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{12295\bibrangedash 12309}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1007/s00521-019-04408-1
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/s00521-019-04408-1
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/s00521-019-04408-1
      \endverb
    \endentry
    \entry{Vatavu:2023b}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{fullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{bibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorbibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authornamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorfullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \field{extraname}{1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We examine gestures performed with a class of input devices with distinctive quality properties in the wearables landscape, which we call “index-Finger Augmentation Devices” (iFADs). We introduce a four-level taxonomy to characterize the diversity of iFAD gestures, evaluate iFAD gesture articulation on a dataset of 6,369 gestures collected from 20 participants, and compute recognition accuracy rates. Our findings show that iFAD gestures are fast (1.84s on average), easy to articulate (1.52 average rating on a difficulty scale from 1 to 5), and socially acceptable (81\% willingness to use them in public places). We compare iFAD gestures with gestures performed using other devices (styli, touchscreens, game controllers) from several public datasets (39,263 gestures, 277 participants), and report that iFAD gestures are two times faster than whole-body gestures and as fast as stylus and finger strokes performed on touchscreens.}
      \field{booktitle}{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450394215}
      \field{series}{CHI '23}
      \field{title}{{IFAD Gestures: Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices}}
      \field{venue}{Hamburg, Germany}
      \field{year}{2023}
      \verb{doi}
      \verb 10.1145/3544548.3580928
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3544548.3580928
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3544548.3580928
      \endverb
      \keyw{finger augmentation devices,taxonomy,gesture analysis,Index finger,gesture recognition,gesture input}
    \endentry
    \entry{Vatavu:2017a}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{fullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{bibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorbibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authornamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorfullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \field{extraname}{2}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the ACM Conference on Human Factors in Computing Systems}
      \field{isbn}{978-1-4503-4655-9}
      \field{series}{CHI '17}
      \field{title}{{Improving Gesture Recognition Accuracy on Touch Screens for Users with Low Vision}}
      \field{venue}{Denver, Colorado, USA}
      \field{year}{2017}
      \field{pages}{4667\bibrangedash 4679}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1145/3025453.3025941
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/3025453.3025941
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/3025453.3025941
      \endverb
      \keyw{1,P,P+,algorithms,evaluation,gesture recognition,low vision,point clouds,recognition,recognition accuracy,touch gestures,touch screens,visual impairments}
    \endentry
    \entry{Vatavu:2019}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{fullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{bibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorbibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authornamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorfullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \field{extraname}{3}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce the dissimilarity-consensus method, a new approach to computing objective measures of consensus between users' gesture preferences to support data analysis in end-user gesture elicitation studies. Our method models and quantifies the relationship between users' consensus over gesture articulation and numerical measures of gesture dissimilarity, e.g., Dynamic Time Warping or Hausdorff distances, by employing growth curves and logistic functions. We exemplify our method on 1,312 whole-body gestures elicited from 30 children, ages 3 to 6 years, and we report the first empirical results in the literature on the consensus between whole-body gestures produced by children this young. We provide C\# and R software implementations of our method and make our gesture dataset publicly available.}
      \field{booktitle}{Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450359702}
      \field{series}{CHI '19}
      \field{title}{{The Dissimilarity-Consensus Approach to Agreement Analysis in Gesture Elicitation Studies}}
      \field{venue}{Glasgow, Scotland Uk}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 13}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1145/3290605.3300454
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3290605.3300454
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3290605.3300454
      \endverb
      \keyw{growth curves,consensus,dataset,gesture elicitation,logistic model,gesture input,children,whole-body gestures}
    \endentry
    \entry{Vatavu:2013}{article}{}
      \name{author}{1}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
      }
      \strng{namehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{fullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{bibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorbibnamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authornamehash}{1a7f437116125039a0d6488efc6ff6c3}
      \strng{authorfullhash}{1a7f437116125039a0d6488efc6ff6c3}
      \field{extraname}{4}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The interactive demands of the upcoming ubiquitous computing era have set off researchers and practitioners toward prototyping new gesture-sensing devices and gadgets. At the same time, the practical needs of developing for such miniaturized prototypes with sometimes very low processing power and memory resources make practitioners in high demand of fast gesture recognizers employing little memory. However, the available work on motion gesture classifiers has mainly focused on delivering high recognition performance with less discussion on execution speed or required memory. This work investigates the performance of today's commonly used 3D motion gesture recognizers under the effect of different gesture dimensionality and bit cardinality representations. Specifically, we show that few sampling points and low bit depths are sufficient for most motion gesture metrics to attain their peak recognition performance in the context of the popular Nearest-Neighbor classification approach. As a practical consequence, 16x faster recognizers working with 32x less memory while delivering the same high levels of recognition performance are being reported. We present recognition results for a large gesture corpus consisting in nearly 20,000 gesture samples. In addition, a toolkit is provided to assist practitioners in optimizing their gesture recognizers in order to increase classification speed and reduce memory consumption for their designs. At a deeper level, our findings suggest that the precision of the human motor control system articulating 3D gestures is needlessly surpassed by the precision of today's motion sensing technology that unfortunately bares a direct connection with the sensors' cost. We hope this work will encourage practitioners to consider improving the performance of their prototypes by careful analysis of motion gesture representation rather than by throwing more processing power and more memory into the design.}
      \field{issn}{1071-5819}
      \field{journaltitle}{International Journal of Human-Computer Studies}
      \field{number}{4}
      \field{title}{The impact of motion dimensionality and bit cardinality on the design of 3D gesture recognizers}
      \field{volume}{71}
      \field{year}{2013}
      \field{pages}{387\bibrangedash 409}
      \range{pages}{23}
      \verb{doi}
      \verb https://doi.org/10.1016/j.ijhcs.2012.11.005
      \endverb
      \verb{urlraw}
      \verb http://www.sciencedirect.com/science/article/pii/S1071581912002108
      \endverb
      \verb{url}
      \verb http://www.sciencedirect.com/science/article/pii/S1071581912002108
      \endverb
      \keyw{Gesture recognition,Gesture dimensionality,Sampling rate,3D gestures,Classifiers,Bit cardinality,Bit depth,Euclidean distance,Angular cosine distance,Dynamic time warping,Hausdorff,Gesture toolkit}
    \endentry
    \entry{Vatavu:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=c409c5ecb8bcc6ef5af1868d1698aa26}{%
           family={Anthony},
           familyi={A\bibinitperiod},
           given={Lisa},
           giveni={L\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{fullhash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{bibnamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authorbibnamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authornamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authorfullhash}{ec930487ab22cf075658ac0703a47dcb}
      \field{extraname}{1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services}
      \field{isbn}{9781450358989}
      \field{series}{MobileHCI '18}
      \field{title}{{\$Q: A Super-Quick, Articulation-Invariant Stroke-Gesture Recognizer for Low-Resource Devices}}
      \field{venue}{Barcelona, Spain}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3229434.3229465
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3229434.3229465
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3229434.3229465
      \endverb
      \keyw{point-cloud recognizer,mobile devices,\$Q,stroke recognition,\$1,\$-family,\$P,gesture recognition,low-resource devices}
    \endentry
    \entry{Vatavu:2012}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=c409c5ecb8bcc6ef5af1868d1698aa26}{%
           family={Anthony},
           familyi={A\bibinitperiod},
           given={Lisa},
           giveni={L\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{fullhash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{bibnamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authorbibnamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authornamehash}{ec930487ab22cf075658ac0703a47dcb}
      \strng{authorfullhash}{ec930487ab22cf075658ac0703a47dcb}
      \field{extraname}{2}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 14th ACM International Conference on Multimodal Interaction}
      \field{isbn}{978-1-4503-1467-1}
      \field{series}{ICMI '12}
      \field{title}{{Gestures As Point Clouds: A \$P Recognizer for User Interface Prototypes}}
      \field{venue}{Santa Monica, California, USA}
      \field{year}{2012}
      \field{pages}{273\bibrangedash 280}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2388676.2388732
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/2388676.2388732
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/2388676.2388732
      \endverb
      \keyw{\$1,\$n,\$p,comparing classifiers,euclidean,gesture recognition,hausdorff,hungarian,multistrokes,point clouds}
    \endentry
    \entry{Vatavu:2008}{article}{}
      \name{author}{2}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=8bcae6e2c6f0093385d2b521eb8a991e}{%
           family={Pentiuc},
           familyi={P\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{b725b4527238266ff2d6070581d1b1cb}
      \strng{fullhash}{b725b4527238266ff2d6070581d1b1cb}
      \strng{bibnamehash}{b725b4527238266ff2d6070581d1b1cb}
      \strng{authorbibnamehash}{b725b4527238266ff2d6070581d1b1cb}
      \strng{authornamehash}{b725b4527238266ff2d6070581d1b1cb}
      \strng{authorfullhash}{b725b4527238266ff2d6070581d1b1cb}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Computing and Informatics}
      \field{month}{01}
      \field{title}{{Multi-Level Representation of Gesture as Command for Human Computer Interaction.}}
      \field{volume}{27}
      \field{year}{2008}
      \field{pages}{837\bibrangedash 851}
      \range{pages}{15}
    \endentry
    \entry{Vatavu:2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu{-}Daniel},
           giveni={R\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=e12759e22be913309860332a8ac7ac33}{%
           family={Begole},
           familyi={B\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=92321658d9245268b5a542a47334f2df}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Jinwoo},
           giveni={J\bibinitperiod}}}%
        {{hash=0e3f2e4008eae58f045d17d431e2227c}{%
           family={Inkpen},
           familyi={I\bibinitperiod},
           given={Kori},
           giveni={K\bibinitperiod}}}%
        {{hash=9165761f8ada6871689b6b78a8c497e7}{%
           family={Woo},
           familyi={W\bibinitperiod},
           given={Woontack},
           giveni={W\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{fb222899e04ec8a403e081d1ba180223}
      \strng{fullhash}{fb222899e04ec8a403e081d1ba180223}
      \strng{bibnamehash}{fb222899e04ec8a403e081d1ba180223}
      \strng{authorbibnamehash}{fb222899e04ec8a403e081d1ba180223}
      \strng{authornamehash}{fb222899e04ec8a403e081d1ba180223}
      \strng{authorfullhash}{fb222899e04ec8a403e081d1ba180223}
      \strng{editorbibnamehash}{4f888223c64ef5e0c78005a0884ff6f8}
      \strng{editornamehash}{4f888223c64ef5e0c78005a0884ff6f8}
      \strng{editorfullhash}{54ed798e53f0a6331a31fb7dd31d778d}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 33rd Annual {ACM} Conference on Human Factors in Computing Systems}
      \field{series}{CHI 2015}
      \field{title}{{Formalizing Agreement Analysis for Elicitation Studies: New Measures, Significance Test, and Toolkit}}
      \field{venue}{Seoul, Republic of Korea}
      \field{year}{2015}
      \field{pages}{1325\bibrangedash 1334}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2702123.2702223
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2702123.2702223
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2702123.2702223
      \endverb
    \endentry
    \entry{Vatavu:2014b}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=842c82970153fc3e64e80be720afacce}{%
           family={Zaiti},
           familyi={Z\bibinitperiod},
           given={Ionut-Alexandru},
           giveni={I\bibinithyphendelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{42a29ce11a6b919f8ab868156db30845}
      \strng{fullhash}{42a29ce11a6b919f8ab868156db30845}
      \strng{bibnamehash}{42a29ce11a6b919f8ab868156db30845}
      \strng{authorbibnamehash}{42a29ce11a6b919f8ab868156db30845}
      \strng{authornamehash}{42a29ce11a6b919f8ab868156db30845}
      \strng{authorfullhash}{42a29ce11a6b919f8ab868156db30845}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present insights from a gesture elicitation study in the context of interacting with TV, during which 18 participants contributed and rated the execution difficulty and recall likeliness of free-hand gestures for 21 distinct TV tasks. Our study complements previous work on gesture interaction design for the TV set with the first exploration of fine-grained resolution 3-D finger movements and hand pose gestures. We report lower agreement rates (.20) than previous gesture studies and 72.8\% recall rate and 15.8\% false positive recall, results that are explained by the complexity and variability of unconstrained finger gestures. Nevertheless, we report a large 82\% preference for gesture commands versus TV remote controls. We also confirm previous findings, such as people's preferences for related gestures for dichotomous tasks, and we report low agreement rates for abstract tasks, such as "open browser" or "show channels list" in our specific TV scenario. In the end, we contribute a set of design guidelines for practitioners interested in free-hand finger and hand pose gestures for interactive TV scenarios, and we release a dataset of 378 Leap Motion gesture records consisting in finger position, direction, and velocity coordinates for further studies in the community. We see this exploration as a first step toward designing low-effort high-resolution finger gestures and hand poses for lean-back interaction with the TV set.}
      \field{booktitle}{Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video}
      \field{isbn}{9781450328388}
      \field{series}{TVX '14}
      \field{title}{{Leap Gestures for TV: Insights from an Elicitation Study}}
      \field{venue}{Newcastle Upon Tyne, United Kingdom}
      \field{year}{2014}
      \field{pages}{131\bibrangedash 138}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/2602299.2602316
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2602299.2602316
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2602299.2602316
      \endverb
      \keyw{recall likeliness,interactive tv,motion gestures,gesture interfaces,hand pose,leap motion,elicitation study}
    \endentry
    \entry{Villarreal:2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=1bf2981168e31dfc774ead23fecaf927}{%
           family={Villarreal-Narvaez},
           familyi={V\bibinithyphendelim N\bibinitperiod},
           given={Santiago},
           giveni={S\bibinitperiod}}}%
        {{hash=bf13e9fd7a02311de6ebe2666bf62a5f}{%
           family={Vanderdonckt},
           familyi={V\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=1a7f437116125039a0d6488efc6ff6c3}{%
           family={Vatavu},
           familyi={V\bibinitperiod},
           given={Radu-Daniel},
           giveni={R\bibinithyphendelim D\bibinitperiod}}}%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{c3813b95464466a5e1a812ea97d9bc68}
      \strng{fullhash}{2f71c679cfb4b91dd76120cc76d5bbca}
      \strng{bibnamehash}{c3813b95464466a5e1a812ea97d9bc68}
      \strng{authorbibnamehash}{c3813b95464466a5e1a812ea97d9bc68}
      \strng{authornamehash}{c3813b95464466a5e1a812ea97d9bc68}
      \strng{authorfullhash}{2f71c679cfb4b91dd76120cc76d5bbca}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture elicitation studies represent a popular and resourceful method in HCI to inform the design of intuitive gesture commands, reflective of end-users' behavior, for controlling all kinds of interactive devices, applications, and systems. In the last ten years, an impressive body of work has been published on this topic, disseminating useful design knowledge regarding users' preferences for finger, hand, wrist, arm, head, leg, foot, and whole-body gestures. In this paper, we deliver a systematic literature review of this large body of work by summarizing the characteristics and findings ofN=216gesture elicitation studies subsuming 5,458 participants, 3,625 referents, and 148,340 elicited gestures. We highlight the descriptive, comparative, and generative virtues of our examination to provide practitioners with an effective method to (i) understand how new gesture elicitation studies position in the literature; (ii) compare studies from different authors; and (iii) identify opportunities for new research. We make our large corpus of papers accessible online as a Zotero group library at https://www.zotero.org/groups/2132650/gesture_elicitation_studies.}
      \field{booktitle}{Proceedings of the 2020 ACM Designing Interactive Systems Conference}
      \field{isbn}{9781450369749}
      \field{series}{DIS '20}
      \field{title}{{A Systematic Review of Gesture Elicitation Studies: What Can We Learn from 216 Studies?}}
      \field{venue}{Eindhoven, Netherlands}
      \field{year}{2020}
      \field{pages}{855\bibrangedash 872}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1145/3357236.3395511
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3357236.3395511
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3357236.3395511
      \endverb
      \keyw{systematic literature review,gesture elicitation,survey}
    \endentry
    \entry{Viunytskyi:2017}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=fea023065633fb9bf41fb9f6a8ce9553}{%
           family={Viunytskyi},
           familyi={V\bibinitperiod},
           given={Oleh},
           giveni={O\bibinitperiod}}}%
        {{hash=adff50d55287fd7ab4e5e856b381a19d}{%
           family={Totsky},
           familyi={T\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{e8c1792f0c017085e4121cdf9719006d}
      \strng{fullhash}{e8c1792f0c017085e4121cdf9719006d}
      \strng{bibnamehash}{e8c1792f0c017085e4121cdf9719006d}
      \strng{authorbibnamehash}{e8c1792f0c017085e4121cdf9719006d}
      \strng{authornamehash}{e8c1792f0c017085e4121cdf9719006d}
      \strng{authorfullhash}{e8c1792f0c017085e4121cdf9719006d}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Novel human gesture recognition and classification technique is suggested and experimentally studied. Suggested strategy is based on exploiting the interactions of human gestures with high-frequency electromagnetic field. Extracting of classification features contained in the wireless radio signal modulated by human gestures is proposed by utilizing bispectrum-based processing of the signal envelope. Novel two kinds of human gesture classification features are computed in the form of biphase values contained in the given slice on the bispectral plane or array of biphase samples contained within the limits of the main bispectral triangular area. It is shown that phase bispectrum contains information about the shape of wireless signal envelope and, consequently, about type of human gesture. Performance of the bispectrum-based human gesture classification technique is studied experimentally. Experimental results obtained by developed measuring hardware and designed software are represented and discussed. The results obtained for the set of test human gestures demonstrate that proposed technique is non-sensitive to random wireless signal delays and magnitude variations commonly observed in closed multi-path interference environment.}
      \field{booktitle}{2017 {Signal} {Processing} {Symposium} ({SPSympo})}
      \field{month}{9}
      \field{title}{{Novel bispectrum-based wireless vision technique using disturbance of electromagnetic field by human gestures}}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/SPS.2017.8053684
      \endverb
      \keyw{biphase,bispectrum,bispectrum-based wireless vision technique,classification features,feature extraction,Feature extraction,gesture recognition,high-frequency electromagnetic field disturbance,human gesture classification,human gesture classification feature extraction,human gesture classification technique,human gesture recognition,Interference,random wireless signal delays,Robustness,Shape,signal classification,Signal processing,Wireless communication,wireless LAN,wireless radio signal,Wireless sensor networks,wireless signal,wireless signal envelope,wireless vision}
    \endentry
    \entry{Vlaming:2008}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=55ff82fcf47ba463ef0698f4c9076cfc}{%
           family={Vlaming},
           familyi={V\bibinitperiod},
           given={Luc},
           giveni={L\bibinitperiod}}}%
        {{hash=5e7994df65761f9c2764fc881b19cb90}{%
           family={Smit},
           familyi={S\bibinitperiod},
           given={Jasper},
           giveni={J\bibinitperiod}}}%
        {{hash=1f980758856350b3e536e3581ce77885}{%
           family={Isenberg},
           familyi={I\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{5698d4fdd82f0c53614ba23438de7855}
      \strng{fullhash}{5698d4fdd82f0c53614ba23438de7855}
      \strng{bibnamehash}{5698d4fdd82f0c53614ba23438de7855}
      \strng{authorbibnamehash}{5698d4fdd82f0c53614ba23438de7855}
      \strng{authornamehash}{5698d4fdd82f0c53614ba23438de7855}
      \strng{authorfullhash}{5698d4fdd82f0c53614ba23438de7855}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2008 3rd IEEE International Workshop on Horizontal Interactive Human Computer Systems}
      \field{title}{{Presenting using two-handed interaction in open space}}
      \field{year}{2008}
      \field{pages}{29\bibrangedash 32}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/TABLETOP.2008.4660180
      \endverb
    \endentry
    \entry{Vogel:2005}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=f94f65826718458aba9a7e2ee4834749}{%
           family={Vogel},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=56b75ac1304af45b6c3f0a9bca7fa615}{%
           family={Balakrishnan},
           familyi={B\bibinitperiod},
           given={Ravin},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \strng{fullhash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \strng{bibnamehash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \strng{authorbibnamehash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \strng{authornamehash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \strng{authorfullhash}{f405fb1a8a5cbc1a766220e329f39dcf}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We explore the design space of freehand pointing and clicking interaction with very large high resolution displays from a distance. Three techniques for gestural pointing and two for clicking are developed and evaluated. In addition, we present subtle auditory and visual feedback techniques to compensate for the lack of kinesthetic feedback in freehand interaction, and to promote learning and use of appropriate postures.}
      \field{booktitle}{Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology}
      \field{isbn}{1595932712}
      \field{series}{UIST '05}
      \field{title}{{Distant Freehand Pointing and Clicking on Very Large, High Resolution Displays}}
      \field{venue}{Seattle, WA, USA}
      \field{year}{2005}
      \field{pages}{33\bibrangedash 42}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1095034.1095041
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1095034.1095041
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1095034.1095041
      \endverb
      \keyw{freehand gestures,pointing,whole hand interaction,very large displays}
    \endentry
    \entry{Vogiatzidakis:2022}{article}{}
      \name{author}{2}{}{%
        {{hash=5c8fbdee829718fcc2eb3f267d8a01a6}{%
           family={Vogiatzidakis},
           familyi={V\bibinitperiod},
           given={Panagiotis},
           giveni={P\bibinitperiod}}}%
        {{hash=4e11216a6d3135760052f5a69e0b46df}{%
           family={Koutsabasis},
           familyi={K\bibinitperiod},
           given={Panayiotis},
           giveni={P\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Academic Press, Inc.}%
      }
      \strng{namehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{fullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{bibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorbibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authornamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorfullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \field{extraname}{1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1071-5819}
      \field{journaltitle}{Int. J. Hum.-Comput. Stud.}
      \field{month}{3}
      \field{number}{C}
      \field{title}{{‘Address and Command’: Two-Handed Mid-Air Interactions with Multiple Home Devices}}
      \field{volume}{159}
      \field{year}{2022}
      \verb{doi}
      \verb 10.1016/j.ijhcs.2021.102755
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.ijhcs.2021.102755
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.ijhcs.2021.102755
      \endverb
      \keyw{Spatial augmented reality,Multiple home devices,Mid-air interaction,Smart home,Prototyping,MS kinect,Projection-mapping,Elicitation study,Gestural interaction,Ubiquitous environment,Address and command,Usability study}
    \endentry
    \entry{Vogiatzidakis:2019}{article}{}
      \name{author}{2}{}{%
        {{hash=5c8fbdee829718fcc2eb3f267d8a01a6}{%
           family={Vogiatzidakis},
           familyi={V\bibinitperiod},
           given={Panagiotis},
           giveni={P\bibinitperiod}}}%
        {{hash=4e11216a6d3135760052f5a69e0b46df}{%
           family={Koutsabasis},
           familyi={K\bibinitperiod},
           given={Panayiotis},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{fullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{bibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorbibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authornamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorfullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \field{extraname}{2}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{If mid-air interaction is to be implemented in smart home environments, then the user would have to exercise in-air gestures to address and manipulate multiple devices. This paper investigates a user-defined gesture vocabulary for basic control of a smart home device ecosystem, consisting of 7 devices and a total of 55 referents (commands for device) that can be grouped to 14 commands (that refer to more than one device). The elicitation study was conducted in a frame (general scenario) of use of all devices to support contextual relevance; also, the referents were presented with minimal affordances to minimize widget-specific proposals. In addition to computing agreement rates for all referents, we also computed the internal consistency of user proposals (single-user agreement for multiple commands). In all, 1047 gestures from 18 participants were recorded, analyzed, and paired with think-aloud data. The study reached to a mid-air gesture vocabulary for a smart-device ecosystem, which includes several gestures with very high, high and medium agreement rates. Furthermore, there was high consistency within most of the single-user gesture proposals, which reveals that each user developed and applied her/his own mental model about the whole set of interactions with the device ecosystem. Thus, we suggest that mid-air interaction support for smart homes should not only offer a built-in gesture set but also provide for functions of identification and definition of personalized gesture assignments to basic user commands.}
      \field{issn}{2227-9709}
      \field{journaltitle}{Informatics}
      \field{number}{2}
      \field{title}{{Frame-Based Elicitation of Mid-Air Gestures for a Smart Home Device Ecosystem}}
      \field{volume}{6}
      \field{year}{2019}
      \verb{doi}
      \verb 10.3390/informatics6020023
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2227-9709/6/2/23
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2227-9709/6/2/23
      \endverb
    \endentry
    \entry{Vogiatzidakis:2020}{article}{}
      \name{author}{2}{}{%
        {{hash=5c8fbdee829718fcc2eb3f267d8a01a6}{%
           family={Vogiatzidakis},
           familyi={V\bibinitperiod},
           given={Panagiotis},
           giveni={P\bibinitperiod}}}%
        {{hash=4e11216a6d3135760052f5a69e0b46df}{%
           family={Koutsabasis},
           familyi={K\bibinitperiod},
           given={Panayiotis},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{fullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{bibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorbibnamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authornamehash}{df85d97dc334388f5ffa70d4feb89c02}
      \strng{authorfullhash}{df85d97dc334388f5ffa70d4feb89c02}
      \field{extraname}{3}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Touchless, mid-air gesture-based interactions with remote devices have been investigated as alternative or complementary to interactions based on remote controls and smartphones. Related studies focus on user elicitation of a gesture vocabulary for one or a few home devices and explore recommendations of respective gesture vocabularies without validating them by empirical testing with interactive prototypes. We have developed an interactive prototype based on spatial Augmented Reality (AR) of seven home devices. Each device responds to touchless gestures (identified from a previous elicitation study) via the MS Kinect sensor. Nineteen users participated in a two-phase test (with and without help provided by a virtual assistant) according to a scenario that required from each user to apply 41 gestural commands (19 unique). We report on main usability indicators: task success, task time, errors (false negative/positives), memorability, perceived usability, and user experience. The main conclusion is that mid-air interaction with multiple home devices is feasible, fairly easy to learn and apply, and enjoyable. The contributions of this paper are (a) validation of a previously elicited gesture set; (b) development of a spatial AR prototype for testing of mid-air gestures, and (c) extensive assessment of gestures and evidence in favor of mid-air interaction in smart environments.}
      \field{issn}{2414-4088}
      \field{journaltitle}{Multimodal Technologies and Interaction}
      \field{number}{3}
      \field{title}{{Mid-Air Gesture Control of Multiple Home Devices in Spatial Augmented Reality Prototype}}
      \field{volume}{4}
      \field{year}{2020}
      \verb{doi}
      \verb 10.3390/mti4030061
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2414-4088/4/3/61
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2414-4088/4/3/61
      \endverb
    \endentry
    \entry{Volioti:2018}{article}{}
      \name{author}{9}{}{%
        {{hash=77b4b13b8c437f8098ee0fab007ae749}{%
           family={Volioti},
           familyi={V\bibinitperiod},
           given={Christina},
           giveni={C\bibinitperiod}}}%
        {{hash=4e0a8e03e9f4d5048766c546c7957fa6}{%
           family={Manitsaris},
           familyi={M\bibinitperiod},
           given={Sotiris},
           giveni={S\bibinitperiod}}}%
        {{hash=430ec4039348abb05dddd67fb54f0bc7}{%
           family={Hemery},
           familyi={H\bibinitperiod},
           given={Edgar},
           giveni={E\bibinitperiod}}}%
        {{hash=3fd559201552a60011abbb2301a5d403}{%
           family={Hadjidimitriou},
           familyi={H\bibinitperiod},
           given={Stelios},
           giveni={S\bibinitperiod}}}%
        {{hash=c7dcdf9a39e0925d7508e57e4e966a8a}{%
           family={Charisis},
           familyi={C\bibinitperiod},
           given={Vasileios},
           giveni={V\bibinitperiod}}}%
        {{hash=1a0fa6906a4f7a2bcbfde3508eac14db}{%
           family={Hadjileontiadis},
           familyi={H\bibinitperiod},
           given={Leontios},
           giveni={L\bibinitperiod}}}%
        {{hash=15f0bb22cc1966a81c6fea79f4b8bdd1}{%
           family={Katsouli},
           familyi={K\bibinitperiod},
           given={Eleni},
           giveni={E\bibinitperiod}}}%
        {{hash=a6e70dfaefa9a1c4907be4911debbc9c}{%
           family={Moutarde},
           familyi={M\bibinitperiod},
           given={Fabien},
           giveni={F\bibinitperiod}}}%
        {{hash=630cda288e9dccf69e89394a3af4ff7c}{%
           family={Manitsaris},
           familyi={M\bibinitperiod},
           given={Athanasios},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{9c3023a1ea4e2fa0e884df114cdc7359}
      \strng{fullhash}{e9c34893d9a28014eecfdb142987f7f3}
      \strng{bibnamehash}{9c3023a1ea4e2fa0e884df114cdc7359}
      \strng{authorbibnamehash}{9c3023a1ea4e2fa0e884df114cdc7359}
      \strng{authornamehash}{9c3023a1ea4e2fa0e884df114cdc7359}
      \strng{authorfullhash}{e9c34893d9a28014eecfdb142987f7f3}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1556-4673}
      \field{journaltitle}{J. Comput. Cult. Herit.}
      \field{month}{4}
      \field{number}{2}
      \field{title}{{A Natural User Interface for Gestural Expression and Emotional Elicitation to Access the Musical Intangible Cultural Heritage}}
      \field{volume}{11}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3127324
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3127324
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3127324
      \endverb
      \keyw{Gesture recognition,sonification,emotional status,evaluation}
    \endentry
    \entry{Walter:2013}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=7025b6a771839a8f1227d089228552d9}{%
           family={Walter},
           familyi={W\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=74bdf17e420a7fd9501b29c772e3b90d}{%
           family={Bailly},
           familyi={B\bibinitperiod},
           given={Gilles},
           giveni={G\bibinitperiod}}}%
        {{hash=7a14b793f9c8206819859db7ee3c9fc9}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Jörg},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Paris, France}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \strng{fullhash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \strng{bibnamehash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \strng{authorbibnamehash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \strng{authornamehash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \strng{authorfullhash}{9ca1a189a324ffbb95fc59a57bc0708d}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56\%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users' variations.}
      \field{booktitle}{Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450318990}
      \field{series}{CHI '13}
      \field{title}{{StrikeAPose: revealing mid-air gestures on public displays}}
      \field{year}{2013}
      \field{pages}{841\bibrangedash 850}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2470654.2470774
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2470654.2470774
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2470654.2470774
      \endverb
      \keyw{revelation,public displays,initial gesture,field study}
    \endentry
    \entry{Wan:2014}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=9bf5cc110f62fef4a61b42f81f95efd0}{%
           family={Wan},
           familyi={W\bibinitperiod},
           given={Qian},
           giveni={Q\bibinitperiod}}}%
        {{hash=04e67240998d775a02d8d19ae85134e8}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yiran},
           giveni={Y\bibinitperiod}}}%
        {{hash=67e9c36fef6ea4addab61a305213f659}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Changzhi},
           giveni={C\bibinitperiod}}}%
        {{hash=c388babfc3cb09497487007e70d699c9}{%
           family={Pal},
           familyi={P\bibinitperiod},
           given={Ranadip},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{183166cc2b92bbe68694314193252722}
      \strng{fullhash}{c9b77b3f5054711baa8082848bd75467}
      \strng{bibnamehash}{183166cc2b92bbe68694314193252722}
      \strng{authorbibnamehash}{183166cc2b92bbe68694314193252722}
      \strng{authornamehash}{183166cc2b92bbe68694314193252722}
      \strng{authorfullhash}{c9b77b3f5054711baa8082848bd75467}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article, we consider the design of a human gesture recognition system based on pattern recognition of signatures from a portable smart radar sensor. Powered by AAA batteries, the smart radar sensor operates in the 2.4 GHz industrial, scientific and medical (ISM) band. We analyzed the feature space using principle components and application-specific time and frequency domain features extracted from radar signals for two different sets of gestures. We illustrate that a nearest neighbor based classifier can achieve greater than 95\% accuracy for multi class classification using 10 fold cross validation when features are extracted based on magnitude differences and Doppler shifts as compared to features extracted through orthogonal transformations. The reported results illustrate the potential of intelligent radars integrated with a pattern recognition system for high accuracy smart home and health monitoring purposes.}
      \field{booktitle}{2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}}
      \field{month}{8}
      \field{note}{ISSN: 1558-4615}
      \field{title}{{Gesture recognition for smart home applications using portable radar sensors}}
      \field{year}{2014}
      \field{pages}{6414\bibrangedash 6417}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/EMBC.2014.6945096
      \endverb
      \keyw{AAA batteries,Accuracy,application specific time,Automated,Doppler effect,Doppler radar,Doppler shifts,Feature extraction,feature space,frequency 2.4 GHz,frequency domain features,gesture recognition,Gesture recognition,Gestures,health monitoring,human gesture recognition,Humans,industrial,intelligent radars,ISM band,Monitoring,Movement,multiclass classification,pattern recognition,Pattern Recognition,Physiologic,portable smart radar sensor,Principal component analysis,Principal Component Analysis,principle components,Radar,radar signal processing,radar signals,scientific and medical band,Sensors,signal classification,smart home applications}
    \endentry
    \entry{Wang:2019b}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=d7eb55a0c586217a7fe342c385b7677b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Liying},
           giveni={L\bibinitperiod}}}%
        {{hash=326371d3c4ab00ee13722c7c525a9871}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Zongyong},
           giveni={Z\bibinitperiod}}}%
        {{hash=cfa0cb6a9268e626bc53b9815a0c19e3}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Zongjie},
           giveni={Z\bibinitperiod}}}%
        {{hash=f2e5113c644373a475ad5d2e3e1f6d2f}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Shengping},
           giveni={S\bibinitperiod}}}%
        {{hash=a26dde94c686700c1527b68c7e808149}{%
           family={Min},
           familyi={M\bibinitperiod},
           given={Rui},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{fullhash}{51faaf452e9160fa31d33319df226453}
      \strng{bibnamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authorbibnamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authornamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authorfullhash}{51faaf452e9160fa31d33319df226453}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As one of the most commonly used natural languages, gesture has become an important approach for people to interact with machines. However, the flexibility of fingers has posed a challenge for detecting fine-grained gestures. In this paper, a novel method of high precision fine-grained gesture recognition is proposed based on a terahertz radar, which is able to sense any gesture movement when its range of motion is greater than 5mm. First, High Resolution Range Profile (HRRP) sequences are extracted from radar echoes. Then, the HRRP features are fed to Random Forest classifier after dimensionality reduction by PCA. In order to verify the proposed method is effective to detect fine-grained gestures, four kinds of similar gestures with multi-fingers are designed for experiments. The results indicate the recognition rate exceeds 99.7\%, which demonstrates a great prospect in fine-grained gesture recognition using a terahertz radar.}
      \field{booktitle}{{IGARSS} 2019 - 2019 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium}}
      \field{month}{7}
      \field{note}{ISSN: 2153-7003}
      \field{title}{Fine-{Grained} {Gesture} {Recognition} {Based} on {High} {Resolution} {Range} {Profiles} of {Terahertz} {Radar}}
      \field{year}{2019}
      \field{pages}{1470\bibrangedash 1473}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/IGARSS.2019.8900601
      \endverb
      \keyw{commonly used natural languages,feature extraction,Feature extraction,fine-grained gestures,gesture movement,gesture recognition,Gesture recognition,high precision fine-grained gesture recognition,High Resolution Range Profile,High Resolution Range Profile sequences,High Resolution Range profiles,Magnetic sensors,principal component analysis,Principal component analysis,Radar,radar echoes,radar resolution,radar target recognition,Radio frequency,similar gestures,size 5.0 mm,terahertz radar}
    \endentry
    \entry{Wang:2020b}{article}{}
      \name{author}{5}{}{%
        {{hash=d7eb55a0c586217a7fe342c385b7677b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Liying},
           giveni={L\bibinitperiod}}}%
        {{hash=cfa0cb6a9268e626bc53b9815a0c19e3}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Zongjie},
           giveni={Z\bibinitperiod}}}%
        {{hash=326371d3c4ab00ee13722c7c525a9871}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Zongyong},
           giveni={Z\bibinitperiod}}}%
        {{hash=7f4574214c98e901c44306cb585762e5}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Changjie},
           giveni={C\bibinitperiod}}}%
        {{hash=cb2915af08f787843a01a76564befe85}{%
           family={Pi},
           familyi={P\bibinitperiod},
           given={Yiming},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{fullhash}{ba005995b821adc70f32be18d4a1a20d}
      \strng{bibnamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authorbibnamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authornamehash}{fe337670aee80e8c71b43abf8f0e7915}
      \strng{authorfullhash}{ba005995b821adc70f32be18d4a1a20d}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Noncontact gesture recognition is gradually being applied to emerging applications, such as smart cars and smart phones. Negative latency gesture recognition (recognition before a gesture is finished) is desirable due to the instantaneous feedback. However, it is difficult for existing methods to achieve a high precision and negative latency gesture recognition. A fragment can provide too few features to directly identify all gestures well. By observing a large number of existing gesture sets and people's daily operating habits, we found that some high frequency used gestures are similar. To the best of our knowledge, it is the first time to redivide the gestures into two subsets according to their movement physical states. We divided the gestures with different shapes or motion states into a parent-class subset, and further divided each pair of parent-class gestures to obtain a child-class subset. In order to achieve a better tradeoff between the high-precision and negative latency, an approach of motion pattern and behavior intention (MPBI) is proposed. Taking full advantage of the characteristics of each subset, MPBI includes two models. First, pattern model coarsely classify the parent-class gestures by a convolutional network, and then intention model further classifies child-class gestures according to their opposite motion direction. MPBI is evaluated on a 340-GHz terahertz radar. With the advantage of its accurate ranging, intention model can recognize child-class gestures directly without training. MPBI is evaluated on 12 gestures and achieves a recognition accuracy of 94.13\%, which only needs a 0.033-s gesture fragment as an input sample.}
      \field{issn}{1558-0644}
      \field{journaltitle}{IEEE Transactions on Geoscience and Remote Sensing}
      \field{month}{11}
      \field{number}{11}
      \field{title}{Negative {Latency} {Recognition} {Method} for {Fine}-{Grained} {Gestures} {Based} on {Terahertz} {Radar}}
      \field{volume}{58}
      \field{year}{2020}
      \field{pages}{7955\bibrangedash 7968}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TGRS.2020.2985421
      \endverb
      \keyw{Acoustics,child-class gestures,child-class subset,convolutional network,convolutional neural nets,Doppler radar,fine-grained gestures,gesture fragment,gesture recognition,Gesture recognition,high resolution range profile (HRRP),Human computer interaction,image classification,Indexes,learning (artificial intelligence),motion pattern and behavior intention,MPBI,negative latency gesture recognition,noncontact gesture recognition,parent-class gestures,parent-class subset,radar imaging,Radar imaging,real-time,terahertz radar}
    \endentry
    \entry{Wang:2020a}{article}{}
      \name{author}{7}{}{%
        {{hash=45f6c698c08078e728a374596bdaa0e0}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Pengcheng},
           giveni={P\bibinitperiod}}}%
        {{hash=25808280f693f61155a803aef8f7ec83}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Junyang},
           giveni={J\bibinitperiod}}}%
        {{hash=9973f1b5336cb4655ed0c90373e0b674}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Fuyue},
           giveni={F\bibinitperiod}}}%
        {{hash=f74cf22f1d9a2efcd31fdf3b77715d5a}{%
           family={Xiu},
           familyi={X\bibinitperiod},
           given={Jianping},
           giveni={J\bibinitperiod}}}%
        {{hash=6f8618d0f8dbfd6fa32d73a2b66c950f}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Yue},
           giveni={Y\bibinitperiod}}}%
        {{hash=f57211918306559d9da1d5dee044b380}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Na},
           giveni={N\bibinitperiod}}}%
        {{hash=a29133e4b50635c46331c8bb9e3d93e6}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Hongtao},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{f4c167e7e6669a16fbec9b474bb280c3}
      \strng{fullhash}{e3fcefcd990b17fe479a9b4e50369059}
      \strng{bibnamehash}{f4c167e7e6669a16fbec9b474bb280c3}
      \strng{authorbibnamehash}{f4c167e7e6669a16fbec9b474bb280c3}
      \strng{authornamehash}{f4c167e7e6669a16fbec9b474bb280c3}
      \strng{authorfullhash}{e3fcefcd990b17fe479a9b4e50369059}
      \field{extraname}{3}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gesture air-writing is an advanced nontouching interaction method that replaces traditional typewriter keyboards, touch screens and other input devices. Due to its low power consumption, noncontact detection and independence from light conditions, millimeter wave radar has become a valuable gesture air-writing solution. In this paper, we proposed a prototype of a gesture air-writing tracking system that is based on the 24-GHz frequency-modulated continuous-wave (FMCW) radar system-on-chip (SoC). The transmitted chirp signal of this radar chip covers up to a 4-GHz bandwidth, which provides sufficient range resolution to track hand gestures. With the development of single input, multiple output (SIMO) antennas, the air-writing symbols can be reconstructed in an observation plane. A system design and signal processing algorithm for gesture air-writing applications is proposed for the prototype system in this paper. To test the performance of the proposed method, experiments with cases of five simple gestures, air-writing numbers and letter tracking are carried out. The experimental results verify the efficiency and accuracy of the proposed method.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{{A Gesture Air-Writing Tracking Method that Uses 24 GHz SIMO Radar SoC}}
      \field{volume}{8}
      \field{year}{2020}
      \field{pages}{152728\bibrangedash 152741}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/ACCESS.2020.3017869
      \endverb
      \keyw{24-GHz frequency-modulated continuous-wave,advanced nontouching interaction method,air-writing numbers,air-writing symbols,angular measurement,Chirp,CW radar,distance measurement,FM radar,FMCW,frequency 24.0 GHz,Gesture air writing,gesture air-writing applications,gesture air-writing tracking method,gesture air-writing tracking system,gesture recognition,hand gestures,indoor communication,input devices,letter tracking,low power consumption,microwave antenna arrays,millimeter wave radar,Millimeter wave radar,multiple output antennas,noncontact detection,prototype system,Radar antennas,radar chip,radar system-on-chip,Radar tracking,Receiving antennas,signal processing algorithm,SIMO,SIMO radar SoC,simple gestures,single input,SoC,system design,touch screens,traditional typewriter keyboards,transmitted chirp signal,valuable gesture air-writing solution,wireless channels,Writing}
    \endentry
    \entry{Wang:2016}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=85bbc5bcff8e32628115edb42f4f0e77}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Saiwen},
           giveni={S\bibinitperiod}}}%
        {{hash=f47cc1ff1ed8ea8025326fb247ba534f}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod}}}%
        {{hash=5858a49df4f45760271051cb85536f29}{%
           family={Lien},
           familyi={L\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod}}}%
        {{hash=e1b6c7b998ff4368f042c24f7c1b6350}{%
           family={Poupyrev},
           familyi={P\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
        {{hash=e4282a8b050f6ec88f43896369f6fe38}{%
           family={Hilliges},
           familyi={H\bibinitperiod},
           given={Otmar},
           giveni={O\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{de3454a1ba296c87d8ced2e04e063a89}
      \strng{fullhash}{2a3a965b5702cf68f4822ffaca188382}
      \strng{bibnamehash}{de3454a1ba296c87d8ced2e04e063a89}
      \strng{authorbibnamehash}{de3454a1ba296c87d8ced2e04e063a89}
      \strng{authornamehash}{de3454a1ba296c87d8ced2e04e063a89}
      \strng{authorfullhash}{2a3a965b5702cf68f4822ffaca188382}
      \field{extraname}{4}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper proposes a novel machine learning architecture, specifically designed for radio-frequency based gesture recognition. We focus on high-frequency (60]GHz), short-range radar based sensing, in particular Google's Soli sensor. The signal has unique properties such as resolving motion at a very fine level and allowing for segmentation in range and velocity spaces rather than image space. This enables recognition of new types of inputs but poses significant difficulties for the design of input recognition algorithms. The proposed algorithm is capable of detecting a rich set of dynamic gestures and can resolve small motions of fingers in fine detail. Our technique is based on an end-to-end trained combination of deep convolutional and recurrent neural networks. The algorithm achieves high recognition rates (avg 87\%) on a challenging set of 11 dynamic gestures and generalizes well across 10 users. The proposed model runs on commodity hardware at 140 Hz (CPU only).}
      \field{booktitle}{Proceedings of the 29th Annual Symposium on User Interface Software and Technology}
      \field{isbn}{9781450341899}
      \field{series}{UIST '16}
      \field{title}{{Interacting with Soli: Exploring Fine-Grained Dynamic Gesture Recognition in the Radio-Frequency Spectrum}}
      \field{venue}{Tokyo, Japan}
      \field{year}{2016}
      \field{pages}{851\bibrangedash 860}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/2984511.2984565
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2984511.2984565
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2984511.2984565
      \endverb
      \keyw{gesture recognition,deep learning,wearables,radar sensing}
    \endentry
    \entry{Wang:2020d}{article}{}
      \name{author}{5}{}{%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=2f887b2df15cc517294b4d30a98ebc4c}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Aihu},
           giveni={A\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=04cdb4a24855839e54389c90008c17fc}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod}}}%
        {{hash=6ed83e16ea05fe9df91b898ed1a30a4c}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaobo},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{fullhash}{6a149c0bccf544e9ff21e23354d4419e}
      \strng{bibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorbibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authornamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorfullhash}{6a149c0bccf544e9ff21e23354d4419e}
      \field{extraname}{5}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article, a novel method for continuous hand gesture detection and recognition is proposed based on a frequency modulated continuous wave (FMCW) radar. Firstly, we adopt the 2-Dimensional Fast Fourier Transform (2D-FFT) to estimate the range and Doppler parameters of the hand gesture raw data, and construct the range-time map (RTM) and Doppler-time map (DTM). Meanwhile, we apply the Multiple Signal Classification (MUSIC) algorithm to calculate the angle and construct the angle-time map (ATM). Secondly, a hand gesture detection method is proposed to segment the continuous hand gestures using a decision threshold. Thirdly, the central time-frequency trajectory of each hand gesture spectrogram is clustered using the k-means algorithm, and then the Fusion Dynamic Time Warping (FDTW) algorithm is presented to recognize the hand gestures. Finally, experiments show that the accuracy of the proposed hand gesture detection method can reach 96.17\%. The hand gesture average recognition accuracy of the proposed FDTW algorithm is 95.83\%, while its time complexity is reduced by more than 50\%.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{A {Novel} {Detection} and {Recognition} {Method} for {Continuous} {Hand} {Gesture} {Using} {FMCW} {Radar}}
      \field{volume}{8}
      \field{year}{2020}
      \field{pages}{167264\bibrangedash 167275}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/ACCESS.2020.3023187
      \endverb
      \keyw{2-Dimensional Fast Fourier Transform,angle-time map,central time-frequency trajectory,Classification algorithms,Clustering algorithms,continuous hand gesture detection,continuous hand gesture recognition detection,continuous wave radar,CW radar,fast Fourier transforms,FDTW,feature extraction,FM radar,FMCW radar,Fusion Dynamic Time Warping algorithm,gesture recognition,Gesture recognition,hand gesture average recognition accuracy,hand gesture detection method,hand gesture raw data,hand gesture spectrogram,Heuristic algorithms,image matching,Multiple Signal Classification algorithm,Radar detection,radar imaging,recognition method,Time-frequency analysis,time-frequency trajectory}
    \endentry
    \entry{Wang:2019c}{article}{}
      \name{author}{5}{}{%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=d815895b444d82d60d1d25bae08cd3e2}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Xiuqian},
           giveni={X\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=7e30671b4c2d2412d2ab402fe9b9fb73}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Liangbo},
           giveni={L\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{fullhash}{1b43b9557e9d6b08e87647faec24c789}
      \strng{bibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorbibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authornamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorfullhash}{1b43b9557e9d6b08e87647faec24c789}
      \field{extraname}{6}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1022-0038, 1572-8196}
      \field{journaltitle}{Wireless Networks}
      \field{month}{7}
      \field{title}{A novel {F}-{RCNN} based hand gesture detection approach for {FMCW} systems}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 14}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1007/s11276-019-02096-2
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/s11276-019-02096-2
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/s11276-019-02096-2
      \endverb
    \endentry
    \entry{Wang:2019f}{article}{}
      \name{author}{5}{}{%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=7e106a17780ec2ccf5426d3e3792bc56}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Shasha},
           giveni={S\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=2f37a4156bd8f2fffa4aeecbf6e010a0}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Qing},
           giveni={Q\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{fullhash}{55571e4220523fde2fbfd15f77db6beb}
      \strng{bibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorbibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authornamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorfullhash}{55571e4220523fde2fbfd15f77db6beb}
      \field{extraname}{7}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Aiming at the problems of the noise impact on the parametric image of hand gestures, the difficulty of gesture feature extraction, and the inefficient utilization of continuous gesture time sequential information, we propose a time sequential inflated 3 dimensions (TS-I3D) convolutional neural network approach for hand gesture recognition based on frequency modulated continuous wave (FMCW) radar sensor. Specifically, the FMCW radar is used to acquire the hand gesture data, and the range and speed of the gesture in each frame signal are calculated by 2 dimensions fast Fourier transform. Then, the range-Doppler map (RDM) is generated based on the relationship between motion parameters and frequency. The interference in RDM caused by people and the external environment is filtered out and the peak of hand gesture in RDM is further enhanced by wavelet transform. Finally, TS-I3D network is designed to extract the range and speed change information of the continuous gestures. The experimental results show that the average recognition accuracy rate of the hand gestures of the proposed method is 96.17\%.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{title}{{TS}-{I3D} {Based} {Hand} {Gesture} {Recognition} {Method} {With} {Radar} {Sensor}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{22902\bibrangedash 22913}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2897060
      \endverb
      \keyw{continuous gesture time sequential information,continuous gestures,convolutional neural nets,Convolutional neural networks,CW radar,Data mining,deep learning,fast Fourier transforms,feature extraction,Feature extraction,FM radar,FMCW radar,frequency modulated continuous wave radar sensor,gesture feature extraction,gesture recognition,Gesture recognition,hand gesture data,hand gesture recognition,Interference,interference filtering,LSTM,radar computing,Radar imaging,RDM,TS-I3D based hand gesture recognition method,TS-I3D network,wavelet transforms}
    \endentry
    \entry{Wang:2019e}{incollection}{}
      \name{author}{4}{}{%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=ede13b54712f0f98cba1bc03785ea650}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Zedong},
           giveni={Z\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=806d33a7ded1f6c724151c2691fb6ce7}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jinjun},
           giveni={J\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=8efee3675f8033f7fe27cd6510bd9a86}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
        {{hash=01961adbf1fcb4df3bbced19dbc886d4}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Qing},
           giveni={Q\bibinitperiod}}}%
        {{hash=c613adae4ad81fee7672676e58319578}{%
           family={Meng},
           familyi={M\bibinitperiod},
           given={Weixiao},
           giveni={W\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{fullhash}{ecd500bddb652c06da7ae5bb5d5b3f24}
      \strng{bibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorbibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authornamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorfullhash}{ecd500bddb652c06da7ae5bb5d5b3f24}
      \strng{editorbibnamehash}{861c4ee22c57334cd42d6afc1107c6ec}
      \strng{editornamehash}{861c4ee22c57334cd42d6afc1107c6ec}
      \strng{editorfullhash}{861c4ee22c57334cd42d6afc1107c6ec}
      \field{extraname}{8}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Wireless and {Satellite} {Systems}}
      \field{isbn}{978-3-030-19152-8 978-3-030-19153-5}
      \field{note}{Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering}
      \field{title}{Two {Dimensional} {Parameters} {Based} {Hand} {Gesture} {Recognition} {Algorithm} for {FMCW} {Radar} {Systems}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{280}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{226\bibrangedash 234}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1007/978-3-030-19153-5_23
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-030-19153-5_23
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-030-19153-5_23
      \endverb
    \endentry
    \entry{Wang:2019a}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=7e106a17780ec2ccf5426d3e3792bc56}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Shasha},
           giveni={S\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=868b05a9388d750f03375b83c816def7}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=15242e5c9f88d20b2fddbf983e204586}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaolong},
           giveni={X\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{fullhash}{b3904b2cec266f65a804bbd4d2d8da60}
      \strng{bibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorbibnamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authornamehash}{78da58c085b7e56d197d94ceb741e3b0}
      \strng{authorfullhash}{b3904b2cec266f65a804bbd4d2d8da60}
      \field{extraname}{9}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper proposes a deep learning based twostream time series hand gesture recognition method using the frequency modulated continuous wave (FMCW) radar. Firstly, we collect the hand gesture data by the FMCW radar, and the range and Doppler of the hand gesture are estimated by the 2 dimensional Fast Fourier Transform (2D-FFT). Then, the angle of hand gesture is estimated by Multiple Signal classification (MUSIC) algorithm. Afterward, we construct the Range- Doppler Map (RDM), and generate the Angle-Time Map (ATM) via multiframe accumulation. The interference in RDM is filtered out by peak interference cancellation, and the hand gesture feature in RDM and ATM are enhanced by wavelet transform. A systematic of two-stream time series neural network is designed for gesture feature extraction and classification. The experimental results show that the recognition accuracy rate for each type hand gesture of the proposed method is higher than 95\%.}
      \field{booktitle}{2019 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})}
      \field{month}{12}
      \field{title}{Two-{Stream} {Time} {Sequential} {Network} {Based} {Hand} {Gesture} {Recognition} {Method} {Using} {Radar} {Sensor}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/GCWkshps45667.2019.9024691
      \endverb
      \keyw{2 dimensional fast Fourier transform,angle-time map,CW radar,deep learning,Doppler radar,fast Fourier transforms,feature extraction,Feature extraction,FM radar,FMCW radar,frequency modulated continuous wave radar,gesture feature extraction,gesture recognition,Gesture recognition,hand gesture data,hand gesture feature,image classification,Interference,learning (artificial intelligence),Multiple signal classification,multiple signal classification algorithm,MUSIC algorithm,neural nets,peak interference cancellation,Radar,radar sensor,radar signal processing,range- Doppler map,RDM,recognition accuracy rate,time series,Time series analysis,time series hand gesture recognition method,two-stream time sequential network,two-stream time series neural network,wavelet transform,wavelet transforms,Wavelet transforms}
    \endentry
    \entry{Wang:2020c}{article}{}
      \name{author}{3}{}{%
        {{hash=45d6d109bc569eaa1e3293cb9a86282b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zetao},
           giveni={Z\bibinitperiod}}}%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=2b6c88d90514c75102a7241d50ace4a0}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Le},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{ae8265c3626a610dda30d754c6af8853}
      \strng{fullhash}{ae8265c3626a610dda30d754c6af8853}
      \strng{bibnamehash}{ae8265c3626a610dda30d754c6af8853}
      \strng{authorbibnamehash}{ae8265c3626a610dda30d754c6af8853}
      \strng{authornamehash}{ae8265c3626a610dda30d754c6af8853}
      \strng{authorfullhash}{ae8265c3626a610dda30d754c6af8853}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Dynamic hand gesture recognition using the microwave or millimeter-wave radar sensors has become a typical technology for many human-computer interaction (HCI) applications. In this letter, a novel method is proposed for dynamic hand gesture recognition based on micro-Doppler radar signatures. The short-time Fourier transform is carried out on the raw data to obtain the time-frequency spectrogram. The time-frequency spectrograms associated with the same dynamic hand gesture are modeled by a hidden Gauss-Markov model (HGMM), and the testing gesture is recognized by the maximum likelihood criterion. Experimental results with real radar data demonstrate that the proposed method has a strong generalization ability for radar gesture recognition in the cases of low signal-to-noise ratio (SNR) and unknown users.}
      \field{issn}{1558-0571}
      \field{journaltitle}{IEEE Geoscience and Remote Sensing Letters}
      \field{number}{2}
      \field{title}{Dynamic {Hand} {Gesture} {Recognition} {Based} on {Micro}-{Doppler} {Radar} {Signatures} {Using} {Hidden} {Gauss}-{Markov} {Models}}
      \field{volume}{18}
      \field{year}{2020}
      \field{pages}{291\bibrangedash 295}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/LGRS.2020.2974821
      \endverb
      \keyw{Dynamic hand gesture recognition,Feature extraction,Gesture recognition,hidden Markov model (HMM),Hidden Markov models,micro-Doppler,Radar,radar sensor.,Sensors,Testing,Training}
    \endentry
    \entry{Wang:2019d}{article}{}
      \name{author}{5}{}{%
        {{hash=53f6f613453932e8b9d343ec613acfde}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhu},
           giveni={Z\bibinitperiod}}}%
        {{hash=380c8705fa630530c27c5974669fb0de}{%
           family={Lou},
           familyi={L\bibinitperiod},
           given={Xinye},
           giveni={X\bibinitperiod}}}%
        {{hash=65ae00ff52a1f9d8174ffcad07d13bfd}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Zhiwen},
           giveni={Z\bibinitperiod}}}%
        {{hash=ac04bd00a003f7c5bed63f9b75fa0c88}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
        {{hash=7ee5ac875eb2aac42aa9da1b7cb264fb}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Xingshe},
           giveni={X\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{bac665484a1d9f61f7381d5940d75805}
      \strng{fullhash}{4148b9f87c38ecfdc1470712a6c1b054}
      \strng{bibnamehash}{bac665484a1d9f61f7381d5940d75805}
      \strng{authorbibnamehash}{bac665484a1d9f61f7381d5940d75805}
      \strng{authornamehash}{bac665484a1d9f61f7381d5940d75805}
      \strng{authorfullhash}{4148b9f87c38ecfdc1470712a6c1b054}
      \field{extraname}{10}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1617-4909, 1617-4917}
      \field{journaltitle}{Personal and Ubiquitous Computing}
      \field{month}{2}
      \field{number}{1}
      \field{title}{{Enabling non-invasive and real-time human-machine interactions based on wireless sensing and fog computing}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{23}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{29\bibrangedash 41}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1007/s00779-018-1185-7
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/s00779-018-1185-7
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/s00779-018-1185-7
      \endverb
    \endentry
    \entry{Weichert:2013}{article}{}
      \name{author}{4}{}{%
        {{hash=e776c75932f3687a061fd53948b02564}{%
           family={Weichert},
           familyi={W\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod}}}%
        {{hash=07694fd4c3f7297f22890df99969a7f2}{%
           family={Bachmann},
           familyi={B\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=e57ecd92f89bbafd625994ae6ddb4fa0}{%
           family={Rudak},
           familyi={R\bibinitperiod},
           given={Bartholomäus},
           giveni={B\bibinitperiod}}}%
        {{hash=f72f8fadc11e45ca728a5c8f2da47bfa}{%
           family={Fisseler},
           familyi={F\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{ec6aafb90f9914d392d00f2019dd190d}
      \strng{fullhash}{8df00f606a979dc80d03fa473b30008a}
      \strng{bibnamehash}{ec6aafb90f9914d392d00f2019dd190d}
      \strng{authorbibnamehash}{ec6aafb90f9914d392d00f2019dd190d}
      \strng{authornamehash}{ec6aafb90f9914d392d00f2019dd190d}
      \strng{authorfullhash}{8df00f606a979dc80d03fa473b30008a}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Sensors}
      \field{month}{05}
      \field{title}{{Analysis of the Accuracy and Robustness of the Leap Motion Controller}}
      \field{venue}{Basel, Switzerland}
      \field{volume}{13}
      \field{year}{2013}
      \field{pages}{6380\bibrangedash 6393}
      \range{pages}{14}
      \verb{doi}
      \verb 10.3390/s130506380
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/13/5/6380
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/13/5/6380
      \endverb
    \endentry
    \entry{White:2007}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=5f8811af36efd2786e45011d6e346788}{%
           family={White},
           familyi={W\bibinitperiod},
           given={Sean},
           giveni={S\bibinitperiod}}}%
        {{hash=e244a2a799743656217fc01732649068}{%
           family={Lister},
           familyi={L\bibinitperiod},
           given={Levi},
           giveni={L\bibinitperiod}}}%
        {{hash=4b3462cefe1c5b2c7537ae21555c665a}{%
           family={Feiner},
           familyi={F\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \strng{fullhash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \strng{bibnamehash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \strng{authorbibnamehash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \strng{authornamehash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \strng{authorfullhash}{bed0dfc5b8f18e11d9f9fce4b9267574}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality}
      \field{title}{{Visual Hints for Tangible Gestures in Augmented Reality}}
      \field{year}{2007}
      \field{pages}{47\bibrangedash 50}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ISMAR.2007.4538824
      \endverb
      \keyw{Augmented reality;Displays;User interfaces;Chromium;Multimedia systems;Virtual reality;Documentation;Morphology;Radio access networks;History;Tangible augmented reality;visual hints;gestures;electronic field guide}
    \endentry
    \entry{Wigdor:2011}{book}{}
      \name{author}{2}{}{%
        {{hash=a1d167c2e159bbe494e59e21a3fb2dbb}{%
           family={Wigdor},
           familyi={W\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=4d07abd669ba921106d63b04a8590dc8}{%
           family={Wixon},
           familyi={W\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Burlington, Massachusetts, United States}%
      }
      \list{publisher}{1}{%
        {Morgan Kaufmann Publishers}%
      }
      \strng{namehash}{4ee6f12e87ef44bd62a029feba26dc03}
      \strng{fullhash}{4ee6f12e87ef44bd62a029feba26dc03}
      \strng{bibnamehash}{4ee6f12e87ef44bd62a029feba26dc03}
      \strng{authorbibnamehash}{4ee6f12e87ef44bd62a029feba26dc03}
      \strng{authornamehash}{4ee6f12e87ef44bd62a029feba26dc03}
      \strng{authorfullhash}{4ee6f12e87ef44bd62a029feba26dc03}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{edition}{1}
      \field{isbn}{978-0-12-382231-4}
      \field{series}{The Morgan Kaufmann Series in Computer Architecture and Design}
      \field{title}{{Brave NUI world: designing natural user interfaces for touch and gesture}}
      \field{year}{2011}
      \verb{doi}
      \verb https://doi.org/10.1016/C2009-0-64091-5
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/book/9780123822314/brave-nui-world
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/book/9780123822314/brave-nui-world
      \endverb
    \endentry
    \entry{Wittorf:2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=a1cef4f1b437a5a9ff35735536925dac}{%
           family={Wittorf},
           familyi={W\bibinitperiod},
           given={Markus\bibnamedelima L.},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=b3169754f246069a906224fc06b9b0c3}{%
           family={Jakobsen},
           familyi={J\bibinitperiod},
           given={Mikkel\bibnamedelima R.},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{4f23f903bb62413a872aba24c9d77abb}
      \strng{fullhash}{4f23f903bb62413a872aba24c9d77abb}
      \strng{bibnamehash}{4f23f903bb62413a872aba24c9d77abb}
      \strng{authorbibnamehash}{4f23f903bb62413a872aba24c9d77abb}
      \strng{authornamehash}{4f23f903bb62413a872aba24c9d77abb}
      \strng{authorfullhash}{4f23f903bb62413a872aba24c9d77abb}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Freehand mid-air gestures are a promising input method for interacting with wall displays. However, work on mid-air gestures for wall-display interaction has mainly explored what is technically possible, which might not result in gestures that users would prefer. This paper presents a guessability study where 20 participants performed gestures for 25 actions on a three-meter wide display. Based on the resulting 1124 gestures, we describe user-defined mid-air gestures for wall-display interaction and characterize the types of gesture users prefer for this context. The resulting gestures were largely influenced by surface interaction; they tended to be larger and more physically-based than gestures elicited in previous studies using smaller displays.}
      \field{booktitle}{Proceedings of the 9th Nordic Conference on Human-Computer Interaction}
      \field{isbn}{9781450347631}
      \field{series}{NordiCHI '16}
      \field{title}{{Eliciting Mid-Air Gestures for Wall-Display Interaction}}
      \field{venue}{Gothenburg, Sweden}
      \field{year}{2016}
      \verb{doi}
      \verb 10.1145/2971485.2971503
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2971485.2971503
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2971485.2971503
      \endverb
      \keyw{Gesture elicitation,Mid-air gestures,Wall displays}
    \endentry
    \entry{Wobbrock:2009}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=5283a53c5c081c04252a659743f886e1}{%
           family={Morris},
           familyi={M\bibinitperiod},
           given={Meredith\bibnamedelima Ringel},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=44a173a4c0ff442bac216e39b38cfc82}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Andrew\bibnamedelima D.},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}, {USA}}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{61dabf6de69f9bf00351ea72b81d28a0}
      \strng{fullhash}{61dabf6de69f9bf00351ea72b81d28a0}
      \strng{bibnamehash}{61dabf6de69f9bf00351ea72b81d28a0}
      \strng{authorbibnamehash}{61dabf6de69f9bf00351ea72b81d28a0}
      \strng{authornamehash}{61dabf6de69f9bf00351ea72b81d28a0}
      \strng{authorfullhash}{61dabf6de69f9bf00351ea72b81d28a0}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations, they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture, and then asking users to perform its cause. In all, 1080 gestures from 20 participants were logged, analyzed, and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users' mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets. We also present a complete user-defined gesture set, quantitative agreement scores, implications for surface technology, and a taxonomy of surface gestures. Our results will help designers create better gesture sets informed by user behavior.}
      \field{booktitle}{Proceedings of the ACM Conference on Human Factors in Computing Systems}
      \field{isbn}{978-1-60558-246-7}
      \field{series}{{CHI} '09}
      \field{title}{{User-defined Gestures for Surface Computing}}
      \field{urlday}{23}
      \field{urlmonth}{2}
      \field{urlyear}{2018}
      \field{venue}{Boston, MA, USA}
      \field{year}{2009}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1083\bibrangedash 1092}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1518701.1518866
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/1518701.1518866
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/1518701.1518866
      \endverb
      \keyw{{ACM},gesture recognition,gestures,guessability,referents,signs,surface,tabletop,think-aloud}
    \endentry
    \entry{Wobbrock:2007}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=44a173a4c0ff442bac216e39b38cfc82}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Andrew\bibnamedelima D.},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=2af761d9bef859ea29248418adce0dd7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {ACM}%
      }
      \strng{namehash}{577f706ff5c21ca727e3785496d64af2}
      \strng{fullhash}{577f706ff5c21ca727e3785496d64af2}
      \strng{bibnamehash}{577f706ff5c21ca727e3785496d64af2}
      \strng{authorbibnamehash}{577f706ff5c21ca727e3785496d64af2}
      \strng{authornamehash}{577f706ff5c21ca727e3785496d64af2}
      \strng{authorfullhash}{577f706ff5c21ca727e3785496d64af2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology}
      \field{isbn}{978-1-59593-679-0}
      \field{series}{UIST '07}
      \field{title}{{Gestures Without Libraries, Toolkits or Training: A \$1 Recognizer for User Interface Prototypes}}
      \field{venue}{Newport, Rhode Island, USA}
      \field{year}{2007}
      \field{pages}{159\bibrangedash 168}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1145/1294211.1294238
      \endverb
      \verb{urlraw}
      \verb http://doi.acm.org/10.1145/1294211.1294238
      \endverb
      \verb{url}
      \verb http://doi.acm.org/10.1145/1294211.1294238
      \endverb
      \keyw{dynamic time warping,gesture recognition,marks,rapid prototyping,recognition rates,rubine,statistical classifiers,strokes,symbols,unistrokes,user interfaces}
    \endentry
    \entry{Wobbrock:2005}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=2b5f7007239862c98855817d78941ae9}{%
           family={Wobbrock},
           familyi={W\bibinitperiod},
           given={Jacob\bibnamedelima O.},
           giveni={J\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=b15ff30a43d35c4767e6f485b870b7ce}{%
           family={Aung},
           familyi={A\bibinitperiod},
           given={Htet\bibnamedelima Htet},
           giveni={H\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=9f0a48ceb962fd7c0a7d40b10c5c5929}{%
           family={Rothrock},
           familyi={R\bibinitperiod},
           given={Brandon},
           giveni={B\bibinitperiod}}}%
        {{hash=7f3139b9d8c689d2ae47ba9be98a69f0}{%
           family={Myers},
           familyi={M\bibinitperiod},
           given={Brad\bibnamedelima A.},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{7929def7a3d8dd40c17a27e55034b42a}
      \strng{fullhash}{9d0764efdad8a719b73c88e8f0613762}
      \strng{bibnamehash}{7929def7a3d8dd40c17a27e55034b42a}
      \strng{authorbibnamehash}{7929def7a3d8dd40c17a27e55034b42a}
      \strng{authornamehash}{7929def7a3d8dd40c17a27e55034b42a}
      \strng{authorfullhash}{9d0764efdad8a719b73c88e8f0613762}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Guessability is essential for symbolic input, in which users enter gestures or keywords to indicate characters or commands, or rely on labels or icons to access features. We present a unified approach to both maximizing and evaluating the guessability of symbolic input. This approach can be used by anyone wishing to design a symbol set with high guessability, or to evaluate the guessability of an existing symbol set. We also present formulae for quantifying guessability and agreement among guesses. An example is offered in which the guessability of the EdgeWrite unistroke alphabet was improved by users from 51.0\% to 80.1\% without designer intervention. The original and improved alphabets were then tested for their immediate usability with the procedure used by MacKenzie and Zhang (1997). Users entered the original alphabet with 78.8\% and 90.2\% accuracy after 1 and 5 minutes of learning, respectively. The improved alphabet bettered this to 81.6\% and 94.2\%. These improved results were competitive with prior results for Graffiti, which were 81.8\% and 95.8\% for the same measures.}
      \field{booktitle}{CHI '05 Extended Abstracts on Human Factors in Computing Systems}
      \field{isbn}{1595930027}
      \field{series}{CHI EA '05}
      \field{title}{{Maximizing the Guessability of Symbolic Input}}
      \field{venue}{Portland, OR, USA}
      \field{year}{2005}
      \field{pages}{1869\bibrangedash 1872}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/1056808.1057043
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1056808.1057043
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1056808.1057043
      \endverb
      \keyw{symbols,labels,keywords,command-line,gestures,edgewrite,immediate usability,icons,unistrokes,guessability,referents,proposals,text entry,commands}
    \endentry
    \entry{Wolff:2022}{misc}{}
      \name{author}{1}{}{%
        {{hash=670de8700acf7793e09f9345af84901d}{%
           family={Wolff},
           familyi={W\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{670de8700acf7793e09f9345af84901d}
      \strng{fullhash}{670de8700acf7793e09f9345af84901d}
      \strng{bibnamehash}{670de8700acf7793e09f9345af84901d}
      \strng{authorbibnamehash}{670de8700acf7793e09f9345af84901d}
      \strng{authornamehash}{670de8700acf7793e09f9345af84901d}
      \strng{authorfullhash}{670de8700acf7793e09f9345af84901d}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{RadarTutorial.eu}
      \field{month}{1}
      \field{title}{{Waves and Frequency Ranges}}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.radartutorial.eu/07.waves/Waves and Frequency Ranges.en.html
      \endverb
      \verb{url}
      \verb https://www.radartutorial.eu/07.waves/Waves%20and%20Frequency%20Ranges.en.html
      \endverb
    \endentry
    \entry{Wu:2020}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=464361705cbbea7149c6cdb6dca355b7}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Te-Yen},
           giveni={T\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=319a271f03ea78b0841a405b4317d6e6}{%
           family={Qi},
           familyi={Q\bibinitperiod},
           given={Shutong},
           giveni={S\bibinitperiod}}}%
        {{hash=3a50b94e729d5f191d150e51ad6b2e1d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Junchi},
           giveni={J\bibinitperiod}}}%
        {{hash=3313fc635b1217ff7039bbafe5e7e09d}{%
           family={Shang},
           familyi={S\bibinitperiod},
           given={MuJie},
           giveni={M\bibinitperiod}}}%
        {{hash=e5cf80adf9b60d1400677771251751e4}{%
           family={Gong},
           familyi={G\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
        {{hash=17fdab55264e0d8cab1acc2f6d92a37a}{%
           family={Seyed},
           familyi={S\bibinitperiod},
           given={Teddy},
           giveni={T\bibinitperiod}}}%
        {{hash=788e21061368f288724159c5854276f2}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xing-Dong},
           giveni={X\bibinithyphendelim D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b024dfab15ebaa2a6b71281d908651eb}
      \strng{fullhash}{01877d9d5a15d0b0588c3ca63694aedc}
      \strng{bibnamehash}{b024dfab15ebaa2a6b71281d908651eb}
      \strng{authorbibnamehash}{b024dfab15ebaa2a6b71281d908651eb}
      \strng{authornamehash}{b024dfab15ebaa2a6b71281d908651eb}
      \strng{authorfullhash}{01877d9d5a15d0b0588c3ca63694aedc}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present Fabriccio, a touchless gesture sensing technique developed for interactive fabrics using Doppler motion sensing. Our prototype was developed using a pair of loop antennas (one for transmitting and the other for receiving), made of conductive thread that was sewn onto a fabric substrate. The antenna type, configuration, transmission lines, and operating frequency were carefully chosen to balance the complexity of the fabrication process and the sensitivity of our system for touchless hand gestures, performed at a 10 cm distance. Through a ten-participant study, we evaluated the performance of our proposed sensing technique across 11 touchless gestures as well as 1 touch gesture. The study result yielded a 92.8\% cross-validation accuracy and 85.2\% leave-one-session-out accuracy. We conclude by presenting several applications to demonstrate the unique interactions enabled by our technique on soft objects.}
      \field{booktitle}{Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}}
      \field{isbn}{978-1-4503-6708-0}
      \field{month}{4}
      \field{series}{{CHI} '20}
      \field{shorttitle}{Fabriccio}
      \field{title}{Fabriccio: {Touchless} {Gestural} {Input} on {Interactive} {Fabrics}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 14}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1145/3313831.3376681
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3313831.3376681
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3313831.3376681
      \endverb
      \keyw{doppler effect,interactive fabrics,touchless gesture}
    \endentry
    \entry{Xia:2020}{article}{}
      \name{author}{4}{}{%
        {{hash=b2023d1bcbc074550af04775814b2b59}{%
           family={Xia},
           familyi={X\bibinitperiod},
           given={Zhaoyang},
           giveni={Z\bibinitperiod}}}%
        {{hash=203db18339c7e2f9315245fdd215c0ff}{%
           family={Luomei},
           familyi={L\bibinitperiod},
           given={Yixiang},
           giveni={Y\bibinitperiod}}}%
        {{hash=216995dd0ca562a9c5d29b4e10193acf}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Chenglong},
           giveni={C\bibinitperiod}}}%
        {{hash=7b489e462941f869f448a19abc85df4b}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Feng},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{95e4b60e783b0879bd670531d048137c}
      \strng{fullhash}{cfa77c357c8d72cefc4fdb0a4261a757}
      \strng{bibnamehash}{95e4b60e783b0879bd670531d048137c}
      \strng{authorbibnamehash}{95e4b60e783b0879bd670531d048137c}
      \strng{authornamehash}{95e4b60e783b0879bd670531d048137c}
      \strng{authorfullhash}{cfa77c357c8d72cefc4fdb0a4261a757}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article presents a robust hand-gesture recognition method via multidimensional feature representation and learning specifically designed for commercial frequency-modulated continuous wave (FMCW) multi-input multi-output (MIMO) millimeter-wave radar. First, the optimal configuration of the radar system parameters for the hand-gesture recognition scenario is investigated and a standard procedure to determine the system configuration is given. Then a moving scattering center model is proposed to represent the 3-D point cloud in the range-Doppler (RD)-angular multidimensional feature space. A scattering point detection and tracking algorithm is presented based on a set of motion constraints in terms of position, velocity, and acceleration. It is derived from the space-time continuity of a nonrigid target. Finally, a lightweight multichannel convolutional neural network (CNN) is designed to learn and classify multidimensional gesture features including radial RD and tangential azimuth-elevation. Extensive experiments are carried out with the developed system and a large data set is obtained to train and test the classifier. The results show that the proposed gesture recognition method can effectively distinguish gestures that are easily confused in the RD domain and achieve robust performances under various conditions.}
      \field{issn}{1558-0644}
      \field{journaltitle}{IEEE Transactions on Geoscience and Remote Sensing}
      \field{number}{6}
      \field{title}{Multidimensional {Feature} {Representation} and {Learning} for {Robust} {Hand}-{Gesture} {Recognition} on {Commercial} {Millimeter}-{Wave} {Radar}}
      \field{volume}{59}
      \field{year}{2020}
      \field{pages}{4749\bibrangedash 4764}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TGRS.2020.3010880
      \endverb
      \keyw{Detection and tracking,Feature extraction,gesture recognition,Gesture recognition,millimeter-wave (mmw) radar,moving scattering center model,multichannel convolutional neural network (CNN),multidimensional feature.,Radar imaging,Robustness,Scattering,Signal resolution}
    \endentry
    \entry{Xu:2022}{inproceedings}{}
      \name{author}{16}{}{%
        {{hash=5be6d0ab3191e4f23b85299fcf0d4e5e}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xuhai},
           giveni={X\bibinitperiod}}}%
        {{hash=e5cf80adf9b60d1400677771251751e4}{%
           family={Gong},
           familyi={G\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
        {{hash=0e80b96a053a9b79fb7d1013b3540d69}{%
           family={Brum},
           familyi={B\bibinitperiod},
           given={Carolina},
           giveni={C\bibinitperiod}}}%
        {{hash=3384e5d87610c643b8187e200dcf04ff}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Lilian},
           giveni={L\bibinitperiod}}}%
        {{hash=158cdc764bc3f132333074f9dc0c48ad}{%
           family={Suh},
           familyi={S\bibinitperiod},
           given={Bongsoo},
           giveni={B\bibinitperiod}}}%
        {{hash=8b2ed392cd50005d67cb4e817a07f459}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Shivam\bibnamedelima Kumar},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=706dc5cf994c56b5c6b9f771e84aaeb0}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Yash},
           giveni={Y\bibinitperiod}}}%
        {{hash=f022d46633eb6607e641862115b32d86}{%
           family={Lindsey},
           familyi={L\bibinitperiod},
           given={Laurence},
           giveni={L\bibinitperiod}}}%
        {{hash=e40c2d9b957cafc62ce817aff691483b}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={Runchang},
           giveni={R\bibinitperiod}}}%
        {{hash=e5c555b2b1cda20e8cdaa0763044a420}{%
           family={Shahsavari},
           familyi={S\bibinitperiod},
           given={Behrooz},
           giveni={B\bibinitperiod}}}%
        {{hash=e2c6ef6f5d0de5d5b0ad981e3c2e48ea}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Tu},
           giveni={T\bibinitperiod}}}%
        {{hash=32358cb61bfa2639dd6701cfebe34e7b}{%
           family={Nieto},
           familyi={N\bibinitperiod},
           given={Heriberto},
           giveni={H\bibinitperiod}}}%
        {{hash=9cfd1775a8ef9e4916d75116dc601b1a}{%
           family={Hudson},
           familyi={H\bibinitperiod},
           given={Scott\bibnamedelima E},
           giveni={S\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=1482cf947d9c1ad8868793eb2eac8032}{%
           family={Maalouf},
           familyi={M\bibinitperiod},
           given={Charlie},
           giveni={C\bibinitperiod}}}%
        {{hash=e557c49f0ea54f542dc861a2ecff716b}{%
           family={Mousavi},
           familyi={M\bibinitperiod},
           given={Jax\bibnamedelima Seyed},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=d26d35b2c718320520622ace630c7516}{%
           family={Laput},
           familyi={L\bibinitperiod},
           given={Gierad},
           giveni={G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New Orleans, LA, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{83d9d45d3ad197ead3103ea49eec2c1d}
      \strng{fullhash}{5910f7a8bae48a6a6af1697aaca711bb}
      \strng{bibnamehash}{83d9d45d3ad197ead3103ea49eec2c1d}
      \strng{authorbibnamehash}{83d9d45d3ad197ead3103ea49eec2c1d}
      \strng{authornamehash}{83d9d45d3ad197ead3103ea49eec2c1d}
      \strng{authorfullhash}{5910f7a8bae48a6a6af1697aaca711bb}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a framework for gesture customization requiring minimal examples from users, all without degrading the performance of existing gesture sets. To achieve this, we first deployed a large-scale study (N=500+) to collect data and train an accelerometer-gyroscope recognition model with a cross-user accuracy of 95.7\% and a false-positive rate of 0.6 per hour when tested on everyday non-gesture data. Next, we design a few-shot learning framework which derives a lightweight model from our pre-trained model, enabling knowledge transfer without performance degradation. We validate our approach through a user study (N=20) examining on-device customization from 12 new gestures, resulting in an average accuracy of 55.3\%, 83.1\%, and 87.2\% on using one, three, or five shots when adding a new gesture, while maintaining the same recognition accuracy and false-positive rate from the pre-existing gesture set. We further evaluate the usability of our real-time implementation with a user experience study (N=20). Our results highlight the effectiveness, learnability, and usability of our customization framework. Our approach paves the way for a future where users are no longer bound to pre-existing gestures, freeing them to creatively introduce new gestures tailored to their preferences and abilities.}
      \field{booktitle}{Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems}
      \field{isbn}{9781450391573}
      \field{series}{CHI '22}
      \field{title}{{Enabling Hand Gesture Customization on Wrist-Worn Devices}}
      \field{year}{2022}
      \verb{doi}
      \verb 10.1145/3491102.3501904
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3491102.3501904
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3491102.3501904
      \endverb
      \keyw{transfer learning,few-shot learning,Gesture customization}
    \endentry
    \entry{Yang:2018}{article}{}
      \name{author}{2}{}{%
        {{hash=7f8a6256a19361714c6f6a011671f17d}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{e0bfe18f6208a14078c350167b963ec0}
      \strng{fullhash}{e0bfe18f6208a14078c350167b963ec0}
      \strng{bibnamehash}{e0bfe18f6208a14078c350167b963ec0}
      \strng{authorbibnamehash}{e0bfe18f6208a14078c350167b963ec0}
      \strng{authornamehash}{e0bfe18f6208a14078c350167b963ec0}
      \strng{authorfullhash}{e0bfe18f6208a14078c350167b963ec0}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this study, two radar sensors with angular diversity are used to recognise dynamic hand gestures by analysing the sparse micro-Doppler signatures. The radar echoes are firstly mapped into the time–frequency domain through the Gaussian-windowed Fourier dictionary at each radar sensor. Then the sparse time–frequency features are extracted via the orthogonal matching pursuit algorithm. Finally, the sparse time–frequency features at two radar sensors are fused and input into the modified-Hausdorff-distance-based nearest neighbour classifier to achieve the dynamic hand gesture recognition. The experimental results based on the measured data under three different experimental scenes demonstrate that (i) the recognition accuracy can be improved by fusing the features extracted at two radar sensors when each radar sensor works well on its own; (ii) the recognition accuracy produced by feature fusion keeps satisfactory even if one of the radar sensors has poor performance, which means that the feature fusion can improve the robustness of the recognition system; and (iii) it would be more helpful if the line-of-sights of the two radar sensors are set to be orthogonal to each other.}
      \field{issn}{1751-8792}
      \field{journaltitle}{IET Radar, Sonar Navigation}
      \field{number}{10}
      \field{title}{{Sparsity aware dynamic gesture recognition using radar sensors with angular diversity}}
      \field{volume}{12}
      \field{year}{2018}
      \field{pages}{1114\bibrangedash 1120}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1049/iet-rsn.2018.5206
      \endverb
      \keyw{angular diversity,Doppler radar,dynamic hand gesture recognition,feature extraction,Gaussian-windowed Fourier dictionary,gesture recognition,modified-Hausdorff-distance-based nearest neighbour classifier,orthogonal matching pursuit algorithm,radar receivers,radar sensor,radar signal processing,sensor fusion,signal classification,sparse microDoppler signatures,sparse time–frequency feature extraction,sparsity aware dynamic gesture recognition,time-frequency analysis,time–frequency domain}
    \endentry
    \entry{Yang:2017}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=eba68d34a25d8e0125cb5eeb7f44fbd9}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Lin},
           giveni={L\bibinitperiod}}}%
        {{hash=9f1ee8822aa6f600a29f25c54c515727}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Long},
           giveni={L\bibinitperiod}}}%
        {{hash=57ba13ea1efe60c5683169b75f2eadca}{%
           family={Zhong},
           familyi={Z\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=7b6f505141daa7b6d93a7267897f0f59}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yingying},
           giveni={Y\bibinitperiod}}}%
        {{hash=ddff1c6ccb542f71c04756739d1db1c5}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Qin},
           giveni={Q\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{ed2bd6fd519124175ed844b0d98262ac}
      \strng{fullhash}{e93489884cf44485c64bb8c84813e7a0}
      \strng{bibnamehash}{ed2bd6fd519124175ed844b0d98262ac}
      \strng{authorbibnamehash}{ed2bd6fd519124175ed844b0d98262ac}
      \strng{authornamehash}{ed2bd6fd519124175ed844b0d98262ac}
      \strng{authorfullhash}{e93489884cf44485c64bb8c84813e7a0}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{LNCS on Transactions on Edutainment XIII - Volume 10092}
      \field{isbn}{9783662543948}
      \field{title}{{A Real-Time Interactive System Based on Hand Gesture Recognition in Virtual Fitting}}
      \field{year}{2017}
      \field{pages}{86\bibrangedash 96}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1007/978-3-662-54395-5_8
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/978-3-662-54395-5_8
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/978-3-662-54395-5_8
      \endverb
      \keyw{Leap motion,Hand gesture interaction,Gesture recognition,Virtual reality}
    \endentry
    \entry{Yao:2017}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=6eeb7f2c1fa2eff006ff7b13c8d06b0d}{%
           family={Yao},
           familyi={Y\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=3d72a02d66490c04599c90bbc7b33171}{%
           family={Chiu},
           familyi={C\bibinitperiod},
           given={Po-Tsung},
           giveni={P\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=cb33c40faa7ce5f6837cac579ff32439}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Wai-Tat},
           giveni={W\bibinithyphendelim T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{b8b6debd07049e7b714dc72cc6969043}
      \strng{fullhash}{b8b6debd07049e7b714dc72cc6969043}
      \strng{bibnamehash}{b8b6debd07049e7b714dc72cc6969043}
      \strng{authorbibnamehash}{b8b6debd07049e7b714dc72cc6969043}
      \strng{authornamehash}{b8b6debd07049e7b714dc72cc6969043}
      \strng{authorfullhash}{b8b6debd07049e7b714dc72cc6969043}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion}
      \field{isbn}{9781450348935}
      \field{series}{IUI '17 Companion}
      \field{title}{{A Gestural Interface for Practicing Children's Spatial Skills}}
      \field{venue}{Limassol, Cyprus}
      \field{year}{2017}
      \field{pages}{43\bibrangedash 47}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1145/3030024.3038265
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3030024.3038265
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3030024.3038265
      \endverb
      \keyw{video game,children,3D interaction,spatial reasoning,gestural interface}
    \endentry
    \entry{Yeo:2017}{article}{}
      \name{author}{2}{}{%
        {{hash=ba585fafe1d97ae953670a4841c354ef}{%
           family={Yeo},
           familyi={Y\bibinitperiod},
           given={Hui-Shyong},
           giveni={H\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=192f4c9db69121c98d7900243b99acf9}{%
           family={Quigley},
           familyi={Q\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{9c88147b5d048de0d134200416e71bce}
      \strng{fullhash}{9c88147b5d048de0d134200416e71bce}
      \strng{bibnamehash}{9c88147b5d048de0d134200416e71bce}
      \strng{authorbibnamehash}{9c88147b5d048de0d134200416e71bce}
      \strng{authornamehash}{9c88147b5d048de0d134200416e71bce}
      \strng{authorfullhash}{9c88147b5d048de0d134200416e71bce}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Envisioning, designing, and implementing the user interface require a comprehensive understanding of interaction technologies. In this forum we scout trends and discuss new technologies with the potential to influence interaction design. ---Albrecht Schmidt, Editor}
      \field{issn}{1072-5520}
      \field{journaltitle}{Interactions}
      \field{month}{12}
      \field{number}{1}
      \field{title}{{Radar Sensing in Human-Computer Interaction}}
      \field{volume}{25}
      \field{year}{2017}
      \field{pages}{70\bibrangedash 73}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/3159651
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3159651
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3159651
      \endverb
    \endentry
    \entry{Yeo:2019}{article}{}
      \name{author}{5}{}{%
        {{hash=ba585fafe1d97ae953670a4841c354ef}{%
           family={Yeo},
           familyi={Y\bibinitperiod},
           given={Hui-Shyong},
           giveni={H\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=fbc0c2a2624e2de7ab615de3de04fdb2}{%
           family={Minami},
           familyi={M\bibinitperiod},
           given={Ryosuke},
           giveni={R\bibinitperiod}}}%
        {{hash=e6f9e280dbe41350742ed929da10b47d}{%
           family={Rodriguez},
           familyi={R\bibinitperiod},
           given={Kirill},
           giveni={K\bibinitperiod}}}%
        {{hash=6cda7e13062091562f92a7fc7790df70}{%
           family={Shaker},
           familyi={S\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=192f4c9db69121c98d7900243b99acf9}{%
           family={Quigley},
           familyi={Q\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{fullhash}{7ddd3e5a5709df0c59192f6c1ecc8f83}
      \strng{bibnamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authorbibnamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authornamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authorfullhash}{7ddd3e5a5709df0c59192f6c1ecc8f83}
      \field{extraname}{1}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Research has explored miniature radar as a promising sensing technique for the recognition of gestures, objects, users' presence and activity. However, within Human-Computer Interaction (HCI), its use remains underexplored, in particular in Tangible User Interface (TUI). In this paper, we explore two research questions with radar as a platform for sensing tangible interaction with the counting, ordering, identification of objects and tracking the orientation, movement and distance of these objects. We detail the design space and practical use-cases for such interaction which allows us to identify a series of design patterns, beyond static interaction, which are continuous and dynamic. With a focus on planar objects, we report on a series of studies which demonstrate the suitability of this approach. This exploration is grounded in both a characterization of the radar sensing and our rigorous experiments which show that such sensing is accurate with minimal training. With these techniques, we envision both realistic and future applications and scenarios. The motivation for what we refer to as Solinteraction, is to demonstrate the potential for radar-based interaction with objects in HCI and TUI.}
      \field{journaltitle}{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}
      \field{month}{12}
      \field{number}{4}
      \field{title}{{Exploring Tangible Interactions with Radar Sensing}}
      \field{volume}{2}
      \field{year}{2018}
      \verb{doi}
      \verb 10.1145/3287078
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3287078
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3287078
      \endverb
      \keyw{Soli,Radar Sensing,Context-Aware Interaction,Machine Learning,Ubiquitous Computing,Token+Constraint,Tangible Interaction,Tangible User Interface}
    \endentry
    \entry{Yeo:2016}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=ba585fafe1d97ae953670a4841c354ef}{%
           family={Yeo},
           familyi={Y\bibinitperiod},
           given={Hui-Shyong},
           giveni={H\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=16dc83391593e5baa8cde097f7b36479}{%
           family={Flamich},
           familyi={F\bibinitperiod},
           given={Gergely},
           giveni={G\bibinitperiod}}}%
        {{hash=6b19d7e869cb1cd05120f82b9ad1044d}{%
           family={Schrempf},
           familyi={S\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
        {{hash=00ea9146a6e61e5a74e6464bafc9856f}{%
           family={Harris-Birtill},
           familyi={H\bibinithyphendelim B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=192f4c9db69121c98d7900243b99acf9}{%
           family={Quigley},
           familyi={Q\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{fullhash}{056909f5c6c4a37f42f20651f45dd36c}
      \strng{bibnamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authorbibnamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authornamehash}{184a29be89e04087f41596fd993a8a8c}
      \strng{authorfullhash}{056909f5c6c4a37f42f20651f45dd36c}
      \field{extraname}{2}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In RadarCat we present a small, versatile radar-based system for material and object classification which enables new forms of everyday proximate interaction with digital devices. We demonstrate that we can train and classify different types of materials and objects which we can then recognize in real time. Based on established research designs, we report on the results of three studies, first with 26 materials (including complex composite objects), next with 16 transparent materials (with different thickness and varying dyes) and finally 10 body parts from 6 participants. Both leave one-out and 10-fold cross-validation demonstrate that our approach of classification of radar signals using random forest classifier is robust and accurate. We further demonstrate four working examples including a physical object dictionary, painting and photo editing application, body shortcuts and automatic refill based on RadarCat. We conclude with a discussion of our results, limitations and outline future directions.}
      \field{booktitle}{Proceedings of the 29th Annual Symposium on User Interface Software and Technology}
      \field{isbn}{9781450341899}
      \field{series}{UIST '16}
      \field{title}{{RadarCat: Radar Categorization for Input \& Interaction}}
      \field{venue}{Tokyo, Japan}
      \field{year}{2016}
      \field{pages}{833\bibrangedash 841}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1145/2984511.2984515
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2984511.2984515
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2984511.2984515
      \endverb
      \keyw{material classification,radar,object recognition,ubiquitous computing,context-aware interaction,machine learning}
    \endentry
    \entry{Yoo:2015}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=af76034c8b2d77f7230f376d098bfbc4}{%
           family={Yoo},
           familyi={Y\bibinitperiod},
           given={Soojeong},
           giveni={S\bibinitperiod}}}%
        {{hash=89c9f635c91c6fc8d9f565eff268d5f6}{%
           family={Parker},
           familyi={P\bibinitperiod},
           given={Callum},
           giveni={C\bibinitperiod}}}%
        {{hash=10d118bb40da1dffa1d8a7942a5961e8}{%
           family={Kay},
           familyi={K\bibinitperiod},
           given={Judy},
           giveni={J\bibinitperiod}}}%
        {{hash=2ddbec28b2e9674b25b164176b225a23}{%
           family={Tomitsch},
           familyi={T\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{7e0df29b7f271372104370243c4999c2}
      \strng{fullhash}{fdc0602e79301270c4af267388639061}
      \strng{bibnamehash}{7e0df29b7f271372104370243c4999c2}
      \strng{authorbibnamehash}{7e0df29b7f271372104370243c4999c2}
      \strng{authornamehash}{7e0df29b7f271372104370243c4999c2}
      \strng{authorfullhash}{fdc0602e79301270c4af267388639061}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper investigates user preferences for mid-air gestures to interact with large public information displays. We designed and implemented a public display application that allows people to navigate between Twitter feeds and to find details about particular tweets. The application supports selection and navigation through (1) point-and-dwell and (2) push and grab-and-pull. A within-subject evaluation with 10 participants found that although point-and-dwell was perceived to be more accurate, push was preferred for selecting items and grab-and-pull was preferred for navigation. Based on our findings we derive recommendations for designing gesture-based information displays.}
      \field{booktitle}{Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction}
      \field{isbn}{9781450336734}
      \field{series}{OzCHI '15}
      \field{title}{{To Dwell or Not to Dwell: An Evaluation of Mid-Air Gestures for Large Information Displays}}
      \field{venue}{Parkville, VIC, Australia}
      \field{year}{2015}
      \field{pages}{187\bibrangedash 191}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1145/2838739.2838819
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/2838739.2838819
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/2838739.2838819
      \endverb
      \keyw{push,point-and-dwell,natural user interfaces,mid-air gestures,grab-and-pull,Public displays}
    \endentry
    \entry{Yu:2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=95542a0e2400dc8af1b7f804fc1a0a63}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Ge},
           giveni={G\bibinitperiod}}}%
        {{hash=548a675c71741e66db909c3fb66d2a36}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Ji},
           giveni={J\bibinitperiod}}}%
        {{hash=be5d03f58577f4fe7e5d098a7769f7c1}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Lili},
           giveni={L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{aa6f011e487c8bae66766573475a28d9}
      \strng{fullhash}{aa6f011e487c8bae66766573475a28d9}
      \strng{bibnamehash}{aa6f011e487c8bae66766573475a28d9}
      \strng{authorbibnamehash}{aa6f011e487c8bae66766573475a28d9}
      \strng{authornamehash}{aa6f011e487c8bae66766573475a28d9}
      \strng{authorfullhash}{aa6f011e487c8bae66766573475a28d9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 2018 International Conference on Artificial Intelligence and Virtual Reality}
      \field{isbn}{9781450366410}
      \field{series}{AIVR 2018}
      \field{title}{{Multi-Modal Interaction for Space Telescience of Fluid Experiments}}
      \field{venue}{Nagoya, Japan}
      \field{year}{2018}
      \field{pages}{35\bibrangedash 41}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1145/3293663.3293672
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3293663.3293672
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3293663.3293672
      \endverb
      \keyw{Single-Channel Speech Separation,Space telescience,Gesture recognition,Space fluid experiment}
    \endentry
    \entry{Yu:2020b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=57913a2449de9ffabf0cce449c768202}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Jih-Tsun},
           giveni={J\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=fe423f34a88627db2f1d2821a97ae328}{%
           family={Yen},
           familyi={Y\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
        {{hash=bbe0d8f50a74ce7efe37ee631164e41a}{%
           family={Tseng},
           familyi={T\bibinitperiod},
           given={Po-Hsuan},
           giveni={P\bibinithyphendelim H\bibinitperiod}}}%
      }
      \strng{namehash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \strng{fullhash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \strng{bibnamehash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \strng{authorbibnamehash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \strng{authornamehash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \strng{authorfullhash}{82152412452b9f0ed8d3df7f3f7a1ada}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The radar sensing on fine human-motion/hand-gesture provides further human-computer interaction (HCI) experience. Most of the studies about gesture recognition with mmWave frequency modulated continuous wave (FMCW) radar adopts the range and the velocity estimated from the raw data, such as the time-frequency spectrogram, micro-doppler spectrogram, or range-Doppler image (RDI). Besides, the angle estimated using multiple receive antennas also contains rich information of gesture, especially in the discrimination among the horizontal movement of the gesture. Thus, we propose to use the range-angle image (RAI) as the input and train a model consisting of the convolutional neural network and long short term memory that is capable of recognizing hand gestures. We validate the proposed scheme based on the collection of hand gestures by several subjects in different classrooms using 77 - 81GHz mmWave radar of Texas Instrument. Based on the configuration of one transmit antenna and four receive antennas, we show that the hand gesture recognition using RAI outperforms that using RDI. Also, we adopt the fusion strategy to consider both RDI and RAI to further improve accuracy.}
      \field{booktitle}{2020 {IEEE} 91st {Vehicular} {Technology} {Conference} ({VTC2020}-{Spring})}
      \field{month}{5}
      \field{note}{ISSN: 2577-2465}
      \field{title}{{mmWave} {Radar}-based {Hand} {Gesture} {Recognition} using {Range}-{Angle} {Image}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 5}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/VTC2020-Spring48590.2020.9128573
      \endverb
      \keyw{antenna arrays,Chirp,continuous wave radar,convolutional neural nets,CW radar,Doppler radar,FM radar,FMCW Radar,frequency 77.0 GHz to 81.0 GHz,gesture recognition,Gesture recognition,Hand-Gesture Recognition,Human-Computer Interaction,human-computer interaction experience,image fusion,image motion analysis,Machine Learning,microdoppler spectrogram,millimetre wave radar,mmWave frequency,mmWave radar,mmWave radar-based hand gesture recognition,multiple receive antennas,Radar antennas,radar imaging,Radar imaging,radar sensing,range-angle image,range-Doppler image,RDI,receiving antennas,Receiving antennas,recurrent neural nets,Time-frequency analysis,time-frequency spectrogram,transmitting antennas}
    \endentry
    \entry{Yu:2020a}{article}{}
      \name{author}{4}{}{%
        {{hash=6d9861754a43f2f298bce708a63874b8}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Myoungseok},
           giveni={M\bibinitperiod}}}%
        {{hash=96534075a7a54640cd11dd2c0a9b038d}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Narae},
           giveni={N\bibinitperiod}}}%
        {{hash=ed2bae283383094e54c0c54b88d142c7}{%
           family={Jung},
           familyi={J\bibinitperiod},
           given={Yunho},
           giveni={Y\bibinitperiod}}}%
        {{hash=e6186c82fe3471f9e06ab71d851e5608}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Seongjoo},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{11a4d6599e170f152c0b33e2b8b2cc7f}
      \strng{fullhash}{85d3eddb179aa8c9a3f6b556679f17a7}
      \strng{bibnamehash}{11a4d6599e170f152c0b33e2b8b2cc7f}
      \strng{authorbibnamehash}{11a4d6599e170f152c0b33e2b8b2cc7f}
      \strng{authornamehash}{11a4d6599e170f152c0b33e2b8b2cc7f}
      \strng{authorfullhash}{85d3eddb179aa8c9a3f6b556679f17a7}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a method to detect frames was described that can be used as hand gesture data when configuring a real-time hand gesture recognition system using continuous wave (CW) radar. Detecting valid frames raises accuracy which recognizes gestures. Therefore, it is essential to detect valid frames in the real-time hand gesture recognition system using CW radar. The conventional research on hand gesture recognition systems has not been conducted on detecting valid frames. We took the R-wave on electrocardiogram (ECG) detection as the conventional method. The detection probability of the conventional method was 85.04\%. It has a low accuracy to use the hand gesture recognition system. The proposal consists of 2-stages to improve accuracy. We measured the performance of the detection method of hand gestures provided by the detection probability and the recognition probability. By comparing the performance of each detection method, we proposed an optimal detection method. The proposal detects valid frames with an accuracy of 96.88\%, 11.84\% higher than the accuracy of the conventional method. Also, the recognition probability of the proposal method was 94.21\%, which was 3.71\% lower than the ideal method.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{8}
      \field{title}{A {Frame} {Detection} {Method} for {Real}-{Time} {Hand} {Gesture} {Recognition} {Systems} {Using} {CW}-{Radar}}
      \field{volume}{20}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 17}
      \range{pages}{17}
      \verb{doi}
      \verb 10.3390/s20082321
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/20/8/2321
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/20/8/2321
      \endverb
    \endentry
    \entry{Zeng:2018}{article}{}
      \name{author}{3}{}{%
        {{hash=c14a2b98f3681abab1366793dca49c73}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=03ebb954658194d4f7fe4cd6f9a1c295}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Cong},
           giveni={C\bibinitperiod}}}%
        {{hash=99c7a29454ab2dc1b5bf6c4c3b44cbbc}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Qinghui},
           giveni={Q\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \strng{fullhash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \strng{bibnamehash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \strng{authorbibnamehash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \strng{authornamehash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \strng{authorfullhash}{4bae8e4ffbb7eb7920684b2c840b4a51}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{1380-7501}
      \field{journaltitle}{Multimedia Tools Appl.}
      \field{month}{11}
      \field{number}{21}
      \field{title}{{Hand Gesture Recognition Using Leap Motion via Deterministic Learning}}
      \field{volume}{77}
      \field{year}{2018}
      \field{pages}{28185\bibrangedash 28206}
      \range{pages}{22}
      \keyw{Deterministic learning,Hand gesture recognition,Leap Motion,Hand motion dynamics,RBF neural networks}
    \endentry
    \entry{Zeng:2020a}{article}{}
      \name{author}{3}{}{%
        {{hash=71ad6b78804801deaf79df5615e86582}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Zhengxin},
           giveni={Z\bibinitperiod}}}%
        {{hash=77203d8e52a8a50d541ea84825719adb}{%
           family={Amin},
           familyi={A\bibinitperiod},
           given={Moeness\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=1432e4d153e4cdd63cfbf5c18fd848c1}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{fullhash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{bibnamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authorbibnamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authornamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authorfullhash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Hand and arm gesture recognition using radio frequency (RF) sensing modality proves valuable in man-machine interfaces and smart environments. In this paper, we use the time-series analysis method to accurately measure the similarity of the micro-Doppler (MD) signatures between the training and test data, thus providing improved gesture classification. We characterize the MD signatures by the maximum instantaneous Doppler frequencies depicted in the spectrograms. In particular, we apply two machine learning (ML) techniques, namely, the dynamic time warping (DTW) method and the long short-term memory (LSTM) network. Both methods take into account the values as well as the temporal evolution and characteristics of the time-series data. It is shown that the DTW method achieves high gesture classification rates and is robust to time misalignment.}
      \field{issn}{2072-4292}
      \field{journaltitle}{Remote Sensing}
      \field{number}{3}
      \field{title}{Arm {Motion} {Classification} {Using} {Time}-{Series} {Analysis} of the {Spectrogram} {Frequency} {Envelopes}}
      \field{volume}{12}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 20}
      \range{pages}{20}
      \verb{doi}
      \verb 10.3390/rs12030454
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2072-4292/12/3/454
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2072-4292/12/3/454
      \endverb
    \endentry
    \entry{Zeng:2020b}{article}{}
      \name{author}{3}{}{%
        {{hash=71ad6b78804801deaf79df5615e86582}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Zhengxin},
           giveni={Z\bibinitperiod}}}%
        {{hash=77203d8e52a8a50d541ea84825719adb}{%
           family={Amin},
           familyi={A\bibinitperiod},
           given={Moeness\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=1432e4d153e4cdd63cfbf5c18fd848c1}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{fullhash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{bibnamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authorbibnamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authornamehash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \strng{authorfullhash}{4bd5b6f11d5bf3d7ce7f144f4f341ee5}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In considering human-machine interface (HMI) for smart environment, a simple but effective method is proposed for automatic arm motion recognition with a Doppler radar sensor. Arms, in lieu of hands, have stronger radar cross-section and can be recognized from relatively longer distances. An energy-based thresholding algorithm is applied to the spectrograms to extract the micro-Doppler (MD) signature envelopes. The positive and negative frequency envelopes are concatenated to form a feature vector. The nearest neighbor (NN) classifier with Manhattan distance (L1) is then used to recognize the arm motions. It is shown that this simple method yields classification accuracy above 97 percent for six classes of arm motions. Despite its simplicity, the proposed method is superior to those of handcrafted feature-based classifications and low-dimension representation techniques based on principal component analysis (PCA), and is comparable to convolutional neural network (CNN).}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{11}
      \field{number}{22}
      \field{title}{Automatic {Arm} {Motion} {Recognition} {Based} on {Radar} {Micro}-{Doppler} {Signature} {Envelopes}}
      \field{volume}{20}
      \field{year}{2020}
      \field{pages}{13523\bibrangedash 13532}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/JSEN.2020.3004581
      \endverb
      \keyw{Arm motion recognition,arm motions,automatic arm motion recognition,Doppler effect,Doppler radar,Doppler radar sensor,energy-based thresholding algorithm,feature extraction,Feature extraction,handcrafted feature-based classifications,human-machine interface,image classification,micro-Doppler signature,negative frequency envelopes,neural nets,positive frequency envelopes,principal component analysis,radar cross-sections,radar microDoppler signature envelopes,relatively longer distances,Sensors,simple but effective method,simple method yields,Spectrogram,spectrograms,stronger radar cross-section,Time-frequency analysis}
    \endentry
    \entry{Zhang:2021}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=4ac36eed64badd6f195e86aeecd037a7}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
        {{hash=3ccecbc0ef7c4eea305915611f46d91f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Mojun},
           giveni={M\bibinitperiod}}}%
        {{hash=5c786d9afb3cf178271120f1fd926d21}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{41d405cc58e0da74af6f14b68e86cf1b}
      \strng{fullhash}{402475391047c7d43483e71ff443498c}
      \strng{bibnamehash}{41d405cc58e0da74af6f14b68e86cf1b}
      \strng{authorbibnamehash}{41d405cc58e0da74af6f14b68e86cf1b}
      \strng{authornamehash}{41d405cc58e0da74af6f14b68e86cf1b}
      \strng{authorfullhash}{402475391047c7d43483e71ff443498c}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2021 IEEE International Symposium on Circuits and Systems (ISCAS)}
      \field{title}{{Dynamic Gesture Recognition Based on RF Sensor and AE-LSTM Neural Network}}
      \field{year}{2021}
      \field{pages}{1\bibrangedash 5}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ISCAS51556.2021.9401065
      \endverb
    \endentry
    \entry{Zhang:2019a}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=496db2da1711740937cf21688f8e79b9}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Guiyuan},
           giveni={G\bibinitperiod}}}%
        {{hash=25b49ae9660c763222a6e0c5e8f355f6}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Kang},
           giveni={K\bibinitperiod}}}%
        {{hash=9f1ab85677af8f7a6a5723a92e9e8149}{%
           family={Yun},
           familyi={Y\bibinitperiod},
           given={Yihan},
           giveni={Y\bibinitperiod}}}%
        {{hash=651d8ad1075af9edde09d25bdff48fc1}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=38b2cef845bc169f5dc21c8c936a7c8f}{%
           family={Lan},
           familyi={L\bibinitperiod},
           given={Shengchang},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{fullhash}{16c28fdc4f4462a47e0eef41e54fa91a}
      \strng{bibnamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authorbibnamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authornamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authorfullhash}{16c28fdc4f4462a47e0eef41e54fa91a}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In order to improve the accuracy of gesture recognition, we investigate the feasibility of using a three-dimensional Doppler-radar array at 24GHz to recognize human gestures with a model consisted of ten classical gestures. On the basis of C4.5 algorithm, phase difference and spectral energy, extracted by correlation processing and power integral, are used as the features to construct decision tree and separate ten gestures. The experiment result shows that this system could achieve a high accuracy of classification reached 99.25\%.}
      \field{booktitle}{2019 {International} {Symposium} on {Antennas} and {Propagation} ({ISAP})}
      \field{month}{10}
      \field{title}{Implementation of {C4}.5 decision tree in {Human} {Gesture} {Recognition} based on {Doppler} radars}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 3}
      \range{pages}{3}
      \keyw{24GHz radar,C4.5 algorithm,C4.5 decision tree algorithm,correlation processing,decision tree,decision trees,Doppler radar,doppler radar array,frequency 24.0 GHz,gesture recognition,human gesture recognition,phase difference,power integral,spectral energy,three-dimensional Doppler-radar array}
    \endentry
    \entry{Zhang:2020b}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=496db2da1711740937cf21688f8e79b9}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Guiyuan},
           giveni={G\bibinitperiod}}}%
        {{hash=38b2cef845bc169f5dc21c8c936a7c8f}{%
           family={Lan},
           familyi={L\bibinitperiod},
           given={Shengchang},
           giveni={S\bibinitperiod}}}%
        {{hash=25b49ae9660c763222a6e0c5e8f355f6}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Kang},
           giveni={K\bibinitperiod}}}%
        {{hash=44249354f266d1c97629cb40e0abdadb}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Linting},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{fullhash}{02c39e045bf2548bef53fa5316ee681f}
      \strng{bibnamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authorbibnamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authornamehash}{5062ad57577abbafe184ad425c5936cc}
      \strng{authorfullhash}{02c39e045bf2548bef53fa5316ee681f}
      \field{extraname}{3}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduced a comparative study of using deep neural networks in non-contact hand gesture recognition based on millimeter wave FMCW radar. Range-doppler maps are processed with a zero-filling strategy to boost the range and velocity information of gesture motions. Two optimal types of deep neural networks, 3D-CNN and CNN-LSTM are respectively constructed to reveal the temporal gesture motion signatures encoded in multiple adjacent radar chirps. With the proposed networks, the recognition accuracy of six popular hand gestures reach to 95\%. Meanwhile, this letter further explores the performance of the proposed networks in the impacts of training data size on the recognition accuracy. The proposed methods can be applied in the recognition of minor finger motions, providing some preliminary experimental results compared with other baseline methods.}
      \field{booktitle}{2020 14th {European} {Conference} on {Antennas} and {Propagation} ({EuCAP})}
      \field{month}{3}
      \field{title}{Temporal-{Range}-{Doppler} {Features} {Interpretation} and {Recognition} of {Hand} {Gestures} {Using} {mmW} {FMCW} {Radar} {Sensors}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.23919/EuCAP48036.2020.9135694
      \endverb
      \keyw{3D-CNN,CNN-LSTM,convolutional neural nets,CW radar,deep neural networks,Doppler radar,finger motions,FM radar,FMCW radar,gesture motions,gesture recognition,hand gesture recognition,hand gestures,millimeter wave,millimeter wave FMCW radar,mmW FMCW radar sensors,multiple adjacent radar chirps,noncontact hand gesture recognition,radar detection,range-doppler maps,recognition accuracy,recurrent neural nets,temporal gesture motion signatures,temporal-range-doppler features interpretation,velocity information,zero-filling strategy}
    \endentry
    \entry{Zhang:2017}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=b5f64909c50a46dc78d434721990127b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jiajun},
           giveni={J\bibinitperiod}}}%
        {{hash=27c529e21d6ea5299bfb7c54043c5c1b}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Zhiguo},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{504a582eb97f370edbf37b3cee775faa}
      \strng{fullhash}{504a582eb97f370edbf37b3cee775faa}
      \strng{bibnamehash}{504a582eb97f370edbf37b3cee775faa}
      \strng{authorbibnamehash}{504a582eb97f370edbf37b3cee775faa}
      \strng{authornamehash}{504a582eb97f370edbf37b3cee775faa}
      \strng{authorfullhash}{504a582eb97f370edbf37b3cee775faa}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Traditional vision-based hand gesture recognition systems is limited under dark circumstances. In this paper, we build a hand gesture recognition system based on microwave transceiver and deep learning algorithm. A Doppler radar sensor with dual receiving channels at 5.8GHz is used to acquire a big database of hand gestures signals. The received hand gesture signals are then processed with time-frequency analysis. Based on these big database of hand gesture, we propose a new classification architecture called deformable deep convolutional generative adversarial network. Experimental results shows the new architecture can upgrade the recognition rate by 10\% and the deformable kernel can reduce the testing time cost by 30\%.}
      \field{booktitle}{2017 9th {International} {Conference} on {Wireless} {Communications} and {Signal} {Processing} ({WCSP})}
      \field{month}{10}
      \field{note}{ISSN: 2472-7628}
      \field{title}{{Deformable deep convolutional generative adversarial network in microwave based hand gesture recognition system}}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/WCSP.2017.8170976
      \endverb
      \keyw{big database,classification architecture,Convolution,Databases,deep learning algorithm,deformable deep convolutional generative adversarial network,Doppler radar,Doppler radar sensor,dual receiving channels,feedforward neural nets,frequency 5.8 GHz,gesture recognition,Gesture recognition,hand gesture signals,image classification,learning (artificial intelligence),microwave based hand gesture recognition system,Microwave imaging,Microwave theory and techniques,microwave transceiver,radio transceivers,recognition rate,Testing,time-frequency analysis,Time-frequency analysis}
    \endentry
    \entry{Zhang:2019c}{incollection}{}
      \name{author}{3}{}{%
        {{hash=b5f64909c50a46dc78d434721990127b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jiajun},
           giveni={J\bibinitperiod}}}%
        {{hash=6134a0358e95c82ea937832d124849fb}{%
           family={Tao},
           familyi={T\bibinitperiod},
           given={Jinkun},
           giveni={J\bibinitperiod}}}%
        {{hash=27c529e21d6ea5299bfb7c54043c5c1b}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Zhiguo},
           giveni={Z\bibinitperiod}}}%
      }
      \name{editor}{6}{}{%
        {{hash=2af77acd572f657066f00be9ae002d72}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Qilian},
           giveni={Q\bibinitperiod}}}%
        {{hash=c4b24b73aa2c7e33f8925feedc6ed4bf}{%
           family={Mu},
           familyi={M\bibinitperiod},
           given={Jiasong},
           giveni={J\bibinitperiod}}}%
        {{hash=8efee3675f8033f7fe27cd6510bd9a86}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
        {{hash=f27ec46ccd272a021fd78bdac92dd490}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=3e858503ebbd26a59f7c4e3727660537}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Xuhong},
           giveni={X\bibinitperiod}}}%
        {{hash=7db0e2c407c3eeba809feb50bf9f9225}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Baoju},
           giveni={B\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Singapore}%
      }
      \list{publisher}{1}{%
        {Springer Singapore}%
      }
      \strng{namehash}{3200a9e78be5bc249ca8735047b62045}
      \strng{fullhash}{3200a9e78be5bc249ca8735047b62045}
      \strng{bibnamehash}{3200a9e78be5bc249ca8735047b62045}
      \strng{authorbibnamehash}{3200a9e78be5bc249ca8735047b62045}
      \strng{authornamehash}{3200a9e78be5bc249ca8735047b62045}
      \strng{authorfullhash}{3200a9e78be5bc249ca8735047b62045}
      \strng{editorbibnamehash}{fd2c275c4049fdc696d8437a2fbad784}
      \strng{editornamehash}{fd2c275c4049fdc696d8437a2fbad784}
      \strng{editorfullhash}{d604e84b98c62a30ec3d0632f0999de4}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Communications, {Signal} {Processing}, and {Systems}}
      \field{isbn}{978-981-10-6570-5 978-981-10-6571-2}
      \field{note}{Series Title: Lecture Notes in Electrical Engineering}
      \field{title}{Doppler-{Radar} {Based} {Hand} {Gesture} {Recognition} {System} {Using} {Convolutional} {Neural} {Networks}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{volume}{463}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{1096\bibrangedash 1113}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1007/978-981-10-6571-2_132
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-981-10-6571-2_132
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-981-10-6571-2_132
      \endverb
    \endentry
    \entry{Zhang:2020a}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=370d19824818ff77df0edac5f5f57ee6}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Kaijie},
           giveni={K\bibinitperiod}}}%
        {{hash=65ae00ff52a1f9d8174ffcad07d13bfd}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Zhiwen},
           giveni={Z\bibinitperiod}}}%
        {{hash=b7a01953210b558b4146902bc09d3564}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Dong},
           giveni={D\bibinitperiod}}}%
        {{hash=53f6f613453932e8b9d343ec613acfde}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhu},
           giveni={Z\bibinitperiod}}}%
        {{hash=ac04bd00a003f7c5bed63f9b75fa0c88}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Bin},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{11ca8392550a91ffdeacdc4bac350122}
      \strng{fullhash}{5d2322822414a714b64359168bfd4681}
      \strng{bibnamehash}{11ca8392550a91ffdeacdc4bac350122}
      \strng{authorbibnamehash}{11ca8392550a91ffdeacdc4bac350122}
      \strng{authornamehash}{11ca8392550a91ffdeacdc4bac350122}
      \strng{authorfullhash}{5d2322822414a714b64359168bfd4681}
      \field{extraname}{4}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As an important entrance for human-robot interaction, the hand gesture recognition based on wireless sensor has received great attention in recent years. By recognizing fine-grained arm movements, remotely deployed collaborative robot could work more accurately to satisfy human demands. Existing approaches mostly use wearable sensors or wireless devices to recognize human movement, which is with strict position requirements. In this paper, we propose a robust gesture recognition method based on double Doppler radars. Specifically, we use two Doppler radars to collect two sources of Doppler signal of a gesture. Then 6 types of gestures with different angles between people and the radar were classified by employing an improved dynamic time warping (DTW) algorithm. Furthermore, we demonstrate the practicability of the proposed method by developing a cooperative robot control system and the average recognition accuracy is 96\%.}
      \field{booktitle}{2020 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PerCom} {Workshops})}
      \field{month}{3}
      \field{title}{{RaCon}: {A} gesture recognition approach via {Doppler} radar for intelligent human-robot interaction}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/PerComWorkshops48775.2020.9156109
      \endverb
      \keyw{collaborative robot,Doppler radar,Doppler signal,double Doppler radars,Feature extraction,fine-grained arm movements,gesture recognition,Gesture recognition,gesture recognition approach,hand gesture recognition,human demands,human movement,human-robot interaction,Human-robot interaction,important entrance,robot control system,robust gesture recognition method,Signal synthesis analysis,strict position requirements,Time-frequency analysis,wearable sensors,Wireless communication,wireless devices,Wireless sensing,wireless sensor,Wireless sensor networks}
    \endentry
    \entry{Zhang:2016}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=1c81a6b30005f498eb8a6d6ec6446bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Shimeng},
           giveni={S\bibinitperiod}}}%
        {{hash=56ba559f18e74cf681fe113aba3fa9af}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Gang},
           giveni={G\bibinitperiod}}}%
        {{hash=7a3871882b5ea1134b4fce7eb830a3d6}{%
           family={Ritchie},
           familyi={R\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=d271b8d79d135292f5569754056368a8}{%
           family={Fioranelli},
           familyi={F\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
        {{hash=4e97f6c29f732a77ae7d4a2e90e1474d}{%
           family={Griffiths},
           familyi={G\bibinitperiod},
           given={Hugh},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{1bd9414e4e3cc5480c635b75fd1cfe03}
      \strng{fullhash}{7511e757665a43df30e575d8fdfb05e0}
      \strng{bibnamehash}{1bd9414e4e3cc5480c635b75fd1cfe03}
      \strng{authorbibnamehash}{1bd9414e4e3cc5480c635b75fd1cfe03}
      \strng{authornamehash}{1bd9414e4e3cc5480c635b75fd1cfe03}
      \strng{authorfullhash}{7511e757665a43df30e575d8fdfb05e0}
      \field{extraname}{5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Dynamic hand gesture recognition is of great importance for human-computer interaction. In this paper, we present a method to discriminate the four kinds of dynamic hand gestures, snapping fingers, flipping fingers, hand rotation and calling, using a radar micro-Doppler sensor. Two micro-Doppler features are extracted from the time-frequency spectrum and the support vector machine is used to classify these four kinds of gestures. The experimental results on measured data demonstrate that the proposed method can produce a classification accuracy higher than 88.56\%.}
      \field{booktitle}{2016 {CIE} {International} {Conference} on {Radar} ({RADAR})}
      \field{month}{10}
      \field{title}{{Dynamic hand gesture classification based on radar micro-{Doppler} signatures}}
      \field{year}{2016}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/RADAR.2016.8059518
      \endverb
      \keyw{classification accuracy,Doppler radar,dynamic hand gesture classification,dynamic hand gesture recognition,feature extraction,Feature extraction,flipping fingers,gesture recognition,Gesture recognition,hand gesture classification,hand rotation,human computer interaction,human-computer interaction,image classification,micro-Doppler signatures,microDoppler feature extraction,Radar,radar computing,radar imaging,radar microDoppler sensor,radar microDoppler signatures,snapping fingers,support vector machine,support vector machines,Support vector machines,Thumb,time-frequency analysis,Time-frequency analysis,time-frequency spectrum}
    \endentry
    \entry{Zhang:2018c}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=8aa8635ded8b5fc0fb91b3f347e83f88}{%
           family={zhang},
           familyi={z\bibinitperiod},
           given={Xuhao},
           giveni={X\bibinitperiod}}}%
        {{hash=3703b88b1f9708eef987c89ce5077711}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Qisong},
           giveni={Q\bibinitperiod}}}%
        {{hash=19a8bca7f1f37493bb1ca8bb8ba443a4}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Dixian},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{4ff6a26d38d9a400687b4825c0afbdea}
      \strng{fullhash}{4ff6a26d38d9a400687b4825c0afbdea}
      \strng{bibnamehash}{4ff6a26d38d9a400687b4825c0afbdea}
      \strng{authorbibnamehash}{4ff6a26d38d9a400687b4825c0afbdea}
      \strng{authornamehash}{4ff6a26d38d9a400687b4825c0afbdea}
      \strng{authorfullhash}{4ff6a26d38d9a400687b4825c0afbdea}
      \field{sortinit}{z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Dynamic hand gesture recognition is very important for human-computer interaction. In vehicles, hand gesture recognition can be used as the driver's auxiliary system to achieve remote control of the instrument. To a certain extent, this system can avoid physical buttons and touch screens causing interference to the driver. In this paper, we describe a driver assisted dynamic gesture recognition system to classify nine hand gestures based on micro-Doppler signatures obtained by 77GHz FMCW radar using a convolutional neural network (CNN). We further explore the changes in the accuracy of same gestures in a variety of experimental scenarios to help optimize the robustness of the system.}
      \field{booktitle}{2018 10th {International} {Conference} on {Wireless} {Communications} and {Signal} {Processing} ({WCSP})}
      \field{month}{10}
      \field{note}{ISSN: 2472-7628}
      \field{title}{Dynamic {Hand} {Gesture} {Recognition} {Using} {FMCW} {Radar} {Sensor} for {Driving} {Assistance}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/WCSP.2018.8555642
      \endverb
      \keyw{Chirp,CNN,convolution,convolutional neural network,CW radar,Doppler radar,driver assistance system,driver assisted dynamic hand gesture recognition system,driver information systems,drivers auxiliary system,feedforward neural nets,FM radar,FMCW radar sensor,gesture recognition,Gesture recognition,hand gesture recognition,human computer interaction,human-computer interaction,micro-Doppler signatures,physical buttons,Radar,Radar antennas,remote control,Spectrogram,telecontrol,Thumb,touch screens,Training}
    \endentry
    \entry{Zhang:2018a}{article}{}
      \name{author}{3}{}{%
        {{hash=59b8db008827a0757e68ae51940ad083}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhenyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{fullhash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{bibnamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authorbibnamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authornamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authorfullhash}{344dc6d91e6964afc01e4e107ab146d5}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, hand gesture recognition systems have become increasingly interesting to researchers in the field of human-computer interfaces. Real-world systems for human dynamic hand gesture recognition is challenging as: 1) the system must be robust to various conditions; 2) there is a rich diversity in how people perform hand gestures, making hand gesture recognition difficult; and 3) the system must detect and recognize hand gestures continuously using unsegmented input streams in order to avoid noticeable lag between performing a gesture and its classification. In this paper, to address these challenges, we present Latern, a novel system for dynamic continuous hand gesture recognition based on a frequency-modulated continuous wave radar sensor. The radar system does not depend on lighting, noise, or atmospheric conditions. We employ a recurrent 3-D convolutional neural network to perform the classification of dynamic hand gestures. To enhance the processing performance, a connectionist temporal classification algorithm is used to train the network to predict class labels from inprogress gestures in unsegmented input streams. The experimental results show that Latern is able to achieve high recognition rates of 96\%, which is higher than state-of-the-art hand gesture recognition systems. In addition, the conclusion in this paper can be used for a real-time hand gesture recognition system design.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{4}
      \field{number}{8}
      \field{title}{Latern: {Dynamic} {Continuous} {Hand} {Gesture} {Recognition} {Using} {FMCW} {Radar} {Sensor}}
      \field{volume}{18}
      \field{year}{2018}
      \field{pages}{3278\bibrangedash 3289}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/JSEN.2018.2808688
      \endverb
      \keyw{connectionist temporal classification,CW radar,Doppler radar,dynamic continuous hand gesture recognition,Feature extraction,FM radar,FMCW radar,FMCW radar sensor,frequency-modulated continuous wave radar sensor,gesture recognition,Gesture recognition,Hand gesture recognition,Heuristic algorithms,Hidden Markov models,human dynamic hand gesture recognition,human-computer interfaces,inprogress gestures,Latern,real-time hand gesture recognition system design,recurrent 3D convolutional neural network,recurrent neural nets,recurrent three-dimensional convolutional neural network,Sensors,unsegmented input streams}
    \endentry
    \entry{Zhang:2019d}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=59b8db008827a0757e68ae51940ad083}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhenyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{fullhash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{bibnamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authorbibnamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authornamehash}{344dc6d91e6964afc01e4e107ab146d5}
      \strng{authorfullhash}{344dc6d91e6964afc01e4e107ab146d5}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we present a finger-grained gesture recognition system that can be deployed on commodity Multiple Input Multiple Output Frequency Modulated Continuous Wave (MIMO-FMCW) radar platform as software, without any hardware modification. Firstly, we utilize the two-dimension fast Fourier transform algorithm (2D-FFT) to jointly estimate range-Doppler information. Secondly, by combining with binary phase modulation MIMO (BPM-MIMO) technique, a discrete Fourier transformation (DFT) based Multiple Signal Classification (MUSIC) algorithm is proposed to jointly measure range and angle of arrival (AOA) information without prior knowledge about the number of targets. Thirdly, a recurrent 3D convolutional neural network (R3DCNN) is employed to extract spatial-temporal fusion- features existing in range-Doppler and range-AOA map sequences. Next, we implement and evaluate this system utilizing commercial-off-the-shelf FMCW radar platform. The experimental results show that this system is able to achieve a high recognition rate of 93\%.}
      \field{booktitle}{2019 {IEEE} {Globecom} {Workshops} ({GC} {Wkshps})}
      \field{month}{12}
      \field{title}{{SmartFinger}: {A} {Finger}-{Sensing} {System} for {Mobile} {Interaction} via {MIMO} {FMCW} {Radar}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 5}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/GCWkshps45667.2019.9024578
      \endverb
      \keyw{angle of arrival information,Antenna arrays,binary phase modulation MIMO technique,BPM-MIMO,Chirp,commercial-off-the-shelf FMCW radar platform,commodity Multiple Input Multiple Output Frequency Modulated Continuous Wave radar platform,convolutional neural nets,direction-of-arrival estimation,discrete Fourier transformation,Doppler radar,fast Fourier transforms,feature extraction,Feature extraction,finger-grained gesture recognition system,finger-sensing system,gesture recognition,Gesture recognition,MIMO communication,MIMO FMCW radar,MIMO radar,mobile computing,mobile interaction,Multiple Signal Classification algorithm,Radar,Radar antennas,range-AOA map sequences,range-Doppler information,recurrent 3D convolutional neural network,recurrent neural nets,signal classification,spatial-temporal fusion-feature extraction,two-dimension fast Fourier transform algorithm}
    \endentry
    \entry{Zhang:2018d}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=59b8db008827a0757e68ae51940ad083}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhenyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
        {{hash=32e9e87631f422b0c6859b67b3598c1f}{%
           family={Mu},
           familyi={M\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod}}}%
        {{hash=c4d8c39e3a63acab6d94c490b6d45028}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Brussels, BEL}%
      }
      \list{publisher}{2}{%
        {ICST (Institute for Computer Sciences, Social-Informatics}%
        {Telecommunications Engineering)}%
      }
      \strng{namehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{fullhash}{5cf9ffc815cc25a3a22d1283f96647eb}
      \strng{bibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorbibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authornamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorfullhash}{5cf9ffc815cc25a3a22d1283f96647eb}
      \field{extraname}{6}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, hand gesture recognition systems have become increasingly interesting to researchers in the field of human-computer interfaces. Real-world systems for human dynamic hand gesture recognition is challenging as: 1) the system must be robustness to various conditions; 2) there is a rich diversity in how people perform hand gestures, making hand gesture recognition difficult; 3) the system must detect and recognize hand gestures continuously using unsegmented input streams in order to avoid noticeable lag between performing a gesture and its classification. In this paper, to address these challenges, we present a novel system for dynamic continuous hand gesture recognition based on Frequency Modulated Continuous Wave (FMCW) radar sensor. The radar system does not depend on lighting, noise or atmospheric conditions. We employ a recurrent three-dimensional convolutional neural network to perform classification of dynamic hand gestures. To enhance the processing performance, Connectionist Temporal Classification (CTC) algorithm is used to train the network to predict class labels from inprogress gestures in unsegmented input streams. The experimental results show that this system is able to achieve high recognition rates of 96\%, which is higher than state-of-the-art hand gesture recognition systems. In addition, the conclusion in this work can be used for real-time hand gesture recognition system design.}
      \field{booktitle}{Proceedings of the 11th {EAI} {International} {Conference} on {Mobile} {Multimedia} {Communications}}
      \field{isbn}{978-1-63190-164-5}
      \field{month}{9}
      \field{series}{{MOBIMEDIA}'18}
      \field{title}{Application of {FMCW} {Radar} for {Dynamic} {Continuous} {Hand} {Gesture} {Recognition}}
      \field{urlday}{21}
      \field{urlmonth}{12}
      \field{urlyear}{2020}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{298\bibrangedash 303}
      \range{pages}{6}
      \keyw{connectionist temporal classification,fmcw radar,hand gesture recognition,recurrent three-dimensional convolutional neural network}
    \endentry
    \entry{Zhang:2018b}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=59b8db008827a0757e68ae51940ad083}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhenyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=868b05a9388d750f03375b83c816def7}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=939a0b1660a3c4386d331ecae4ca255b}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Ze},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{fullhash}{074b8301f42de6fd2237ac7cb053d08a}
      \strng{bibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorbibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authornamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorfullhash}{074b8301f42de6fd2237ac7cb053d08a}
      \field{extraname}{7}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we present a Real-time Interacting with Hand Description system via Millimeter-wave Sensor (Riddle) for human-computer interaction. Firstly, we describe a new approach to developing a radar-based system. When hand motions are captured by millimeter- wave radar sensor, the unique range information can be observed in the spectrogram. Compared to traditional hand gesture recognition systems based on optical sensors, the radar-based system avoids the influence of ambient light conditions. Secondly, we employ deep neural networks combined with connectionist temporal classification algorithm to recognize diverse hand gestures in real-time. Besides, we visualize the feature maps extracted from different layers to understand the deep neural networks. The deep neural networks are powerful to extract hand gesture features as well as class boundaries through a training process. Finally, we demonstrate that Riddle is capable of detecting six hand gestures and achieving high recognition accuracy of 96\%.}
      \field{booktitle}{2018 {IEEE} {International} {Conference} on {Communications} ({ICC})}
      \field{month}{5}
      \field{note}{ISSN: 1938-1883}
      \field{title}{Riddle: {Real}-{Time} {Interacting} with {Hand} {Description} via {Millimeter}-{Wave} {Sensor}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ICC.2018.8422765
      \endverb
      \keyw{connectionist temporal classification algorithm,deep neural networks,feature extraction,Feature extraction,Frequency modulation,gesture recognition,Gesture recognition,hand gesture features,hand gesture recognition systems,hand motions,human computer interaction,human-computer interaction,image classification,image motion analysis,Millimeter wave radar,millimeter-wave radar sensor,millimetre wave radar,neural nets,Neural networks,real-time interacting with hand description system,Real-time systems,Riddle}
    \endentry
    \entry{Zhang:2019b}{article}{}
      \name{author}{5}{}{%
        {{hash=59b8db008827a0757e68ae51940ad083}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhenyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=694493ac50f2625151d17508a4c8c135}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Zengshan},
           giveni={Z\bibinitperiod}}}%
        {{hash=f5acec98b29ee91fa6b08b85a6a0adad}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ying},
           giveni={Y\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=4a6089159f2666b639761dbe478ee27f}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Bang},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{fullhash}{3449aefc5d4fadd1690e8192687896de}
      \strng{bibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorbibnamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authornamehash}{0d190cffa15822c2fb14ae3777cda5f1}
      \strng{authorfullhash}{3449aefc5d4fadd1690e8192687896de}
      \field{extraname}{8}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, although radar sensors have been widely applied for hand gesture recognition (HGR) tasks, conventional radar-based HGR systems still have two major challenges. First, these systems rely on supervised learning approaches to learn gesture features, which normally require a large-scale labeled dataset to address the overfitting problem. However, the acquisition of such dataset is time-consuming. Second, the radar signature of hand movement is often influenced by micromotion caused by other body parts, which leads to distorted motion features, resulting in poor identification accuracy. To overcome these problems, we propose an unsupervised hand gesture feature learning method using the deep convolutional auto-encoder network to analyze hand gesture signal collected by a frequency modulated continuous wave (FMCW) radar sensor. First, via a convolutional encoder sub-network, input radar range profiles are transformed into lower dimensional representations. Then, the representations are expanded to reconstruct the corresponding input profiles by a deconvolutional decoder sub-network. In addition, to investigate the mechanisms of the proposed network and evaluate its performance, we conduct an in-depth study of the feature maps learned from various hand gesture experimental data and evaluate the corresponding classification performance. The results demonstrate that the proposed convolutional auto-encoder network is able to achieve high recognition accuracy with low training sample cost, which outperforms the state-of-the-art hand gesture recognition systems based on transfer learning VGGNet and fully connected-based auto-encoder network.}
      \field{issn}{1558-1748}
      \field{journaltitle}{IEEE Sensors Journal}
      \field{month}{8}
      \field{number}{16}
      \field{title}{u-{DeepHand}: {FMCW} {Radar}-{Based} {Unsupervised} {Hand} {Gesture} {Feature} {Learning} {Using} {Deep} {Convolutional} {Auto}-{Encoder} {Network}}
      \field{volume}{19}
      \field{year}{2019}
      \field{pages}{6811\bibrangedash 6821}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/JSEN.2019.2910810
      \endverb
      \keyw{classification performance,Convolution,convolutional auto-encoder network,convolutional encoder sub-network,convolutional neural nets,CW radar,deconvolutional decoder sub-network,deep convolutional auto-encoder network,distorted motion features,Doppler radar,feature extraction,Feature extraction,feature maps,FM radar,FMCW radar,FMCW radar-based unsupervised hand gesture feature learning,frequency modulated continuous wave radar sensor,gesture recognition,hand gesture experimental data,Hand gesture recognition,hand gesture recognition tasks,hand gesture signal,hand movement,image classification,input radar range profiles,performance evaluation,radar imaging,radar sensors,radar signature,radar-based HGR systems,Sensors,Task analysis,Training,transfer learning VGGNet,unsupervised learning}
    \endentry
    \entry{Zhao:2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=ede13b54712f0f98cba1bc03785ea650}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Zedong},
           giveni={Z\bibinitperiod}}}%
        {{hash=97ea4addef0a6948a5af2dcd3a97e675}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=c5dfce1dfb9d271fc0867b6b0f13ce36}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
        {{hash=15242e5c9f88d20b2fddbf983e204586}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaolong},
           giveni={X\bibinitperiod}}}%
        {{hash=7e30671b4c2d2412d2ab402fe9b9fb73}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Liangbo},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{e3909bcd695932a7b4c5072158e121aa}
      \strng{fullhash}{020f2e9b6c5a38cc3f692d36470df13d}
      \strng{bibnamehash}{e3909bcd695932a7b4c5072158e121aa}
      \strng{authorbibnamehash}{e3909bcd695932a7b4c5072158e121aa}
      \strng{authornamehash}{e3909bcd695932a7b4c5072158e121aa}
      \strng{authorfullhash}{020f2e9b6c5a38cc3f692d36470df13d}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a gesture recognition method based on interference suppression with Frequency Modulation Continuous Wave (FMCW)radar. We analyze the sampling point and the time needed for snapshot of radar signal, and estimate the range and doppler parameter of gesture. Afterward, we design a complete background and target interference suppression method for the characteristics of radar signal interference, then use Time Sequential Inflated 3 Dimensions(TS- I3D)network for gesture feature extraction and classification. The experimental results show that the suppression method has effectively solved the problems caused by non-gesture interference, and the average accuracy rate of gesture recognition is 96.67 \%.}
      \field{booktitle}{2019 11th {International} {Conference} on {Wireless} {Communications} and {Signal} {Processing} ({WCSP})}
      \field{month}{10}
      \field{note}{ISSN: 2472-7628}
      \field{title}{Interference {Suppression} {Based} {Gesture} {Recognition} {Method} with {FMCW} {Radar}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/WCSP.2019.8928108
      \endverb
      \keyw{CW radar,Delays,Doppler parameter estimation,Doppler radar,feature extraction,Feature extraction,FM radar,FMCW radar,frequency modulation continuous wave radar,gesture feature classification,gesture feature extraction,gesture recognition,Gesture recognition,image classification,image denoising,image sampling,Interference suppression,interference suppression based gesture recognition method,nongesture interference,parameter estimation,radar imaging,radar interference,radar signal interference,range parameter estimation,sampling point,target interference suppression method,time sequential inflated 3 dimension network,TS- I3D network,TS-I3D network}
    \endentry
    \entry{Zhou:2018b}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2c5968348a8a56975a5b5d9136d75f01}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Andrew\bibnamedelima Jie},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=eaaa4baf14ef1b8d18b4ae025584c87c}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Grace\bibnamedelima Hui},
           giveni={G\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{04433426281584abbe6c718ff1648547}
      \strng{fullhash}{04433426281584abbe6c718ff1648547}
      \strng{bibnamehash}{04433426281584abbe6c718ff1648547}
      \strng{authorbibnamehash}{04433426281584abbe6c718ff1648547}
      \strng{authornamehash}{04433426281584abbe6c718ff1648547}
      \strng{authorfullhash}{04433426281584abbe6c718ff1648547}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval}
      \field{isbn}{9781450356572}
      \field{series}{SIGIR '18}
      \field{title}{{Minority Report by Lemur: Supporting Search Engine with Virtual Reality}}
      \field{venue}{Ann Arbor, MI, USA}
      \field{year}{2018}
      \field{pages}{1329\bibrangedash 1332}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/3209978.3210179
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/3209978.3210179
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/3209978.3210179
      \endverb
      \keyw{virtual reality,search engine,user interface}
    \endentry
    \entry{Zhou:2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=f1c27383e48e81151c8d04b9dfdea400}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Feifei},
           giveni={F\bibinitperiod}}}%
        {{hash=fc2923cf2bb4bae12a09ae4d9cd20967}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xiangyu},
           giveni={X\bibinitperiod}}}%
        {{hash=49ca3ec61f3dcc5da4a1e97f24077541}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhihua},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{e36b4ecbbbf16912978195e4702212ab}
      \strng{fullhash}{e36b4ecbbbf16912978195e4702212ab}
      \strng{bibnamehash}{e36b4ecbbbf16912978195e4702212ab}
      \strng{authorbibnamehash}{e36b4ecbbbf16912978195e4702212ab}
      \strng{authornamehash}{e36b4ecbbbf16912978195e4702212ab}
      \strng{authorfullhash}{e36b4ecbbbf16912978195e4702212ab}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2019 IEEE SENSORS}
      \field{title}{{Efficiently User-Independent Ultrasonic-Based Gesture Recognition Algorithm}}
      \field{year}{2019}
      \field{pages}{1\bibrangedash 4}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/SENSORS43011.2019.8956774
      \endverb
    \endentry
    \entry{Zhou:2018a}{article}{}
      \name{author}{3}{}{%
        {{hash=3d4b498f7b5894cc848a49f575d7a8ba}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Zhi},
           giveni={Z\bibinitperiod}}}%
        {{hash=cfa0cb6a9268e626bc53b9815a0c19e3}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Zongjie},
           giveni={Z\bibinitperiod}}}%
        {{hash=cb2915af08f787843a01a76564befe85}{%
           family={Pi},
           familyi={P\bibinitperiod},
           given={Yiming},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{8175681c551f94bc93653a29d7cf5451}
      \strng{fullhash}{8175681c551f94bc93653a29d7cf5451}
      \strng{bibnamehash}{8175681c551f94bc93653a29d7cf5451}
      \strng{authorbibnamehash}{8175681c551f94bc93653a29d7cf5451}
      \strng{authornamehash}{8175681c551f94bc93653a29d7cf5451}
      \strng{authorfullhash}{8175681c551f94bc93653a29d7cf5451}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The frequency of terahertz radar ranges from 0.1 THz to 10 THz, which is higher than that of microwaves. Multi-modal signals, including high-resolution range profile (HRRP) and Doppler signatures, can be acquired by the terahertz radar system. These two kinds of information are commonly used in automatic target recognition; however, dynamic gesture recognition is rarely discussed in the terahertz regime. In this paper, a dynamic gesture recognition system using a terahertz radar is proposed, based on multi-modal signals. The HRRP sequences and Doppler signatures were first achieved from the radar echoes. Considering the electromagnetic scattering characteristics, a feature extraction model is designed using location parameter estimation of scattering centers. Dynamic Time Warping (DTW) extended to multi-modal signals is used to accomplish the classifications. Ten types of gesture signals, collected from a terahertz radar, are applied to validate the analysis and the recognition system. The results of the experiment indicate that the recognition rate reaches more than 91\%. This research verifies the potential applications of dynamic gesture recognition using a terahertz radar.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{number}{1}
      \field{title}{Dynamic {Gesture} {Recognition} with a {Terahertz} {Radar} {Based} on {Range} {Profile} {Sequences} and {Doppler} {Signatures}}
      \field{volume}{18}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 15}
      \range{pages}{15}
      \verb{doi}
      \verb 10.3390/s18010010
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/18/1/10
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/18/1/10
      \endverb
    \endentry
    \entry{Zhu:2018}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=4b7c6f6cbac7b44fdd362af27e5f8899}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Shangyue},
           giveni={S\bibinitperiod}}}%
        {{hash=b3550e4ac0c3edd171a1f624eb941ccd}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Junhong},
           giveni={J\bibinitperiod}}}%
        {{hash=04666d6d41e615ccf0ca2895c181c014}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Hanqing},
           giveni={H\bibinitperiod}}}%
        {{hash=b6a425ea4939e6397d89664b68670402}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qiwei},
           giveni={Q\bibinitperiod}}}%
        {{hash=c5df33c624447c662e64d4fe533bfb28}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Shaoen},
           giveni={S\bibinitperiod}}}%
        {{hash=5c759bd0a5762f3c6960e56a59ceaffd}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Honggang},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{2a9b9daebd675600569b04283b9a728a}
      \strng{fullhash}{7d10fe596dd07a6165b9f593cfd7e0fb}
      \strng{bibnamehash}{2a9b9daebd675600569b04283b9a728a}
      \strng{authorbibnamehash}{2a9b9daebd675600569b04283b9a728a}
      \strng{authornamehash}{2a9b9daebd675600569b04283b9a728a}
      \strng{authorfullhash}{7d10fe596dd07a6165b9f593cfd7e0fb}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2018 IEEE International Conference on Communications (ICC)}
      \field{title}{{Indoor Human Activity Recognition Based on Ambient Radar with Signal Processing and Machine Learning}}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ICC.2018.8422107
      \endverb
    \endentry
    \entry{Zigelbaum:2010}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=9e4d5068b470adce63bbda4f7f5c78e6}{%
           family={Zigelbaum},
           familyi={Z\bibinitperiod},
           given={Jamie},
           giveni={J\bibinitperiod}}}%
        {{hash=102ac0af8abda256f571aed0ba85beaa}{%
           family={Browning},
           familyi={B\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod}}}%
        {{hash=b29a16d007751b01cfce0f392f196683}{%
           family={Leithinger},
           familyi={L\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=351236e64198d96c9bbee359740732ee}{%
           family={Bau},
           familyi={B\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
        {{hash=f9477c2d8165fba57b180a69748ccead}{%
           family={Ishii},
           familyi={I\bibinitperiod},
           given={Hiroshi},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, NY, USA}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{c904a2cc14612a0195357f4e839bba85}
      \strng{fullhash}{d9c060c6851d4ad4e23ca5d5ac3fe53d}
      \strng{bibnamehash}{c904a2cc14612a0195357f4e839bba85}
      \strng{authorbibnamehash}{c904a2cc14612a0195357f4e839bba85}
      \strng{authornamehash}{c904a2cc14612a0195357f4e839bba85}
      \strng{authorfullhash}{d9c060c6851d4ad4e23ca5d5ac3fe53d}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we present g-stalt, a gestural interface for interacting with video. g-stalt is built upon the g-speak spatial operating environment (SOE) from Oblong Industries. The version of g-stalt presented here is realized as a three-dimensional graphical space filled with over 60 cartoons. These cartoons can be viewed and rearranged along with their metadata using a specialized gesture set. g-stalt is designed to be chirocentric, spatiotemporal, and telekinetic.}
      \field{booktitle}{Proceedings of the Fourth International Conference on Tangible, Embedded, and Embodied Interaction}
      \field{isbn}{9781605588414}
      \field{series}{TEI '10}
      \field{title}{{G-Stalt: A Chirocentric, Spatiotemporal, and Telekinetic Gestural Interface}}
      \field{venue}{Cambridge, Massachusetts, USA}
      \field{year}{2010}
      \field{pages}{261\bibrangedash 264}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1145/1709886.1709939
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1145/1709886.1709939
      \endverb
      \verb{url}
      \verb https://doi.org/10.1145/1709886.1709939
      \endverb
      \keyw{spatiotemporal,g-speak,gesture,pinch,chirocentric,video,telekinetic,gestural interface,3d}
    \endentry
    \entry{Zocco:2015}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=36fc84f8bd379ff568b5ebf6fe1fcaac}{%
           family={Zocco},
           familyi={Z\bibinitperiod},
           given={Alessandro},
           giveni={A\bibinitperiod}}}%
        {{hash=cd2eee2232c2bde76acf5a1aca4cdba5}{%
           family={Zocco},
           familyi={Z\bibinitperiod},
           given={Matteo\bibnamedelima D.},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=307b6cf513fee700be0f5e483256aa3c}{%
           family={Greco},
           familyi={G\bibinitperiod},
           given={Antonella},
           giveni={A\bibinitperiod}}}%
        {{hash=10e71c36190dfc9678c34c0b30aabac1}{%
           family={Livatino},
           familyi={L\bibinitperiod},
           given={Salvatore},
           giveni={S\bibinitperiod}}}%
        {{hash=3600d7d109e4a9c52d696955e7ce6e73}{%
           family={Paolis},
           familyi={P\bibinitperiod},
           given={Lucio\bibnamedelima Tommaso},
           giveni={L\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer-Verlag}%
      }
      \strng{namehash}{43515e83a0b6b286d5d14321beb627c0}
      \strng{fullhash}{7f73dffabb816fefa2f20419155b0189}
      \strng{bibnamehash}{43515e83a0b6b286d5d14321beb627c0}
      \strng{authorbibnamehash}{43515e83a0b6b286d5d14321beb627c0}
      \strng{authornamehash}{43515e83a0b6b286d5d14321beb627c0}
      \strng{authorfullhash}{7f73dffabb816fefa2f20419155b0189}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Second International Conference on Augmented and Virtual Reality - Volume 9254}
      \field{isbn}{9783319228877}
      \field{title}{{Touchless Interaction for Command and Control in Military Operations}}
      \field{year}{2015}
      \field{pages}{432\bibrangedash 445}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1007/978-3-319-22888-4_32
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/978-3-319-22888-4_32
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/978-3-319-22888-4_32
      \endverb
      \keyw{Network Centric Warfare,Touchless Interaction,Augmented Reality,Leap Motion,Human computer interaction,Command and control system}
    \endentry
    \entry{Zou:2017}{article}{}
      \name{author}{9}{}{%
        {{hash=2555e1f449dc8f4bee72ce7f23960932}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={Yi-Bo},
           giveni={Y\bibinithyphendelim B\bibinitperiod}}}%
        {{hash=076c0377672e513f63c996dc34d3a602}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Yi-Min},
           giveni={Y\bibinithyphendelim M\bibinitperiod}}}%
        {{hash=eeadcb493d919d69d75a57148bcea22d}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Ming-Ke},
           giveni={M\bibinithyphendelim K\bibinitperiod}}}%
        {{hash=8a84298a1096b86e848fe3dc0ea5bbd5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Quan},
           giveni={Q\bibinitperiod}}}%
        {{hash=ae094003d2b2214525f905d4eb083b6a}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Si-Yu},
           giveni={S\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=b0fc8d17edcf133eb3a7c7697fe41e8c}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Jia-Hui},
           giveni={J\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=1bd49eb4c6192a4275de364675f1d9b6}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Chen},
           giveni={C\bibinitperiod}}}%
        {{hash=f1770d9758a17238a78954e157ab21eb}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Ze-Yu},
           giveni={Z\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=802a65c3764e48083e84a41317fb86d8}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Dian-Hua},
           giveni={D\bibinithyphendelim H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {USA}%
      }
      \list{publisher}{1}{%
        {Plenum Press}%
      }
      \strng{namehash}{34509abc23d466a0917c7b36198b5ecc}
      \strng{fullhash}{30e113d6d714d08d2f3907f88c87c68a}
      \strng{bibnamehash}{34509abc23d466a0917c7b36198b5ecc}
      \strng{authorbibnamehash}{34509abc23d466a0917c7b36198b5ecc}
      \strng{authornamehash}{34509abc23d466a0917c7b36198b5ecc}
      \strng{authorfullhash}{30e113d6d714d08d2f3907f88c87c68a}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0148-5598}
      \field{journaltitle}{J. Med. Syst.}
      \field{month}{8}
      \field{number}{8}
      \field{title}{{Coronary Heart Disease Preoperative Gesture Interactive Diagnostic System Based on Augmented Reality}}
      \field{volume}{41}
      \field{year}{2017}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1007/s10916-017-0768-6
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10916-017-0768-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10916-017-0768-6
      \endverb
      \keyw{coronary heart disease,gesture interaction,HMM,leap motion controller,augmented reality,preoperative diagnosis,K-means}
    \endentry
  \enddatalist
\endrefsection
\endinput

